[["index.html", "Métodos de matemáticas aplicadas Prefacio", " Métodos de matemáticas aplicadas Héctor Andrés Chang-Lara 2022-08-18 Prefacio Hola "],["entramados.html", "Capítulo 1 Entramados", " Capítulo 1 Entramados La siguiente figura ilustra cuatro puntos masivos unidos por tres barras de longitudes conocidas \\(\\ell_{01}, \\ell_{12}, \\ell_{23}\\), y masas despreciables. Los extremos etiquetados por \\(0\\) y \\(3\\) tienen posiciones fijas y los nodos intermedios de masas \\(m_1\\) y \\(m_2\\) ocupan posiciones de equilibrio. ¿A partir de cuales ecuaciones se podrían determinar las posiciones \\(q_i=(x_i,y_i)\\) de estos nodos? Antes de proceder a plantear el sistema de ecuaciones recordemos que por lo general el número de ecuaciones e incógnitas deben ser iguales para que este esté bien planteado, es decir que existan soluciones y que sean únicas (al menos localmente). En nuestro caso tenemos cuatro incógnitas, los dos pares de coordenadas de cada nodo libre. Además debemos considerar las restricciones impuestas por las distancias entre los nodos, es decir tres ecuaciones. Hasta el momento el sistema es indeterminado, tiene más incógnitas (4) que ecuaciones (3), sin embargo aún nos falta incorporar la información del fenómeno de equilibrio. \\[ \\begin{cases} (x_1-0)^2 + (y_1-0)^2 = \\ell_{01}^2\\\\ (x_1-x_2)^2 + (y_1-y_2)^2 = \\ell_{12}^2\\\\ (x_2-3)^2 + (y_2-0)^2 = \\ell_{23}^2 \\end{cases} \\] En cada nodo libre actúan tres fuerzas: dos tensiones y la gravedad \\((= -m_ige_y)\\). Por ejemplo, la tensión \\(T_{12}\\) sobre el nodo 1 y que se produce sobre el segmento que une los nodos 1 y 2 es proporcional al vector \\(q_2-q_1\\), es decir \\(T_{12} = \\lambda_{12} (q_2-q_1)\\) para un cierto escalar \\(\\lambda_{12}\\). Similarmente podemos razonar sobre las demás interacciones, introduciendo así cuatro nuevas variables \\(\\lambda_{10}, \\lambda_{12}, \\lambda_{21}\\), y \\(\\lambda_{23}\\). Para que el sistema se encuentre en equilibrio, la suma de las fuerzas sobre cada nodo debe anularse, lo cual nos da igualmente cuatro ecuaciones: \\[ \\begin{cases} \\lambda_{10}(x_{0}-x_{1})+\\lambda_{12}(x_{2}-x_{1}) = 0\\\\ \\lambda_{10}(y_{0}-y_{1})+\\lambda_{12}(y_{2}-y_{1}) = m_{1}g\\\\ \\lambda_{23}(x_{3}-x_{2})+\\lambda_{21}(x_{1}-x_{2}) = 0\\\\ \\lambda_{23}(y_{3}-y_{2})+\\lambda_{21}(y_{1}-y_{2}) = m_{2}g \\end{cases} \\] Pareciera que no hemos logrado mucho en términos del sistema que sigue siendo indeterminado con ocho incógnitas (2 \\(x\\)’s, 2 \\(y\\)’s y 4 \\(\\lambda\\)’s) y siete ecuaciones (3 distancias y 4 balances de fuerzas). Sin embargo, la tercera ley de Newton nos dice que las interacciones entre pares de nodos guarda una simetría: toda acción produce una reacción opuesta de la misma magnitud. En nuestro modelo esto se refleja en \\(T_{12} = -T_{21}\\), de donde obtenemos la última ecuación \\[ \\lambda_{12}=\\lambda_{21}. \\] De hecho es más sencillo eliminar una de las incógnitas (\\(\\lambda_{21}\\)) que añadir otra ecuación. En conclusión obtenemos el siguiente sistema con siete ecuaciones e incógnitas \\[ \\begin{cases} \\lambda_{10}(x_{0}-x_{1})+\\lambda_{12}(x_{2}-x_{1}) = 0\\\\ \\lambda_{10}(y_{0}-y_{1})+\\lambda_{12}(y_{2}-y_{1}) = m_{1}g\\\\ \\lambda_{23}(x_{3}-x_{2})+\\lambda_{12}(x_{1}-x_{2}) = 0\\\\ \\lambda_{23}(y_{3}-y_{2})+\\lambda_{12}(y_{1}-y_{2}) = m_{2}g\\\\ (x_1-0)^2 + (y_1-0)^2 = \\ell_{01}^2\\\\ (x_1-x_2)^2 + (y_1-y_2)^2 = \\ell_{12}^2\\\\ (x_2-3)^2 + (y_2-0)^2 = \\ell_{23}^2 \\end{cases} \\] Una forma de obtener solución a este sistema es el método de Newton. Por ejemplo, para los valores \\(\\ell_{01}=\\sqrt{5}, \\ell_{12}=\\sqrt{5}, \\ell_{23}=\\sqrt{10}, m_1=1, m_2=2, q_0=(0,0), q_3=(4,0)\\) la siguiente implementación ilustra como obtener la solución usando Python1. #Librerías import matplotlib.pyplot as plt import numpy as np from scipy.optimize import fsolve #Parámetros l01=np.sqrt(5) l12=np.sqrt(5) l23=np.sqrt(10) x3,y3=4,0 m1=1 m2=2 #Sistema de ecuaciones y gráfica def f(x): x1,y1,x2,y2,lambda01,lambda12,lambda23 = x f=np.zeros(7) f[0] = x1**2+y1**2-l01**2 f[1] = (x2-x1)**2+(y2-y1)**2-l12**2 f[2] = (x3-x2)**2+(y3-y2)**2-l23**2 f[3] = -lambda01*x1+lambda12*(x2-x1) f[4] = -lambda01*y1+lambda12*(y2-y1)-m1 f[5] = lambda12*(x1-x2)+lambda23*(x3-x2) f[6] = lambda12*(y1-y2)+lambda23*(y3-y2)-m2 return f r = fsolve(f,[1,-1,3,-2,0,0,0]) x1,y1=r[0],r[1] x2,y2=r[2],r[3] fig, ax = plt.subplots() ax.plot([0,r[0],r[2],x3], [0,r[1],r[3],y3]) ax.plot(0,0,color=&#39;tab:blue&#39;, marker=&#39;o&#39;, label=&#39;$q_0=(0,0)$&#39;) ax.plot(x1,y1,color=&#39;tab:orange&#39;, marker=&#39;o&#39;, label=&quot;$q_1=({:.4f},{:.4f})$&quot;.format(x1, y1)) ax.plot(x2,y2,color=&#39;tab:green&#39;, marker=&#39;o&#39;, label=&quot;$q_1=({:.4f},{:.4f})$&quot;.format(x2, y2)) ax.plot(x3,y3,color=&#39;tab:red&#39;, marker=&#39;o&#39;, label=&quot;$q_1=({},{})$&quot;.format(x3, y3)) leg = ax.legend(); plt.show() Estas ideas son fácilmente generalizables a configuraciones lineales con más nodos. En el límite se obtiene el problema de la catenaria. También podemos considerar estructuras más complejas, por ejemplo un pañuelo sujeto por las esquinas. Para poder dar una generalización de estos modelos presentamos en la siguiente sección algunas nociones básicas de teoría de grafos. Una referencia entretenida con aplicaciones en arquitectura está en el siguiente enlace: Diseñar estructuras… ¿sin cálculos?  La magia de la CATENARIA Ejercicio 1.1 Calcula \\(m_2\\) para que el entramado esté en equilibrio dado que los nodos en \\((0,0)\\) y \\((13,0)\\) están fijos Solución Las fuerzas en el nodo \\(1\\) están dadas por \\[ \\begin{cases} 5\\lambda_{01}=6\\lambda_{12},\\\\ 8\\lambda_{01}+\\lambda_{12}=g \\end{cases} \\qquad\\Rightarrow\\qquad \\lambda_{01}=\\frac{6g}{53}, \\lambda_{12}=\\frac{5g}{53} \\] Las fuerzas en el nodo \\(2\\) están dadas por \\[ \\begin{cases} 6\\lambda_{12}=2\\lambda_{23},\\\\ -\\lambda_{12}+7\\lambda_{23}=m_2g \\end{cases} \\qquad\\Rightarrow\\qquad \\lambda_{23}=\\frac{15g}{53}, m_2=\\frac{100}{53}. \\] Ejercicio 1.2 Demuestra que si un dado entramado como en la figura, y con extremos en el eje horizontal, está en equilibro, entonces su correspondiente reflexión en el eje horizontal también está en equilibrio. ¿Será posible generalizar este principio a un entramado general? Solución Denotamos por \\(\\lambda_i=\\lambda_{i,i-1} = -\\lambda_{i-1,i}\\). En cada nodo del entramado original se tiene el balance de fuerzas está dado por \\[ \\begin{cases} (x_i-x_{i-1})\\lambda_i=(x_{i+1}-x_{i})\\lambda_{i+1},\\\\ (y_{i-1}-y_{i})\\lambda_i+(y_{i+1}-y_{i})\\lambda_{i+1}=m_ig \\end{cases} \\] Al tomar la reflexión en el eje horizontal las coordenadas de los nodos pasan a ser \\((x_i,y_i)\\mapsto (x_i&#39;,y_i&#39;) = (x_i,-y_i)\\). Gracias a las relaciones previas, se observa que estas coordenadas satisfacen igualmente las ecuaciones de balance de fuerzas cuando igualmente reemplazamos \\(\\lambda_i\\mapsto \\lambda_i&#39; =-\\lambda_i\\) \\[ \\begin{cases} (x_i&#39;-x_{i-1}&#39;)\\lambda_i&#39;=(x_{i+1}&#39;-x_{i}&#39;)\\lambda_{i+1}&#39;,\\\\ (y_{i-1}&#39;-y_{i}&#39;)\\lambda_i&#39;+(y_{i+1}&#39;-y_{i}&#39;)\\lambda_{i+1}&#39;=m_ig. \\end{cases} \\] Este principio se generaliza a un entramado general con una notación adecuada. Advertencia: El código es sensible a las condiciones iniciales para la iteración y no siempre converge.↩︎ "],["cálculo-discreto.html", "Capítulo 2 Cálculo discreto 2.1 Gradiente 2.2 Divergencia 2.3 Integración por partes 2.4 Laplaciano", " Capítulo 2 Cálculo discreto Una grafo dirigido \\(G = (V,E)\\) consiste de un conjunto de vértices \\(V\\), también llamados nodos, y un conjunto de aristas \\(E \\subseteq V^2\\), es decir pares ordenados de \\(V\\). Dado \\(e = (a,b)\\in E\\), denotamos por \\(e_-=a\\) y \\(e_+=b\\) los nodos de partida y llegada de \\(e\\) respectivamente y decimos que \\(e\\) está orientado del nodo de salida \\(a\\) al nodo de llegada \\(b\\). En general trabajaremos con grafos con aristas simples, es decir que a lo sumo existe una arista que conecta dos vértices en cualquier orientación. Sin embargo, cuando \\(e=(a,b)\\in E\\) podríamos hacer referencia a la arista \\(-e:=(b,a)\\) como la arista \\(e\\) pero con el sentido opuesto. Denotaremos \\(-E = \\{-e \\in V^2:e\\in E\\}\\). Finalmente, podemos considerar también conjuntos de aristas no orientadas en cuyo caso decimos que el grafo es no dirigido. Ejercicio 2.1 Dibuja el grafo \\(G=(V,E)\\) para \\[ V = \\{1,2,3,a,b,c\\}, \\qquad E = \\{(1,a),(1,b),(1,c),(2,a),(2,b),(2,c),(3,a),(3,b),(3,c)\\}. \\] Solución Las redes eléctricas son uno de los modelos más conocidos que se pueden formular en términos de grafos. Sobre el grafo podemos caracterizar por ejemplo el potencial o voltaje como una función \\(u:V\\to \\mathbb R\\) y la corriente como una función \\(i:E\\to \\mathbb R\\). Siguiendo un poco la nomenclatura que sugiere este modelo, distinguimos dos tipos de funciones en \\(G\\): Potencial: Es una función sobre el conjunto de vértices \\(u: V \\to \\mathbb R\\). Flujo: Es una función sobre el conjunto de aristas \\(f: E \\to \\mathbb R\\). En algunos casos también podríamos considerar que dichas funciones tomen valores en \\(\\mathbb C\\), \\(\\mathbb R^n\\) ó \\(\\mathbb C^n\\). También denominamos como flujos a funciones que están definidas en \\(E\\cup -E\\), es decir que consideran ambas orientaciones de las aristas. Decimos que \\(f:E\\cup -E\\to\\mathbb R\\) es par cuando no depende de la orientación \\(f(-e) = f(e)\\), y decimos que impar si en cambio \\(f(-e) = -f(e)\\). Una función \\(f:E\\to\\mathbb R\\) en un grafo no dirigido es equivalente a una función par en el mismo grafo y con cualquier orientación sobre las aristas. Ejemplo 2.1 En el modelo de entramados en la sección anterior, el grafo no dirigido \\(G=(V,E)\\) con \\(V = \\{0,1,2,3\\}\\) y \\(E=\\{\\{0,1\\},\\{1,2\\},\\{2,3\\}\\}\\) nos proporciona la información sobre cuales nodos están conectados entre si. Las posiciones de los nodos se caracterizan por \\(q:V\\to \\mathbb R^2\\) y las longitudes de los enlaces están determinadas por \\(\\ell:E\\to\\mathbb R\\). Para modelar las tensiones es conveniente considerar el grafo dirigido \\(G=(V,E&#39;)\\) de alguna forma arbitraria, quizás \\(E&#39;=\\{(0,1),(1,2),(2,3)\\}\\). De esta forma contamos con la función par \\(\\lambda:E&#39;\\to\\mathbb R\\) y la función impar \\(T: E&#39; \\to \\mathbb R^2\\) tales que \\[ T(e) = \\lambda(e)(q(e_+)-q(e_-)) \\] es la tensión sobre el nodo \\(e_-\\) a lo largo de \\(e\\). A su vez y gracias a la ley de acción y reacción, \\(T(-e) = -T(e)\\) es la tensión sobre el nodo \\(e_+\\) a lo largo de \\(e\\) pero en la orientación opuesta, es decir \\(-e\\). Ejemplo 2.2 Un potencial \\(u:V\\to\\mathbb R\\) sobre una red de resistencia genera una corriente \\(i:E\\to \\mathbb R\\) que modelamos usando la ley de Ohm para una dada resistencia \\(R:E\\to (0,\\infty)\\) (función par). Esto quiere decir que la corriente \\(i(e)\\) que atraviesa una arista \\(e = (e_-,e_+)\\) es proporcional a la diferencia de los potenciales en los extremos de la arista \\[ i(e) = \\frac{u(e_+) - u(e_-)}{R(e)}, \\qquad R(e) &gt;0: \\text{ Resistencia.} \\] 2.1 Gradiente Tanto en la construcción de las tensiones \\(T\\), como en la de la corriente eléctrica \\(i\\), estamos considerando la variación de una dada función (las posiciones \\(q\\) ó el potencial \\(u\\)) a lo largo de una arista dada. Esto es una versión discreta de la derivada direccional. En este caso requerimos que el grafo sea orientado. Definición 2.1 Dado potencial \\(u:V\\to\\mathbb R\\) sobre un grafo dirigido \\(G=(V,E)\\), definimos el gradiente \\(Du: E\\cup -E \\to \\mathbb R\\) tal que \\[ Du(e) = u(e_{+})-u(e_{-}). \\] En particular, el gradiente es una función impar. Ejercicio 2.2 Calcula el gradiente de la función dada en los vértices del siguiente grafo Solución Ejercicio 2.3 Verifica que el gradiente satisface la identidad de Leibniz \\[ D(u_1u_2) = u_1^+ Du_2 + u_2^-Du_1 \\] donde \\(u^\\pm:E\\to\\mathbb R\\) se define a partir de \\(u:V\\to\\mathbb R\\) como \\(u^\\pm(e) = u(e_\\pm)\\). Solución \\[ \\begin{aligned} D(u_1u_2)(e) &amp;= u_1(e_+)u_2(e_+) - u_1(e_-)u_2(e_-),\\\\ &amp;= u_1(e_+)u_2(e_+) - u_1(e_+)u_2(e_-) + u_1(e_+)u_2(e_-) - u_1(e_-)u_2(e_-),\\\\ &amp;= u_1(e_+)(u_2(e_+)-u_2(e_-)) + u_2(e_-)(u_1(e_+)-u_1(e_-)),\\\\ &amp;= u_1(e_+)Du_2(e) + u_2(e_-)Du_1(e),\\\\ &amp;= (u_1^+Du_2 + u_2^-Du_1)(e). \\end{aligned} \\] 2.1.1 Ley de ciclos No toda función (impar) \\(f:E\\cup -E \\to \\mathbb R\\) es necesariamente un gradiente. Una condición necesaria y suficiente es la ley de ciclos. Para poder enunciar esta ley es conveniente dar algunas definiciones previas para un dado grafo dirigido \\(G=(V,E)\\). Definición 2.2 Un camino no orientado es una sucesión de vértices \\(x_0,x_1, \\dots, x_n \\in V\\) tal que \\((x_j,x_{j+1}) \\in E\\cup -E\\) para todo \\(j\\in\\{0,1,\\ldots,(n-1)\\}\\). Se dice que el camino es un ciclo si además \\(x_n=x_0\\). Definición 2.3 Una componente conexa de \\(G\\) es un subconjunto \\(V&#39;\\subseteq V\\) tal que: Todos los vértices en \\(V&#39;\\) están conectados entre si por algún camino. Ningún vértice de \\(V&#39;\\) está conectado con ningún vértice de \\(V\\setminus V&#39;\\). Decimos que \\(G\\) es conexo si tiene una única componente conexa. Teorema 2.1 (Ley de ciclos) Sea \\(G=(V,E)\\) un grafo dirigido finito. Una función impar \\(f:E\\cup -E\\to\\mathbb R\\) es igual al gradiente de una función \\(u:V\\to \\mathbb R\\) si y solo si para todo ciclo \\(x_0,x_1, \\dots, x_n=x_0\\) se tiene que \\[ \\sum_{j=0}^{n-1} f(x_j,x_{j+1}) = 0. \\] Demostración. Por un lado es fácil verificar la identidad para flujos gradientes usando la propiedad telescópica. Dado un ciclo \\(x_0,x_1, \\dots, x_n=x_0\\) \\[ \\sum_{j=0}^{n-1} Du(x_j,x_{j+1}) = \\sum_{j=0}^{n-1} (u(x_{j+1})-u(x_j)) = u(x_n)-u(x_0)=0. \\] Podemos construir \\(u:V&#39;\\to \\mathbb R\\) sobre cada una de las componentes conexas de \\(G\\) de la siguiente forma: Fijemos \\(x_0 \\in V&#39;\\) y definimos \\[ u(x) := \\sum_{j=0}^{n-1} f(x_j,x_{j+1}) \\] donde \\(x_0,x_1, \\dots, x_n=x\\) es un camino no orientado que conecta \\(x_0\\) con \\(x\\in V&#39;\\). La hipótesis dada por la ley de ciclos garantiza que esta construcción no depende del camino escogido, es decir que está bien definida sin posible ambigüedad: Dados dos caminos \\(x_0,\\ldots,x_n=x\\) y \\(y_0=x_0,\\ldots,y_m=x\\) se tiene que \\(z_0=x_0,\\ldots,z_n=x_n,z_{n+1}=y_{m-1},\\ldots,z_{n+m}=y_0\\) es un ciclo y por lo tanto \\[ 0 = \\sum_{j=0}^{n+m-1} f(z_j,z_{j+1}) = \\sum_{j=0}^{n-1} f(x_j,x_{j+1}) - \\sum_{j=0}^{m-1} f(y_j,y_{j+1}). \\] Veamos finalmente que \\(Du = f\\). Dado \\(e\\in E\\) con \\(e_\\pm\\) en la misma componente que \\(x_0\\), tomamos un camino \\(x_0,x_1,\\ldots, x_n=e_-\\) de \\(x_0\\) a \\(e_-\\) y luego añadimos \\(x_{n+1}=e_+\\) para formar un camino de \\(x_0\\) a \\(e_+\\). Por lo tanto \\[ Du(e) = u(e_+)-u(e_-) = \\sum_{j=0}^{n} f(x_j,x_{j+1})-\\sum_{j=0}^{n-1} f(x_j,x_{j+1}) = f(e), \\] con lo cual concluímos la demostración. Este argumento nos permite apreciar que \\(u\\) está únicamente determinado salvo potenciales constantes en cada componente conexa de \\(G\\). Las constantes son los valores arbitrarios que daríamos a \\(u\\) sobre el nodo \\(x_0\\), que en nuestra demostración fue cero. En otras palabras, la nulidad del gradiente captura el número de compnentes conexas del grafo. Ejercicio 2.4 Calcula los potenciales que generan el flujo dado en la siguiente figura Solución El flujo satisface la ley de ciclos. Por ejemplo en el triángulo de la izquierda la suma correspondiente es \\(-3+1+2=0\\) y de igual forma podemos verificar en el triángulo de la derecha (\\(2+(-1)+(-1)=0\\)) o en el cuadrado exterior (\\((-3)+1-(-1)-(-1)=0\\)). Si tomamos \\(u(A)=0\\) sin pérdida de generalidad tenemos que \\[ \\begin{cases} u(B) = 1 + u(A) = 1,\\\\ u(C) = 3 + u(A) = 3,\\\\ u(D) = -1 + u(C) = 2. \\end{cases} \\] Verificamos además que con estos valores se obtiene el gradiente prescrito \\[ \\begin{cases} Du(AB) = u(B)-u(A) = 1-0 = 1,\\\\ Du(BC) = u(C)-u(B) = 3-1 = 2,\\\\ Du(CA) = u(A)-u(C) = 0-3 = -3,\\\\ Du(CD) = u(D)-u(C) = 2-3 = -1,\\\\ Du(DB) = u(B)-u(D) = 1-2 = -1. \\end{cases} \\] En general, \\(u\\) tiene el gradiente prescrito si y solo si \\[ u(A) = C, \\qquad u(B) = 1+C, \\qquad u(C) = 3+C, \\qquad u(D)=2+C. \\] Margen de cálculo: El lema de Poincaré Como ya el lector habrá notado, estas construcciones y propiedades encuentran paralelos en cálculo multivariable, y de hecho las demostraciones reproducen las mismas ideas: Los caminos son curvas, los ciclos son lazos o curvas cerradas y la expresión \\(\\sum_{j=0}^{n-1} f(x_j,x_{j+1})\\) es análoga a la integral de línea o el trabajo de un campo vectorial sobre una curva. El resultado que acabamos de enunciar se conoce como el Lema de Poincaré global. Recordemos su enunciado junto con el resultado local. Lema de Poincaré (global): Un campo vectorial \\(f \\in C(\\Omega\\subseteq\\mathbb R^n\\to\\mathbb R^n)\\) es el gradiente de algún potencial \\(u\\in C^1(\\Omega\\to\\mathbb R)\\) si y sólo si para cualquier curva cerrada \\(\\gamma \\in C^1([a,b]\\to\\Omega)\\) (i.e. \\(\\gamma(b)=\\gamma(a)\\)) se tiene que el trabajo que ejerce \\(f\\) sobre la curva \\(\\gamma\\) se anula \\[ \\int_\\gamma f = \\int_a^b f(\\gamma(t))\\cdot \\gamma&#39;(t)dt = 0. \\] Lema de Poincaré (local): Si \\(\\Omega\\subseteq\\mathbb R^n\\) es simplemente conexo2 entonces \\(f \\in C^1(\\Omega\\to\\mathbb R^n)\\) es un gradiente si y solo si \\(\\partial_if_j = \\partial_jf_i\\). 2.2 Divergencia Otro operador diferencial que tiene su análogo en grafos es la divergencia. Heurísticamente, la divergencia de un campo vectorial mide cuando es positiva la cantidad de flujo que sale o diverge del nodo dado, mientras que cuando es negativa mide la cantidad de flujo que recibe o converge en el nodo. Definición 2.4 Dado \\(f: E \\to \\mathbb R\\) denotamos por \\(\\operatorname{div} f:V\\to \\mathbb R\\) a la divergencia de \\(f\\) donde \\[ \\operatorname{div} f(v) = \\sum_{e_-=v}f(e)-\\sum_{e_+=v}f(e) \\] Ejemplo 2.3 En la siguiente figura se calculó la divergencia de la función dada en las aristas Ejemplo 2.4 Las ecuaciones de balance para un entramado se escriben en términos de la divergencia de las tensiones sobre los nodos libres como \\[ \\operatorname{div} T = -mge_y \\] Ejemplo 2.5 La ley de Kirchhoff dice que en en un nodo que no está conectado a la batería, la corriente que entra y sale de este son iguales. En términos de la divergencia quiere decir que \\[ \\operatorname{div} i = 0 \\] 2.2.1 Fórmula de la divergencia Al igual que antes, podríamos preguntarnos si todo potencial es la divergencia de algún campo. Esto no es necesariamente cierto, la divergencia satisface la ley de conservación, análoga al teorema de la divergencia. Un caso particular ilustrativo de esta ley postula que la suma de la divergencia sobre un grafo finito es igual a cero \\[ \\sum_{v\\in V} \\operatorname{div} f(v) = 0. \\] Una vez más la justificación se basa en una propiedad telescópica para la suma: Cada arista aparece dos veces en la suma con signos opuestos dependiendo si se considera su vértice origen o de llegada. Para dar una versión discreta del teorema de la divergencia consideramos el campo normal exterior \\(n_\\Omega:E\\to \\mathbb R\\) tal que \\[ n_\\Omega(e) = \\begin{cases} +1 \\text{ si $e_-\\in \\Omega$ y $e_+\\in V\\setminus \\Omega$},\\\\ -1 \\text{ si $e_-\\in V\\setminus \\Omega$ y $e_+\\in \\Omega$},\\\\ 0 \\text{ en cualquier otro caso} \\end{cases} \\] en este caso el signo de \\(n_\\Omega(e)\\) indica cuando la arista orientada conecta a \\(\\Omega\\) con su complemento o viceversa. Ejercicio 2.5 El campo normal es el gradiente de una dada función ¿Cuál?. Solución \\(n_\\Omega = D1_{V\\setminus \\Omega}\\) donde \\[ 1_{V\\setminus \\Omega}(x) = \\begin{cases} 1 \\text{ si } x\\in V\\setminus \\Omega,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Teorema 2.2 (Fórmula de la divergencia) Sea \\(G=(V,E)\\) un grafo dirigido finito. La divergencia de \\(f:E\\to \\mathbb R\\) verifica \\[\\begin{equation} \\sum_{v\\in \\Omega} \\operatorname{div} f(v) = \\sum_{e\\in E} f(e)n_\\Omega(e) \\tag{2.1} \\end{equation}\\] De hecho la suma en el lado derecho ocurre en realidad sobre un subconjunto de aristas que podemos definir como el borde de \\(\\partial\\Omega\\) \\[ \\partial \\Omega := \\{e\\in E\\ | \\ \\{e_+,e_-\\} \\cap \\Omega \\neq \\emptyset \\text{ y } \\{e_+,e_-\\} \\cap E\\setminus \\Omega \\neq \\emptyset\\} \\] es decir las aristas que conectan \\(\\Omega\\) con su complemento en cualquier orientación. La cantidad \\(f(e)n_\\Omega(e)\\) es positiva cuando \\(e_-\\in \\Omega\\), \\(e_+\\in V\\setminus \\Omega\\) y \\(f(e)&gt;0\\); o bien cuando \\(e_-\\in V\\setminus \\Omega\\), \\(e_+\\in \\Omega\\) y \\(f(e)&lt;0\\). En cualquier caso, \\(f(e)n_\\Omega(e)\\) se interpreta como la cantidad de masa que escapa de \\(\\Omega\\) por medio de \\(e\\). Un razonamiento similar se dá cuando \\(f(e)n_\\Omega(e)\\) es negativo para la masa que entra. El balance total nos dice que la masa que se produce o absorbe en \\(\\Omega\\) se puede medir de dos formas, sumando las divergencias en \\(\\Omega\\) u observando las contribuciones que escapan o entran por las aristas que conectan a \\(\\Omega\\) con su complemento \\(V\\setminus \\Omega\\) en cualquier orientación. Demostración. Sean \\(1_\\pm:V\\times E\\to \\mathbb R\\) definidas según \\[ 1_\\pm(v,e) := \\begin{cases} 1 \\text{ si } e_\\pm = v,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] En particular usaremos que \\[ \\sum_{v\\in \\Omega} 1_\\pm(v,e) = \\begin{cases} 1 \\text{ si } e_\\pm \\in \\Omega,\\\\ 0 \\text{ encualquier otro caso} \\end{cases} \\] Tenemos así que \\[ \\begin{aligned} \\sum_{v\\in \\Omega} \\operatorname{div} f(v) &amp;= \\sum_{v\\in \\Omega} \\sum_{e_-=v} f(e) - \\sum_{v\\in \\Omega} \\sum_{e_+=v} f(e),\\\\ &amp;= \\sum_{v\\in \\Omega} \\sum_{e \\in E} f(e)1_-(v,e) - \\sum_{v\\in \\Omega} \\sum_{e \\in E} f(e)1_+(v,e),\\\\ &amp;= \\sum_{e \\in E} \\sum_{v\\in \\Omega}f(e)1_-(v,e) - \\sum_{e \\in E} \\sum_{v\\in \\Omega}f(e)1_+(v,e),\\\\ &amp;= \\sum_{e_-\\in \\Omega} f(e) -\\sum_{e_+\\in \\Omega} f(e),\\\\ &amp;= \\sum_{\\substack{e_-\\in \\Omega\\\\e_+\\in V\\setminus \\Omega}} f(e) + \\sum_{e_-, e_+\\in \\Omega} f(e) - \\sum_{\\substack{e_+\\in \\Omega\\\\e_-\\in V\\setminus \\Omega}} f(e) - \\sum_{e_-, e_+\\in \\Omega} f(e),\\\\ &amp;= \\sum_{\\substack{e_-\\in \\Omega\\\\e_+\\in V\\setminus \\Omega}} f(e) - \\sum_{\\substack{e_+\\in \\Omega\\\\e_-\\in V\\setminus \\Omega}} f(e) \\end{aligned} \\] Esta última expresión es por definición de \\(n_\\Omega\\) igual a \\[ \\sum_{e\\in E} f(e)n_\\Omega(e), \\] con lo cual se concluye la demostración. Margen de cálculo: El teorema de la divergencia El teorema de la divergencia nos dice que dado un subconjunto \\(\\Omega \\subset\\mathbb R^n\\) con frontera localmente de clase \\(C^1\\) a trozos, y campo \\(v\\in C^1(\\overline{\\Omega}\\to\\mathbb R^n)\\), entonces \\[ \\int_\\Omega \\operatorname{div} v = \\int_{\\partial \\Omega} v\\cdot n \\] donde \\(n\\) es el vector normal exterior a \\(\\Omega\\). El lado derecho integra el flujo que escapa o entra en \\(\\Omega\\) a través de su borde. En concreto, si en un punto dado del borde \\(v\\cdot n &gt;0\\) entonces \\(v\\) apunta en la dirección de \\(n\\) y el flujo escapa con una tasa igual a \\(v\\cdot n\\), si en cambio \\(v\\cdot n &lt; 0\\) el flujo estaría entrando, y si \\(v\\cdot n=0\\) se tiene que \\(v\\) es tangente y el flujo apenas roza la superficie. El lado izquierdo de la expresión es una integral sobre \\(\\Omega\\) que representa la producción/absorción de flujo por el campo \\(v\\). 2.2.2 Lema de Poincaré para la divergencia Teorema 2.3 Sea \\(G=(V,E)\\) un grafo dirigido finito y conexo. Para cualquier \\(\\mu:V\\to\\mathbb R\\) tal que \\[ \\sum_{x\\in V}\\mu(x)=0 \\] existe por lo menos una solución \\(f:E\\to\\mathbb R\\) de \\[ \\operatorname{div} f = \\mu. \\] Demostración. Tomemos un nodo arbitrario \\(x_0\\in V\\) y consideremos inductivamente caminos no orientados que vayan conectando a \\(x_0\\) con cada uno de los nodos restantes y de tal forma que nunca se formen ciclos en esta construcción. Es decir, estamos proponiendo un árbol generador del grafo con raíz en el nodo \\(x_0\\), en otras palabras un sub-grafo \\(T_0 := (V_0=V,E_0\\subseteq E)\\) libre de ciclos y conexo. Fijamos \\(f=0\\) en las aristas de \\(E\\setminus E_0\\) y en los demás ajustaremos \\(f\\) para que satisfaga la ecuación dada. En la siguiente construcción estaremos definiendo a \\(f:E\\cup-E\\to \\mathbb R\\) como una función impar. La idea consiste en ir podando las ramas del árbol a medida que asignamos \\(f\\) convenientemente. Si \\(|V_0|=1\\) el problema sería trivial, asumamos así que \\(|V_0|&gt;1\\). En el primer paso tomamos una hoja de \\(T_0\\), es decir un \\(x\\in V_0\\) con un único nodo \\(y \\sim_{T_0} x\\). Declaramos así \\(f(x,y) = \\mu(x)\\) de modo que se tiene que \\(\\operatorname{div}f(x) = \\mu(x)\\) (\\(f\\) es distinto de cero en a lo sumo una arista en esta suma). Una vez declarado \\(f\\) en la arista \\(e=(x,y)\\) procedemos a considerar el árbol \\(T_1 = (V_0\\setminus \\{x\\},E_1:=E_0\\setminus \\{(x,y),(y,x)\\})\\). Asumamos de forma inductiva que luego de \\(k\\) pasos contamos con los árboles \\[ T_k = (V_k,E_k) \\subset T_{k-1} := (V_{k-1},E_{k-1}) \\subset \\ldots \\subset T_0 \\] tales que \\(f\\) ha sido definida en \\(E\\setminus E_k\\) tal que \\(\\operatorname{div}f=\\mu\\) se satisface sobre \\(V\\setminus V_k\\). Para el siguiente paso tomamos una hoja \\(x \\in V_k\\) y fijamos \\(f\\) sobre la (única) arista \\((x,y) \\in E_k\\cup-E_k\\) de modo que la ecuación ahora se satisfaga sobre el nodo \\(x\\). Para el siguiente paso podamos a \\(x\\) de \\(T_k\\), es decir que \\[ T_{k+1}:= (V_{k+1}=V_k\\setminus\\{x\\},E_{k+1}:=E_k\\setminus\\{(x,y),(y,x)\\}). \\] Claramente esta construcción garantiza que las hipótesis inductivas se siguen cumpliendo en el siguiente paso. Una vez terminado este algoritmo garantizamos que \\(\\operatorname{div} f=\\mu\\) se cumple en \\(V\\setminus \\{x_0\\}\\) (la raíz del árbol). Como última observación tenemos que la ecuación también debe cumplirse en \\(x_0\\) gracias a que \\(\\sum_{x\\in V} \\operatorname{div} f(x)=\\sum_{x\\in V} \\mu(x)=0\\). Notemos que si \\(x_0,\\ldots,x_k=x_0\\) es un dado ciclo del grafo, entonces si tomamos \\(f=1\\) en las aristas del ciclo y cero por fuera de estas, obtenemos una solución de \\(\\operatorname{div} f=0\\). De hecho, todas las soluciones homogéneas se obtienen por superposiciones de este ejemplo. El núcleo de la divergencia es un espacio vectorial generado por los ciclos independientes del grafo y su dimensión es un importante invariante topológico conocido como el primer número de Betti. Ejercicio 2.6 Calcula los flujos \\(f:E\\to \\mathbb R\\) tal que \\(\\operatorname{div} f=\\mu\\) para la función \\(\\mu\\) dada sobre los nodos del siguiente grafo. Solución Verificamos primero que la suma de los valores en los nodos se anula. Para calcular una solución particular tomamos el árbol generador con aristas \\(a\\), \\(b\\), \\(-e\\) y definimos así \\[ f(c)=f(d)=0, \\qquad f(a)=1, \\qquad f(e)=2, \\qquad f(b)=0 \\] el cual verifica fácilmente la ecuación de divergencia esperada en todos los nodos. Cualquier otra solución se obtiene como la superposición de la solución previa con las del sistema homogéneo \\[ \\begin{cases} f(a)+f(b)-f(e)=0,\\\\ -f(a)+f(c)=0,\\\\ -f(b)+f(d)=0,\\\\ -f(c)-f(d)+f(e)=0. \\end{cases} \\] Dos soluciones linealmente independientes se obtienen por ejemplo de los ciclos \\(a,c,e\\) y \\(b,d,e\\) respectivamente \\[ \\begin{aligned} &amp;f(a)=f(c)=f(e)=1,\\qquad f(b)=f(d)=0,\\\\ &amp;f(a)=f(c)=0, \\qquad f(b)=f(d)=f(e)=1. \\end{aligned} \\] Si usamos la reducción de Gauss-Jordan podemos verificar que esta es además una base de las soluciones homogéneas. 2.3 Integración por partes En esta sección identificamos a las funciones \\(u:V\\to \\mathbb R\\) con vectores de \\(\\mathbb R^{|V|}\\). Igualmente identificamos a las funciones \\(f:E\\to \\mathbb R\\) con vectores de \\(\\mathbb R^{|E|}\\). Eventualmente también podríamos considerar funciones complejas. El gradiente \\(D:\\mathbb R^{|V|}\\to\\mathbb R^{|E|}\\) se representa así por la matriz \\((D_{e,x}) \\in \\mathbb R^{|E|\\times |V|}\\) tal que \\[ D_{e,x} = \\begin{cases} 1 \\text{ si } x=e_+,\\\\ -1 \\text{ si } x=e_-,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Mientras que la divergencia \\(\\operatorname{div}:\\mathbb R^{|E|}\\to\\mathbb R^{|V|}\\) se representa por la matriz \\((\\operatorname{div}_{x,e}) \\in \\mathbb R^{M\\times N}\\) tal que \\[ \\operatorname{div}_{x,e} = \\begin{cases} -1 \\text{ si } e_+=x,\\\\ 1 \\text{ si } e_-=x,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Descubrimos de esta forma que \\(D^T = -\\operatorname{div}\\) o equivalentemente la fórmula de integración por partes \\[ \\sum_{e\\in E} (fDu)(e) = f\\cdot Du = -u\\cdot \\operatorname{div} f = -\\sum_{x\\in V} (u\\operatorname{div} f)(x). \\] Ejercicio 2.7 Calcula las matrices asociadas con el gradiente y la divergencia para el siguiente grafo Solución \\[ D = \\begin{pmatrix} -1 &amp; 1 &amp; 0 &amp; 0\\\\ 0 &amp; -1 &amp; 1 &amp; 0\\\\ 1 &amp; 0 &amp; -1 &amp; 0\\\\ -1 &amp; 0 &amp; 0 &amp; 1\\\\ 0 &amp; 0 &amp; 1 &amp; -1 \\end{pmatrix} \\qquad \\operatorname{div} = -D^T = \\begin{pmatrix} 1 &amp; 0 &amp; -1 &amp; 1 &amp; 0\\\\ -1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; -1 &amp; 1 &amp; 0 &amp; -1\\\\ 0 &amp; 0 &amp; 0 &amp; -1 &amp; 1 \\end{pmatrix}. \\] Ejercicio 2.8 Demuestra la fórmula de integración por partes sobre un dominio \\(\\Omega \\subseteq V\\) \\[\\begin{equation} \\sum_{\\Omega} u\\operatorname{div}f = \\sum_{E} u^-fn_\\Omega - \\sum_{e_+\\in \\Omega} fDu. \\tag{2.2} \\end{equation}\\] En particular, si \\(u=1\\) recuperamos la fórmula de la divergencia (2.1). Solución Basta con usar que \\(Dv\\cdot f = - v\\cdot \\operatorname{div} f\\) para \\(v := u 1_{\\Omega}\\). Margen de cálculo: Integración por partes La fórmula de integración por partes nos dice que dado un subconjunto \\(\\Omega \\subset\\mathbb R^n\\) con frontera localmente de clase \\(C^1\\) a trozos, un campo vectorial \\(v\\in C^1(\\overline{\\Omega}\\to\\mathbb R^n)\\), y un campo escalar \\(u\\in C^1(\\overline{\\Omega}\\to\\mathbb R^n)\\) entonces \\[ \\int_\\Omega u \\operatorname{div} v = \\int_{\\partial \\Omega} u v\\cdot n - \\int_\\Omega Du\\cdot v \\] donde \\(n\\) es el vector normal exterior a \\(\\Omega\\). 2.3.1 Descomposición de Helmholtz La relación \\(D^T=-\\operatorname{div}\\) nos permite dar la descomposición ortogonal \\[ \\mathbb R^{|E|} = D(\\mathbb R^{|V|}) + \\ker(\\operatorname{div}). \\] también conocida como la descomposición de Helmholtz. Es decir que cualquier \\(f:E\\to\\mathbb R\\) puede escribirse de forma única3 como \\[ f = Du + g \\] tal que \\[ \\operatorname{div} g = 0, \\] y como corolario \\(Du \\perp g\\). En términos físicos, cualquier flujo se descompone en una parte que preserva la masa (\\(g\\)) y en un flujo gradiente (\\(Du\\)). Margen de álgebra lineal: El teorema fundamental de álgebra lineal Dado \\(A:\\mathbb R^M\\to \\mathbb R^{N}\\) se tiene que \\[ A(\\mathbb R^{M})^\\perp = \\ker(A^T). \\] Si \\(x \\perp A(\\mathbb R^M)\\) entonces \\(0 = x\\cdot AA^Tx = \\|A^T x\\|^2\\), lo cual implica \\(A^Tx=0\\). Por otro lado si \\(A^Tx=0\\) entonces para \\(y\\in \\mathbb R^M\\) arbitrario \\(x\\cdot Ay = A^Tx\\cdot y=0\\). Ejercicio 2.9 Calcula la descomposición de Helmholtz para el siguiente flujo Solución Sea \\(f:E\\to \\mathbb R\\) los valores que se muestran en la gráfica. Buscamos calcular \\(u:V\\to \\mathbb R\\) y \\(g:E\\to \\mathbb R\\) tales que \\(f=Du+g\\) y \\(\\operatorname{div}g=0\\). Si tomamos así la divergencia en la expresión \\(f=Du+g\\) encontramos que \\(u\\) satisface \\[ \\begin{cases} -2u(A)+u(B)+u(C)=3,\\\\ u(A)-3u(B)+u(C)+u(D)=4,\\\\ u(A)+u(B)-3u(C)+u(D)=-7,\\\\ u(B)+u(C)-2u(D)=0. \\end{cases} \\] Las soluciones homogéneas del sistema son los potenciales constantes4. Ajustando esta constante de forma que \\(u(A)=0\\) obtenemos un sistema que podemos resolver numéricamente import numpy as np A = np.array([[ 1, 1, 0], [-3, 1, 1], [ 1,-3, 1]]) B = np.array([3, 4, -7]) X = np.linalg.inv(A).dot(B) Du = [X[0],X[1]-X[0],-X[1],X[2]-X[1],X[0]-X[2]] f = np.array([1,5,-2,0,0]) g = f-Du print(&quot;[Du(AB), Du(BC), Du(CA), Du(CD), Du(DB)] = {}.&quot;.format(Du)) ## [Du(AB), Du(BC), Du(CA), Du(CD), Du(DB)] = [0.125, 2.75, -2.875, -1.375, -1.375]. print(&quot;[g(AB), g(BC), g(CA), g(CD), g(DB)] = {}.&quot;.format(g)) ## [g(AB), g(BC), g(CA), g(CD), g(DB)] = [0.875 2.25 0.875 1.375 1.375]. 2.4 Laplaciano El Laplaciano es un operador diferencial que se construye aplicando sucesivamente el gradiente y la divergencia. Es decir que mide la producción de masa del gradiente. Además, luego de una manipulación algebraica, observamos que es proporcional a la diferencia entre el promedio en los vértices adyacentes y el valor en el centro. Definición 2.5 Dado \\(u: V \\to \\mathbb R\\), el Laplaciano \\(\\Delta u: V \\to \\mathbb R\\) se define tal que \\[ \\Delta u(v) = \\operatorname{div}(D u)(v) = \\sum_{w \\sim v} (u(w)-u(v)). \\] donde \\(w \\sim v\\) si existe una arista que une a \\(v\\) y \\(w\\) en cualquier orientación. A pesar de que tanto el gradiente como la divergencia requieren que el grafo tenga una orientación, el Laplaciano está bien definido en grafos no dirigidos. Cuando \\(u: V \\to \\mathbb R\\) es un potencial tal que \\(\\Delta u=0\\) en \\(\\Omega \\subseteq V\\), decimos que \\(u\\) es una función armónica sobre \\(\\Omega\\). Ejemplo 2.6 Considera una red eléctrica con resistencias de un Ohm (\\(R(e)=1\\)) la cual modelamos como una grafo dirigido de forma arbitraria. Una batería de un voltio entre dos nodos \\(v_+,v_-\\in V\\) genera un potencial eléctrico \\(u:V\\to \\mathbb R\\) que se puede determinar a partir de la ley de Ohm y la ley de Kirchhoff. Según la ley de Ohm tenemos que la corriente se calcula según \\[ i=Du. \\] Según la ley de Kirchhoff tenemos que fuera de los nodos donde se conecta la bateria, la corriente se conserva, es decir \\[ 0=\\operatorname{div}i = \\Delta u \\text{ en } V\\setminus\\{v_\\pm\\} \\] Junto con las condiciones de borde en los nodos donde se conecta la batería \\[ \\qquad u(v_+) = 1, \\qquad u(v_-) = 0, \\] obtenemos un sistema de ecuaciones lineales con igual número de ecuaciones que de incógnitas. Ejercicio 2.10 Calcula el potencial eléctrico que se genera en un cubo de resistencias de un Ohm, cuando se conecta una batería de un voltio entre dos nodos opuestos del cubo Solución Asumamos sin pérdida de generalidad que se conecta la bateria de los nodos \\(A\\) a \\(D\\) tal que \\(v(A)=1\\) y \\(v(D)=0\\). Tenemos un sistema de ecuaciones lineales de dimensiones 6 por 6. De existir una única solución5 observamos que por simetría se debe cumplir que \\(v(B)=v(F)=v(H)=\\alpha\\) (los nodos adyacentes a \\(A\\)) y \\(v(C)=v(E)=v(G)=\\beta\\) (los nodos adyacentes a \\(E\\)). Esto reduce el sistema a uno de 2 por 2 \\[ \\begin{cases} -9\\alpha+6\\beta = -3,\\\\ 6\\alpha -9\\beta = 0 \\end{cases} \\qquad\\Rightarrow\\qquad \\alpha = \\frac{3}{5}, \\qquad \\beta = \\frac{2}{5}. \\] Ejercicio 2.11 Calcula la matriz asociada al Laplaciano para el grafo a continuación Solución \\[ \\Delta = \\operatorname{div} D = \\begin{pmatrix} 1 &amp; 0 &amp; -1 &amp; 1 &amp; 0\\\\ -1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; -1 &amp; 1 &amp; 0 &amp; -1\\\\ 0 &amp; 0 &amp; 0 &amp; -1 &amp; 1 \\end{pmatrix}\\begin{pmatrix} -1 &amp; 1 &amp; 0 &amp; 0\\\\ 0 &amp; -1 &amp; 1 &amp; 0\\\\ 1 &amp; 0 &amp; -1 &amp; 0\\\\ -1 &amp; 0 &amp; 0 &amp; 1\\\\ 0 &amp; 0 &amp; 1 &amp; -1 \\end{pmatrix} = \\begin{pmatrix} -3 &amp; 1 &amp; 1 &amp; 1\\\\ 1 &amp; -2 &amp; 1 &amp; 0\\\\ 1 &amp; 1&amp; -3 &amp; 1\\\\ 1 &amp; 0 &amp; 1 &amp; -2 \\end{pmatrix} \\] Ejercicio 2.12 Da un análogo discreto para la fórmula de Green \\[ \\int_\\Omega (u_1\\Delta u_2 - u_2\\Delta u_1) = \\int_{\\partial\\Omega} (u_1Du_2 - u_2 Du_1)\\cdot n \\] Solución De la fórmula de integración por partes (2.2) \\[ \\sum_\\Omega u_i \\Delta u_j = \\sum_{E} u_i^- Du_j n_\\Omega - \\sum_{e_+\\in \\Omega} Du_iDu_j \\] Por lo tanto al tomar la resta se cancelan el segundo término a la deracha quedando así \\[ \\sum_\\Omega (u_1 \\Delta u_2-u_2 \\Delta u_1) = \\sum_{E} (u_1^- Du_2 - u_2^- Du_1)n_\\Omega. \\] En general podemos añadir una operación intermedia entre el gradiente y la divergencia. Esto genera operadores con características similares al Laplaciano. Ejemplo 2.7 Considera ahora una red eléctrica con resistencias variables. La ley de Ohm consiste en tomar el gradiente del potencial y luego dividir por las resistencias para obtener la corriente. Al recíproco de la resistencia también se le conoce como la capacitancia y puede ser más conveniente de usar en este ejemplo. En este caso las ecuaciones de balance para el potencial eléctrico tienen la forma \\[ \\operatorname{div} (CDu) = 0 \\qquad C = 1/R : \\text{Capacitancia} \\] (fuera de los nodos donde se conecta la batería). En el caso particular de las resistencias dadas en la siguiente gráfica, obtenemos el operador lineal asociado a la siguiente matriz import numpy as np # Gradiente D = np.array([[-1, 1, 0, 0], [0, -1, 1, 0], [1, 0, -1, 0], [-1, 0, 0, 1], [0, 0, 1, -1]]) # Capacitancia (C=1/R) C = np.array([[1, 0, 0, 0, 0], [0, 1/4, 0, 0, 0], [0, 0, 1/2, 0, 0], [0, 0, 0, 1/5, 0], [0, 0, 0, 0, 1/3]]) # Operador L = div(CD) L = -np.matmul(D.T,np.matmul(C,D)) print(L) ## [[-1.7 1. 0.5 0.2 ] ## [ 1. -1.25 0.25 -0. ] ## [ 0.5 0.25 -1.08333333 0.33333333] ## [ 0.2 -0. 0.33333333 -0.53333333]] Ejemplo 2.8 Las ecuaciones de balance en los entramados se implementan en tres pasos: Se toman las posiciones relativas entre nodos adyacentes, es decir el gradiente de las posiciones \\(q:V\\to\\mathbb R^2\\). Se forman las tensiones a partir de las posiciones relativas y los multiplicadores \\(\\lambda:E\\to \\mathbb R\\). Se propone el balance de fuerzas en términos de la divergencia de la tensión. En síntesis se obtiene que en los nodos libres \\[ \\operatorname{div} (\\lambda D q) = mge_2 \\] A diferencia de los problemas de redes eléctricas, tanto \\(q\\) como \\(\\lambda\\) son variables por ser determinadas lo cual hace que el problema sea no-lineal en dichas incógnitas. es decir que cualquier ciclo puede ser deformado continuamente a un punto. Por ejemplo, si \\(n=2\\) dice que \\(\\Omega\\) no tiene hoyos.↩︎ Dado \\(f:E\\to \\mathbb R\\), el potencial \\(u\\) no es único pero su gradiente \\(Du\\) sí.↩︎ Esto puede verificarse de la reducción de Gauss-Jordan en este caso, y además será demostrado con mayor generalidad.↩︎ Una vez más, esto puede chequearse a mano o con una herramienta numérica.↩︎ "],["dinámica.html", "Capítulo 3 Dinámica 3.1 Transporte 3.2 Difusión 3.3 Oscilación", " Capítulo 3 Dinámica 3.1 Transporte Consideremos un grafo dirigido \\(G=(V,E)\\) y una familia de densidades \\(u(x,t)\\) que toma valores reales para cada vértice \\(x\\in V\\) en tiempo \\(t\\in\\mathbb R\\). Decimos que un flujo \\(f(e,t)\\) transporta a \\(u\\) si en cada instante salen \\(f(e,t)\\) unidades de masa de \\(e_-\\) hacia \\(e_+\\) por la arista \\(e\\). Es decir que sobre cada \\(x\\in V\\) se tiene que \\[ \\partial_t u(x,t) = \\sum_{e_+=x} f(e,t) - \\sum_{e_-=x} f(e,t) = -\\operatorname{div} f(x,t). \\] Observamos que si en un dado nodo \\(x\\in V\\) se tiene que \\(\\operatorname{div} f(x)&gt;0\\) entonces \\(u\\) es decreciente. Esto quiere decir que el flujo hace que la densidad se esparza o diverja sobre dicho nodo. De igual forma, si \\(\\operatorname{div} f(x)&lt;0\\), \\(u\\) es creciente y el flujo hace que la densidad en cambio converga en dicho nodo. Ejemplo 3.1 Consideremos una densidad \\(u:V\\times \\mathbb R\\to \\mathbb R\\) transportada por un flujo \\(f := \\mu u^-\\) donde \\(\\mu:E\\to \\mathbb R\\) son tazas de movilidad dadas sobre las aristas en el grafo a continuación y recordemos que \\(u^-(e)=u(e_-)\\) Comenzando de la distribución de densidades \\[ u(0) = (1,0,0,0) \\] integramos numericamente las cuatro ecuaciones dadas por \\[ \\partial_t u = -\\operatorname{div}(\\mu u^-) \\qquad\\Leftrightarrow \\qquad \\begin{cases} u(1)&#39; = -3u(1)+3u(3),\\\\ u(2)&#39; = u(1) - u(2),\\\\ u(3)&#39; = u(2) - 3u(3) + 2u(4),\\\\ u(4)&#39; = 2u(1)-2u(4). \\end{cases} \\] y obtenemos lo siguiente: import numpy as np import matplotlib.pyplot as plt import scipy as sp from scipy.integrate import odeint A = np.array([[-3, 0, 3, 0], [1, -1, 0, 0], [0, 1, -3, 2], [2, 0, 0, -2]]) def dudt(u,t): return np.matmul(A,u) u0 = np.array([1,0,0,0]) t = np.linspace(0,2,1000) sol = odeint(dudt,u0,t) plt.plot(t,sol[:,0], label=&#39;1&#39;) plt.plot(t,sol[:,1], label=&#39;2&#39;) plt.plot(t,sol[:,2], label=&#39;3&#39;) plt.plot(t,sol[:,3], label=&#39;4&#39;) plt.legend() plt.show() Adicionalmente podemos considerar modelos donde además del fenómeno de transporte, una o más densidades tienen distintas reacciones en cada uno de los nodos. Ejemplo 3.2 Las funciones \\(S,I:V\\to \\mathbb R\\) representan poblaciones de individuos susceptibles e infectados para una dada epidemia modelada geográficamente sobre un grafo dirigido \\(G=(V,E)\\). Cada una de estas poblaciones se mueve sobre las aristas por flujos dados por \\[ f_S := \\mu_S S^-, \\qquad f_I := \\mu_I I^-. \\] donde \\(\\mu_S,\\mu_I: E\\to \\mathbb R\\) son tazas de movilidad sobre las aristas. La dinámica de la epidemia en cada nodo está dada por las tazas de transmisión (\\(\\beta\\)) y recuperación (\\(\\gamma\\)). En específico planteamos el modelo de \\(2|V|\\) ecuaciones de primer orden no-lineales \\[ \\partial_t S = -\\beta SI + \\operatorname{div}(\\mu_S S^-), \\qquad \\partial_t I = \\beta SI - \\gamma I + \\operatorname{div}(\\mu_I I^-),\\\\ \\] Ejercicio 3.1 Demuestra que el total de la población susceptible o infectada es una función decreciente. Solución \\[ \\partial_t \\sum_{V} (S+I) = \\sum_{V} (-\\gamma I + \\operatorname{div} f_S+\\operatorname{div}f_I) = - \\gamma \\sum_{V} I \\leq 0. \\] Ejercicio 3.2 Considera una epidemia dada en la siguiente red con los parámetros dados. En las aristas se muestran ciertas tasas de movilidad, para los susceptibles estas deben multiplicarse por \\(10^{-2}\\) y para los infectados por \\(10^{-4}\\). Implementa numéricamente y grafica las soluciones en el intervalo \\([0,160]\\) con condiciones iniciales \\[ S(0) = (1,1,1,1), \\qquad I(0) = (0, 10^{-6},0,0). \\] Solución import numpy as np import matplotlib.pyplot as plt import scipy as sp from scipy.integrate import odeint beta = 0.5 gamma = 0.3 L = np.array([[-5, 1, 2, 1], [2, -3, 1, 0], [1, 2, -4, 2], [2, 0, 1, -3]]) def dSIdt(SI,t): S = SI[:4] I = SI[4:] dS = -beta*S*I + 0.01*np.matmul(L,S) dI = beta*S*I - gamma*I + 0.0001*np.matmul(L,I) return np.concatenate((dS,dI)) S0 = np.array([1,1,1,1]) I0 = np.array([0,0.00000001,0,0]) SI0 = np.concatenate((S0,I0)) t = np.linspace(0,160,1000) sol = odeint(dSIdt,SI0,t) fig, ax = plt.subplots(2,2,figsize=(10,5)) ax[0,0].plot(t,sol[:,0], label=&#39;S1&#39;) ax[0,0].plot(t,sol[:,4], label=&#39;I1&#39;) ax[0,0].legend() ax[1,0].plot(t,sol[:,1], label=&#39;S2&#39;) ax[1,0].plot(t,sol[:,5], label=&#39;I2&#39;) ax[1,0].legend() ax[0,1].plot(t,sol[:,2], label=&#39;S3&#39;) ax[0,1].plot(t,sol[:,6], label=&#39;I3&#39;) ax[0,1].legend() ax[1,1].plot(t,sol[:,3], label=&#39;S4&#39;) ax[1,1].plot(t,sol[:,7], label=&#39;I4&#39;) ax[1,1].legend() 3.2 Difusión Así como vimos en los ejemplos anteriores donde el flujo era proporcional a \\(u^-\\), en general puede darse el caso de que \\(f\\) esté determinada por alguna otra función de \\(u\\), esto se conoce como una ley constitutiva. Un caso muy común es que \\(f\\) sea proporcional a \\(-Du\\), en el cual obtenemos un modelo de difusión. Ejemplo 3.3 Sea \\(G=(V,E)\\) un grafo que modela una red de habitaciones en renta y \\(u:V\\times \\mathbb R\\to\\mathbb R\\) la población que vive en dicha red. Asumiendo la ley de oferta y demanda, el precio de renta \\(p=p(x,t)\\) de una habitación \\(x\\) en el instante \\(t\\) debe ser proporcional a la demanda, la cual podemos considerar en nuestro caso proporcional a la población que habita dicho nodo, digamos por ejemplo que \\(p = k_1u\\). La población busca moverse entre nodos adyacentes si percibe que el precio le es favorable, por ejemplo \\(f=-k_2Dp\\). Llegamos así a la ecuación \\[ \\partial_t u = -\\operatorname{div} f = \\operatorname{div}(k_2Dp) = \\operatorname{div}(aDu), \\qquad a := k_1k_2. \\] El problema \\(\\partial_t u = \\operatorname{div}(aDu)\\), también conocido como la ecuación de calor o difusión, representa un sistema de EDOs lineales y de primer orden con tantas ecuaciones e incógnitas como la cardinalidad de \\(V\\). Ejercicio 3.3 Considera una difusión de la forma \\(\\partial_t u = \\Delta u\\) sobre el siguiente grafo. Calcula \\(u\\) para todo tiempo dadas las condiciones iniciales ilustradas en la figura. ¿Converge la solución a algún punto fijo? Solución El sistema de 4 EDOs se presenta como \\[ \\frac{d}{dt}\\begin{pmatrix} u(a)\\\\ u(b)\\\\ u(c)\\\\ u(d) \\end{pmatrix} = \\begin{pmatrix} -3 &amp; 1 &amp; 1 &amp; 1\\\\ 1 &amp; -2 &amp; 1 &amp; 0\\\\ 1 &amp; 1 &amp; -3 &amp; 1\\\\ 1 &amp; 0 &amp; 1 &amp; -2 \\end{pmatrix}\\begin{pmatrix} u(a)\\\\ u(b)\\\\ u(c)\\\\ u(d) \\end{pmatrix} \\] Dada que la condición inicial es \\((1,0,0,0)^T\\) buscamos la primera columna de la matriz exponencial. El siguiente resultado se obtuvo con la ayuda de sympy, una librería de cálculo simbólico de python from sympy import * t = Symbol(&#39;t&#39;) mt = Matrix([[-3, 1, 1, 1], [1, -2, 1, 0], [1, 1, -3, 1], [1, 0, 1, -2]]) * t mexp = mt.exp() print(&#39;$$&#39; + latex(mexp) + &#39;$$&#39;) \\[\\left[\\begin{matrix}\\frac{1}{4} + \\frac{3 e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4}\\\\\\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} + \\frac{e^{- 2 t}}{2} + \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 2 t}}{2} + \\frac{e^{- 4 t}}{4}\\\\\\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} + \\frac{3 e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4}\\\\\\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 2 t}}{2} + \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} + \\frac{e^{- 2 t}}{2} + \\frac{e^{- 4 t}}{4}\\end{matrix}\\right]\\] Observamos que cuando \\(t\\to\\infty\\) la solución converge exponencialemente al vector \\((1/4,1/4,1/4,1/4)^T\\). De hecho esto sucede para cualquier condición incial. Ejercicio 3.4 Sea \\(G=(V,E)\\) un grafo lineal con 100 vértices \\[ V=\\{1,2,\\ldots,100\\}, \\qquad E = \\{(1,2),(2,3),\\ldots,(99,100)\\}. \\] Sea \\(u\\) solución de la ecuación de calor \\(\\partial_t u=\\Delta u\\) en \\(G\\) con condición inicial \\[ u(0) = e_{50} = (0,\\ldots,0,1,0,\\ldots,0). \\] Calcula el primer \\(t&gt;0\\) tal que \\(u(50,t)\\leq 0.1\\). Solución En este caso la dificultad está en cómo implementar el Laplaciano y encontrar el primer índice donde la solución baje de \\(0.1\\). import numpy as np import matplotlib.pyplot as plt from scipy.integrate import odeint Delta = -2*np.eye(100)+np.eye(100,k=1)+np.eye(100,k=-1) Delta[0,0] = -1 Delta[99,99] = -1 def dudt(u,t): return np.matmul(Delta,u) u0 = np.zeros(100) u0[49] = 1 t = np.linspace(0,20,1000) sol = odeint(dudt,u0,t) index = np.where(sol[:,49]&lt;0.1)[0][0] plt.plot(t,sol[:,49]) plt.plot(t[index],sol[index,49],&#39;ro&#39;,label=&quot;({:.2f},{:.2f})&quot;.format(t[index],sol[index,49])) plt.legend() plt.title(&quot;u(50,t)&quot;) plt.show() 3.3 Oscilación El sistema de EDOs lineales y de segundo orden dado por \\[ \\partial_t^2 u = \\operatorname{div}(aDu) \\] también es común en distintos modelos. Esta se conoce como la ecuación de onda. Ejemplo 3.4 Un grafo \\(G=(V,E)\\) modela las conexiones en un sistema de masas \\(m:V\\to (0,\\infty)\\) unidas por resortes con constantes \\(k:E\\to[0,\\infty)\\). Sea \\(q:V\\to \\mathbb R^n\\) los desplazamientos de las masas a partir de una configuración dada de equilibrio. A partir de la ley de Hooke planteamos el sistema \\(n\\times|V|\\) ecuaciones e incógnitas, \\[ m\\partial_t^2 q = \\operatorname{div}(kDq). \\] Recordemos que cualquier sistema de segundo orden puede ser llevado a un sistema de primer orden tomando a las velocidades como incógnitas del sistema. Por ejemplo, \\[ \\partial_t^2 u = \\operatorname{div}(aDu) \\qquad \\Leftrightarrow\\qquad \\begin{cases} \\partial_t u = v,\\\\ \\partial_t v = \\operatorname{div}(aDu). \\end{cases} \\] Ejemplo 3.5 El grafo \\(G=(V,E)\\) vuelve a modelar una red de habitaciones en renta, \\(u:V\\times \\mathbb R\\to\\mathbb R\\) la población que vive en dicha red y \\(p:V\\times \\mathbb R\\to\\mathbb R\\) los precios. Una vez más asumimos que la población se mueve según el flujo \\(f = -Dp\\). Por otro lado los precios se modifican gradualmente dependiendo de la demanda en relación a los nodos adyacentes. Esto último puede ser reflejado por ejemplo en la ecuación \\(\\partial_t p = -\\Delta u\\), es decir que el precio disminuye si el promedio de la población vecina es mayor la población en el nodo en consideración, con la intención de atraerla. En resumen obtenemos el sistema de ecuaciones \\[ \\partial_t u = \\Delta p, \\qquad \\partial_t p = -\\Delta u. \\] Estas implican las ecuaciones de onda desacopladas para el bilaplaciano \\[ \\partial_t^2 u = -\\Delta^2 u, \\qquad \\partial_t^2 p = -\\Delta^2p. \\] Ejercicio 3.5 Considera una oscilación de la forma \\(\\partial_t^2 u = -\\Delta^2 u\\) sobre el siguiente grafo. Calcula \\(u\\) para todo tiempo dadas las condiciones iniciales ilustradas en la figura, partiendo del reposo. Grafica la solución en el intervalo \\([0,6]\\). Solución El sistema de 4 EDOs se presenta como \\[ \\frac{d}{dt}\\begin{pmatrix} u(a)\\\\ u(b)\\\\ u(c)\\\\ u(d)\\\\ u&#39;(a)\\\\ u&#39;(b)\\\\ u&#39;(c)\\\\ u&#39;(d) \\end{pmatrix} = \\begin{pmatrix} 0_4 &amp; I_4\\\\ -\\Delta^2 &amp; 0_4 \\end{pmatrix}\\begin{pmatrix} u(a)\\\\ u(b)\\\\ u(c)\\\\ u(d)\\\\ u&#39;(a)\\\\ u&#39;(b)\\\\ u&#39;(c)\\\\ u&#39;(d) \\end{pmatrix}, \\qquad \\Delta = \\begin{pmatrix} -3 &amp; 1 &amp; 1 &amp; 1\\\\ 1 &amp; -2 &amp; 1 &amp; 0\\\\ 1 &amp; 1 &amp; -3 &amp; 1\\\\ 1 &amp; 0 &amp; 1 &amp; -2 \\end{pmatrix} \\] Para calcular la solución analítica usamos el paquete simbólico de python. import numpy as np import matplotlib.pyplot as plt import sympy as smp from sympy.plotting import plot Delta = smp.Matrix([[-3,1,1,1], [1,-2,1,0], [1,1,-3,1], [1,0,1,-2]]) t = smp.symbols(&#39;t&#39;,real=&#39;True&#39;) B = smp.Matrix(smp.BlockMatrix([[smp.ZeroMatrix(4,4),smp.Identity(4)], [-Delta*Delta,smp.ZeroMatrix(4,4)]]))*t eB = smp.re(B.exp()) y0 = smp.Matrix([0,1,2,3,0,0,0,0]) y_s = eB*y0 print(&#39;$$&#39; + smp.latex(y_s[:4]) + &#39;$$&#39;) \\[\\left[ \\frac{3}{2} - \\frac{3 \\cos{\\left(4 t \\right)}}{2}, \\ - \\cos{\\left(2 t \\right)} + \\frac{\\cos{\\left(4 t \\right)}}{2} + \\frac{3}{2}, \\ \\frac{\\cos{\\left(4 t \\right)}}{2} + \\frac{3}{2}, \\ \\cos{\\left(2 t \\right)} + \\frac{\\cos{\\left(4 t \\right)}}{2} + \\frac{3}{2}\\right]\\] Las gráficas están dadas por eB_f = smp.lambdify(t,eB) t = np.linspace(0,6,600) y0 = np.array([0,1,2,3,0,0,0,0]) y = np.einsum(&#39;ijk,j-&gt;ik&#39;,eB_f(t),y0) plt.plot(t,y[0,:],label=&#39;a&#39;) plt.plot(t,y[1,:],label=&#39;b&#39;) plt.plot(t,y[2,:],label=&#39;c&#39;) plt.plot(t,y[3,:],label=&#39;d&#39;) plt.legend(loc=&#39;lower right&#39;) "],["implementación-del-entramado.html", "Capítulo 4 Implementación del entramado 4.1 Librerías y datos 4.2 Ecuación diferencial 4.3 Integración y graficación", " Capítulo 4 Implementación del entramado En esta sección veremos como poner en práctica los conceptos aprendidos para modelar una red cuadrada sujetada por sus cuatro esquinas. Recordemos que a pesar de que podemos dar una forma explícita de las ecuaciones que se deben resolver, el método de Newton parece ser muy sensible a las condiciones iniciales, por lo que hay que ingeniarse una forma alternativa. La idea que tenemos en mente es proponer que las conexiones entre nodos elásticas. Con esto proponemos un modelo elástico que gracias a un término de viscosidad podemos llevar al reposo. Con estas configuraciones terminales podemos luego ir haciendo la dureza (stiffness) de los resortes cada vez más y más grande, aproximando así la configuración de equilibrio cuando las barras son rígidas. 4.1 Librerías y datos Para fijar ideas proponemos una red con \\(N\\) por \\(N\\) nodos de masa \\(m&gt;0\\) como la ilustrada a continuación. La esquinas serán colgadas en los puntos \\((0,0,0)\\), \\((1,0,0)\\), \\((1,1,0)\\), y \\((0,1,0)\\). Entre cada par de nodos adyacentes se ubica un resorte cuya longitud natural es \\(l &gt; 1/(N-1)\\), dureza \\(k\\gg 1\\), y amortiguación \\(\\gamma &gt; 0\\). Es decir que si dos nodos adyacentes están a distancia \\(d\\), la magnitud de la fuerza que ejerce el resorte entre ellos es \\(k|d-l|\\). Esta fuerza es paralela a la línea que contiene a estos nodos y la dirección (o el signo) dependen de como se compare \\(d\\) respecto de \\(l\\): Para \\(d&gt;l\\) el resorte atrae a los nodos entre si, y para \\(d&lt;l\\) el resorte los repele. import numpy as np from numpy import linalg as la import matplotlib.pyplot as plt import scipy as sp import scipy.sparse as sps from scipy.integrate import odeint N = 10 # Longitud de la red m = 0.1 # Masa de los nodos gamma = 1 # Coeficiente de amortiguación k = 100 # Coeficiente de dureza l = 1.1/(N-1) # Longitud natural del resorte fijos = [0, N-1, N**2-N, N**2-1] # Esquinas fijas # Listas para enumerar las aristas de la red # Aristas verticales ini_v = list(range(N**2-N)) fin_v = list(range(N,N**2)) # Aristas horizontales ini_h = list(range(N**2)) del ini_h[slice(N-1,N**2,N)] fin_h = list(range(1,N**2+1)) del fin_h[slice(N-1,N**2,N)] ini = ini_h + ini_v # Nodos de salida fin = fin_h + fin_v # Nodos de llegada Ne = len(ini) # Número de aristas 4.2 Ecuación diferencial La ecuación diferencial que buscamos modelar para la posición \\(p=(x,y,z)\\) de cada nodo está dada por las leyes de Newton: \\[ mp&#39;&#39; = \\text{gravedad} + \\text{tensión} + \\text{amortiguación} \\] De estos tres tréminos la gravedad y la tensión son fáciles de calcular. Respectivamente son \\(-mge_z\\) y \\(-\\gamma p&#39;\\). Asumiendo el sistema internacional de unidades tomamos \\(g = 9.8\\). La dificultad reside ahora en implementar el cálculo de las tensiones. Recordemos además que para poder resolver nuestra EDO usando la librería de integración numérica de Scipy (odeint) debemos transformar el sistema a uno de primer orden. Esto significa que las velocidades pasan a ser parte de las incógnitas. Codificamos en la curva \\(s=s(t)\\) las configuraciones de nuestro sistema de la siguiente forma \\[ s = (pos,vel) = ((x,y,z),(vx,vy,vz)) \\in (\\mathbb R^{N^2}\\times\\mathbb R^{N^2}\\times\\mathbb R^{N^2})\\times(\\mathbb R^{N^2}\\times\\mathbb R^{N^2}\\times\\mathbb R^{N^2}) \\] Dadas las posiciones \\(p_{ini}\\) y \\(p_{fin}\\) de dos nodos extremos sobre una arista dada tenemos que la tensión sobre dicha arista se calcula por \\[ T := k(d-l)\\theta, \\qquad d := |p_{fin}-p_{ini}|, \\qquad \\theta := \\frac{p_{fin}-p_{ini}}{d} \\] Esta es justamente la tensión que se ejerce sobre el nodo inicial de la arista, siendo la fuerza opuesta en el otro nodo gracias a la tercera ley de Newton. Un paso técnico a partir de acá consiste en transferir está informaición dada sobre las aristas a los nodos. Estas consideraciones teóricas quedan reflejadas en la siguiente función: def dsdt(s,t): pos = np.reshape(s[:3*N**2],(3,N**2)).T vel = np.reshape(s[3*N**2:],(3,N**2)).T pos_rel = pos[fin] - pos[ini] lon_rel = np.tile(la.norm(pos_rel,axis=1),(3,1)).T # d dir_rel = pos_rel/lon_rel # theta ten_esc = k*(lon_rel-l*np.ones((Ne,3))) # Magnitud de la tensión (signada) ten_ari = ten_esc*dir_rel # Tensión sobre el nodo inicial # Tensión total sobre cada nodo. Usamos una estructura de matrices ralas (sparse) para codificarlas eficientemente. data = np.concatenate((ten_ari.T.reshape(-1),-ten_ari.T.reshape(-1))) fila = 3*ini+3*fin colu = 2*(Ne*[0]+Ne*[1]+Ne*[2]) ten_nod = sps.coo_matrix((data, (fila, colu))).toarray() # Fuerzas y aceleración fue_gra = -9.8*m*np.tile(np.array([0,0,1]),(N**2,1)) # Gravedad visc = -gamma*vel # Amortiguación acel = (ten_nod + fue_gra + visc)/m # Aceleración acel[fijos,:] = [0,0,0] # Esquinas fijas return np.concatenate((s[3*N**2:],acel.T.reshape(-1))) 4.3 Integración y graficación Una vez modelada la ecuación diferencial ya podemos proceder a integrarla usando por ejemplo el comando odeint de la librería Scipy. Para ello necesitamos dar adicionalmente un intervalo de tiempo discreto y una condición inicial. px, py = np.meshgrid(np.linspace(0,1,N),np.linspace(0,1,N)) s0 = np.concatenate((px.reshape(-1), py.reshape(-1),np.zeros(N**2),np.zeros(3*N**2))) t = np.linspace(0,10,2000) sol = odeint(dsdt,s0,t) Visualización del último instante fig = plt.figure() ax = plt.axes(projection=&#39;3d&#39;) ax.axes.set_xlim3d(left=0, right=1); ax.axes.set_ylim3d(bottom=0, top=1); ax.axes.set_zlim3d(bottom=-1, top=0); ax.view_init(60, 80); sol_fin = sol[-1,:] pos = np.reshape(sol_fin[:3*N**2],(3,N**2)).T for i in range(N): ax.plot3D(pos[i*N:(i+1)*N,0], pos[i*N:(i+1)*N:,1], pos[i*N:(i+1)*N,2],&#39;bo-&#39;) ax.plot3D(pos[i:N**2:N,0], pos[i:N**2:N,1], pos[i:N**2:N,2],&#39;b-&#39;) "],["espectro-del-laplaciano.html", "Capítulo 5 Espectro del Laplaciano 5.1 Problema elíptico 5.2 Problema parabólico 5.3 Problema hiperbólico 5.4 Nerd sniping", " Capítulo 5 Espectro del Laplaciano Hemos visto tres familias de problemas relacionados con el operador lineal \\(u \\mapsto Lu = \\operatorname{div}(aDu)\\): Elíptico: \\(\\operatorname{div}(aDu) = f\\), Parabólico: \\(\\partial_t u = \\operatorname{div}(aDu) + f\\), Hiperbólico: \\(\\partial_t^2 u = \\operatorname{div}(aDu) + f\\). Como tales, la descomposición espectral de \\(L\\) trivializa el cálculo de las soluciones. A continuación daremos un breve recorrido a la teoría discreta de Fourier con la cual podemos clarificar como resolver cada uno de estos problemas. Para \\(a:E\\to (0,\\infty)\\) la composición dada por \\(Lu = \\operatorname{div}(aDu)\\) es un operador simétrico, negativo semi-definido. La simetría es una aplicación de la fórmula de integración por partes, bien sea usando que \\[ (\\operatorname{div} \\operatorname{diag}(a) D)^T = D^T \\operatorname{diag}(a)^T \\operatorname{div}^T = (-\\operatorname{div}) \\operatorname{diag}(a)(-D) = \\operatorname{div}\\operatorname{diag}(a)D, \\] o en términos de las sumas \\[ \\sum_{x\\in V} v(x)\\operatorname{div}(aDu)(x) = -\\sum_{e\\in E} Dv(e)Du(e)a(e) = \\sum_{x\\in V} u(x)\\operatorname{div}(aDv)(x). \\] La no-positividad la verificamos tomando \\(v=u\\) tal que \\[ \\sum_{x\\in V} u(x)\\operatorname{div}(aDu)(x) = -\\sum_{e\\in E} (Du(e))^2a(e) \\leq 0. \\tag{5.1} \\] Gracias al teorema espectral sabemos que \\(L\\) es diagonalizable, sus autovalores son reales no-positivos y además posee una base de autofunciones ortogonales. Denotemos por \\(\\phi_0,\\ldots,\\phi_{M-1}\\) a una base ortogonal con autovalores \\(-\\lambda_0,\\ldots,-\\lambda_{M-1}\\) respectivamente. Margen de álgebra lineal: El teorema espectral El teorema espectral dice que si \\(L\\in \\mathbb R^{N\\times N}\\) es simétrica, entonces sus autovectores son reales y existe una base ortogonal de autovectores. Para ver que un dado autovector \\(\\lambda\\) es real consideramos un correspondiente autovector \\(\\xi\\) (posiblemente complejo) tal que \\[ \\lambda\\|\\xi\\|^2 = L\\xi\\cdot \\overline{\\xi} = \\xi\\cdot L\\overline{\\xi} = \\xi\\cdot \\overline{L\\xi} = \\overline{\\lambda}\\|\\xi\\|^2. \\] Dado que \\(\\xi\\neq0\\) la única opción posible es que \\(\\lambda=\\overline{\\lambda}\\), es decir \\(\\lambda\\in \\mathbb R\\). Más aún, podemos considerar de ahora en adelante que \\(\\xi\\) también es real dado que las partes real e imaginarias de un dado autovector son también autovectores (dado que \\(L\\) es real). Autovectores \\(\\xi\\), \\(\\xi&#39;\\) con autovalores distintos \\(\\lambda\\), \\(\\lambda&#39;\\) (respectivamente) son ortogonales dado que \\[ \\lambda (\\xi\\cdot\\overline{\\xi&#39;}) = L\\xi\\cdot \\overline{\\xi&#39;} = \\xi\\cdot L\\overline{\\xi&#39;} = \\xi\\cdot \\overline{L\\xi&#39;} = \\overline{\\lambda&#39;} (\\xi\\cdot\\overline{\\xi&#39;}) = \\lambda&#39; (\\xi\\cdot\\overline{\\xi&#39;}). \\] Para ver que existe una base de autovectores se puede proceder por inducción. Si \\(\\lambda\\) es un autovalor con autovector \\(\\xi\\), entonces podemos descomponer \\(\\mathbb R^N\\) como la suma directa de la línea \\(\\operatorname{vspan}\\{\\xi\\}\\) y su complemento ortogonal \\(S = \\operatorname{vspan}\\{\\xi\\}^\\perp\\). El operador \\(L|_S\\) tiene rango en \\(S\\), dado que para \\(x\\in S\\) \\[ Lx\\cdot \\overline{\\xi} = x\\cdot L\\overline{\\xi} = x\\cdot \\overline{L\\xi} = \\overline{\\lambda} (x\\cdot \\overline{\\xi}) = 0. \\] Además vuelve a ser simétrico (con respecto al producto interno). Tenemos de esta forma el paso para llevar adelante un argumento por inducción. Finalmente, cuando \\(L\\) se corresponde con una forma cuadrática negativa semi-definida tenemos que los autovalores son no-positivos dado que \\[ 0\\geq L\\xi\\cdot \\xi = \\lambda\\|\\xi\\|^2. \\] Gracias a la identidad (5.1) vemos además que \\(\\operatorname{div}(aDu)=0\\) si y solo si \\(Du=0\\). Si \\(G\\) es conexo entonces esto solamente se cumple para las funciones constantes. En otras palabras, \\(\\lambda=0\\) es un autovalor simple cuyo autoespacio consiste de las funciones constantes. En general, \\(\\lambda=0\\) es un autovalor de \\(L\\) cuya multiplicidad geométrica es igual al número de componentes conexas de \\(G\\). Asumiremos además de ahora en adelante que \\(G\\) es conexo y \\(\\phi_0=1\\) es la autofunción asociada a \\(\\lambda_0=0\\), siendo los demás autovalores estrictamente negativos (es decir que \\(\\lambda_j&gt;0\\) para \\(j\\neq 0\\)). Ejercicio 5.1 Demuestra que para cualquier autofunción \\(\\phi_j\\) para \\(j\\neq 0\\) se tiene que \\(\\phi_j\\) cambia de signo. Es decir que ninguno conjuntos \\(\\{\\phi_j&gt;0\\}\\), \\(\\{\\phi_j&lt;0\\}\\) es vacío. Solución Dado que \\(\\phi_0=1\\) es ortogonal a \\(\\phi_j\\) tenemos que \\(\\sum\\phi_j=0\\). Como \\(\\phi_j\\neq 0\\), necesariamente debe tener tanto valores positivos como negativos. Gracias a la ortogonalidad podemos calcular la descomposición de una función arbitraria usando productos internos. Esta se conoce como la transformada de Fourier discreta. Dado que \\[ u = \\sum_{j=0}^{|V|-1} \\hat u_j \\phi_j \\] tenemos que tomando en ambos lados el producto interno con \\(\\phi_j\\) obtenemos que \\[ \\hat u_j = \\frac{1}{\\|\\phi_j\\|^2}\\sum_{x\\in V} u(x) \\overline{\\phi_j(x)}. \\] Los coeficientes \\(\\hat u_j\\) se conocen como los coeficientes de Fourier. Ejemplo 5.1 Consideremos el grafo cíclico con \\(M\\) vértices los cuales identificamos con los enteros módulo \\(M\\). En este caso \\[ \\Delta u(x) = u(x+1) - 2u(x) + u(x-1). \\] Para calcular el espectro de \\(\\Delta\\) debemos encontrar las soluciones \\(M\\)-periódicas de la recurrencia \\[ \\phi(x+1) - 2\\phi(x) + \\phi(x-1) = -\\lambda \\phi(x). \\] Sean \\(r_\\pm\\) las raíces del polinomio característico \\(p(r) = r^2-(2-\\lambda)r+1\\). Tenemos así que6 \\[ \\phi(x) = A_+r_+^x+A_-r_-^x. \\] Observamos que para obtener soluciones \\(M\\)-periódicas basta con tomar a \\(r_\\pm\\) como raíces \\(M\\)-ésimas de la unidad, conjugadas entre si (dado que \\(r_+r_-=1\\)), de hecho la condición también terminará siendo necesaria. Es decir que \\[ r_\\pm = \\omega^{\\pm j}, \\qquad \\omega := e^{2\\pi i/M}, \\qquad j\\in\\{0,1,\\ldots,M-1\\}. \\] A partir de estas encontramos las autofunciones \\[ \\phi_{j}(x) := \\omega^{jx} \\] cuyos autovalores son \\(-\\lambda_j\\) donde \\[ \\lambda_j := \\omega^{j}+\\omega^{-j}-2 = 2\\cos(2\\pi j/M)-2 = 4\\sin^2(\\pi j/M). \\] La colección \\(\\phi_0,\\ldots,\\phi_{M-1}\\) forma una base ortogonal de \\(\\mathbb C^M\\) conocida como la base de Fourier \\[ \\sum_{x\\in V} \\phi_k(x)\\overline{\\phi_l(x)} = \\sum_{j=0}^{M-1} \\omega^{(k-l)j} = \\begin{cases} M \\text{ si } k=l,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Observa que \\(\\lambda_j = \\lambda_{M-j}\\), por lo que si \\(j\\) no es divisible por \\(M/2\\), el autovalor \\(\\lambda_j\\) tiene multiplicidad dos. En los demás casos el autovalor tiene multiplicidad uno. Ejercicio 5.2 Demuestra que a partir de \\[ \\varphi_j(x) := \\cos(2\\pi j x/M), \\qquad \\psi_j(x) := \\sin(2\\pi j x/M) \\] también se puede construir una base ortogonal de autovectores para el ejemplo anterior. Acá debes prestar atención de lo que sucede cuando \\(j=M/2\\) en caso de que \\(M\\) sea par. Solución Ejercicio 5.3 Calcula las normas de \\(\\varphi_j\\) y \\(\\psi_{j}\\). Solución \\(\\|\\varphi_j\\|^2=\\|\\psi_{j}\\|^2=M/2\\) Ejercicio 5.4 Calcula el espectro del Laplaciano en los siguientes casos: Sólidos platónicos: tetraedro, cubo, octaedro, dodecaedro, icosaedro, Grafo completo, Grafo bipartito completo, Grafo lineal, Grafo producto7 en términos del espectro de sus factores (que asumimos conocido). Por ejemplo un toro puede verse como el producto de grafos cíclicos. Solución 5.1 Problema elíptico Dada la descomposición \\[ f = \\sum_{j=0}^{|V|-1} \\hat f_j\\phi_j, \\qquad \\hat f_j = \\frac{1}{\\|\\phi_j\\|^2}\\sum_{x\\in V} f(x)\\overline{\\phi_j(x)}, \\] tenemos que \\(u = \\sum_{j=0}^{|V|-1} \\hat u_j\\phi_j\\) satisface \\(Lu=f\\) si y solo si para todo \\(j\\in\\{0,\\ldots,(|V|-1)\\}\\) \\[ -\\lambda_j \\hat u_j = \\hat f_j. \\] Recordemos la hipótesis de conexidad para \\(G\\) la cual garantiza que \\(\\lambda_0=0\\) es un autovalor simple cuyo autoespacio son las funciones constantes generadas por \\(\\phi_0=1\\). Para \\(j\\neq 0\\) tenemos \\(\\lambda_j &gt; 0\\) por lo cual \\(\\hat u_j = -\\hat f_j/\\lambda_j\\). Para \\(j=0\\) tenemos sin embargo que \\(\\lambda_0=0\\) en cuyo caso la ecuación tiene solución solamente si se da la condición de ortogonalidad \\(f\\perp \\phi_0\\), equivalente a decir que8 \\[ \\sum_{x\\in V} f(x) = 0. \\] Bajo esta hipótesis, el correspondiente coeficiente \\(\\hat u_0\\) es arbitrario. Bajo la condición anterior para \\(f\\), tenemos que las soluciones de \\(Lu=f\\) están dadas por \\[ u(x) = c - \\sum_{j=1}^{|V|-1} \\frac{\\hat f_j}{\\lambda_j}\\phi_j(x) = c - \\sum_{j=1}^{|V|-1} \\frac{1}{\\lambda_j\\|\\phi_j\\|^2}\\left(\\sum_{y\\in V} f(y)\\overline{\\phi_j(y)}\\right)\\phi_j(x). \\] El término constante es la solución homogénea del sistema. El segundo es una solución particular la cual podemos reescribir como \\[ u_p(x) := -\\sum_{y\\in V} G(x,y)f(y), \\qquad G(x,y) := \\sum_{j=1}^{|V|-1} \\frac{\\phi_j(x)\\overline{\\phi_j(y)}}{\\|\\phi_j\\|^2}\\lambda_j^{-1}. \\] Ejercicio 5.5 Demuestra que9 \\[ \\Delta_1 G(x,y) = \\Delta_2 G(x,y) = \\frac{1}{|V|}- 1_y(x)=\\frac{1}{|V|}- 1_x(y). \\] Solución Ejercicio 5.6 Demuestra que \\[ \\sum_{x\\in V} G(x,x) = \\sum_{j=1}^{|V|-1} \\lambda_j^{-1}. \\] Solución Ejercicio 5.7 Demuestra que \\(G\\) es independiente de la base de Fourier. Solución Ejercicio 5.8 Demuestra que \\(G(x,y)=G(y,x)\\). Solución Ejercicio 5.9 Demuestra que para \\(x\\in[0,M]\\) \\[ \\sum_{j=1}^{M-1} \\frac{e^{2\\pi i j x}-1}{\\sin^2(\\pi j/M)} = 2x(x-M) \\] Solución 5.2 Problema parabólico El sistema \\(\\partial_t u = Lu+f\\) se reduce a un sistema de ecuaciones diferenciales ordinarias desacopladas \\[ \\hat u_j&#39; = -\\lambda_j \\hat u_j + \\hat f_j \\] Usando por ejemplo la técnica del factor integrante obtenemos \\[ \\begin{aligned} \\hat u_j(t) &amp;= \\hat u_j(0)e^{-\\lambda_j t} + \\int_0^t \\hat f_j(s)e^{-\\lambda_j(t-s)}ds\\\\ &amp;= \\frac{1}{\\|\\phi_j\\|^2}\\sum_{y=1}^{|V|} \\left(u(y,0)\\overline{\\phi_j(y)}e^{-\\lambda_j t} + \\int_0^t f(y,s)\\overline{\\phi_j(y)}e^{-\\lambda_j(t-s)}ds\\right) \\end{aligned} \\] Agrupando los términos para la solución concluimos que \\[ u(x,t) = \\sum_{y\\in V} u(y,0)H(x,y,t) + \\int_0^t\\sum_{y\\in V} f(y,s)H(x,y,t-s)ds \\] donde \\[ H(x,y,t) := \\sum_{j=0}^{|V|-1} \\frac{\\phi_j(x)\\overline{\\phi_j(y)}}{\\|\\phi_j\\|^2}e^{-\\lambda_j t} = \\frac{1}{|V|} + \\sum_{j=1}^{|V|-1} \\frac{\\phi_j(x)\\overline{\\phi_j(y)}}{\\|\\phi_j\\|^2}e^{-\\lambda_j t}. \\] Ejercicio 5.10 Demuestra que \\(H(y,x,t) = H(x,y,t)\\). Solución Ejercicio 5.11 Demuestra que \\(H\\) es la solución del problema de valores iniciales \\[ \\begin{cases} \\partial_t H = \\Delta_1 H = \\Delta_2 H,\\\\ H = 1_y(x)= 1_x(y) \\text{ para $t=0$}. \\end{cases} \\] Concluye a partir de esto que \\(H\\) es independiente de la base de Fourier. Solución Ejercicio 5.12 Sea \\(u\\) tal que \\(\\partial_t u = \\Delta u\\). Calcula \\(\\lim_{t\\to\\infty} u(t)\\) en términos de \\(u(0)\\). Solución \\(\\lim_{t\\to\\infty} u(t) = \\frac{1}{M}\\sum_{x\\in V}u(x,0)\\) Ejercicio 5.13 Para \\(G\\) conexo demuestra que se da la siguiente expresión asintótica cuando \\(t\\to\\infty\\) \\[ \\int_0^t H(x,y,s)ds = \\frac{t}{|V|} + G(x,y) + O(e^{-\\lambda_1 t}) \\] Solución 5.3 Problema hiperbólico El sistema \\(\\partial_t^2 u = Lu+f\\) también se reduce a un sistema de ecuaciones desacopladas de segundo orden \\[ \\hat u_j&#39;&#39; = -\\lambda_j \\hat u_j + \\hat f_j \\] Tenemos así que \\(\\hat u_j(t)\\) se puede calcular en términos de su posición y velocidad inicial. Para \\(j=0\\) \\[\\begin{align*} \\hat u_0(t) &amp;= \\hat u_0(0) + \\hat u_0&#39;(0) t + \\int_0^t \\hat f_0(s)(t-s)ds. \\end{align*}\\] Para \\(j\\neq0\\) denotamos la frecuencia \\(\\omega_j=\\sqrt{\\lambda_j}\\) tal que \\[\\begin{align*} \\hat u_j(t) &amp;= \\hat u_j(0)\\cos(\\omega_j t) + \\hat u_j&#39;(0)\\frac{\\sin(\\omega_j t)}{\\omega_j} + \\int_0^t \\hat f_j(s)\\frac{\\sin(\\omega_j(t-s))}{\\omega_j}ds. \\end{align*}\\] Agrupando los términos para la solución concluimos que \\[ u(x,t) = \\sum_{j=0}^{|V|-1} u(y,0)W_1(x,y,t)+\\partial_t u(y,0)W_2(x,y,t) + \\int_0^t f(y,s)W_2(x,y,t-s)ds \\] donde \\[\\begin{align*} W_1(x,y,t) &amp;:= \\sum_{j=0}^{|V|-1} \\frac{\\phi_j(x)\\overline{\\phi_j(y)}}{\\|\\phi_j\\|^2}\\cos(\\omega_j t), \\\\ W_2(x,y,t) &amp;:= \\frac{t}{|V|} + \\sum_{j=1}^{|V|-1} \\frac{\\phi_j(x)\\overline{\\phi_j(y)}}{\\|\\phi_j\\|^2}\\frac{\\sin(\\omega_j t)}{\\omega_j}. \\end{align*}\\] Ejercicio 5.14 (Ley de Stokes) Demuestra que si \\[ \\begin{cases} \\partial_t^2u = Lu,\\\\ u|_{t=0} = 0,\\\\ \\partial_t u|_{t=0} = v_0, \\end{cases} \\qquad\\Leftrightarrow\\qquad u(x,t) = \\sum_{j=0}^{M-1} v_0(y)W_2(x,y,t) \\] entonces \\(v = \\partial_tu\\) satisface \\[ \\begin{cases} \\partial_t^2v = Lv,\\\\ v|_{t=0} = v_0,\\\\ \\partial_t v|_{t=0} = 0, \\end{cases} \\qquad\\Leftrightarrow\\qquad v(x,t) = \\sum_{j=0}^{M-1} v_0(y)W_1(x,y,t). \\] Solución 5.4 Nerd sniping En esta sección veremos como resolver el problema presentado en la siguiente caricatura de Randall Munroe autor de XKCD. La resistencia efectiva se define de la siguiente forma. Etiquetemos primero los nodos de la red por \\((x,y) \\in \\mathbb Z^2\\) tales que los nodos marcados son el origen \\((0,0)\\) y \\((2,1)\\). Se fija un potencial \\(u\\) sobre la red tal que \\(u(0,0)=0\\), \\(u(2,1)=1\\), mientras que en los demás nodos \\(u\\) es armónica, es decir que para \\((x,y) \\in \\mathbb Z^2 \\setminus \\{(0,0),(2,1)\\}\\) \\[ \\Delta u(x,y) = u(x-1,y) + u(x+1,y) + u(x,y-1) + u(x,y+1) - 4u(x,y) = 0. \\] Para que \\(u\\) esté definida de forma unívoca hay que pedir adicionalmente que \\(u\\to 0\\) cuando \\(|(x,y)|\\to \\infty\\). Desde una perspectiva física esta condición en infinito es la más natural. La corriente \\(i\\) que sale del origen es la divergencia de \\(u\\) en dicho punto, \\(i= \\operatorname{div} u(0,0)\\). Este es a su vez la corriente que entra en el vértice \\((2,1)\\) la cual se calcula de igual forma como \\(i = -\\operatorname{div} u(2,1)\\). Si buscamos simplificar la red por el caso más sencillo que conecta a \\((0,0)\\) y \\((2,1)\\), es decir el grafo con solamente estos dos vértices y una arista entre ellos, entonces la resistencia efectiva \\(R\\) es aquella que debemos dar a esta única conexión para que la corriente siga siendo \\(i\\) bajo el mismo potencial. En otras palabras \\(R = 1/i\\). Como primer paso veremos como calcular el potencial análogo en el toro \\(V_{N} = (\\mathbb Z/N\\mathbb Z)^2\\), es decir un problema periódico donde identificamos las coordenadas enteras módulo \\(N\\gg1\\). Cuando \\(N\\to \\infty\\) el potencial eléctrico converge al potencial en \\(\\mathbb Z^2\\). Este límite, a pesar de ser intuitivo, amerita una demostración que no presentaremos dado que buscamos enfatizar otras ideas por el momento. La ventaja de esta aproximación es que ahora nuestra ecuación es un problema de álgebra lineal en un espacio de dimensión \\(N^2-2\\) \\[ \\Delta u = 0 \\text{ en } V_{N}\\setminus \\{(0,0),(2,1)\\}, \\qquad u(0,0)=0,\\qquad u(2,1)=1. \\] De las discusiones previas sabemos que a partir de la descomposición espectral del Laplaciano en \\(V_{N}\\) podríamos calcular en cambio una solución particular de \\[ \\Delta v = 1_{(0,0)}- 1_{(2,1)} \\text{ en } V_{N}. \\] Notemos que el lado derecho es de hecho perpendicular a las constantes, lo cual garantiza la existencia de soluciones. Para obtener \\(u\\) a partir de \\(v\\) verificamos que \\[ u(x,y) = \\frac{v(x,y)-v(0,0)}{v(2,1)-v(0,0)} \\] satisface la ecuación requerida y entonces \\[ R_N = \\frac{1}{\\operatorname{div} u(0,0)} = \\frac{v(2,1)-v(0,0)}{\\operatorname{div} v(0,0)} = v(2,1)-v(0,0). \\] Nuestra estrategia será entonces calcular el límite de esta expresión cuando \\(N\\to\\infty\\). Procedamos a calcular el espectro del Laplaciano sobre el toro (Ejercicio 5.4). Asumamos la hipótesis de \\[ \\phi(x,y) = \\alpha(x)\\beta(y). \\] Este tipo de funciones toman ventaja de la simetría del problema con lo cual el Laplaciano se simplifica como operadores discretos más sencillos para cada factor \\[ \\Delta \\phi(x,y) = \\alpha(x)(\\beta(y-1)-2\\beta(y)+\\beta(y+1)) + (\\alpha(x-1)-2\\alpha(x)+\\alpha(x+1))\\beta(y). \\] Si \\(\\alpha\\) y \\(\\beta\\) son autofunciones del Laplaciano en el grafo cíclico de tamaño \\(N\\), entonces \\(\\phi\\) es una autofunción en el toro. Tomemos de esta forma la base de Fourier \\[ \\phi_{k,l}(x,y) = \\omega^{kx+ly}, \\qquad \\omega = e^{2\\pi i/N}, \\qquad (k,l)\\in\\{0,1,\\ldots,(N-1)\\}^2, \\] con autovalores \\(-\\lambda_{k,l}\\) tal que \\[ \\lambda_{k,l} := 4(\\sin^2(\\pi k/N)+\\sin^2(\\pi l/N)), \\] y normas \\[ \\|\\phi_{k,l}\\|^2=\\sum_{(x,y)\\in V_N} \\phi_{k,l}(x,y)\\overline{\\phi_{k,l}(x,y)} = N^2. \\] Ejercicio 5.15 Verifica que a partir de las siguientes funciones también se puede formar una base ortogonal del Laplaciano \\[\\begin{align*} \\cos(2\\pi kx/N)\\cos(2\\pi ly/N),\\quad \\cos(2\\pi kx/N)\\sin(2\\pi ly/N),\\quad \\sin(2\\pi kx/N)\\sin(2\\pi ly/N). \\end{align*}\\] Solución Finalmente reconstruimos la solución particular usando la fórmula de representación \\[\\begin{align*} v(x,y) &amp;= -\\sum_{(x&#39;,y&#39;) \\in V_N} K(x,y;x&#39;,y&#39;)( 1_{(0,0)}- 1_{(2,1)})(x&#39;,y&#39;) = K(x,y;2,1)-K(x,y;0,0). \\end{align*}\\] donde para \\(\\omega = e^{2\\pi i/N}\\) \\[ K(x,y;x&#39;,y&#39;) = \\frac{1}{N^2}\\sum_{(k,l)\\neq (0,0)} \\frac{\\phi_{k,l}(x,y)\\overline{\\phi_{k,l}(x&#39;,y&#39;)}}{\\lambda_{k,l}} = \\frac{1}{4N^2}\\sum_{(k,l)\\neq (0,0)} \\frac{\\omega^{k(x-x&#39;)+l(y-y&#39;)}}{\\sin^2(\\pi k/N)+\\sin^2(\\pi l/N)}. \\] La resistencia efectiva es calculada así por \\[\\begin{align*} R &amp;= v(2,1)-v(0,0),\\\\ &amp;= K(2,1;2,1)-K(2,1;0,0) - K(0,0;2,1)+K(0,0;0,0),\\\\ &amp;= \\frac{1}{2N^2} \\sum_{(k,l)\\neq (0,0)} \\frac{1-\\cos((2k+l)2\\pi/N)}{\\sin^2(\\pi k/N)+\\sin^2(\\pi l/N)},\\\\ &amp;= \\frac{1}{N^2} \\sum_{(k,l)\\neq (0,0)} \\frac{\\sin^2((2k+l)\\pi/N)}{\\sin^2(\\pi k/N)+\\sin^2(\\pi l/N)}. \\end{align*}\\] En el límite podemos entonces calcular \\(R\\) por la integral de Riemann \\[ R = \\frac{1}{\\pi^2}\\int_0^\\pi\\int_0^\\pi \\frac{\\sin^2(2x+y)}{\\sin^2x+\\sin^2y}dydx \\] Evaluamos numericamente la integral usando import numpy as np from scipy.integrate import dblquad integrando = lambda x, y : np.sin(2*x+y)**2/(np.sin(x)**2+np.sin(y)**2) integral, error = dblquad(integrando,0,np.pi,0,np.pi) R = integral/np.pi**2 print(R) ## 0.7732395447351639 De forma alternativa es posible calcular analíticamente la integral dando como resultado \\[ R = \\frac{4}{\\pi}-\\frac{1}{2} \\] Ejercicio 5.16 Sea \\[ R(m,n) = \\int_0^\\pi\\int_0^\\pi \\frac{\\sin^2(mx+ny)}{\\sin^2x+\\sin^2y}dydx. \\] Demuestra que \\(R:\\mathbb Z^2\\to \\mathbb R\\) es una función armónica en \\(\\mathbb Z^2\\setminus\\{(0,0)\\}\\). Solución Salvo en el caso de que \\(r_+=r_-\\) que podemos analizar más adelante si hiciese falta… No hará falta.↩︎ El producto de \\(G_1\\) y \\(G_2\\) tiene como vértices \\(V_1\\times V_2\\) siendo \\(((x_1,x_2),(y_1,y_2))\\) una arista en este grafo si alguna de las siguientes dos condiciones se cumplen: \\(x_1=y_1\\) y \\((x_2,y_2)\\) es una arista en \\(G_1\\), o bien \\(x_2=y_2\\) y \\((x_1,y_1)\\) es una arista en \\(G_2\\).↩︎ También puede verse como consecuencia del Teorema de la divergencia↩︎ Como \\(G\\) es una función en \\(V^2\\), definimos a \\(\\Delta_1\\) y \\(\\Delta_2\\) como los Laplacianos en la primera o segunda entrada respectivamente.↩︎ "],["el-problema-de-dirichlet.html", "Capítulo 6 El problema de Dirichlet 6.1 Ley de conservación 6.2 Existencia y unicidad de soluciones 6.3 Fórmulas de representación 6.4 Caminatas Aleatorias", " Capítulo 6 El problema de Dirichlet Un barrendero tiene la tarea de limpiar una dada región (acotada) en cuarto cubierto de baldosas. Cada vez que este barre una baldosa, toda la masa que se encuentra en ella se distribuye en porciones iguales entre las cuatro baldosas adyacentes. En general, limpiar la región es un proceso que entendemos en el límite de un número infinito de pasos. El orden en que se barren las baldosas no es conmutativo, véase por ejemplo la figura a continuación. Sin embargo, descubrimos que en el límite se recupera una cierta propiedad Abeliana: Una vez limpia la región, la distribución de masa alrededor de ella es independiente de como se haya barrido. El problema lo podemos modelar en un grafo general pero con la intención de ilustrar un caso concreto pensemos en la retícula \\(\\mathbb Z^2\\) con la relación de adyacencia \\(x\\sim y\\) cuando \\(\\|x-y\\| = 1\\). Es decir que cada baldosa tiene exactamente cuatro baldosas adyacentes en cada una de las direcciones cardinales. Sea \\(\\mu:\\mathbb Z^2\\to [0,\\infty)\\) la distribución de masa inicial que buscamos barrer de algún \\(\\Omega\\subseteq\\mathbb Z^2\\). Un plan de barridas está dado por una lista de baldosas \\(b_1,b_2,\\ldots \\in \\Omega\\), las que iremos barriendo en el orden respectivo. Si \\(\\infty_i:\\mathbb Z^2\\to [0,\\infty)\\) denota la distribución de masa luego del \\(i^{mo}\\) paso, se tiene entonces la siguiente fórmula recursiva comenzando de \\(\\mu_0:=\\mu\\), \\[ \\mu_i(x) := \\begin{cases} 0 \\text{ si } x=b_i\\\\ \\mu_{i-1}(x) + \\tfrac{1}{4}\\mu_{i-1}(b_i) \\text{ si } x\\sim b_i\\\\ \\mu_{i-1}(x) \\text{ en cualquier otro caso}. \\end{cases} \\] Decimos que el plan plan \\(b_1,b_2,\\ldots \\in \\Omega\\) barre a \\(\\mu\\) de \\(\\Omega\\) si \\[ \\lim_{i\\to\\infty} \\mu_i(x) = 0, \\qquad \\forall x\\in \\Omega. \\] Nuestro teorema puede ser entonces formulado de la siguiente manera. Teorema 6.1 Dado \\(\\Omega\\subseteq\\mathbb Z^2\\) finito y \\(\\mu:\\mathbb Z^2\\to [0,\\infty)\\) se tiene que cualesquiera dos planes \\(b_1,b_2,\\ldots \\in \\Omega\\) y \\(b_1&#39;,b_2&#39;,\\ldots \\in \\Omega\\) que barren a \\(\\mu\\) de \\(\\Omega\\) satisfacen que los siguientes límites existen para todo \\(x\\in \\mathbb Z^2\\) y \\[ \\lim_{i\\to \\infty} \\mu_i(x) = \\lim_{i\\to \\infty} \\mu&#39;_i(x). \\] Daremos la demostración del teorema en la Sección Principio del mínimo luego de presentar y motivar algunas construcciones auxiliares. 6.1 Ley de conservación Una idea útil es llevar el registro de cuánta masa ha salido de una dada baldosa \\(x\\) hasta una dada iteración. Para ser precisos definimos para cada subíndice \\(i\\geq 0\\) las funciones \\(u_i:\\mathbb Z^2\\to [0,\\infty)\\) comenzando por \\(u_0=0\\) y de forma inductiva según \\[ u_i := u_{i-1} + \\mu_{i-1}(b_i) 1_{b_i} \\] Observemos que para cualquier plan \\(b_1,b_2,\\ldots \\in \\Omega\\) se tiene necesariamente que \\(u_i=0\\) en \\(\\mathbb Z^2\\setminus \\Omega\\). La función \\(u_i\\) nos permite dar una fórmula para la ley de conservación de masas: En los primeros \\(i\\) pasos, la masa que entra menos la que sale de una baldosa \\(x\\) es justamente la diferencia entre las distribuciones \\(\\mu_i\\) menos \\(\\mu_0\\) en \\(x\\) \\[ \\underbrace{\\mu_i(x)}_{\\text{masa final}}-\\underbrace{\\mu_0(x)}_{\\text{masa inicial}} = \\underbrace{\\frac{1}{4}\\sum_{y\\sim x} u_i(y)}_{\\text{masa que entra}} - \\underbrace{u_i(x)}_{\\text{masa que sale}} = \\tfrac{1}{4}\\Delta u(x) \\] Esta puede ser demostrada por un argumento inductivo que dejamos de ejercicio. Volviendo al modelo del barrendero, vemos que si \\(\\mu_i \\to \\mu_\\infty\\) entonces \\(u_i\\) también converge a una función \\(u:\\mathbb Z^2\\to[0,\\infty)\\)10 tal que \\(\\tfrac{1}{4}\\Delta u = \\mu_\\infty - \\mu_0 = \\mu_\\infty-\\mu\\). Si el plan barre a \\(\\Omega\\) recuperamos el siguiente sistema de ecuaciones lineales \\[\\begin{align}\\label{eq:lap} \\begin{cases} -\\tfrac{1}{4}\\Delta u = -\\mu \\text{ en } \\Omega,\\\\ u = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\end{align}\\] Veamos a grandes rasgos las ideas en la demostración del Teorema 6.1 a partir de estas construcciones. Si el sistema que satisface \\(u\\) tiene una solución, entonces esta función queda determinada por \\(\\mu\\) y \\(\\Omega\\) y es independientemente del plan. Usando que \\(\\mu_\\infty = \\mu + \\lim_{i\\to\\infty} \\tfrac{1}{4}\\Delta u_i = \\mu+\\tfrac{1}{4}\\Delta u\\) vemos que también \\(\\mu_\\infty\\) es independientemente del plan, lo cual concluiría la demostración. Ejercicio 6.1 Asumiendo la estrategia esbozada en esta sección, calcula la distribución final \\(\\mu_\\infty\\) si \\(\\Omega = \\{(0,0),(1,0),(0,1)\\}\\) y \\(\\mu= 1_\\Omega\\). Solución 6.2 Existencia y unicidad de soluciones El principio del mínimo nos permitirá demostrar que el sistema dado por \\(\\eqref{eq:lap}\\) no tiene más de una solución. Para problemas lineales con igual número (finito) de ecuaciones e incógnitas, esto equivale a decir que el sistema de hecho siempre tiene solución. 6.2.1 Principio del mínimo La idea consiste en el siguiente principio general: Si \\(u:V\\to\\mathbb R\\) es no-negativa en \\(V\\setminus \\Omega\\) y satisface \\(\\Delta u\\leq 0\\) en \\(\\Omega\\) entonces \\(u\\) es necesariamente no-negativa en \\(\\Omega\\). Como veremos en la siguiente demostración, esto es una manifestación del criterio de la segunda derivada (discreto): \\(\\Delta u(x^*)\\geq 0\\) si \\(u\\) alcanza su mínimo en \\(x^*\\). Lema 6.1 (Principio del Mínimo) Sea \\(u:V\\to\\mathbb R\\) tal que para \\(\\Omega\\subseteq V\\) finito \\(\\Delta u \\leq 0\\) en \\(\\Omega\\). Entonces \\[ \\inf_{V\\setminus\\Omega} u \\geq 0 \\qquad\\Rightarrow\\qquad \\min_{\\Omega} u\\geq 0. \\] Demostración. Asumamos por contradicción que \\(m:= \\min_{\\Omega} u &lt; 0\\) y sea \\(\\Omega&#39;=\\{x\\in \\Omega : u(x) = m\\}\\) finito y no vacío, más aún sabemos que es finito dado que \\(\\Omega&#39;\\subseteq\\Omega\\). Tomemos ahora \\(x^*\\in \\Omega&#39;\\) tal que existe \\(y\\sim x^*\\) para el cual \\(u(y)&gt;u(x^*)\\). Vemos ahora que tenemos la siguiente contradicción a partir de evaluar la ecuación \\(\\Delta u\\leq 0\\) sobre \\(x^*\\) \\[ 0 &lt; \\sum_{z\\sim x^*} (u(z) -u(x^*)) = \\Delta u(x^*) \\leq 0. \\] Corolario 6.1 (Existencia y unicidad de soluciones) Para \\(\\Omega\\subseteq V\\) finito y \\(\\mu,\\varphi:V\\to\\mathbb R\\) el siguiente sistema tiene solución única \\[ \\begin{cases} \\Delta u = \\mu \\text{ en } \\Omega,\\\\ u = \\varphi \\text{ en } V\\setminus \\Omega. \\end{cases} \\] Demostración. Basta con demostrar que el sistema lineal dado por las ecuaciones en \\(\\Omega\\), con \\(N=|\\Omega|\\) ecuaciones e incógnitas, tiene a lo sumo una solución. En otras palabras, el operador lineal asociado de \\(\\mathbb R^N\\) en si mismo es inyectivo, y por lo tanto también es biyectivo gracias al teorema fundamental del álgebra lineal. Si \\(u,v:V\\to \\mathbb R\\) son dos soluciones, entonces \\(w:=u-v\\) satisface \\(\\Delta w=0\\) en \\(\\Omega\\) y \\(w = 0\\) en \\(V\\setminus \\Omega\\). Gracias al principio del mínimo obtenemos que \\(w\\geq 0\\) en \\(\\Omega\\) y por lo tanto en todo \\(V\\). Si aplicamos el mismo razonamiento a \\(-w\\) obtenemos la otra desigualdad de donde concluimos \\(w=0\\), es decir que queda establecida la unicidad de soluciones y con ello la demostración. Ejercicio 6.2 Demuestra que si \\(\\Omega = \\{x = (x_1,x_2) \\in \\mathbb Z^2 : x_2&gt;0\\}\\) entonces existen por lo menos dos soluciones distintas del problema \\[ \\begin{cases} \\Delta u = 0 \\text{ en } \\Omega,\\\\ u = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Es decir que la hipótesis de que \\(\\Omega\\) sea finito es necesaria para la unicidad de soluciones. Solución Demostración (Teorema 6.1). Construimos de forma recursiva y partiendo de \\(u_0 := 0\\) las funciones \\(u_i := u_{i-1} + \\mu_{i-1} 1_{b_i}\\) las cuales verifican \\[ \\begin{cases} \\tfrac{1}{4}\\Delta u_i = \\mu_i-\\mu \\text{ en } \\Omega,\\\\ u_i = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Definimos también \\(u:\\mathbb Z^2\\to \\mathbb R\\) como la solución de \\[ \\begin{cases} \\tfrac{1}{4}\\Delta u = -\\mu \\text{ en } \\Omega,\\\\ u = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Debemos corroborar entonces los siguientes puntos: \\(\\mu_{\\infty} := \\lim_{i\\to\\infty}\\mu_i\\) está bien definido. \\(u_\\infty := \\lim_{i\\to\\infty}u_i\\) está bien definido. \\(u_\\infty = u\\). Para ver el primer punto basta con fijarse en el comportamiento de \\(\\mu_i\\) en \\(\\mathbb Z^2\\setminus \\Omega\\), ya que sabemos por hipótesis que estas tienden a cero en \\(\\Omega\\). En \\(\\mathbb Z^2\\setminus \\Omega\\) se tiene que \\(\\mu_i\\) es una sucesión no-decreciente de funciones que está mayorizada por \\(\\mu + \\sum_{x\\in\\Omega} \\mu(x)\\). Como \\(u_i\\) es no-decreciente, basta con probar que \\(u\\geq u_i\\) para demostrar el segundo punto y adicionalmente obtener \\(u\\geq u_\\infty\\). La diferencia \\(v_i := u-u_i\\) satisface \\[ \\begin{cases} \\Delta v_i = \\Delta u - \\Delta u_i = -4\\mu_i \\leq 0 \\text{ en } \\Omega,\\\\ v_i = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Gracias principio del mínimo se deduce que \\(\\min_\\Omega v_i \\geq 0\\) y por lo tanto \\(u\\geq u_i\\). Dado que \\(b_1,b_2,\\ldots\\in\\Omega\\) barre a \\(\\mu\\) de \\(\\Omega\\) tenemos que tomando \\(i\\to\\infty\\) en el sistema para \\(u_i\\) \\[ \\begin{cases} \\tfrac{1}{4}\\Delta u_\\infty = -\\mu \\text{ en } \\Omega,\\\\ u_\\infty = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Por la unicidad de soluciones del problema lineal llegamos a que necesariamente \\(u_\\infty=u\\). Finalmente para concluir la demostración podemos calcular \\(\\mu_\\infty\\) a partir de \\(\\mu_\\infty = \\mu+\\tfrac{1}{4}\\Delta u_\\infty\\). Recordemos que \\(u_\\infty=u\\) está igualmente definido por un sistema de ecuaciones lineales que depende solamente de \\(\\Omega\\) y \\(\\mu\\) y no del plan. Esto indica que \\(\\mu_\\infty\\) también está definida independientemente del plan. Nuestro teorema garantiza que para cualquier \\(\\Omega\\subseteq\\mathbb Z^2\\) finito y \\(\\mu:\\mathbb Z^2\\to [0,\\infty)\\) se tiene que si \\(\\mu\\) puede ser barrido de \\(\\Omega\\), entonces la distribución de masa que queda por fuera de \\(\\Omega\\) es independiente del plan. Queda abierta la pregunta de si podemos en todo caso barrer o no a \\(\\mu\\) de \\(\\Omega\\). Teorema 6.2 Dado \\(\\Omega\\subseteq\\mathbb Z^2\\) finito y \\(\\mu:\\mathbb Z^2\\to[0,\\infty)\\) existe un plan \\(b_1,b_2,\\ldots\\in\\Omega\\) que barre a \\(\\mu\\) de \\(\\Omega\\). Demostración. Sea \\(b_1,b_2,\\ldots\\in\\Omega\\) un plan que recorre cada baldosa un número infinito de veces. Ciertamente estos planes existen incluso si \\(\\Omega\\) es infinito (usando un argumento de diagonal de Cantor). Esta condición implica que para cada \\(x\\in\\Omega\\), existe un número infinito de sub-índices tales que \\(\\mu_i(x)=0\\). Basta probar así que \\(\\mu_\\infty = \\lim_{i\\to\\infty}\\mu_i\\) existe para deducir que necesariamente \\(\\mu_\\infty=0\\) en \\(\\Omega\\). Definimos \\(u_i\\) y \\(u\\) exactamente como en la demostración anterior. Recordemos que \\(u_i\\) es no-decreciente y (por el principio del mínimo) acotada por \\(u\\), por lo tanto \\(u_\\infty:=\\lim_{i\\to\\infty}u_i\\) está bien definida. Dado que \\(\\mu_i = \\mu + \\Delta u_i\\) tenemos que la existencia del límite para \\(\\mu_i\\) queda demostrada por la existencia del límite para \\(u_i\\). Ejercicio 6.3 Demuestra que existe un plan que barre a \\(\\mu= 1_{(1,0)}\\) de \\(\\Omega = \\mathbb Z^2\\setminus \\{(0,0)\\}\\). Solución Ejercicio 6.4 Sea \\(\\Omega\\subseteq\\mathbb Z^2\\) finito, \\(\\mu:\\mathbb Z^2\\to[0,\\infty)\\) y \\(\\mu_\\infty\\) la distribución que resulta al barrer \\(\\mu\\) de \\(\\Omega\\). Demuestra ley de conservación de masa dada por \\[ \\sum_{x\\in\\mathbb Z^2} \\mu_\\infty(x) = \\sum_{x\\in \\mathbb Z^2} \\mu(x). \\] Solución Ejercicio 6.5 Sea \\(\\mu= 1_{(1,0)}\\) y \\(\\mu_\\infty\\) la distribución que resulta al barrer \\(\\mu\\) de \\(\\Omega= \\mathbb Z^2\\setminus \\{(0,0)\\}\\). ¿Será cierto que \\(\\mu_\\infty(0,0) = 1\\), o habrá masa que escapa a infinito?11 Solución 6.2.2 Método de Balayage Poincaré propuso a finales del siglo XIX el siguiente algoritmo para resolver el sistema \\[ \\begin{cases} \\Delta u = 0 \\text{ en } \\Omega,\\\\ u = \\varphi \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases}. \\] Asumamos \\(\\Omega\\) finito y sea \\(\\partial\\Omega := \\{y \\in \\mathbb Z^2\\setminus \\Omega : \\exists x\\in \\Omega \\text{ adyacente a } y\\}\\). Comenzamos entonces a partir de \\[ u_0(x) := \\begin{cases} \\max_{\\partial\\Omega}\\varphi \\text{ si } x\\in\\Omega,\\\\ \\varphi(x) \\text{ en cualquier otro caso}. \\end{cases}, \\] tal que \\[ \\begin{cases} \\Delta u_0 \\leq 0 \\text{ en } \\Omega,\\\\ u_0 = \\varphi \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Hagamos notar que por el principio del mínimo, \\(u_0\\geq \\min_{\\partial\\Omega} \\varphi\\). Sea \\(b_1,b_2,\\ldots \\in \\Omega\\) tal que para cada \\(x\\in \\Omega\\) el conjunto de índices \\(\\{i : b_i=x\\}\\) es infinito. Definimos ahora \\(u_i\\) modificando a \\(u_{i-1}\\) en \\(b_i\\) de forma que \\(\\Delta u_i(b_i) =0\\), es decir \\[ u_i(x) := \\begin{cases} \\frac{1}{4} \\sum_{y\\sim b_i} u_{i-1}(y) \\text{ si } x = b_i,\\\\ u_{i-1}(x) \\text{ en cualquier otro caso}. \\end{cases} \\] En otras palabras, en el paso \\(i\\) estamos barriendo el Laplaciano de \\(u_{i-1}\\) en \\(b_i\\). Se puede demostrar por inducción que cada \\(u_i\\) satisface \\[ \\begin{cases} \\Delta u_i \\leq 0 \\text{ en } \\Omega,\\\\ u_i = \\varphi \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Gracias a esto observamos que la sucesión es decreciente. También, cuando la restringimos a \\(\\Omega\\), está acotada por debajo por \\(\\min_{\\partial\\Omega}\\varphi\\). Como consecuencia converge a la solución que se busca calcular. Ejercicio 6.6 Implementa el método de balayage. El programa debe recibir un conjunto \\(\\Omega\\subseteq\\mathbb Z^2\\) finito junto con \\(\\varphi:\\partial\\Omega\\to\\mathbb R\\), debe devolver la solución correspondiente del problema de Dirichlet \\(u:\\Omega\\to \\mathbb Z^2\\). Solución 6.3 Fórmulas de representación 6.3.1 La función de Green Para \\(\\Omega\\subseteq V\\) finito, definimos la función de Green \\(G_\\Omega:V^2\\to\\mathbb R\\) tal que \\(u(y)=G_\\Omega(x,y)\\) es la solución de \\[ \\begin{cases} \\Delta u = - 1_x \\text{ en } \\Omega,\\\\ u=0 \\text{ en } V\\setminus \\Omega. \\end{cases} \\] Ejemplo 6.1 Si \\(\\Omega=\\{x_0\\}\\), entonces \\[ G_\\Omega(x,y) = \\begin{cases} 1/\\deg(x_0) \\text{ si } y=x=x_0,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] donde \\(\\deg(x_0)\\) es el grado del vértice \\(x_0\\), es decir cuantas aristas llegan y salen de \\(x_0\\). Igualmente definimos \\(G_\\Omega\\) sobre una distribución \\(\\mu:V\\to\\mathbb R\\) tal que \\(u(y)=G_\\Omega(\\mu,y)\\) es la solución de \\[ \\begin{cases} \\Delta u = -\\mu \\text{ en } \\Omega,\\\\ u=0 \\text{ en } V\\setminus \\Omega. \\end{cases} \\] Es decir que en particular \\(G_\\Omega(x,\\cdot) = G_\\Omega( 1_x,\\cdot)\\). Gracias al principio de superposición tenemos que a partir de esta podemos resolver \\[ \\begin{cases} \\Delta u = -\\mu \\text{ en } \\Omega,\\\\ u=0 \\text{ en } V\\setminus \\Omega. \\end{cases} \\] usando la fórmula de representación \\[ u(y) = \\sum_{x\\in V} \\mu(x)G_\\Omega(x,y) = G_\\Omega(\\mu,y). \\] Ejemplo 6.2 Para el problema del barrendero (\\(V=\\mathbb Z^2\\)) tenemos que \\(u(y)= 4G_\\Omega(\\mu,y)\\) indica cuanta masa sale de \\(y\\) cuando se barre \\(\\mu\\) de \\(\\Omega\\). Ejemplo 6.3 Veamos como calcular la función de Green para \\(\\Omega = [1,n] \\subseteq V=\\mathbb Z\\) con \\(n\\geq 1\\) y la relación de adyacencia dada por \\(x\\sim y\\) si \\(|x-y|=1\\). Denotamos a lo largo de este ejemplo a \\(g_{i,j} := G_\\Omega(i,j)\\) con \\(i,j\\in \\{0,1,\\ldots,n,n+1\\}\\), los valores de interés (\\(G_\\Omega(x,y) = 0\\) fuera de estos casos). Para \\(j\\in[1,i-1]\\), tenemos la ecuación \\[ 2g_{i,j} = g_{i,j-1}+g_{i,j+1}, \\] la cual junto a \\(g_{i,0} = 0\\) indica que \\(g_{i,j}=\\alpha j\\) para \\(j\\in[0,i]\\). Para \\(j\\in[i+1,n]\\), tenemos también la ecuación \\[ 2g_{i,j} = g_{i,j-1}+g_{i,j+1}, \\] la cual junto a \\(g_{i,n+1} = 0\\) indica que \\(g_{i,j}=\\beta(n+1-j)\\) para \\(j\\in[i,n+1]\\). Por un lado sabemos que \\(\\alpha i = \\beta(n+1-i)\\) y adicionalmente usando la ecuación para \\(j=i\\) \\[ -1=g_{i,i-1}+g_{i,i+1}-2g_{i,i} = -\\alpha-\\beta \\] obtenemos que \\(\\alpha=(n+1-i)/(n+1)\\) y \\(\\beta=i/(n+1)\\). En conclusión \\[ g_{i,j} = \\begin{cases} (n+1-i)j/(n+1) \\text{ si } j\\in[1,i),\\\\ (n+1-j)i/(n+1) \\text{ si } j\\in(i,n],\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Ejercicio 6.7 Calcula la función de Green para \\(\\Omega = [1,n]\\times\\{0\\}\\cap \\mathbb Z^2\\). Solución Los ejemplos previos sugieren la siguiente simetría \\[ G_\\Omega(x,y)=G_\\Omega(y,x). \\] Demostración. Usaremos en repetidas ocasiones que si alguno de los nodos \\(x\\) o \\(y\\) están en \\(V\\setminus \\Omega\\) se tiene automáticamente que \\(G_\\Omega(x,y)=G_\\Omega(y,x)=0\\). Basta ver que \\((x,y) \\mapsto G_\\Omega(y,x)\\) satisface las mismas condiciones para la definición de \\(G_\\Omega\\), es decir que \\(v(y) = G_\\Omega(y,x)\\) cumple \\[ \\begin{cases} \\Delta v = - 1_x \\text{ en } \\Omega,\\\\ v = 0 \\text{ en } V\\setminus \\Omega. \\end{cases} \\] Las condición de borde ya sabemos que se satisface. Para ver la ecuación asumimos que \\(x\\in \\Omega\\) (el otro caso siendo tivial) y comprobaremos que \\(w(x) = \\Delta_1 G(y,x)+ 1_y(x) = \\Delta_1 G(y,x)+ 1_x(y)=0\\) para cualquier \\(y\\in \\Omega\\). Por un lado tenemos la condición de borde \\[ w(x) = 0+0 = 0 \\text{ si } x\\in V\\setminus \\Omega. \\] Por el otro tenemos que \\[ \\Delta w (x) = \\Delta_2\\Delta_1G(y,x)+\\Delta 1_y(x) = \\Delta_1\\Delta_2 G(y,x)+\\Delta 1_y(x) = \\Delta 1_{y}(x) - \\Delta 1_y(x)=0. \\] Gracias a la unicidad de la solución trivial podemos finalmente concluir la demostración. 6.3.2 El núcleo de Poisson Para \\(\\Omega\\subseteq V\\) finito, \\(x,y \\in V\\) definimos el núcleo de Poisson \\[ P_\\Omega(x,y) := 1_x (y) + \\Delta_2 G_\\Omega(x,y). \\] Observemos los valores no triviales de \\(P_\\Omega(x,y)\\) ocurren cuando \\(x\\in \\Omega\\) y \\(y\\in V\\setminus \\Omega\\). Si \\(x\\in V\\setminus \\Omega\\) entonces \\(G_\\Omega(x,\\cdot) = 0\\) y \\(P_\\Omega(x,y) = 1_x (y)\\). Si \\(y\\in \\Omega\\) entonces \\(\\Delta_2 G_\\Omega(x,y) = - 1_x (y)\\) y \\(P_\\Omega(x,y)=0\\). En particular, la simetría de \\(G\\) no implica la propiedad análoga para \\(P_\\Omega\\). Igualmente extendemos la construcción para \\(\\mu:V\\to \\mathbb R\\) usando \\[ P_\\Omega(\\mu,y) := \\mu(y) + \\Delta_2 G_\\Omega(\\mu,y). \\] Ejemplo 6.4 Si \\(\\Omega=\\{x_0\\}\\), entonces \\[ P_\\Omega(x,y) = \\begin{cases} 1/\\deg(x_0) \\text{ si } x=x_0,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Ejemplo 6.5 Para el problema del barrendero (\\(V=\\mathbb Z^2\\)) tenemos que al barrer \\(\\mu\\) de \\(\\Omega\\) la distribución de masa que resulta está dada por \\(P_\\Omega(\\mu)\\). De la linealidad del problema junto con la existencia y unicidad de soluciones se deduce que \\[ P_\\Omega(\\alpha\\mu+\\beta\\nu) = \\alpha P_\\Omega(\\mu) +\\beta P_\\Omega(\\nu). \\] Gracias a la interpretación de núcleo de Poisson en términos del problema del barrendero es natural pensar que dados \\(\\Omega_1\\subseteq\\Omega_2\\subseteq V\\) finitos, se tiene la siguiente propiedad \\[ P_{\\Omega_2} = P_{\\Omega_2}\\circ P_{\\Omega_1}. \\] Denominaremos a esta como la propiedad de semi-grupo. Como consecuencia de la linealidad y la propiedad de semi-grupo tenemos la siguiente interpretación dual del núcleo de Poisson: Para \\(y\\in V\\) fijo, la función \\(u(x) = P_\\Omega(x,y)\\) es la solución de \\[ \\begin{cases} \\Delta u = 0 \\text{ en } \\Omega,\\\\ u= 1_{y} \\text{ en } V\\setminus \\Omega. \\end{cases} \\] Esta formulación es más sencilla de recordar y conveniente al momento de calcular \\(P_\\Omega\\) sin necesidad de calcular la función de Green. Como consecuencia de la formulación dual de núcleo de Poisson y el principio de superposición tenemos la fórmula de representación \\[ u(x) = \\sum_{y\\in V} \\varphi(y) P_\\Omega(x,y) \\qquad\\Leftrightarrow\\qquad\\begin{cases} \\Delta u = 0 \\text{ en } \\Omega,\\\\ u= \\varphi \\text{ en } V\\setminus \\Omega. \\end{cases} \\] Más aún, si a esta añadimos la fórmula de representación para la función de Green, junto con su propia simetría, obtenemos que \\[ u(x) = \\sum_{y\\in V} \\varphi(y) P_\\Omega(x,y)+\\mu(y) G_\\Omega(x,y) \\qquad\\Leftrightarrow\\qquad \\begin{cases} \\Delta u = -\\mu \\text{ en }\\Omega,\\\\ u=\\varphi \\text{ en } V\\setminus \\Omega. \\end{cases}. \\] Ejemplo 6.6 Veamos como calcular el núcleo de Poisson para \\(\\Omega = [1,n] \\subseteq V=\\mathbb Z\\) con \\(n\\geq 1\\) y la relación de adyacencia dada por \\(x\\sim y\\) si \\(|x-y|=1\\). Denotamos a lo largo de este ejemplo a \\(p_{i,j} := P_\\Omega(i,j)\\) con \\(i,j\\in \\{0,1,\\ldots,n,n+1\\}\\), los valores de interés (\\(P_\\Omega(x,y) = 0\\) fuera de estos casos). En realidad solamente debemos calcular \\(p_{i,0}\\) y \\(p_{i,n+1}\\), los demás valores también se anulan. Para \\(j=0\\), tenemos la ecuación \\[ 2p_{i,0} = p_{i-1,0}+p_{i+1,0}, \\] la cual junto a \\(p_{0,0} = 1\\) y \\(p_{n+1,0}=0\\) indica que \\(p_{i,0}=(n+1-i)/(n+1)\\) para \\(i\\in[0,n+1]\\).\\ Para \\(j=n+1\\), tenemos también la ecuación \\[ 2p_{i,n+1} = p_{i-1,n+1}+p_{i+1,n+1}, \\] la cual junto a \\(p_{0,n+1} = 0\\) y \\(p_{n+1,n+1}=1\\) indica que \\(p_{i,n+1}=i/(n+1)\\) para \\(i\\in[0,n+1]\\). Ejercicio 6.8 Calcula el núcleo de Poisson para \\(\\Omega=[1,n]\\times \\{0\\}\\cap \\mathbb Z^2\\). Solución 6.4 Caminatas Aleatorias Consideremos ahora un problema que afinará nuestra intuición con respecto a las herramientas que hemos presentado. Volvemos a trabajar en la retícula \\(\\mathbb Z^2\\) a pesar de que el modelo es claramente generalizable a otros grafos. Un borracho parte de una posición inicial \\(x\\in\\mathbb Z^2\\) y se mueve con igual probabilidad a cualquiera de sus cuatro posiciones adyacentes. Es decir que si \\(x_i\\) es la posición (aleatoria) del borracho luego de \\(i\\) pasos, tenemos que las probabilidades de transición están dadas por \\[ \\mathbb P(x_i = y \\ | \\ x_{i-1} = x) = \\begin{cases} 1/4 \\text{ si } y \\sim x,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Dado \\(\\Omega \\subseteq\\mathbb Z^2\\), sea \\(\\tau\\) el número de pasos que toma el borracho para salir de \\(\\Omega\\) por primera vez, también conocido como el tiempo de salida de la caminata \\[ \\tau := \\min\\{i \\geq 0 : x_i \\in \\mathbb Z^2\\setminus \\Omega\\}. \\] Para nuestro modelo, podemos interpretar \\(\\mathbb Z^2\\setminus \\Omega\\) como la región en la ciudad \\(\\mathbb Z^2\\) donde hay ley seca. El borracho pasea en \\(\\Omega\\) y una vez que sale de \\(\\Omega\\) se queda dormido o lo atrapa la policía. Dado \\(A \\subseteq\\mathbb Z^2\\) (quizás sea la casa del nuestro protagonista) queremos calcular la probabilidad de que el paseo en \\(\\Omega\\) termine (felizmente) en \\(A\\) dado que comienza en \\(x\\), es decir \\[ p(x) := \\mathbb P(x_\\tau \\in A \\ | \\ x_0 = x). \\] Si inicialmente \\(x \\in \\mathbb Z^2\\setminus\\Omega\\), tenemos que \\(x_\\tau =x_0=x\\) y por lo tanto \\(p= 1_A\\). Si en cambio \\(x \\in \\Omega\\), la probabilidad \\(p(x)\\) puede ser calculada si conocemos los valores de \\(p(y)\\) para \\(y\\sim x\\). Para \\(y\\sim x\\) fijo, tenemos que con probabilidad \\(1/4\\) se tiene que \\(x_1=y\\), y a partir de \\(y\\) tenemos que el paseo en \\(\\Omega\\) sale por \\(A\\) con probabilidad \\(p(y)\\). En otras palabras \\[ p(x) = \\frac{1}{4}\\sum_{y\\sim x}p(y). \\] En términos del Laplaciano podemos caracterizar a la probabilidad \\(p\\) como la solución del sistema \\[ \\begin{cases} \\Delta p = 0 \\text{ en } \\Omega,\\\\ p = 1_A \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases}. \\] Cuando \\(A=\\{y\\}\\) conseguimos interpretar al núcleo de Poisson \\(P_\\Omega(x,y) = p(x)\\) como la probabilidad de que la caminata que comienza en \\(x\\) termine en \\(y\\). Esto es una probabilidad de transición para el tiempo aleatorio \\(\\tau\\) \\[ P_\\Omega(x,y) = \\mathbb P(x_\\t=y\\ | \\ x_0=x). \\] La interpretación probabilista de la fórmula de representación para el núcleo de Poisson está dada en cambio por el valor esperado \\[ u(x) = \\mathbb E(\\varphi(x_\\tau) \\ | \\ x_0=x) \\qquad \\Leftrightarrow\\qquad \\begin{cases} \\Delta u = 0 \\text{ en }\\Omega,\\\\ u=\\varphi \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Ejercicio 6.9 Dos borrachitos se encuentran paseando en la avenida \\(\\Omega = [1,n]\\times \\{0\\} \\cap \\mathbb Z^2\\) con \\(n\\geq 2\\). Uno parte de \\(x=(1,0)\\), el otro de \\(y = (n,0)\\), y ambos toman pasos simultáneamente en \\(\\mathbb Z^2\\) con igual probabilidad en las cuatro direcciones cardinales. Da una fórmula para la probabilidad \\(p(n)\\) de que se encuentren en \\(\\Omega\\) (es decir que ambos coinciden en la misma casilla al mismo tiempo, no vale que se crucen) antes de que alguno de ellos salga de \\(\\Omega\\). Solución Dado \\(A\\subseteq\\mathbb Z^2\\), otra variable aleatoria de interés es el número de veces que encontramos \\(x_i \\in A\\) para \\(i &lt; \\tau\\), es decir antes de salir de la región \\(\\Omega\\). Esta variable también se conoce como el tiempo de ocupación de \\(A\\) y está definida de forma precisa por \\[ N := \\sum_{i=0}^{\\tau-1} 1_A(x_i). \\] El valor esperado en función de la posición inicial de la caminata \\[ n(x) := \\mathbb E(N \\ | \\ x_0=x), \\] también satisface un sistema de ecuaciones lineales \\[ \\begin{cases} \\tfrac{1}{4}\\Delta n = - 1_A \\text{ en } \\Omega,\\\\ n = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases}. \\] Por un lado la condición de borde es automática puesto que si \\(x_0=x\\in \\mathbb Z^2\\setminus\\Omega\\) entonces como ya está fuera de \\(\\Omega\\), nunca puede visitar a \\(A\\) en su paseo (inexistente) por \\(\\Omega\\). Por otro lado, para \\(x\\in \\Omega\\), \\(n(x)\\) se puede obtener a partir de los valores de \\(n(y)\\) para \\(y\\sim x\\). Dado \\(y\\sim x\\), la probabilidad de que \\(x_1=y\\) es un cuarto, y a partir de acá consideramos dos casos: Si \\(x\\in A\\) entonces el tiempo de ocupación partiendo de \\(x\\) es uno más que el tiempo de ocupación partiendo de \\(y\\). Si \\(x\\in \\Omega\\setminus A\\), el tiempo de ocupación partiendo de \\(x\\) es el mismo tiempo de ocupación partiendo de \\(y\\). Tomando los valores esperados \\[ n(x) = 1_A(x) + \\frac{1}{4}\\sum_{y\\sim x} n(y). \\] Lo cual es equivalente a \\(\\tfrac{1}{4}\\Delta n = - 1_A\\) en \\(\\Omega\\). Es decir que \\(n=4G_\\Omega( 1_A)\\) está dado en términos de la función de Green. En términos probabilistas interpretamos la fórmula de representación para la función de Green como, \\[ u(x) = \\mathbb E\\left(\\sum_{i=0}^{\\tau-1}\\mu(x_i) \\ | \\ x_0=x\\right) \\qquad\\Leftrightarrow\\qquad \\begin{cases} \\frac{1}{4}\\Delta u = -\\mu \\text{ en } \\Omega,\\\\ u=0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases}. \\] Finalmente observamos que la simetría de la función de Green se interpreta como una propiedad de reversibilidad para las caminatas aleatorias. Es decir que el número promedio de veces que una caminata que comienza en \\(x\\) visita a \\(y\\) antes de salir de \\(\\Omega\\) (\\(G_\\Omega(x,y)\\)) es igual al número promedio de veces que una caminata que comienza en \\(y\\) visita a \\(x\\) antes de salir de \\(\\Omega\\) (\\(G_\\Omega(y,x)\\)). Esto se debe a que las caminatas de \\(x\\) a \\(y\\) que permanecen en \\(\\Omega\\) están en biyección con las caminatas de \\(y\\) a \\(x\\) que permanecen en \\(\\Omega\\), simplemente cambiando la orientación. Daremos una prueba rigurosa de este hecho en la Sección Principio del Mínimo↩︎ Pista: El problema se puede reducir a verificar que \\(\\Delta u(0,0) = -\\Delta u(1,0)\\). La función \\(u\\) parece tener una simetría en el eje \\(x=1/2\\) la cual podría ser demostrada por un resultado de unicidad (Liouville): Las funciones armónicas y acotadas en \\(\\mathbb Z^2\\) son únicamente las constantes.↩︎ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
