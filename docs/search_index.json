[["index.html", "Métodos de matemáticas aplicadas Prefacio", " Métodos de matemáticas aplicadas Héctor Andrés Chang-Lara 2022-09-23 Prefacio Hola "],["entramados.html", "Capítulo 1 Entramados", " Capítulo 1 Entramados La siguiente figura ilustra cuatro puntos masivos unidos por tres barras de longitudes conocidas \\(\\ell_{01}, \\ell_{12}, \\ell_{23}\\), y masas despreciables. Los extremos etiquetados por \\(0\\) y \\(3\\) tienen posiciones fijas y los nodos intermedios de masas \\(m_1\\) y \\(m_2\\) ocupan posiciones de equilibrio. ¿A partir de cuales ecuaciones se podrían determinar las posiciones \\(q_i=(x_i,y_i)\\) de estos nodos? Antes de proceder a plantear el sistema de ecuaciones recordemos que por lo general el número de ecuaciones e incógnitas deben ser iguales para que este esté bien planteado, es decir que existan soluciones y que sean únicas (al menos localmente). En nuestro caso tenemos cuatro incógnitas, los dos pares de coordenadas de cada nodo libre. Además debemos considerar las restricciones impuestas por las distancias entre los nodos, es decir tres ecuaciones. Hasta el momento el sistema es indeterminado, tiene más incógnitas (4) que ecuaciones (3), sin embargo aún nos falta incorporar la información del fenómeno de equilibrio. \\[ \\begin{cases} (x_1-0)^2 + (y_1-0)^2 = \\ell_{01}^2\\\\ (x_1-x_2)^2 + (y_1-y_2)^2 = \\ell_{12}^2\\\\ (x_2-3)^2 + (y_2-0)^2 = \\ell_{23}^2 \\end{cases} \\] En cada nodo libre actúan tres fuerzas: dos tensiones y la gravedad \\((= -m_ige_y)\\). Por ejemplo, la tensión \\(T_{12}\\) sobre el nodo 1 y que se produce sobre el segmento que une los nodos 1 y 2 es proporcional al vector \\(q_2-q_1\\), es decir \\(T_{12} = \\lambda_{12} (q_2-q_1)\\) para un cierto escalar \\(\\lambda_{12}\\). Similarmente podemos razonar sobre las demás interacciones, introduciendo así cuatro nuevas variables \\(\\lambda_{10}, \\lambda_{12}, \\lambda_{21}\\), y \\(\\lambda_{23}\\). Para que el sistema se encuentre en equilibrio, la suma de las fuerzas sobre cada nodo debe anularse, lo cual nos da igualmente cuatro ecuaciones: \\[ \\begin{cases} \\lambda_{10}(x_{0}-x_{1})+\\lambda_{12}(x_{2}-x_{1}) = 0\\\\ \\lambda_{10}(y_{0}-y_{1})+\\lambda_{12}(y_{2}-y_{1}) = m_{1}g\\\\ \\lambda_{23}(x_{3}-x_{2})+\\lambda_{21}(x_{1}-x_{2}) = 0\\\\ \\lambda_{23}(y_{3}-y_{2})+\\lambda_{21}(y_{1}-y_{2}) = m_{2}g \\end{cases} \\] Pareciera que no hemos logrado mucho en términos del sistema que sigue siendo indeterminado con ocho incógnitas (2 \\(x\\)’s, 2 \\(y\\)’s y 4 \\(\\lambda\\)’s) y siete ecuaciones (3 distancias y 4 balances de fuerzas). Sin embargo, la tercera ley de Newton nos dice que las interacciones entre pares de nodos guarda una simetría: toda acción produce una reacción opuesta de la misma magnitud. En nuestro modelo esto se refleja en \\(T_{12} = -T_{21}\\), de donde obtenemos la última ecuación \\[ \\lambda_{12}=\\lambda_{21}. \\] De hecho es más sencillo eliminar una de las incógnitas (\\(\\lambda_{21}\\)) que añadir otra ecuación. En conclusión obtenemos el siguiente sistema con siete ecuaciones e incógnitas \\[ \\begin{cases} \\lambda_{10}(x_{0}-x_{1})+\\lambda_{12}(x_{2}-x_{1}) = 0\\\\ \\lambda_{10}(y_{0}-y_{1})+\\lambda_{12}(y_{2}-y_{1}) = m_{1}g\\\\ \\lambda_{23}(x_{3}-x_{2})+\\lambda_{12}(x_{1}-x_{2}) = 0\\\\ \\lambda_{23}(y_{3}-y_{2})+\\lambda_{12}(y_{1}-y_{2}) = m_{2}g\\\\ (x_1-0)^2 + (y_1-0)^2 = \\ell_{01}^2\\\\ (x_1-x_2)^2 + (y_1-y_2)^2 = \\ell_{12}^2\\\\ (x_2-3)^2 + (y_2-0)^2 = \\ell_{23}^2 \\end{cases} \\] Una forma de obtener solución a este sistema es el método de Newton. Por ejemplo, para los valores \\(\\ell_{01}=\\sqrt{5}, \\ell_{12}=\\sqrt{5}, \\ell_{23}=\\sqrt{10}, m_1=1, m_2=2, q_0=(0,0), q_3=(4,0)\\) la siguiente implementación ilustra como obtener la solución usando Python1. #Librerías import matplotlib.pyplot as plt import numpy as np from scipy.optimize import fsolve #Parámetros l01=np.sqrt(5) l12=np.sqrt(5) l23=np.sqrt(10) x3,y3=4,0 m1=1 m2=2 #Sistema de ecuaciones y gráfica def f(x): x1,y1,x2,y2,lambda01,lambda12,lambda23 = x f=np.zeros(7) f[0] = x1**2+y1**2-l01**2 f[1] = (x2-x1)**2+(y2-y1)**2-l12**2 f[2] = (x3-x2)**2+(y3-y2)**2-l23**2 f[3] = -lambda01*x1+lambda12*(x2-x1) f[4] = -lambda01*y1+lambda12*(y2-y1)-m1 f[5] = lambda12*(x1-x2)+lambda23*(x3-x2) f[6] = lambda12*(y1-y2)+lambda23*(y3-y2)-m2 return f r = fsolve(f,[1,-1,3,-2,0,0,0]) x1,y1=r[0],r[1] x2,y2=r[2],r[3] fig, ax = plt.subplots() ax.plot([0,r[0],r[2],x3], [0,r[1],r[3],y3]) ax.plot(0,0,color=&#39;tab:blue&#39;, marker=&#39;o&#39;, label=&#39;$q_0=(0,0)$&#39;) ax.plot(x1,y1,color=&#39;tab:orange&#39;, marker=&#39;o&#39;, label=&quot;$q_1=({:.4f},{:.4f})$&quot;.format(x1, y1)) ax.plot(x2,y2,color=&#39;tab:green&#39;, marker=&#39;o&#39;, label=&quot;$q_1=({:.4f},{:.4f})$&quot;.format(x2, y2)) ax.plot(x3,y3,color=&#39;tab:red&#39;, marker=&#39;o&#39;, label=&quot;$q_1=({},{})$&quot;.format(x3, y3)) leg = ax.legend(); plt.show() Estas ideas son fácilmente generalizables a configuraciones lineales con más nodos. En el límite se obtiene el problema de la catenaria. También podemos considerar estructuras más complejas, por ejemplo un pañuelo sujeto por las esquinas. Para poder dar una generalización de estos modelos presentamos en la siguiente sección algunas nociones básicas de teoría de grafos. Una referencia entretenida con aplicaciones en arquitectura está en el siguiente enlace: Diseñar estructuras… ¿sin cálculos?  La magia de la CATENARIA Ejercicio 1.1 Calcula \\(m_2\\) para que el entramado esté en equilibrio dado que los nodos en \\((0,0)\\) y \\((13,0)\\) están fijos Solución Las fuerzas en el nodo \\(1\\) están dadas por \\[ \\begin{cases} 5\\lambda_{01}=6\\lambda_{12},\\\\ 8\\lambda_{01}+\\lambda_{12}=g \\end{cases} \\qquad\\Rightarrow\\qquad \\lambda_{01}=\\frac{6g}{53}, \\lambda_{12}=\\frac{5g}{53} \\] Las fuerzas en el nodo \\(2\\) están dadas por \\[ \\begin{cases} 6\\lambda_{12}=2\\lambda_{23},\\\\ -\\lambda_{12}+7\\lambda_{23}=m_2g \\end{cases} \\qquad\\Rightarrow\\qquad \\lambda_{23}=\\frac{15g}{53}, m_2=\\frac{100}{53}. \\] Ejercicio 1.2 Demuestra que si un dado entramado como en la figura, y con extremos en el eje horizontal, está en equilibro, entonces su correspondiente reflexión en el eje horizontal también está en equilibrio. ¿Será posible generalizar este principio a un entramado general? Solución Denotamos por \\(\\lambda_i=\\lambda_{i,i-1} = -\\lambda_{i-1,i}\\). En cada nodo del entramado original se tiene el balance de fuerzas está dado por \\[ \\begin{cases} (x_i-x_{i-1})\\lambda_i=(x_{i+1}-x_{i})\\lambda_{i+1},\\\\ (y_{i-1}-y_{i})\\lambda_i+(y_{i+1}-y_{i})\\lambda_{i+1}=m_ig \\end{cases} \\] Al tomar la reflexión en el eje horizontal las coordenadas de los nodos pasan a ser \\((x_i,y_i)\\mapsto (x_i&#39;,y_i&#39;) = (x_i,-y_i)\\). Gracias a las relaciones previas, se observa que estas coordenadas satisfacen igualmente las ecuaciones de balance de fuerzas cuando igualmente reemplazamos \\(\\lambda_i\\mapsto \\lambda_i&#39; =-\\lambda_i\\) \\[ \\begin{cases} (x_i&#39;-x_{i-1}&#39;)\\lambda_i&#39;=(x_{i+1}&#39;-x_{i}&#39;)\\lambda_{i+1}&#39;,\\\\ (y_{i-1}&#39;-y_{i}&#39;)\\lambda_i&#39;+(y_{i+1}&#39;-y_{i}&#39;)\\lambda_{i+1}&#39;=m_ig. \\end{cases} \\] Este principio se generaliza a un entramado general con una notación adecuada. Advertencia: El código es sensible a las condiciones iniciales para la iteración y no siempre converge.↩︎ "],["cálculo-discreto.html", "Capítulo 2 Cálculo discreto 2.1 Gradiente 2.2 Divergencia 2.3 Integración por partes 2.4 Laplaciano", " Capítulo 2 Cálculo discreto Una grafo dirigido \\(G = (V,E)\\) consiste de un conjunto de vértices \\(V\\), también llamados nodos, y un conjunto de aristas \\(E \\subseteq V^2\\), es decir pares ordenados de \\(V\\). Dado \\(e = (a,b)\\in E\\), denotamos por \\(e_-=a\\) y \\(e_+=b\\) los nodos de partida y llegada de \\(e\\) respectivamente y decimos que \\(e\\) está orientado del nodo de salida \\(a\\) al nodo de llegada \\(b\\). En general trabajaremos con grafos con aristas simples, es decir que a lo sumo existe una arista que conecta dos vértices en cualquier orientación. Sin embargo, cuando \\(e=(a,b)\\in E\\) podríamos hacer referencia a la arista \\(-e:=(b,a)\\) como la arista \\(e\\) pero con el sentido opuesto. Denotaremos \\(-E = \\{-e \\in V^2:e\\in E\\}\\). Finalmente, podemos considerar también conjuntos de aristas no orientadas en cuyo caso decimos que el grafo es no dirigido. Ejercicio 2.1 Dibuja el grafo \\(G=(V,E)\\) para \\[ V = \\{1,2,3,a,b,c\\}, \\qquad E = \\{(1,a),(1,b),(1,c),(2,a),(2,b),(2,c),(3,a),(3,b),(3,c)\\}. \\] Solución Las redes eléctricas son uno de los modelos más conocidos que se pueden formular en términos de grafos. Sobre el grafo podemos caracterizar por ejemplo el potencial o voltaje como una función \\(u:V\\to \\mathbb R\\) y la corriente como una función \\(i:E\\to \\mathbb R\\). Siguiendo un poco la nomenclatura que sugiere este modelo, distinguimos dos tipos de funciones en \\(G\\): Potencial: Es una función sobre el conjunto de vértices \\(u: V \\to \\mathbb R\\). Flujo: Es una función sobre el conjunto de aristas \\(f: E \\to \\mathbb R\\). En algunos casos también podríamos considerar que dichas funciones tomen valores en \\(\\mathbb C\\), \\(\\mathbb R^n\\) ó \\(\\mathbb C^n\\). También denominamos como flujos a funciones que están definidas en \\(E\\cup -E\\), es decir que consideran ambas orientaciones de las aristas. Decimos que \\(f:E\\cup -E\\to\\mathbb R\\) es par cuando no depende de la orientación \\(f(-e) = f(e)\\), y decimos que impar si en cambio \\(f(-e) = -f(e)\\). Una función \\(f:E\\to\\mathbb R\\) en un grafo no dirigido es equivalente a una función par en el mismo grafo y con cualquier orientación sobre las aristas. Ejemplo 2.1 En el modelo de entramados en la sección anterior, el grafo no dirigido \\(G=(V,E)\\) con \\(V = \\{0,1,2,3\\}\\) y \\(E=\\{\\{0,1\\},\\{1,2\\},\\{2,3\\}\\}\\) nos proporciona la información sobre cuales nodos están conectados entre si. Las posiciones de los nodos se caracterizan por \\(q:V\\to \\mathbb R^2\\) y las longitudes de los enlaces están determinadas por \\(\\ell:E\\to\\mathbb R\\). Para modelar las tensiones es conveniente considerar el grafo dirigido \\(G=(V,E&#39;)\\) de alguna forma arbitraria, quizás \\(E&#39;=\\{(0,1),(1,2),(2,3)\\}\\). De esta forma contamos con la función par \\(\\lambda:E&#39;\\to\\mathbb R\\) y la función impar \\(T: E&#39; \\to \\mathbb R^2\\) tales que \\[ T(e) = \\lambda(e)(q(e_+)-q(e_-)) \\] es la tensión sobre el nodo \\(e_-\\) a lo largo de \\(e\\). A su vez y gracias a la ley de acción y reacción, \\(T(-e) = -T(e)\\) es la tensión sobre el nodo \\(e_+\\) a lo largo de \\(e\\) pero en la orientación opuesta, es decir \\(-e\\). Ejemplo 2.2 Un potencial \\(u:V\\to\\mathbb R\\) sobre una red de resistencia genera una corriente \\(i:E\\to \\mathbb R\\) que modelamos usando la ley de Ohm para una dada resistencia \\(R:E\\cup -E \\to (0,\\infty)\\) (función par). Esto quiere decir que la corriente \\(i(e)\\) que atraviesa una arista \\(e = (e_-,e_+)\\) es proporcional a la diferencia de los potenciales en los extremos de la arista \\[ i(e) = \\frac{u(e_+) - u(e_-)}{R(e)}, \\qquad R(e) &gt;0: \\text{ Resistencia.} \\] 2.1 Gradiente Tanto en la construcción de las tensiones \\(T\\), como en la de la corriente eléctrica \\(i\\), estamos considerando la variación de una dada función (las posiciones \\(q\\) ó el potencial \\(u\\)) a lo largo de una arista dada. Esto es una versión discreta de la derivada direccional. En este caso requerimos que el grafo sea orientado. Definición 2.1 Dado potencial \\(u:V\\to\\mathbb R\\) sobre un grafo dirigido \\(G=(V,E)\\), definimos el gradiente \\(Du: E\\cup -E \\to \\mathbb R\\) tal que \\[ Du(e) = u(e_{+})-u(e_{-}). \\] En particular, el gradiente es una función impar. Ejercicio 2.2 Calcula el gradiente de la función dada en los vértices del siguiente grafo Solución Ejercicio 2.3 Verifica que el gradiente satisface la identidad de Leibniz \\[ D(u_1u_2) = u_1^+ Du_2 + u_2^-Du_1 \\] donde \\(u^\\pm:E\\to\\mathbb R\\) se define a partir de \\(u:V\\to\\mathbb R\\) como \\(u^\\pm(e) = u(e_\\pm)\\). Solución \\[ \\begin{aligned} D(u_1u_2)(e) &amp;= u_1(e_+)u_2(e_+) - u_1(e_-)u_2(e_-),\\\\ &amp;= u_1(e_+)u_2(e_+) - u_1(e_+)u_2(e_-) + u_1(e_+)u_2(e_-) - u_1(e_-)u_2(e_-),\\\\ &amp;= u_1(e_+)(u_2(e_+)-u_2(e_-)) + u_2(e_-)(u_1(e_+)-u_1(e_-)),\\\\ &amp;= u_1(e_+)Du_2(e) + u_2(e_-)Du_1(e),\\\\ &amp;= (u_1^+Du_2 + u_2^-Du_1)(e). \\end{aligned} \\] 2.1.1 Ley de ciclos No toda función (impar) \\(f:E\\cup -E \\to \\mathbb R\\) es necesariamente un gradiente. Una condición necesaria y suficiente es la ley de ciclos. Para poder enunciar esta ley es conveniente dar algunas definiciones previas para un dado grafo dirigido \\(G=(V,E)\\). Definición 2.2 Un camino no orientado es una sucesión de vértices \\(x_0,x_1, \\dots, x_n \\in V\\) tal que \\((x_j,x_{j+1}) \\in E\\cup -E\\) para todo \\(j\\in\\{0,1,\\ldots,(n-1)\\}\\). Se dice que el camino es un ciclo si además \\(x_n=x_0\\). Definición 2.3 Una componente conexa de \\(G\\) es un subconjunto \\(V&#39;\\subseteq V\\) tal que: Todos los vértices en \\(V&#39;\\) están conectados entre si por algún camino. Ningún vértice de \\(V&#39;\\) está conectado con ningún vértice de \\(V\\setminus V&#39;\\). Decimos que \\(G\\) es conexo si tiene una única componente conexa. Teorema 2.1 (Ley de ciclos) Sea \\(G=(V,E)\\) un grafo dirigido finito. Una función impar \\(f:E\\cup -E\\to\\mathbb R\\) es igual al gradiente de una función \\(u:V\\to \\mathbb R\\) si y solo si para todo ciclo \\(x_0,x_1, \\dots, x_n=x_0\\) se tiene que \\[ \\sum_{j=0}^{n-1} f(x_j,x_{j+1}) = 0. \\] Demostración. Por un lado es fácil verificar la identidad para flujos gradientes usando la propiedad telescópica. Dado un ciclo \\(x_0,x_1, \\dots, x_n=x_0\\) \\[ \\sum_{j=0}^{n-1} Du(x_j,x_{j+1}) = \\sum_{j=0}^{n-1} (u(x_{j+1})-u(x_j)) = u(x_n)-u(x_0)=0. \\] Podemos construir \\(u:V&#39;\\to \\mathbb R\\) sobre cada una de las componentes conexas de \\(G\\) de la siguiente forma: Fijemos \\(x_0 \\in V&#39;\\) y definimos \\[ u(x) := \\sum_{j=0}^{n-1} f(x_j,x_{j+1}) \\] donde \\(x_0,x_1, \\dots, x_n=x\\) es un camino no orientado que conecta \\(x_0\\) con \\(x\\in V&#39;\\). La hipótesis dada por la ley de ciclos garantiza que esta construcción no depende del camino escogido, es decir que está bien definida sin posible ambigüedad: Dados dos caminos \\(x_0,\\ldots,x_n=x\\) y \\(y_0=x_0,\\ldots,y_m=x\\) se tiene que \\(z_0=x_0,\\ldots,z_n=x_n,z_{n+1}=y_{m-1},\\ldots,z_{n+m}=y_0\\) es un ciclo y por lo tanto \\[ 0 = \\sum_{j=0}^{n+m-1} f(z_j,z_{j+1}) = \\sum_{j=0}^{n-1} f(x_j,x_{j+1}) - \\sum_{j=0}^{m-1} f(y_j,y_{j+1}). \\] Veamos finalmente que \\(Du = f\\). Dado \\(e\\in E\\) con \\(e_\\pm\\) en la misma componente que \\(x_0\\), tomamos un camino \\(x_0,x_1,\\ldots, x_n=e_-\\) de \\(x_0\\) a \\(e_-\\) y luego añadimos \\(x_{n+1}=e_+\\) para formar un camino de \\(x_0\\) a \\(e_+\\). Por lo tanto \\[ Du(e) = u(e_+)-u(e_-) = \\sum_{j=0}^{n} f(x_j,x_{j+1})-\\sum_{j=0}^{n-1} f(x_j,x_{j+1}) = f(e), \\] con lo cual concluímos la demostración. Este argumento nos permite apreciar que \\(u\\) está únicamente determinado salvo potenciales constantes en cada componente conexa de \\(G\\). Las constantes son los valores arbitrarios que daríamos a \\(u\\) sobre el nodo \\(x_0\\), que en nuestra demostración fue cero. En otras palabras, la nulidad del gradiente captura el número de compnentes conexas del grafo. Ejercicio 2.4 Calcula los potenciales que generan el flujo dado en la siguiente figura Solución El flujo satisface la ley de ciclos. Por ejemplo en el triángulo de la izquierda la suma correspondiente es \\(-3+1+2=0\\) y de igual forma podemos verificar en el triángulo de la derecha (\\(2+(-1)+(-1)=0\\)) o en el cuadrado exterior (\\((-3)+1-(-1)-(-1)=0\\)). Si tomamos \\(u(A)=0\\) sin pérdida de generalidad tenemos que \\[ \\begin{cases} u(B) = 1 + u(A) = 1,\\\\ u(C) = 3 + u(A) = 3,\\\\ u(D) = -1 + u(C) = 2. \\end{cases} \\] Verificamos además que con estos valores se obtiene el gradiente prescrito \\[ \\begin{cases} Du(AB) = u(B)-u(A) = 1-0 = 1,\\\\ Du(BC) = u(C)-u(B) = 3-1 = 2,\\\\ Du(CA) = u(A)-u(C) = 0-3 = -3,\\\\ Du(CD) = u(D)-u(C) = 2-3 = -1,\\\\ Du(DB) = u(B)-u(D) = 1-2 = -1. \\end{cases} \\] En general, \\(u\\) tiene el gradiente prescrito si y solo si \\[ u(A) = C, \\qquad u(B) = 1+C, \\qquad u(C) = 3+C, \\qquad u(D)=2+C. \\] Margen de cálculo: El lema de Poincaré Como ya el lector habrá notado, estas construcciones y propiedades encuentran paralelos en cálculo multivariable, y de hecho las demostraciones reproducen las mismas ideas: Los caminos son curvas, los ciclos son lazos o curvas cerradas y la expresión \\(\\sum_{j=0}^{n-1} f(x_j,x_{j+1})\\) es análoga a la integral de línea o el trabajo de un campo vectorial sobre una curva. El resultado que acabamos de enunciar se conoce como el Lema de Poincaré global. Recordemos su enunciado junto con el resultado local. Lema de Poincaré (global): Un campo vectorial \\(f \\in C(\\Omega\\subseteq\\mathbb R^n\\to\\mathbb R^n)\\) es el gradiente de algún potencial \\(u\\in C^1(\\Omega\\to\\mathbb R)\\) si y sólo si para cualquier curva cerrada \\(\\gamma \\in C^1([a,b]\\to\\Omega)\\) (i.e. \\(\\gamma(b)=\\gamma(a)\\)) se tiene que el trabajo que ejerce \\(f\\) sobre la curva \\(\\gamma\\) se anula \\[ \\int_\\gamma f = \\int_a^b f(\\gamma(t))\\cdot \\gamma&#39;(t)dt = 0. \\] Lema de Poincaré (local): Si \\(\\Omega\\subseteq\\mathbb R^n\\) es simplemente conexo2 entonces \\(f \\in C^1(\\Omega\\to\\mathbb R^n)\\) es un gradiente si y solo si \\(\\partial_if_j = \\partial_jf_i\\). 2.2 Divergencia Otro operador diferencial que tiene su análogo en grafos es la divergencia. Heurísticamente, la divergencia de un campo vectorial mide cuando es positiva la cantidad de flujo que sale o diverge del nodo dado, mientras que cuando es negativa mide la cantidad de flujo que recibe o converge en el nodo. Definición 2.4 Dado \\(f: E \\to \\mathbb R\\) denotamos por \\(\\operatorname{div} f:V\\to \\mathbb R\\) a la divergencia de \\(f\\) donde \\[ \\operatorname{div} f(v) = \\sum_{e_-=v}f(e)-\\sum_{e_+=v}f(e) \\] Ejemplo 2.3 En la siguiente figura se calculó la divergencia de la función dada en las aristas Ejemplo 2.4 Las ecuaciones de balance para un entramado se escriben en términos de la divergencia de las tensiones sobre los nodos libres como \\[ \\operatorname{div} T = mge_y \\] Ejemplo 2.5 La ley de Kirchhoff dice que en en un nodo que no está conectado a la batería, la corriente que entra y sale de este son iguales. En términos de la divergencia quiere decir que \\[ \\operatorname{div} i = 0 \\] 2.2.1 Fórmula de la divergencia Al igual que antes, podríamos preguntarnos si todo potencial es la divergencia de algún campo. Esto no es necesariamente cierto, la divergencia satisface la ley de conservación, análoga al teorema de la divergencia. Un caso particular ilustrativo de esta ley postula que la suma de la divergencia sobre un grafo finito es igual a cero \\[ \\sum_{v\\in V} \\operatorname{div} f(v) = 0. \\] Una vez más la justificación se basa en una propiedad telescópica para la suma: Cada arista aparece dos veces en la suma con signos opuestos dependiendo si se considera su vértice origen o de llegada. Para dar una versión discreta del teorema de la divergencia consideramos el campo normal exterior \\(n_\\Omega:E\\to \\mathbb R\\) tal que \\[ n_\\Omega(e) = \\begin{cases} +1 \\text{ si $e_-\\in \\Omega$ y $e_+\\in V\\setminus \\Omega$},\\\\ -1 \\text{ si $e_-\\in V\\setminus \\Omega$ y $e_+\\in \\Omega$},\\\\ 0 \\text{ en cualquier otro caso} \\end{cases} \\] en este caso el signo de \\(n_\\Omega(e)\\) indica cuando la arista orientada conecta a \\(\\Omega\\) con su complemento o viceversa. Ejercicio 2.5 El campo normal es el gradiente de una dada función ¿Cuál?. Solución \\(n_\\Omega = D1_{V\\setminus \\Omega}\\) donde \\[ 1_{V\\setminus \\Omega}(x) = \\begin{cases} 1 \\text{ si } x\\in V\\setminus \\Omega,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Teorema 2.2 (Fórmula de la divergencia) Sea \\(G=(V,E)\\) un grafo dirigido finito y \\(\\Omega \\ss V\\). La divergencia de \\(f:E\\to \\mathbb R\\) verifica \\[\\begin{equation} \\sum_{v\\in \\Omega} \\operatorname{div} f(v) = \\sum_{e\\in E} f(e)n_\\Omega(e) \\tag{2.1} \\end{equation}\\] De hecho la suma en el lado derecho ocurre en realidad sobre un subconjunto de aristas que podemos definir como el borde de \\(\\partial\\Omega\\) \\[ \\partial \\Omega := \\{e\\in E\\ | \\ \\{e_+,e_-\\} \\cap \\Omega \\neq \\emptyset \\text{ y } \\{e_+,e_-\\} \\cap E\\setminus \\Omega \\neq \\emptyset\\}. \\] Es decir las aristas que conectan \\(\\Omega\\) con su complemento en cualquier orientación. La cantidad \\(f(e)n_\\Omega(e)\\) es positiva cuando \\(e_-\\in \\Omega\\), \\(e_+\\in V\\setminus \\Omega\\) y \\(f(e)&gt;0\\); o bien cuando \\(e_-\\in V\\setminus \\Omega\\), \\(e_+\\in \\Omega\\) y \\(f(e)&lt;0\\). En cualquier caso, \\(f(e)n_\\Omega(e)\\) se interpreta como el flujo que escapa de \\(\\Omega\\) por medio de \\(e\\). Un razonamiento similar se dá cuando \\(f(e)n_\\Omega(e)\\) es negativo para el flujo que entra. El balance total nos dice que la masa que se produce o absorbe en \\(\\Omega\\) se puede medir de dos formas, sumando las divergencias en \\(\\Omega\\) u observando las contribuciones que escapan o entran por las aristas que conectan a \\(\\Omega\\) con su complemento \\(V\\setminus \\Omega\\) en cualquier orientación. Demostración. Sean \\(1_\\pm:V\\times E\\to \\mathbb R\\) definidas según \\[ 1_\\pm(v,e) := \\begin{cases} 1 \\text{ si } e_\\pm = v,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] En particular usaremos que \\[ \\sum_{v\\in \\Omega} 1_\\pm(v,e) = \\begin{cases} 1 \\text{ si } e_\\pm \\in \\Omega,\\\\ 0 \\text{ en cualquier otro caso} \\end{cases} \\] Tenemos así que \\[ \\begin{aligned} \\sum_{v\\in \\Omega} \\operatorname{div} f(v) &amp;= \\sum_{v\\in \\Omega} \\sum_{e_-=v} f(e) - \\sum_{v\\in \\Omega} \\sum_{e_+=v} f(e),\\\\ &amp;= \\sum_{v\\in \\Omega} \\sum_{e \\in E} f(e)1_-(v,e) - \\sum_{v\\in \\Omega} \\sum_{e \\in E} f(e)1_+(v,e),\\\\ &amp;= \\sum_{e \\in E} \\sum_{v\\in \\Omega}f(e)1_-(v,e) - \\sum_{e \\in E} \\sum_{v\\in \\Omega}f(e)1_+(v,e),\\\\ &amp;= \\sum_{e_-\\in \\Omega} f(e) -\\sum_{e_+\\in \\Omega} f(e),\\\\ &amp;= \\sum_{\\substack{e_-\\in \\Omega\\\\e_+\\in V\\setminus \\Omega}} f(e) + \\sum_{e_-, e_+\\in \\Omega} f(e) - \\sum_{\\substack{e_+\\in \\Omega\\\\e_-\\in V\\setminus \\Omega}} f(e) - \\sum_{e_-, e_+\\in \\Omega} f(e),\\\\ &amp;= \\sum_{\\substack{e_-\\in \\Omega\\\\e_+\\in V\\setminus \\Omega}} f(e) - \\sum_{\\substack{e_+\\in \\Omega\\\\e_-\\in V\\setminus \\Omega}} f(e) \\end{aligned} \\] Esta última expresión es por definición de \\(n_\\Omega\\) igual a \\[ \\sum_{e\\in E} f(e)n_\\Omega(e), \\] con lo cual se concluye la demostración. Margen de cálculo: El teorema de la divergencia El teorema de la divergencia nos dice que dado un subconjunto \\(\\Omega \\subset\\mathbb R^n\\) con frontera localmente de clase \\(C^1\\) a trozos, y campo \\(v\\in C^1(\\overline{\\Omega}\\to\\mathbb R^n)\\), entonces \\[ \\int_\\Omega \\operatorname{div} v = \\int_{\\partial \\Omega} v\\cdot n \\] donde \\(n\\) es el vector normal exterior a \\(\\Omega\\). El lado derecho integra el flujo que escapa o entra en \\(\\Omega\\) a través de su borde. En concreto, si en un punto dado del borde \\(v\\cdot n &gt;0\\) entonces \\(v\\) apunta en la dirección de \\(n\\) y el flujo escapa con una tasa igual a \\(v\\cdot n\\), si en cambio \\(v\\cdot n &lt; 0\\) el flujo estaría entrando, y si \\(v\\cdot n=0\\) se tiene que \\(v\\) es tangente y el flujo apenas roza la superficie. El lado izquierdo de la expresión es una integral sobre \\(\\Omega\\) que representa la producción/absorción de flujo por el campo \\(v\\). 2.2.2 Lema de Poincaré para la divergencia Teorema 2.3 Sea \\(G=(V,E)\\) un grafo dirigido finito y conexo. Para cualquier \\(\\mu:V\\to\\mathbb R\\) tal que \\[ \\sum_{x\\in V}\\mu(x)=0 \\] existe por lo menos una solución \\(f:E\\to\\mathbb R\\) de \\[ \\operatorname{div} f = \\mu. \\] Demostración. Tomemos un nodo arbitrario \\(x_0\\in V\\) y consideremos inductivamente caminos no orientados que vayan conectando a \\(x_0\\) con cada uno de los nodos restantes y de tal forma que nunca se formen ciclos en esta construcción. Es decir, estamos proponiendo un árbol generador del grafo con raíz en el nodo \\(x_0\\)3. Fijamos \\(f=0\\) en las aristas de \\(E\\setminus E_0\\) y en los demás ajustaremos \\(f\\) para que satisfaga la ecuación dada. En la siguiente construcción estaremos definiendo a \\(f:E\\cup-E\\to \\mathbb R\\) como una función impar. La idea consiste en ir podando las ramas del árbol a medida que asignamos \\(f\\) convenientemente. Si \\(|V_0|=1\\) el problema sería trivial, asumamos así que \\(|V_0|&gt;1\\). En el primer paso tomamos una hoja de \\(T_0\\), es decir un \\(x\\in V_0\\) con un único nodo \\(y \\sim_{T_0} x\\). Declaramos así \\(f(x,y) = \\mu(x)\\) de modo que se tiene que \\(\\operatorname{div}f(x) = \\mu(x)\\) (\\(f\\) es distinto de cero en a lo sumo una arista en esta suma). Una vez declarado \\(f\\) en la arista \\(e=(x,y)\\) procedemos a considerar el árbol \\(T_1 = (V_0\\setminus \\{x\\},E_1:=E_0\\setminus \\{(x,y),(y,x)\\})\\). Asumamos de forma inductiva que luego de \\(k\\) pasos contamos con los árboles \\[ T_k = (V_k,E_k) \\subset T_{k-1} := (V_{k-1},E_{k-1}) \\subset \\ldots \\subset T_0 \\] tales que \\(f\\) ha sido definida en \\(E\\setminus E_k\\) tal que \\(\\operatorname{div}f=\\mu\\) se satisface sobre \\(V\\setminus V_k\\). Para el siguiente paso tomamos una hoja \\(x \\in V_k\\) y fijamos \\(f\\) sobre la (única) arista \\((x,y) \\in E_k\\cup-E_k\\) de modo que la ecuación ahora se satisfaga sobre el nodo \\(x\\). Para el siguiente paso podamos a \\(x\\) de \\(T_k\\), es decir que \\[ T_{k+1}:= (V_{k+1}=V_k\\setminus\\{x\\},E_{k+1}:=E_k\\setminus\\{(x,y),(y,x)\\}). \\] Claramente esta construcción garantiza que las hipótesis inductivas se siguen cumpliendo en el siguiente paso. Una vez terminado este algoritmo garantizamos que \\(\\operatorname{div} f=\\mu\\) se cumple en \\(V\\setminus \\{x_0\\}\\) (la raíz del árbol). Como última observación tenemos que la ecuación también debe cumplirse en \\(x_0\\) gracias a que \\(\\sum_{x\\in V} \\operatorname{div} f(x)=\\sum_{x\\in V} \\mu(x)=0\\). Notemos que si \\(x_0,\\ldots,x_k=x_0\\) es un dado ciclo del grafo, entonces si tomamos \\(f=1\\) en las aristas del ciclo y cero por fuera de estas, obtenemos una solución de \\(\\operatorname{div} f=0\\). De hecho, todas las soluciones homogéneas se obtienen por superposiciones de este ejemplo. El núcleo de la divergencia es un espacio vectorial generado por los ciclos independientes del grafo y su dimensión es un importante invariante topológico conocido como el primer número de Betti. Ejercicio 2.6 Calcula los flujos \\(f:E\\to \\mathbb R\\) tal que \\(\\operatorname{div} f=\\mu\\) para la función \\(\\mu\\) dada sobre los nodos del siguiente grafo. Solución Verificamos primero que la suma de los valores en los nodos se anula. Para calcular una solución particular tomamos el árbol generador con aristas \\(a\\), \\(b\\), \\(-e\\) y definimos así \\[ f(c)=f(d)=0, \\qquad f(a)=1, \\qquad f(e)=2, \\qquad f(b)=0 \\] el cual verifica fácilmente la ecuación de divergencia esperada en todos los nodos. Cualquier otra solución se obtiene como la superposición de la solución previa con las del sistema homogéneo \\[ \\begin{cases} f(a)+f(b)-f(e)=0,\\\\ -f(a)+f(c)=0,\\\\ -f(b)+f(d)=0,\\\\ -f(c)-f(d)+f(e)=0. \\end{cases} \\] Dos soluciones linealmente independientes se obtienen por ejemplo de los ciclos \\(a,c,e\\) y \\(b,d,e\\) respectivamente \\[ \\begin{aligned} &amp;f(a)=f(c)=f(e)=1,\\qquad f(b)=f(d)=0,\\\\ &amp;f(a)=f(c)=0, \\qquad f(b)=f(d)=f(e)=1. \\end{aligned} \\] Si usamos la reducción de Gauss-Jordan podemos verificar que esta es además una base de las soluciones homogéneas. Ejercicio 2.7 El primer número de Betti de \\(G=(V,E)\\) es igual a \\(|E|-|V|+C\\) donde \\(C\\) es el número de componentes conexas. Solución Asumamos sin pérdida de generalidad que \\(G\\) es conexo, es decir \\(C=1\\), y en el caso general podemos aplicar el siguiente razonamiento a cada componente conexa de \\(G\\). Un árbol generador \\(T=(V,E_0)\\) de \\(G\\) tiene \\(|V|-1\\) aristas. Por definición, cualquier arista en \\(E\\sm E_0\\) cierra un ciclo en \\(G\\) y genera las soluciones triviales del problema \\(\\div f=0\\). 2.3 Integración por partes En esta sección identificamos a las funciones \\(u:V\\to \\mathbb R\\) con vectores de \\(\\mathbb R^{|V|}\\). Igualmente identificamos a las funciones \\(f:E\\to \\mathbb R\\) con vectores de \\(\\mathbb R^{|E|}\\). Eventualmente también podríamos considerar funciones complejas. El gradiente \\(D:\\mathbb R^{|V|}\\to\\mathbb R^{|E|}\\) se representa así por la matriz \\((D_{e,x}) \\in \\mathbb R^{|E|\\times |V|}\\) tal que \\[ D_{e,x} = \\begin{cases} 1 \\text{ si } x=e_+,\\\\ -1 \\text{ si } x=e_-,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Mientras que la divergencia \\(\\operatorname{div}:\\mathbb R^{|E|}\\to\\mathbb R^{|V|}\\) se representa por la matriz \\((\\operatorname{div}_{x,e}) \\in \\mathbb R^{M\\times N}\\) tal que \\[ \\operatorname{div}_{x,e} = \\begin{cases} -1 \\text{ si } e_+=x,\\\\ 1 \\text{ si } e_-=x,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Descubrimos de esta forma que \\(D^T = -\\operatorname{div}\\) o equivalentemente la fórmula de integración por partes \\[ \\sum_{e\\in E} (fDu)(e) = f\\cdot Du = -u\\cdot \\operatorname{div} f = -\\sum_{x\\in V} (u\\operatorname{div} f)(x). \\] Ejercicio 2.8 Calcula las matrices asociadas con el gradiente y la divergencia para el siguiente grafo Solución \\[ D = \\begin{pmatrix} -1 &amp; 1 &amp; 0 &amp; 0\\\\ 0 &amp; -1 &amp; 1 &amp; 0\\\\ 1 &amp; 0 &amp; -1 &amp; 0\\\\ -1 &amp; 0 &amp; 0 &amp; 1\\\\ 0 &amp; 0 &amp; 1 &amp; -1 \\end{pmatrix} \\qquad \\operatorname{div} = -D^T = \\begin{pmatrix} 1 &amp; 0 &amp; -1 &amp; 1 &amp; 0\\\\ -1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; -1 &amp; 1 &amp; 0 &amp; -1\\\\ 0 &amp; 0 &amp; 0 &amp; -1 &amp; 1 \\end{pmatrix}. \\] Ejercicio 2.9 Demuestra la fórmula de integración por partes sobre un dominio \\(\\Omega \\subseteq V\\) \\[\\begin{equation} \\sum_{\\Omega} u\\operatorname{div}f = \\sum_{E} u^-fn_\\Omega - \\sum_{e_+\\in \\Omega} fDu. \\tag{2.2} \\end{equation}\\] En particular, si \\(u=1\\) recuperamos la fórmula de la divergencia (2.1). Solución Basta con usar que \\(Dv\\cdot f = - v\\cdot \\operatorname{div} f\\) para \\(v := u 1_{\\Omega}\\). Margen de cálculo: Integración por partes La fórmula de integración por partes nos dice que dado un subconjunto \\(\\Omega \\subset\\mathbb R^n\\) con frontera localmente de clase \\(C^1\\) a trozos, un campo vectorial \\(v\\in C^1(\\overline{\\Omega}\\to\\mathbb R^n)\\), y un campo escalar \\(u\\in C^1(\\overline{\\Omega}\\to\\mathbb R^n)\\) entonces \\[ \\int_\\Omega u \\operatorname{div} v = \\int_{\\partial \\Omega} u (v\\cdot n) - \\int_\\Omega Du\\cdot v \\] donde \\(n\\) es el vector normal exterior a \\(\\Omega\\). 2.3.1 Descomposición de Helmholtz La relación \\(D^T=-\\operatorname{div}\\) nos permite dar la descomposición ortogonal \\[ \\mathbb R^{|E|} = D(\\mathbb R^{|V|}) + \\ker(\\operatorname{div}). \\] también conocida como la descomposición de Helmholtz. Es decir que cualquier \\(f:E\\to\\mathbb R\\) puede escribirse de forma única4 como \\[ f = Du + g \\] tal que \\[ \\operatorname{div} g = 0, \\] y como corolario \\(Du \\perp g\\). En términos físicos, cualquier flujo se descompone en una parte que preserva la masa (\\(g\\)) y en un flujo gradiente (\\(Du\\)). Margen de álgebra lineal: El teorema fundamental de álgebra lineal Dado \\(A:\\mathbb R^M\\to \\mathbb R^{N}\\) se tiene que \\[ A(\\mathbb R^{M})^\\perp = \\ker(A^T). \\] Si \\(x \\perp A(\\mathbb R^M)\\) entonces \\(0 = x\\cdot AA^Tx = \\|A^T x\\|^2\\), lo cual implica \\(A^Tx=0\\). Por otro lado si \\(A^Tx=0\\) entonces para \\(y\\in \\mathbb R^M\\) arbitrario \\(x\\cdot Ay = A^Tx\\cdot y=0\\). Ejercicio 2.10 Calcula la descomposición de Helmholtz para el siguiente flujo Solución Sea \\(f:E\\to \\mathbb R\\) los valores que se muestran en la gráfica. Buscamos calcular \\(u:V\\to \\mathbb R\\) y \\(g:E\\to \\mathbb R\\) tales que \\(f=Du+g\\) y \\(\\operatorname{div}g=0\\). Si tomamos así la divergencia en la expresión \\(f=Du+g\\) encontramos que \\(u\\) satisface \\[ \\begin{cases} -2u(A)+u(B)+u(C)=3,\\\\ u(A)-3u(B)+u(C)+u(D)=4,\\\\ u(A)+u(B)-3u(C)+u(D)=-7,\\\\ u(B)+u(C)-2u(D)=0. \\end{cases} \\] Las soluciones homogéneas del sistema son los potenciales constantes5. Ajustando esta constante de forma que \\(u(A)=0\\) obtenemos un sistema que podemos resolver numéricamente import numpy as np A = np.array([[ 1, 1, 0], [-3, 1, 1], [ 1,-3, 1]]) B = np.array([3, 4, -7]) X = np.linalg.inv(A).dot(B) Du = [X[0],X[1]-X[0],-X[1],X[2]-X[1],X[0]-X[2]] f = np.array([1,5,-2,0,0]) g = f-Du print(&quot;[Du(AB), Du(BC), Du(CA), Du(CD), Du(DB)] = {}.&quot;.format(Du)) ## [Du(AB), Du(BC), Du(CA), Du(CD), Du(DB)] = [0.125, 2.75, -2.875, -1.375, -1.375]. print(&quot;[g(AB), g(BC), g(CA), g(CD), g(DB)] = {}.&quot;.format(g)) ## [g(AB), g(BC), g(CA), g(CD), g(DB)] = [0.875 2.25 0.875 1.375 1.375]. 2.4 Laplaciano El Laplaciano es un operador diferencial que se construye aplicando sucesivamente el gradiente y la divergencia. Es decir que mide la producción de masa del gradiente. Además, luego de una manipulación algebraica, observamos que es proporcional a la diferencia entre el promedio en los vértices adyacentes y el valor en el centro. Definición 2.5 Dado \\(u: V \\to \\mathbb R\\), el Laplaciano \\(\\Delta u: V \\to \\mathbb R\\) se define tal que \\[ \\Delta u(v) = \\operatorname{div}(D u)(v) = \\sum_{w \\sim v} (u(w)-u(v)). \\] donde \\(w \\sim v\\) si existe una arista que une a \\(v\\) y \\(w\\) en cualquier orientación. A pesar de que tanto el gradiente como la divergencia requieren que el grafo tenga una orientación, el Laplaciano está bien definido en grafos no dirigidos. Cuando \\(u: V \\to \\mathbb R\\) es un potencial tal que \\(\\Delta u=0\\) en \\(\\Omega \\subseteq V\\), decimos que \\(u\\) es una función armónica sobre \\(\\Omega\\). Ejemplo 2.6 Considera una red eléctrica con resistencias de un Ohm (\\(R(e)=1\\)) la cual modelamos como una grafo dirigido de forma arbitraria. Una batería de un voltio entre dos nodos \\(v_+,v_-\\in V\\) genera un potencial eléctrico \\(u:V\\to \\mathbb R\\) que se puede determinar a partir de la ley de Ohm y la ley de Kirchhoff. Según la ley de Ohm tenemos que la corriente se calcula según \\[ i=Du. \\] Según la ley de Kirchhoff tenemos que fuera de los nodos donde se conecta la bateria, la corriente se conserva, es decir \\[ 0=\\operatorname{div}i = \\Delta u \\text{ en } V\\setminus\\{v_\\pm\\} \\] Junto con las condiciones de borde en los nodos donde se conecta la batería \\[ \\qquad u(v_+) = 1, \\qquad u(v_-) = 0, \\] obtenemos un sistema de ecuaciones lineales con igual número de ecuaciones que de incógnitas. Ejercicio 2.11 Calcula el potencial eléctrico que se genera en un cubo de resistencias de un Ohm, cuando se conecta una batería de un voltio entre dos nodos opuestos del cubo Solución Asumamos sin pérdida de generalidad que se conecta la bateria de los nodos \\(A\\) a \\(D\\) tal que \\(v(A)=1\\) y \\(v(D)=0\\). Tenemos un sistema de ecuaciones lineales de dimensiones 6 por 6. De existir una única solución6 observamos que por simetría se debe cumplir que \\(v(B)=v(F)=v(H)=\\alpha\\) (los nodos adyacentes a \\(A\\)) y \\(v(C)=v(E)=v(G)=\\beta\\) (los nodos adyacentes a \\(E\\)). Esto reduce el sistema a uno de 2 por 2 \\[ \\begin{cases} -9\\alpha+6\\beta = -3,\\\\ 6\\alpha -9\\beta = 0 \\end{cases} \\qquad\\Rightarrow\\qquad \\alpha = \\frac{3}{5}, \\qquad \\beta = \\frac{2}{5}. \\] Finalmente es inmediato verificar que con estos valores se obtiene una solución satisfactoria. Más adelante veremos que las soluciones de estos sistemas siempre son únicas (inyectividad del Laplaciano). Ejercicio 2.12 Calcula la matriz asociada al Laplaciano para el grafo a continuación Solución \\[ \\Delta = \\operatorname{div} D = \\begin{pmatrix} 1 &amp; 0 &amp; -1 &amp; 1 &amp; 0\\\\ -1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; -1 &amp; 1 &amp; 0 &amp; -1\\\\ 0 &amp; 0 &amp; 0 &amp; -1 &amp; 1 \\end{pmatrix}\\begin{pmatrix} -1 &amp; 1 &amp; 0 &amp; 0\\\\ 0 &amp; -1 &amp; 1 &amp; 0\\\\ 1 &amp; 0 &amp; -1 &amp; 0\\\\ -1 &amp; 0 &amp; 0 &amp; 1\\\\ 0 &amp; 0 &amp; 1 &amp; -1 \\end{pmatrix} = \\begin{pmatrix} -3 &amp; 1 &amp; 1 &amp; 1\\\\ 1 &amp; -2 &amp; 1 &amp; 0\\\\ 1 &amp; 1&amp; -3 &amp; 1\\\\ 1 &amp; 0 &amp; 1 &amp; -2 \\end{pmatrix} \\] Ejercicio 2.13 Da un análogo discreto para la fórmula de Green \\[ \\int_\\Omega (u_1\\Delta u_2 - u_2\\Delta u_1) = \\int_{\\partial\\Omega} (u_1Du_2 - u_2 Du_1)\\cdot n \\] Solución De la fórmula de integración por partes (2.2) \\[ \\sum_\\Omega u_i \\Delta u_j = \\sum_{E} u_i^- Du_j n_\\Omega - \\sum_{e_+\\in \\Omega} Du_iDu_j \\] Por lo tanto al tomar la resta se cancelan el segundo término a la deracha quedando así \\[ \\sum_\\Omega (u_1 \\Delta u_2-u_2 \\Delta u_1) = \\sum_{E} (u_1^- Du_2 - u_2^- Du_1)n_\\Omega. \\] En general podemos añadir una operación intermedia entre el gradiente y la divergencia. Esto genera operadores con características similares al Laplaciano. Ejemplo 2.7 Considera ahora una red eléctrica con resistencias variables. La ley de Ohm consiste en tomar el gradiente del potencial y luego dividir por las resistencias para obtener la corriente. Al recíproco de la resistencia también se le conoce como la capacitancia y puede ser más conveniente de usar en este ejemplo. En este caso las ecuaciones de balance para el potencial eléctrico tienen la forma \\[ \\operatorname{div} (CDu) = 0 \\qquad C = 1/R : \\text{Capacitancia} \\] (fuera de los nodos donde se conecta la batería). En el caso particular de las resistencias dadas en la siguiente gráfica, obtenemos el operador lineal asociado a la siguiente matriz import numpy as np # Gradiente D = np.array([[-1, 1, 0, 0], [0, -1, 1, 0], [1, 0, -1, 0], [-1, 0, 0, 1], [0, 0, 1, -1]]) # Capacitancia (C=1/R) C = np.array([[1, 0, 0, 0, 0], [0, 1/4, 0, 0, 0], [0, 0, 1/2, 0, 0], [0, 0, 0, 1/5, 0], [0, 0, 0, 0, 1/3]]) # Operador L = div(CD) L = -np.matmul(D.T,np.matmul(C,D)) print(L) ## [[-1.7 1. 0.5 0.2 ] ## [ 1. -1.25 0.25 -0. ] ## [ 0.5 0.25 -1.08333333 0.33333333] ## [ 0.2 -0. 0.33333333 -0.53333333]] Ejemplo 2.8 Las ecuaciones de balance en los entramados se implementan en tres pasos: Se toman las posiciones relativas entre nodos adyacentes, es decir el gradiente de las posiciones \\(q:V\\to\\mathbb R^2\\). Se forman las tensiones a partir de las posiciones relativas y los multiplicadores \\(\\lambda:E\\to \\mathbb R\\). Se propone el balance de fuerzas en términos de la divergencia de la tensión. En síntesis se obtiene que en los nodos libres \\[ \\operatorname{div} (\\lambda D q) = mge_2 \\] A diferencia de los problemas de redes eléctricas, tanto \\(q\\) como \\(\\lambda\\) son variables por ser determinadas lo cual hace que el problema sea no-lineal en dichas incógnitas. es decir que cualquier ciclo puede ser deformado continuamente a un punto. Por ejemplo, si \\(n=2\\) dice que \\(\\Omega\\) no tiene hoyos.↩︎ En otras palabras un sub-grafo \\(T_0 := (V_0=V,E_0\\subseteq E)\\) libre de ciclos y conexo↩︎ Dado \\(f:E\\to \\mathbb R\\), el potencial \\(u\\) no es único pero su gradiente \\(Du\\) sí.↩︎ Esto puede verificarse de la reducción de Gauss-Jordan en este caso, y además será demostrado con mayor generalidad.↩︎ Una vez más, esto puede chequearse a mano o con una herramienta numérica.↩︎ "],["dinámica.html", "Capítulo 3 Dinámica 3.1 Transporte 3.2 Difusión 3.3 Oscilación", " Capítulo 3 Dinámica 3.1 Transporte Consideremos un grafo dirigido \\(G=(V,E)\\) y una familia de densidades \\(u(x,t)\\) que toma valores reales para cada vértice \\(x\\in V\\) en tiempo \\(t\\in\\mathbb R\\). Decimos que un flujo \\(f(e,t)\\) transporta a \\(u\\) si en cada instante salen \\(f(e,t)\\) unidades de masa de \\(e_-\\) hacia \\(e_+\\) por la arista \\(e\\). Es decir que sobre cada \\(x\\in V\\) se tiene que \\[ \\partial_t u(x,t) = \\sum_{e_+=x} f(e,t) - \\sum_{e_-=x} f(e,t) = -\\operatorname{div} f(x,t). \\] Observamos que si en un dado nodo \\(x\\in V\\) se tiene que \\(\\operatorname{div} f(x)&gt;0\\) entonces \\(u\\) es decreciente. Esto quiere decir que el flujo hace que la densidad se esparza o diverja sobre dicho nodo. De igual forma, si \\(\\operatorname{div} f(x)&lt;0\\), \\(u\\) es creciente y el flujo hace que la densidad en cambio converja en dicho nodo. Ejemplo 3.1 Consideremos una densidad \\(u:V\\times \\mathbb R\\to \\mathbb R\\) transportada por un flujo \\(f := \\mu u^-\\) donde \\(\\mu:E\\to \\mathbb R\\) son tazas de movilidad dadas sobre las aristas en el grafo a continuación y recordemos que \\(u^-(e)=u(e_-)\\) Comenzando de la distribución de densidades \\[ u(0) = (1,0,0,0) \\] integramos numericamente las cuatro ecuaciones dadas por \\[ \\partial_t u = -\\operatorname{div}(\\mu u^-) \\qquad\\Leftrightarrow \\qquad \\begin{cases} u(1)&#39; = -3u(1)+3u(3),\\\\ u(2)&#39; = u(1) - u(2),\\\\ u(3)&#39; = u(2) - 3u(3) + 2u(4),\\\\ u(4)&#39; = 2u(1)-2u(4). \\end{cases} \\] y obtenemos lo siguiente: import numpy as np import matplotlib.pyplot as plt import scipy as sp from scipy.integrate import odeint A = np.array([[-3, 0, 3, 0], [1, -1, 0, 0], [0, 1, -3, 2], [2, 0, 0, -2]]) def dudt(u,t): return np.matmul(A,u) u0 = np.array([1,0,0,0]) t = np.linspace(0,2,1000) sol = odeint(dudt,u0,t) plt.plot(t,sol[:,0], label=&#39;1&#39;) plt.plot(t,sol[:,1], label=&#39;2&#39;) plt.plot(t,sol[:,2], label=&#39;3&#39;) plt.plot(t,sol[:,3], label=&#39;4&#39;) plt.legend() plt.show() Adicionalmente podemos considerar modelos donde además del fenómeno de transporte, una o más densidades tienen distintas reacciones en cada uno de los nodos. Ejemplo 3.2 Las funciones \\(S,I:V\\to \\mathbb R\\) representan poblaciones de individuos susceptibles e infectados para una dada epidemia modelada geográficamente sobre un grafo dirigido \\(G=(V,E)\\). Cada una de estas poblaciones se mueve sobre las aristas por flujos dados por \\[ f_S := \\mu_S S^-, \\qquad f_I := \\mu_I I^-. \\] donde \\(\\mu_S,\\mu_I: E\\to \\mathbb R\\) son tazas de movilidad sobre las aristas. La dinámica de la epidemia en cada nodo está dada por las tazas de transmisión (\\(\\beta\\)) y recuperación (\\(\\gamma\\)). En específico planteamos el modelo de \\(2|V|\\) ecuaciones de primer orden no-lineales \\[ \\partial_t S = -\\beta SI + \\operatorname{div}(\\mu_S S^-), \\qquad \\partial_t I = \\beta SI - \\gamma I + \\operatorname{div}(\\mu_I I^-),\\\\ \\] Ejercicio 3.1 Demuestra que el total de la población susceptible o infectada es una función decreciente. Solución \\[ \\partial_t \\sum_{V} (S+I) = \\sum_{V} (-\\gamma I + \\operatorname{div} f_S+\\operatorname{div}f_I) = - \\gamma \\sum_{V} I \\leq 0. \\] Ejercicio 3.2 Considera una epidemia dada en la siguiente red con los parámetros dados. En las aristas se muestran ciertas tasas de movilidad, para los susceptibles estas deben multiplicarse por \\(10^{-2}\\) y para los infectados por \\(10^{-4}\\). Implementa numéricamente y grafica las soluciones en el intervalo \\([0,160]\\) con condiciones iniciales \\[ S(0) = (1,1,1,1), \\qquad I(0) = (0, 10^{-6},0,0). \\] Solución import numpy as np import matplotlib.pyplot as plt import scipy as sp from scipy.integrate import odeint beta = 0.5 gamma = 0.3 L = np.array([[-5, 1, 2, 1], [2, -3, 1, 0], [1, 2, -4, 2], [2, 0, 1, -3]]) def dSIdt(SI,t): S = SI[:4] I = SI[4:] dS = -beta*S*I + 0.01*np.matmul(L,S) dI = beta*S*I - gamma*I + 0.0001*np.matmul(L,I) return np.concatenate((dS,dI)) S0 = np.array([1,1,1,1]) I0 = np.array([0,0.00000001,0,0]) SI0 = np.concatenate((S0,I0)) t = np.linspace(0,160,1000) sol = odeint(dSIdt,SI0,t) fig, ax = plt.subplots(2,2,figsize=(10,5)) ax[0,0].plot(t,sol[:,0], label=&#39;S1&#39;) ax[0,0].plot(t,sol[:,4], label=&#39;I1&#39;) ax[0,0].legend() ax[1,0].plot(t,sol[:,1], label=&#39;S2&#39;) ax[1,0].plot(t,sol[:,5], label=&#39;I2&#39;) ax[1,0].legend() ax[0,1].plot(t,sol[:,2], label=&#39;S3&#39;) ax[0,1].plot(t,sol[:,6], label=&#39;I3&#39;) ax[0,1].legend() ax[1,1].plot(t,sol[:,3], label=&#39;S4&#39;) ax[1,1].plot(t,sol[:,7], label=&#39;I4&#39;) ax[1,1].legend() 3.2 Difusión Así como vimos en los ejemplos anteriores donde el flujo era proporcional a \\(u^-\\), en general puede darse el caso de que \\(f\\) esté determinada por alguna otra función de \\(u\\), esto se conoce como una ley constitutiva. Un caso muy común es que \\(f\\) sea proporcional a \\(-Du\\), en el cual obtenemos un modelo de difusión. Ejemplo 3.3 Sea \\(G=(V,E)\\) un grafo que modela una red de habitaciones en renta y \\(u:V\\times \\mathbb R\\to\\mathbb R\\) la población que vive en dicha red. Asumiendo la ley de oferta y demanda, el precio de renta \\(p=p(x,t)\\) de una habitación \\(x\\) en el instante \\(t\\) debe ser proporcional a la demanda, la cual podemos considerar en nuestro caso proporcional a la población que habita dicho nodo, digamos por ejemplo que \\(p = k_1u\\). La población busca moverse entre nodos adyacentes si percibe que el precio le es favorable, por ejemplo \\(f=-k_2Dp\\). Llegamos así a la ecuación \\[ \\partial_t u = -\\operatorname{div} f = \\operatorname{div}(k_2Dp) = \\operatorname{div}(aDu), \\qquad a := k_1k_2. \\] El problema \\(\\partial_t u = \\operatorname{div}(aDu)\\), también conocido como la ecuación de calor o difusión, representa un sistema de EDOs lineales y de primer orden con tantas ecuaciones e incógnitas como la cardinalidad de \\(V\\). Ejercicio 3.3 Considera una difusión de la forma \\(\\partial_t u = \\Delta u\\) sobre el siguiente grafo. Calcula \\(u\\) para todo tiempo dadas las condiciones iniciales ilustradas en la figura. ¿Converge la solución a algún punto fijo? Solución El sistema de 4 EDOs se presenta como \\[ \\frac{d}{dt}\\begin{pmatrix} u(a)\\\\ u(b)\\\\ u(c)\\\\ u(d) \\end{pmatrix} = \\begin{pmatrix} -3 &amp; 1 &amp; 1 &amp; 1\\\\ 1 &amp; -2 &amp; 1 &amp; 0\\\\ 1 &amp; 1 &amp; -3 &amp; 1\\\\ 1 &amp; 0 &amp; 1 &amp; -2 \\end{pmatrix}\\begin{pmatrix} u(a)\\\\ u(b)\\\\ u(c)\\\\ u(d) \\end{pmatrix} \\] Dada que la condición inicial es \\((1,0,0,0)^T\\) buscamos la primera columna de la matriz exponencial. El siguiente resultado se obtuvo con la ayuda de sympy, una librería de cálculo simbólico de python from sympy import * t = Symbol(&#39;t&#39;) mt = Matrix([[-3, 1, 1, 1], [1, -2, 1, 0], [1, 1, -3, 1], [1, 0, 1, -2]]) * t mexp = mt.exp() print(&#39;$$&#39; + latex(mexp) + &#39;$$&#39;) \\[\\left[\\begin{matrix}\\frac{1}{4} + \\frac{3 e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4}\\\\\\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} + \\frac{e^{- 2 t}}{2} + \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 2 t}}{2} + \\frac{e^{- 4 t}}{4}\\\\\\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} + \\frac{3 e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4}\\\\\\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 2 t}}{2} + \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} - \\frac{e^{- 4 t}}{4} &amp; \\frac{1}{4} + \\frac{e^{- 2 t}}{2} + \\frac{e^{- 4 t}}{4}\\end{matrix}\\right]\\] Observamos que cuando \\(t\\to\\infty\\) la solución converge exponencialemente al vector \\((1/4,1/4,1/4,1/4)^T\\). De hecho esto sucede para cualquier condición incial. Ejercicio 3.4 Sea \\(G=(V,E)\\) un grafo lineal con 100 vértices \\[ V=\\{1,2,\\ldots,100\\}, \\qquad E = \\{(1,2),(2,3),\\ldots,(99,100)\\}. \\] Sea \\(u\\) solución de la ecuación de calor \\(\\partial_t u=\\Delta u\\) en \\(G\\) con condición inicial \\[ u(0) = e_{50} = (0,\\ldots,0,1,0,\\ldots,0). \\] Calcula el primer \\(t&gt;0\\) tal que \\(u(50,t)\\leq 0.1\\). Solución En este caso la dificultad está en cómo implementar el Laplaciano y encontrar el primer índice donde la solución baje de \\(0.1\\). import numpy as np import matplotlib.pyplot as plt from scipy.integrate import odeint Delta = -2*np.eye(100)+np.eye(100,k=1)+np.eye(100,k=-1) Delta[0,0] = -1 Delta[99,99] = -1 def dudt(u,t): return np.matmul(Delta,u) u0 = np.zeros(100) u0[49] = 1 t = np.linspace(0,20,1000) sol = odeint(dudt,u0,t) index = np.where(sol[:,49]&lt;0.1)[0][0] plt.plot(t,sol[:,49]) plt.plot(t[index],sol[index,49],&#39;ro&#39;,label=&quot;({:.2f},{:.2f})&quot;.format(t[index],sol[index,49])) plt.legend() plt.title(&quot;u(50,t)&quot;) plt.show() 3.3 Oscilación El sistema de EDOs lineales y de segundo orden dado por \\[ \\partial_t^2 u = \\operatorname{div}(aDu) \\] también es común en distintos modelos. Esta se conoce como la ecuación de onda. Ejemplo 3.4 Un grafo \\(G=(V,E)\\) modela las conexiones en un sistema de masas \\(m:V\\to (0,\\infty)\\) unidas por resortes con constantes \\(k:E\\to[0,\\infty)\\). Sea \\(q:V\\to \\mathbb R^n\\) los desplazamientos de las masas a partir de una configuración dada de equilibrio. A partir de la ley de Hooke planteamos el sistema \\(n\\times|V|\\) ecuaciones e incógnitas, \\[ m\\partial_t^2 q = \\operatorname{div}(kDq). \\] Recordemos que cualquier sistema de segundo orden puede ser llevado a un sistema de primer orden tomando a las velocidades como incógnitas del sistema. Por ejemplo, \\[ \\partial_t^2 u = \\operatorname{div}(aDu) \\qquad \\Leftrightarrow\\qquad \\begin{cases} \\partial_t u = v,\\\\ \\partial_t v = \\operatorname{div}(aDu). \\end{cases} \\] Ejemplo 3.5 El grafo \\(G=(V,E)\\) vuelve a modelar una red de habitaciones en renta, \\(u:V\\times \\mathbb R\\to\\mathbb R\\) la población que vive en dicha red y \\(p:V\\times \\mathbb R\\to\\mathbb R\\) los precios. Una vez más asumimos que la población se mueve según el flujo \\(f = -Dp\\). Por otro lado los precios se modifican gradualmente dependiendo de la demanda en relación a los nodos adyacentes. Esto último puede ser reflejado por ejemplo en la ecuación \\(\\partial_t p = -\\Delta u\\), es decir que el precio disminuye si el promedio de la población vecina es mayor la población en el nodo en consideración, con la intención de atraerla. En resumen obtenemos el sistema de ecuaciones \\[ \\partial_t u = \\Delta p, \\qquad \\partial_t p = -\\Delta u. \\] Estas implican las ecuaciones de onda desacopladas para el bilaplaciano \\[ \\partial_t^2 u = -\\Delta^2 u, \\qquad \\partial_t^2 p = -\\Delta^2p. \\] Ejercicio 3.5 Considera una oscilación de la forma \\(\\partial_t^2 u = -\\Delta^2 u\\) sobre el siguiente grafo. Calcula \\(u\\) para todo tiempo dadas las condiciones iniciales ilustradas en la figura, partiendo del reposo. Grafica la solución en el intervalo \\([0,6]\\). Solución El sistema de 4 EDOs se presenta como \\[ \\frac{d}{dt}\\begin{pmatrix} u(a)\\\\ u(b)\\\\ u(c)\\\\ u(d)\\\\ u&#39;(a)\\\\ u&#39;(b)\\\\ u&#39;(c)\\\\ u&#39;(d) \\end{pmatrix} = \\begin{pmatrix} 0_4 &amp; I_4\\\\ -\\Delta^2 &amp; 0_4 \\end{pmatrix}\\begin{pmatrix} u(a)\\\\ u(b)\\\\ u(c)\\\\ u(d)\\\\ u&#39;(a)\\\\ u&#39;(b)\\\\ u&#39;(c)\\\\ u&#39;(d) \\end{pmatrix}, \\qquad \\Delta = \\begin{pmatrix} -3 &amp; 1 &amp; 1 &amp; 1\\\\ 1 &amp; -2 &amp; 1 &amp; 0\\\\ 1 &amp; 1 &amp; -3 &amp; 1\\\\ 1 &amp; 0 &amp; 1 &amp; -2 \\end{pmatrix} \\] Para calcular la solución analítica usamos el paquete simbólico de python. import numpy as np import matplotlib.pyplot as plt import sympy as smp from sympy.plotting import plot Delta = smp.Matrix([[-3,1,1,1], [1,-2,1,0], [1,1,-3,1], [1,0,1,-2]]) t = smp.symbols(&#39;t&#39;,real=&#39;True&#39;) B = smp.Matrix(smp.BlockMatrix([[smp.ZeroMatrix(4,4),smp.Identity(4)], [-Delta*Delta,smp.ZeroMatrix(4,4)]]))*t eB = smp.re(B.exp()) y0 = smp.Matrix([0,1,2,3,0,0,0,0]) y_s = eB*y0 print(&#39;$$&#39; + smp.latex(y_s[:4]) + &#39;$$&#39;) \\[\\left[ \\frac{3}{2} - \\frac{3 \\cos{\\left(4 t \\right)}}{2}, \\ - \\cos{\\left(2 t \\right)} + \\frac{\\cos{\\left(4 t \\right)}}{2} + \\frac{3}{2}, \\ \\frac{\\cos{\\left(4 t \\right)}}{2} + \\frac{3}{2}, \\ \\cos{\\left(2 t \\right)} + \\frac{\\cos{\\left(4 t \\right)}}{2} + \\frac{3}{2}\\right]\\] Las gráficas están dadas por eB_f = smp.lambdify(t,eB) t = np.linspace(0,6,600) y0 = np.array([0,1,2,3,0,0,0,0]) y = np.einsum(&#39;ijk,j-&gt;ik&#39;,eB_f(t),y0) plt.plot(t,y[0,:],label=&#39;a&#39;) plt.plot(t,y[1,:],label=&#39;b&#39;) plt.plot(t,y[2,:],label=&#39;c&#39;) plt.plot(t,y[3,:],label=&#39;d&#39;) plt.legend(loc=&#39;lower right&#39;) "],["implementación-del-entramado.html", "Capítulo 4 Implementación del entramado 4.1 Librerías y datos 4.2 Ecuación diferencial 4.3 Integración y graficación", " Capítulo 4 Implementación del entramado En esta sección veremos como poner en práctica los conceptos aprendidos para modelar una red cuadrada sujetada por sus cuatro esquinas. Recordemos que a pesar de que podemos dar una forma explícita de las ecuaciones que se deben resolver, el método de Newton parece ser muy sensible a las condiciones iniciales, por lo que hay que ingeniarse una forma alternativa. La idea que tenemos en mente es proponer que las conexiones entre nodos son inicialmente elásticas con un mecanismo adicional de amortiguamiento (para poder llevar el sistema al reposo). La configuración términa noe s exactamente la deseada puesto que la deformación del resorte no satisface exactamente la restricción de longitud sobre las aristas. Sin embargo podemos luego ir haciendo la dureza (stiffness) de los resortes cada vez más y más grande, aproximando así la configuración de equilibrio cuando las barras son rígidas. 4.1 Librerías y datos Para fijar ideas proponemos una red con \\(N\\) por \\(N\\) nodos de masa \\(m&gt;0\\) como la ilustrada a continuación. La esquinas serán colgadas en los puntos \\((0,0,0)\\), \\((1,0,0)\\), \\((1,1,0)\\), y \\((0,1,0)\\). Entre cada par de nodos adyacentes se ubica un resorte cuya longitud natural es \\(l &gt; 1/(N-1)\\), dureza \\(k\\gg 1\\), y amortiguación \\(\\gamma &gt; 0\\). Es decir que si dos nodos adyacentes están a distancia \\(d\\), la magnitud de la fuerza que ejerce el resorte entre ellos es \\(k|d-l|\\). Esta fuerza es paralela a la línea que contiene a estos nodos y la dirección (o el signo) dependen de como se compare \\(d\\) respecto de \\(l\\): Para \\(d&gt;l\\) el resorte atrae a los nodos entre si, y para \\(d&lt;l\\) el resorte los repele. import numpy as np from numpy import linalg as la import matplotlib.pyplot as plt import scipy as sp import scipy.sparse as sps from scipy.integrate import odeint N = 10 # Longitud de la red m = 0.1 # Masa de los nodos gamma = 1 # Coeficiente de amortiguación k = 100 # Coeficiente de dureza l = 1.1/(N-1) # Longitud natural del resorte fijos = [0, N-1, N**2-N, N**2-1] # Esquinas fijas # Listas para enumerar las aristas de la red # Aristas verticales ini_v = list(range(N**2-N)) fin_v = list(range(N,N**2)) # Aristas horizontales ini_h = list(range(N**2)) del ini_h[slice(N-1,N**2,N)] fin_h = list(range(1,N**2+1)) del fin_h[slice(N-1,N**2,N)] ini = ini_h + ini_v # Nodos de salida fin = fin_h + fin_v # Nodos de llegada Ne = len(ini) # Número de aristas 4.2 Ecuación diferencial La ecuación diferencial que buscamos modelar para la posición \\(p=(x,y,z)\\) de cada nodo está dada por las leyes de Newton: \\[ mp&#39;&#39; = \\text{gravedad} + \\text{tensión} + \\text{amortiguación} \\] De estos tres tréminos la gravedad y la amortiguación son fáciles de calcular. Respectivamente son \\(-mge_z\\) y \\(-\\gamma p&#39;\\). Asumiendo el sistema internacional de unidades tomamos \\(g = 9.8\\). La dificultad reside ahora en implementar el cálculo de las tensiones. Recordemos además que para poder resolver nuestra EDO usando la librería de integración numérica de Scipy (odeint) debemos transformar el sistema a uno de primer orden. Esto significa que las velocidades pasan a ser parte de las incógnitas. Codificamos en la curva \\(s=s(t)\\) las configuraciones de nuestro sistema de la siguiente forma \\[ s = (pos,vel) = ((x,y,z),(vx,vy,vz)) \\in (\\mathbb R^{N^2}\\times\\mathbb R^{N^2}\\times\\mathbb R^{N^2})\\times(\\mathbb R^{N^2}\\times\\mathbb R^{N^2}\\times\\mathbb R^{N^2}) \\] Dadas las posiciones \\(p_{ini}\\) y \\(p_{fin}\\) de dos nodos extremos sobre una arista dada tenemos que la tensión sobre dicha arista se calcula por \\[ T := k(d-l)\\theta, \\qquad d := |p_{fin}-p_{ini}|, \\qquad \\theta := \\frac{p_{fin}-p_{ini}}{d} \\] Esta es justamente la tensión que se ejerce sobre el nodo inicial de la arista, siendo la fuerza opuesta en el otro nodo gracias a la tercera ley de Newton. Un paso técnico a partir de acá consiste en transferir está informaición dada sobre las aristas a los nodos. Estas consideraciones teóricas quedan reflejadas en la siguiente función: def dsdt(s,t): pos = np.reshape(s[:3*N**2],(3,N**2)).T vel = np.reshape(s[3*N**2:],(3,N**2)).T pos_rel = pos[fin] - pos[ini] lon_rel = np.tile(la.norm(pos_rel,axis=1),(3,1)).T # d dir_rel = pos_rel/lon_rel # theta ten_esc = k*(lon_rel-l*np.ones((Ne,3))) # Magnitud de la tensión (signada) ten_ari = ten_esc*dir_rel # Tensión sobre el nodo inicial # Tensión total sobre cada nodo. Usamos una estructura de matrices ralas (sparse) para codificarlas eficientemente. data = np.concatenate((ten_ari.T.reshape(-1),-ten_ari.T.reshape(-1))) fila = 3*ini+3*fin colu = 2*(Ne*[0]+Ne*[1]+Ne*[2]) ten_nod = sps.coo_matrix((data, (fila, colu))).toarray() # Fuerzas y aceleración fue_gra = -9.8*m*np.tile(np.array([0,0,1]),(N**2,1)) # Gravedad visc = -gamma*vel # Amortiguación acel = (ten_nod + fue_gra + visc)/m # Aceleración acel[fijos,:] = [0,0,0] # Esquinas fijas return np.concatenate((s[3*N**2:],acel.T.reshape(-1))) 4.3 Integración y graficación Una vez modelada la ecuación diferencial ya podemos proceder a integrarla usando por ejemplo el comando odeint de la librería Scipy. Para ello necesitamos dar adicionalmente un intervalo de tiempo discreto y una condición inicial. px, py = np.meshgrid(np.linspace(0,1,N),np.linspace(0,1,N)) s0 = np.concatenate((px.reshape(-1), py.reshape(-1),np.zeros(N**2),np.zeros(3*N**2))) t = np.linspace(0,10,2000) sol = odeint(dsdt,s0,t) Visualización del último instante fig = plt.figure() ax = plt.axes(projection=&#39;3d&#39;) ax.axes.set_xlim3d(left=0, right=1); ax.axes.set_ylim3d(bottom=0, top=1); ax.axes.set_zlim3d(bottom=-1, top=0); ax.view_init(60, 80); sol_fin = sol[-1,:] pos = np.reshape(sol_fin[:3*N**2],(3,N**2)).T for i in range(N): ax.plot3D(pos[i*N:(i+1)*N,0], pos[i*N:(i+1)*N:,1], pos[i*N:(i+1)*N,2],&#39;bo-&#39;) ax.plot3D(pos[i:N**2:N,0], pos[i:N**2:N,1], pos[i:N**2:N,2],&#39;b-&#39;) "],["espectro-del-laplaciano.html", "Capítulo 5 Espectro del Laplaciano 5.1 Problema elíptico 5.2 Problema parabólico 5.3 Problema hiperbólico 5.4 Nerd sniping", " Capítulo 5 Espectro del Laplaciano Hemos visto tres familias de problemas relacionados con el operador lineal \\(u \\mapsto Lu = \\operatorname{div}(aDu)\\): Elíptico: \\(\\operatorname{div}(aDu) = f\\), Parabólico: \\(\\partial_t u = \\operatorname{div}(aDu) + f\\), Hiperbólico: \\(\\partial_t^2 u = \\operatorname{div}(aDu) + f\\). Como tales, la descomposición espectral de \\(L\\) trivializa el cálculo de las soluciones. A continuación daremos un breve recorrido a la teoría discreta de Fourier con la cual podemos clarificar como resolver cada uno de estos problemas. Para \\(a:E\\to (0,\\infty)\\) la composición dada por \\(Lu = \\operatorname{div}(aDu)\\) es un operador simétrico, negativo semi-definido. La simetría es una aplicación de la fórmula de integración por partes, bien sea usando que \\[ (\\operatorname{div} \\operatorname{diag}(a) D)^T = D^T \\operatorname{diag}(a)^T \\operatorname{div}^T = (-\\operatorname{div}) \\operatorname{diag}(a)(-D) = \\operatorname{div}\\operatorname{diag}(a)D, \\] o en términos de las sumas \\[ \\sum_{x\\in V} v(x)\\operatorname{div}(aDu)(x) = -\\sum_{e\\in E} Dv(e)Du(e)a(e) = \\sum_{x\\in V} u(x)\\operatorname{div}(aDv)(x). \\] La no-positividad la verificamos tomando \\(v=u\\) tal que \\[ \\sum_{x\\in V} u(x)\\operatorname{div}(aDu)(x) = -\\sum_{e\\in E} (Du(e))^2a(e) \\leq 0. \\tag{5.1} \\] Gracias al teorema espectral sabemos que \\(L\\) es diagonalizable, sus autovalores son reales no-positivos y además posee una base de autofunciones ortogonales. Denotemos por \\(\\phi_0,\\ldots,\\phi_{M-1}\\) a una base ortogonal con autovalores \\(-\\lambda_0,\\ldots,-\\lambda_{M-1}\\) respectivamente. Margen de álgebra lineal: El teorema espectral El teorema espectral dice que si \\(L\\in \\mathbb R^{N\\times N}\\) es simétrica, entonces sus autovectores son reales y existe una base ortogonal de autovectores. Para ver que un dado autovector \\(\\lambda\\) es real consideramos un correspondiente autovector \\(\\xi\\) (posiblemente complejo) tal que \\[ \\lambda\\|\\xi\\|^2 = L\\xi\\cdot \\overline{\\xi} = \\xi\\cdot L\\overline{\\xi} = \\xi\\cdot \\overline{L\\xi} = \\overline{\\lambda}\\|\\xi\\|^2. \\] Dado que \\(\\xi\\neq0\\) la única opción posible es que \\(\\lambda=\\overline{\\lambda}\\), es decir \\(\\lambda\\in \\mathbb R\\). Más aún, podemos considerar de ahora en adelante que \\(\\xi\\) también es real dado que las partes real e imaginarias de un dado autovector son también autovectores (dado que \\(L\\) es real). Autovectores \\(\\xi\\), \\(\\xi&#39;\\) con autovalores distintos \\(\\lambda\\), \\(\\lambda&#39;\\) (respectivamente) son ortogonales dado que \\[ \\lambda (\\xi\\cdot\\overline{\\xi&#39;}) = L\\xi\\cdot \\overline{\\xi&#39;} = \\xi\\cdot L\\overline{\\xi&#39;} = \\xi\\cdot \\overline{L\\xi&#39;} = \\overline{\\lambda&#39;} (\\xi\\cdot\\overline{\\xi&#39;}) = \\lambda&#39; (\\xi\\cdot\\overline{\\xi&#39;}). \\] Para ver que existe una base de autovectores se puede proceder por inducción. Si \\(\\lambda\\) es un autovalor con autovector \\(\\xi\\), entonces podemos descomponer \\(\\mathbb R^N\\) como la suma directa de la línea \\(\\operatorname{vspan}\\{\\xi\\}\\) y su complemento ortogonal \\(S = \\operatorname{vspan}\\{\\xi\\}^\\perp\\). El operador \\(L|_S\\) tiene rango en \\(S\\), dado que para \\(x\\in S\\) \\[ Lx\\cdot \\overline{\\xi} = x\\cdot L\\overline{\\xi} = x\\cdot \\overline{L\\xi} = \\overline{\\lambda} (x\\cdot \\overline{\\xi}) = 0. \\] Además vuelve a ser simétrico (con respecto al producto interno). Tenemos de esta forma el paso para llevar adelante un argumento por inducción. Finalmente, cuando \\(L\\) se corresponde con una forma cuadrática negativa semi-definida tenemos que los autovalores son no-positivos dado que \\[ 0\\geq L\\xi\\cdot \\xi = \\lambda\\|\\xi\\|^2. \\] Gracias a la identidad (5.1) vemos además que \\(\\operatorname{div}(aDu)=0\\) si y solo si \\(Du=0\\). Si \\(G\\) es conexo entonces esto solamente se cumple para las funciones constantes. En otras palabras, \\(\\lambda=0\\) es un autovalor simple cuyo autoespacio consiste de las funciones constantes. En general, \\(\\lambda=0\\) es un autovalor de \\(L\\) cuya multiplicidad geométrica es igual al número de componentes conexas de \\(G\\). Asumiremos además de ahora en adelante que \\(G\\) es conexo y \\(\\phi_0=1\\) es la autofunción asociada a \\(\\lambda_0=0\\), siendo los demás autovalores estrictamente negativos (es decir que \\(\\lambda_j&gt;0\\) para \\(j\\neq 0\\)). Ejercicio 5.1 Demuestra que para cualquier autofunción \\(\\phi_j\\) para \\(j\\neq 0\\) se tiene que \\(\\phi_j\\) cambia de signo. Es decir que ninguno conjuntos \\(\\{\\phi_j&gt;0\\}\\), \\(\\{\\phi_j&lt;0\\}\\) es vacío. Solución Dado que \\(\\phi_0=1\\) es ortogonal a \\(\\phi_j\\) tenemos que \\(\\sum\\phi_j=0\\). Como \\(\\phi_j\\neq 0\\), necesariamente debe tener tanto valores positivos como negativos. Gracias a la ortogonalidad podemos calcular la descomposición de una función arbitraria usando productos internos. Esta se conoce como la transformada de Fourier discreta. Dado que \\[ u = \\sum_{j=0}^{|V|-1} \\hat u_j \\phi_j \\] tenemos que tomando en ambos lados el producto interno con \\(\\phi_j\\) obtenemos que \\[ \\hat u_j = \\frac{1}{\\|\\phi_j\\|^2}\\sum_{x\\in V} u(x) \\overline{\\phi_j(x)}. \\] Los coeficientes \\(\\hat u_j\\) se conocen como los coeficientes de Fourier. Ejemplo 5.1 Consideremos el grafo cíclico con \\(M\\) vértices los cuales identificamos con los enteros módulo \\(M\\). En este caso \\[ \\Delta u(x) = u(x+1) - 2u(x) + u(x-1). \\] Para calcular el espectro de \\(\\Delta\\) debemos encontrar las soluciones \\(M\\)-periódicas de la recurrencia \\[ \\phi(x+1) - 2\\phi(x) + \\phi(x-1) = -\\lambda \\phi(x). \\] Sean \\(r_\\pm\\) las raíces del polinomio característico \\(p(r) = r^2-(2-\\lambda)r+1\\). Tenemos así que7 \\[ \\phi(x) = A_+r_+^x+A_-r_-^x. \\] Observamos que para obtener soluciones \\(M\\)-periódicas basta con tomar a \\(r_\\pm\\) como raíces \\(M\\)-ésimas de la unidad, conjugadas entre si (dado que \\(r_+r_-=1\\)), de hecho la condición también terminará siendo necesaria. Es decir que \\[ r_\\pm = \\omega^{\\pm j}, \\qquad \\omega := e^{2\\pi i/M}, \\qquad j\\in\\{0,1,\\ldots,M-1\\}. \\] A partir de estas encontramos las autofunciones \\[ \\phi_{j}(x) := \\omega^{jx} \\] cuyos autovalores son \\(-\\lambda_j\\) donde \\[ \\lambda_j := \\omega^{j}+\\omega^{-j}-2 = 2\\cos(2\\pi j/M)-2 = 4\\sin^2(\\pi j/M). \\] La colección \\(\\phi_0,\\ldots,\\phi_{M-1}\\) forma una base ortogonal de \\(\\mathbb C^M\\) conocida como la base de Fourier \\[ \\sum_{x\\in V} \\phi_k(x)\\overline{\\phi_l(x)} = \\sum_{j=0}^{M-1} \\omega^{(k-l)j} = \\begin{cases} M \\text{ si } k=l,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Observa que \\(\\lambda_j = \\lambda_{M-j}\\), por lo que si \\(j\\) no es divisible por \\(M/2\\), el autovalor \\(\\lambda_j\\) tiene multiplicidad dos. En los demás casos el autovalor tiene multiplicidad uno. Ejercicio 5.2 Demuestra que a partir de \\[ \\varphi_j(x) := \\cos(2\\pi j x/M), \\qquad \\psi_j(x) := \\sin(2\\pi j x/M) \\] también se puede construir una base ortogonal de autovectores para el ejemplo anterior. Acá debes prestar atención de lo que sucede cuando \\(j=M/2\\) en caso de que \\(M\\) sea par. Solución \\[ \\begin{aligned} (\\Delta \\varphi_j)(x) &amp;= \\cos(2\\pi j(x-1)/M)-2\\cos(2\\pi j x/M)+\\cos(2\\pi j(x+1)/M),\\\\ &amp;= 2(\\cos(2\\pi j/M)-1)\\cos(2\\pi j x/M),\\\\ &amp;= -\\lambda_j \\varphi_j(x) \\end{aligned} \\] De igual forma \\[ \\Delta \\psi_j = -\\lambda_j \\psi_j. \\] Observamos además que \\(\\varphi_{M-j}=\\varphi_j\\) y además \\(\\psi_{M-j}=-\\psi_j\\). Para \\(M\\) par, proponemos entonces tomar \\(\\varphi_0,\\varphi_1,\\ldots,\\varphi_{M/2},\\psi_1,\\ldots,\\psi_{M/2-1}\\) como una base. Observa que \\(\\varphi_0(x)=1\\) representa las funciones constantes y que hemos evitado deliberadamente tomar \\(\\psi_{M/2}\\), la cual es la función trivial. Dado que autovectores con autovalores distintos son ortogonales, basta con verificar que \\(\\varphi_j\\) y \\(\\psi_j\\) son linealmente independientes para obtener que el conjunto propuesto es una base. Esto se deduce de \\[ \\varphi_j(0)=1 \\qquad\\text{ y }\\qquad \\psi_j(0)=0. \\] Para \\(M\\) impar proponemos en cambio la base \\(\\varphi_0,\\varphi_1,\\ldots,\\varphi_{(M-1)/2},\\psi_1,\\ldots,\\psi_{(M-1)/2}\\) como una base. Una vez más basta verificar que \\(\\varphi_j\\) y \\(\\psi_j\\) son linealmente independientes, lo cual se deduce igualmente de la identidad dada arriba. Ejercicio 5.3 Calcula las normas de \\(\\varphi_j\\) y \\(\\psi_{j}\\). Solución \\(\\|\\varphi_j\\|^2=\\|\\psi_{j}\\|^2=M/2\\) Ejercicio 5.4 Calcula el espectro del Laplaciano en los siguientes casos: Sólidos platónicos: tetraedro, cubo, octaedro, dodecaedro, icosaedro, Grafo completo, Grafo bipartito completo, Grafo lineal, Grafo producto8 en términos del espectro de sus factores (que asumimos conocido). Por ejemplo un toro puede verse como el producto de grafos cíclicos. Solución Tetraedro Cubo Octaedro Dodecaedro Icosaedro Grafo completo Grafo bipartito completo Grafo lineal Grafo producto 5.1 Problema elíptico Dada la descomposición \\[ f = \\sum_{j=0}^{|V|-1} \\hat f_j\\phi_j, \\qquad \\hat f_j = \\frac{1}{\\|\\phi_j\\|^2}\\sum_{x\\in V} f(x)\\overline{\\phi_j(x)}, \\] tenemos que \\(u = \\sum_{j=0}^{|V|-1} \\hat u_j\\phi_j\\) satisface \\(Lu=f\\) si y solo si para todo \\(j\\in\\{0,\\ldots,(|V|-1)\\}\\) \\[ -\\lambda_j \\hat u_j = \\hat f_j. \\] Recordemos la hipótesis de conexidad para \\(G\\) la cual garantiza que \\(\\lambda_0=0\\) es un autovalor simple cuyo autoespacio son las funciones constantes generadas por \\(\\phi_0=1\\). Para \\(j\\neq 0\\) tenemos \\(\\lambda_j &gt; 0\\) por lo cual \\(\\hat u_j = -\\hat f_j/\\lambda_j\\). Para \\(j=0\\) tenemos sin embargo que \\(\\lambda_0=0\\) en cuyo caso la ecuación tiene solución solamente si se da la condición de ortogonalidad \\(f\\perp \\phi_0\\), equivalente a decir que9 \\[ \\sum_{x\\in V} f(x) = 0. \\] Bajo esta hipótesis, el correspondiente coeficiente \\(\\hat u_0\\) es arbitrario. Bajo la condición anterior para \\(f\\), tenemos que las soluciones de \\(Lu=f\\) están dadas por \\[ u(x) = c - \\sum_{j=1}^{|V|-1} \\frac{\\hat f_j}{\\lambda_j}\\phi_j(x) = c - \\sum_{j=1}^{|V|-1} \\frac{1}{\\lambda_j\\|\\phi_j\\|^2}\\left(\\sum_{y\\in V} f(y)\\overline{\\phi_j(y)}\\right)\\phi_j(x). \\] El término constante es la solución homogénea del sistema. El segundo es una solución particular la cual podemos reescribir como \\[ u_p(x) := -\\sum_{y\\in V} G(x,y)f(y), \\qquad G(x,y) := \\sum_{j=1}^{|V|-1} \\frac{\\phi_j(x)\\overline{\\phi_j(y)}}{\\|\\phi_j\\|^2}\\lambda_j^{-1}. \\] Ejercicio 5.5 Demuestra que10 \\[ \\Delta_1 G(x,y) = \\Delta_2 G(x,y) = \\frac{1}{|V|}- 1_y(x)=\\frac{1}{|V|}- 1_x(y). \\] Solución Ejercicio 5.6 Demuestra que \\[ \\sum_{x\\in V} G(x,x) = \\sum_{j=1}^{|V|-1} \\lambda_j^{-1}. \\] Solución Ejercicio 5.7 Demuestra que \\(G\\) es independiente de la base de Fourier. Solución Ejercicio 5.8 Demuestra que \\(G(x,y)=G(y,x)\\). Solución Ejercicio 5.9 Demuestra que para \\(x\\in[0,M]\\) \\[ \\sum_{j=1}^{M-1} \\frac{e^{2\\pi i j x}-1}{\\sin^2(\\pi j/M)} = 2x(x-M) \\] Solución 5.2 Problema parabólico El sistema \\(\\partial_t u = Lu+f\\) se reduce a un sistema de ecuaciones diferenciales ordinarias desacopladas \\[ \\hat u_j&#39; = -\\lambda_j \\hat u_j + \\hat f_j \\] Usando por ejemplo la técnica del factor integrante obtenemos \\[ \\begin{aligned} \\hat u_j(t) &amp;= \\hat u_j(0)e^{-\\lambda_j t} + \\int_0^t \\hat f_j(s)e^{-\\lambda_j(t-s)}ds\\\\ &amp;= \\frac{1}{\\|\\phi_j\\|^2}\\sum_{y=1}^{|V|} \\left(u(y,0)\\overline{\\phi_j(y)}e^{-\\lambda_j t} + \\int_0^t f(y,s)\\overline{\\phi_j(y)}e^{-\\lambda_j(t-s)}ds\\right) \\end{aligned} \\] Agrupando los términos para la solución concluimos que \\[ u(x,t) = \\sum_{y\\in V} u(y,0)H(x,y,t) + \\int_0^t\\sum_{y\\in V} f(y,s)H(x,y,t-s)ds \\] donde \\[ H(x,y,t) := \\sum_{j=0}^{|V|-1} \\frac{\\phi_j(x)\\overline{\\phi_j(y)}}{\\|\\phi_j\\|^2}e^{-\\lambda_j t} = \\frac{1}{|V|} + \\sum_{j=1}^{|V|-1} \\frac{\\phi_j(x)\\overline{\\phi_j(y)}}{\\|\\phi_j\\|^2}e^{-\\lambda_j t}. \\] Ejercicio 5.10 Demuestra que \\(H(y,x,t) = H(x,y,t)\\). Solución Ejercicio 5.11 Demuestra que \\(H\\) es la solución del problema de valores iniciales \\[ \\begin{cases} \\partial_t H = \\Delta_1 H = \\Delta_2 H,\\\\ H = 1_y(x)= 1_x(y) \\text{ para $t=0$}. \\end{cases} \\] Concluye a partir de esto que \\(H\\) es independiente de la base de Fourier. Solución Ejercicio 5.12 Sea \\(u\\) tal que \\(\\partial_t u = \\Delta u\\). Calcula \\(\\lim_{t\\to\\infty} u(t)\\) en términos de \\(u(0)\\). Solución \\(\\lim_{t\\to\\infty} u(t) = \\frac{1}{M}\\sum_{x\\in V}u(x,0)\\) Ejercicio 5.13 Para \\(G\\) conexo demuestra que se da la siguiente expresión asintótica cuando \\(t\\to\\infty\\) \\[ \\int_0^t H(x,y,s)ds = \\frac{t}{|V|} + G(x,y) + O(e^{-\\lambda_1 t}) \\] Solución 5.3 Problema hiperbólico El sistema \\(\\partial_t^2 u = Lu+f\\) también se reduce a un sistema de ecuaciones desacopladas de segundo orden \\[ \\hat u_j&#39;&#39; = -\\lambda_j \\hat u_j + \\hat f_j \\] Tenemos así que \\(\\hat u_j(t)\\) se puede calcular en términos de su posición y velocidad inicial. Para \\(j=0\\) \\[\\begin{align*} \\hat u_0(t) &amp;= \\hat u_0(0) + \\hat u_0&#39;(0) t + \\int_0^t \\hat f_0(s)(t-s)ds. \\end{align*}\\] Para \\(j\\neq0\\) denotamos la frecuencia \\(\\omega_j=\\sqrt{\\lambda_j}\\) tal que \\[\\begin{align*} \\hat u_j(t) &amp;= \\hat u_j(0)\\cos(\\omega_j t) + \\hat u_j&#39;(0)\\frac{\\sin(\\omega_j t)}{\\omega_j} + \\int_0^t \\hat f_j(s)\\frac{\\sin(\\omega_j(t-s))}{\\omega_j}ds. \\end{align*}\\] Agrupando los términos para la solución concluimos que \\[ u(x,t) = \\sum_{j=0}^{|V|-1} u(y,0)W_1(x,y,t)+\\partial_t u(y,0)W_2(x,y,t) + \\int_0^t f(y,s)W_2(x,y,t-s)ds \\] donde \\[\\begin{align*} W_1(x,y,t) &amp;:= \\sum_{j=0}^{|V|-1} \\frac{\\phi_j(x)\\overline{\\phi_j(y)}}{\\|\\phi_j\\|^2}\\cos(\\omega_j t), \\\\ W_2(x,y,t) &amp;:= \\frac{t}{|V|} + \\sum_{j=1}^{|V|-1} \\frac{\\phi_j(x)\\overline{\\phi_j(y)}}{\\|\\phi_j\\|^2}\\frac{\\sin(\\omega_j t)}{\\omega_j}. \\end{align*}\\] Ejercicio 5.14 (Ley de Stokes) Demuestra que si \\[ \\begin{cases} \\partial_t^2u = Lu,\\\\ u|_{t=0} = 0,\\\\ \\partial_t u|_{t=0} = v_0, \\end{cases} \\qquad\\Leftrightarrow\\qquad u(x,t) = \\sum_{j=0}^{M-1} v_0(y)W_2(x,y,t) \\] entonces \\(v = \\partial_tu\\) satisface \\[ \\begin{cases} \\partial_t^2v = Lv,\\\\ v|_{t=0} = v_0,\\\\ \\partial_t v|_{t=0} = 0, \\end{cases} \\qquad\\Leftrightarrow\\qquad v(x,t) = \\sum_{j=0}^{M-1} v_0(y)W_1(x,y,t). \\] Solución 5.4 Nerd sniping En esta sección veremos como resolver el problema presentado en la siguiente caricatura de Randall Munroe autor de XKCD. La resistencia efectiva se define de la siguiente forma. Etiquetemos primero los nodos de la red por \\((x,y) \\in \\mathbb Z^2\\) tales que los nodos marcados son el origen \\((0,0)\\) y \\((2,1)\\). Se fija un potencial \\(u\\) sobre la red tal que \\(u(0,0)=0\\), \\(u(2,1)=1\\), mientras que en los demás nodos \\(u\\) es armónica, es decir que para \\((x,y) \\in \\mathbb Z^2 \\setminus \\{(0,0),(2,1)\\}\\) \\[ \\Delta u(x,y) = u(x-1,y) + u(x+1,y) + u(x,y-1) + u(x,y+1) - 4u(x,y) = 0. \\] Para que \\(u\\) esté definida de forma unívoca hay que pedir adicionalmente que \\(u\\to 0\\) cuando \\(|(x,y)|\\to \\infty\\). Desde una perspectiva física esta condición en infinito es la más natural. La corriente \\(i\\) que sale del origen es la divergencia de \\(u\\) en dicho punto, \\(i= \\operatorname{div} u(0,0)\\). Este es a su vez la corriente que entra en el vértice \\((2,1)\\) la cual se calcula de igual forma como \\(i = -\\operatorname{div} u(2,1)\\). Si buscamos simplificar la red por el caso más sencillo que conecta a \\((0,0)\\) y \\((2,1)\\), es decir el grafo con solamente estos dos vértices y una arista entre ellos, entonces la resistencia efectiva \\(R\\) es aquella que debemos dar a esta única conexión para que la corriente siga siendo \\(i\\) bajo el mismo potencial. En otras palabras \\(R = 1/i\\). Como primer paso veremos como calcular el potencial análogo en el toro \\(V_{N} = (\\mathbb Z/N\\mathbb Z)^2\\), es decir un problema periódico donde identificamos las coordenadas enteras módulo \\(N\\gg1\\). Cuando \\(N\\to \\infty\\) el potencial eléctrico converge al potencial en \\(\\mathbb Z^2\\). Este límite, a pesar de ser intuitivo, amerita una demostración que no presentaremos dado que buscamos enfatizar otras ideas por el momento. La ventaja de esta aproximación es que ahora nuestra ecuación es un problema de álgebra lineal en un espacio de dimensión \\(N^2-2\\) \\[ \\Delta u = 0 \\text{ en } V_{N}\\setminus \\{(0,0),(2,1)\\}, \\qquad u(0,0)=0,\\qquad u(2,1)=1. \\] De las discusiones previas sabemos que a partir de la descomposición espectral del Laplaciano en \\(V_{N}\\) podríamos calcular en cambio una solución particular de \\[ \\Delta v = 1_{(0,0)}- 1_{(2,1)} \\text{ en } V_{N}. \\] Notemos que el lado derecho es de hecho perpendicular a las constantes, lo cual garantiza la existencia de soluciones. Para obtener \\(u\\) a partir de \\(v\\) verificamos que \\[ u(x,y) = \\frac{v(x,y)-v(0,0)}{v(2,1)-v(0,0)} \\] satisface la ecuación requerida y entonces \\[ R_N = \\frac{1}{\\operatorname{div} u(0,0)} = \\frac{v(2,1)-v(0,0)}{\\operatorname{div} v(0,0)} = v(2,1)-v(0,0). \\] Nuestra estrategia será entonces calcular el límite de esta expresión cuando \\(N\\to\\infty\\). Procedamos a calcular el espectro del Laplaciano sobre el toro (Ejercicio 5.4). Asumamos la hipótesis de \\[ \\phi(x,y) = \\alpha(x)\\beta(y). \\] Este tipo de funciones toman ventaja de la simetría del problema con lo cual el Laplaciano se simplifica como operadores discretos más sencillos para cada factor \\[ \\Delta \\phi(x,y) = \\alpha(x)(\\beta(y-1)-2\\beta(y)+\\beta(y+1)) + (\\alpha(x-1)-2\\alpha(x)+\\alpha(x+1))\\beta(y). \\] Si \\(\\alpha\\) y \\(\\beta\\) son autofunciones del Laplaciano en el grafo cíclico de tamaño \\(N\\), entonces \\(\\phi\\) es una autofunción en el toro. Tomemos de esta forma la base de Fourier \\[ \\phi_{k,l}(x,y) = \\omega^{kx+ly}, \\qquad \\omega = e^{2\\pi i/N}, \\qquad (k,l)\\in\\{0,1,\\ldots,(N-1)\\}^2, \\] con autovalores \\(-\\lambda_{k,l}\\) tal que \\[ \\lambda_{k,l} := 4(\\sin^2(\\pi k/N)+\\sin^2(\\pi l/N)), \\] y normas \\[ \\|\\phi_{k,l}\\|^2=\\sum_{(x,y)\\in V_N} \\phi_{k,l}(x,y)\\overline{\\phi_{k,l}(x,y)} = N^2. \\] Ejercicio 5.15 Verifica que a partir de las siguientes funciones también se puede formar una base ortogonal del Laplaciano \\[\\begin{align*} \\cos(2\\pi kx/N)\\cos(2\\pi ly/N),\\quad \\cos(2\\pi kx/N)\\sin(2\\pi ly/N),\\quad \\sin(2\\pi kx/N)\\sin(2\\pi ly/N). \\end{align*}\\] Solución Finalmente reconstruimos la solución particular usando la fórmula de representación \\[\\begin{align*} v(x,y) &amp;= -\\sum_{(x&#39;,y&#39;) \\in V_N} K(x,y;x&#39;,y&#39;)( 1_{(0,0)}- 1_{(2,1)})(x&#39;,y&#39;) = K(x,y;2,1)-K(x,y;0,0). \\end{align*}\\] donde para \\(\\omega = e^{2\\pi i/N}\\) \\[ K(x,y;x&#39;,y&#39;) = \\frac{1}{N^2}\\sum_{(k,l)\\neq (0,0)} \\frac{\\phi_{k,l}(x,y)\\overline{\\phi_{k,l}(x&#39;,y&#39;)}}{\\lambda_{k,l}} = \\frac{1}{4N^2}\\sum_{(k,l)\\neq (0,0)} \\frac{\\omega^{k(x-x&#39;)+l(y-y&#39;)}}{\\sin^2(\\pi k/N)+\\sin^2(\\pi l/N)}. \\] La resistencia efectiva es calculada así por \\[\\begin{align*} R &amp;= v(2,1)-v(0,0),\\\\ &amp;= K(2,1;2,1)-K(2,1;0,0) - K(0,0;2,1)+K(0,0;0,0),\\\\ &amp;= \\frac{1}{2N^2} \\sum_{(k,l)\\neq (0,0)} \\frac{1-\\cos((2k+l)2\\pi/N)}{\\sin^2(\\pi k/N)+\\sin^2(\\pi l/N)},\\\\ &amp;= \\frac{1}{N^2} \\sum_{(k,l)\\neq (0,0)} \\frac{\\sin^2((2k+l)\\pi/N)}{\\sin^2(\\pi k/N)+\\sin^2(\\pi l/N)}. \\end{align*}\\] En el límite podemos entonces calcular \\(R\\) por la integral de Riemann \\[ R = \\frac{1}{\\pi^2}\\int_0^\\pi\\int_0^\\pi \\frac{\\sin^2(2x+y)}{\\sin^2x+\\sin^2y}dydx \\] Evaluamos numericamente la integral usando import numpy as np from scipy.integrate import dblquad integrando = lambda x, y : np.sin(2*x+y)**2/(np.sin(x)**2+np.sin(y)**2) integral, error = dblquad(integrando,0,np.pi,0,np.pi) R = integral/np.pi**2 print(R) ## 0.7732395447351639 De forma alternativa es posible calcular analíticamente la integral dando como resultado \\[ R = \\frac{4}{\\pi}-\\frac{1}{2} \\] Ejercicio 5.16 Sea \\[ R(m,n) = \\int_0^\\pi\\int_0^\\pi \\frac{\\sin^2(mx+ny)}{\\sin^2x+\\sin^2y}dydx. \\] Demuestra que \\(R:\\mathbb Z^2\\to \\mathbb R\\) es una función armónica en \\(\\mathbb Z^2\\setminus\\{(0,0)\\}\\). Solución Salvo en el caso de que \\(r_+=r_-\\) que podemos analizar más adelante si hiciese falta… No hará falta.↩︎ El producto de \\(G_1\\) y \\(G_2\\) tiene como vértices \\(V_1\\times V_2\\) siendo \\(((x_1,x_2),(y_1,y_2))\\) una arista en este grafo si alguna de las siguientes dos condiciones se cumplen: \\(x_1=y_1\\) y \\((x_2,y_2)\\) es una arista en \\(G_1\\), o bien \\(x_2=y_2\\) y \\((x_1,y_1)\\) es una arista en \\(G_2\\).↩︎ También puede verse como consecuencia del Teorema de la divergencia↩︎ Como \\(G\\) es una función en \\(V^2\\), definimos a \\(\\Delta_1\\) y \\(\\Delta_2\\) como los Laplacianos en la primera o segunda entrada respectivamente.↩︎ "],["el-problema-de-dirichlet.html", "Capítulo 6 El problema de Dirichlet 6.1 Ley de conservación 6.2 Existencia y unicidad de soluciones 6.3 Fórmulas de representación 6.4 Caminatas Aleatorias", " Capítulo 6 El problema de Dirichlet Un barrendero tiene la tarea de limpiar una dada región (acotada) en cuarto cubierto de baldosas. Cada vez que este barre una baldosa, toda la masa que se encuentra en ella se distribuye en porciones iguales entre las cuatro baldosas adyacentes. En general, limpiar la región es un proceso que entendemos en el límite de un número infinito de pasos. El orden en que se barren las baldosas no es conmutativo, véase por ejemplo la figura a continuación. Sin embargo, descubrimos que en el límite se recupera una cierta propiedad Abeliana: Una vez limpia la región, la distribución de masa alrededor de ella es independiente de como se haya barrido. El problema lo podemos modelar en un grafo general pero con la intención de ilustrar un caso concreto pensemos en la retícula \\(\\mathbb Z^2\\) con la relación de adyacencia \\(x\\sim y\\) cuando \\(\\|x-y\\| = 1\\). Es decir que cada baldosa tiene exactamente cuatro baldosas adyacentes en cada una de las direcciones cardinales. Sea \\(\\mu:\\mathbb Z^2\\to [0,\\infty)\\) la distribución de masa inicial que buscamos barrer de algún \\(\\Omega\\subseteq\\mathbb Z^2\\). Un plan de barridas está dado por una lista de baldosas \\(b_1,b_2,\\ldots \\in \\Omega\\), las que iremos barriendo en el orden respectivo. Si \\(\\infty_i:\\mathbb Z^2\\to [0,\\infty)\\) denota la distribución de masa luego del \\(i^{mo}\\) paso, se tiene entonces la siguiente fórmula recursiva comenzando de \\(\\mu_0:=\\mu\\), \\[ \\mu_i(x) := \\begin{cases} 0 \\text{ si } x=b_i\\\\ \\mu_{i-1}(x) + \\tfrac{1}{4}\\mu_{i-1}(b_i) \\text{ si } x\\sim b_i\\\\ \\mu_{i-1}(x) \\text{ en cualquier otro caso}. \\end{cases} \\] Decimos que el plan plan \\(b_1,b_2,\\ldots \\in \\Omega\\) barre a \\(\\mu\\) de \\(\\Omega\\) si \\[ \\lim_{i\\to\\infty} \\mu_i(x) = 0, \\qquad \\forall x\\in \\Omega. \\] Nuestro teorema puede ser entonces formulado de la siguiente manera. Teorema 6.1 Dado \\(\\Omega\\subseteq\\mathbb Z^2\\) finito y \\(\\mu:\\mathbb Z^2\\to [0,\\infty)\\) se tiene que cualesquiera dos planes \\(b_1,b_2,\\ldots \\in \\Omega\\) y \\(b_1&#39;,b_2&#39;,\\ldots \\in \\Omega\\) que barren a \\(\\mu\\) de \\(\\Omega\\) satisfacen que los siguientes límites existen para todo \\(x\\in \\mathbb Z^2\\) y \\[ \\lim_{i\\to \\infty} \\mu_i(x) = \\lim_{i\\to \\infty} \\mu&#39;_i(x). \\] Daremos la demostración del teorema en la Sección Principio del mínimo luego de presentar y motivar algunas construcciones auxiliares. 6.1 Ley de conservación Una idea útil es llevar el registro de cuánta masa ha salido de una dada baldosa \\(x\\) hasta una dada iteración. Para ser precisos definimos para cada subíndice \\(i\\geq 0\\) las funciones \\(u_i:\\mathbb Z^2\\to [0,\\infty)\\) comenzando por \\(u_0=0\\) y de forma inductiva según \\[ u_i := u_{i-1} + \\mu_{i-1}(b_i) 1_{b_i} \\] Observemos que para cualquier plan \\(b_1,b_2,\\ldots \\in \\Omega\\) se tiene necesariamente que \\(u_i=0\\) en \\(\\mathbb Z^2\\setminus \\Omega\\). La función \\(u_i\\) nos permite dar una fórmula para la ley de conservación de masas: En los primeros \\(i\\) pasos, la masa que entra menos la que sale de una baldosa \\(x\\) es justamente la diferencia entre las distribuciones \\(\\mu_i\\) menos \\(\\mu_0\\) en \\(x\\) \\[ \\underbrace{\\mu_i(x)}_{\\text{masa final}}-\\underbrace{\\mu_0(x)}_{\\text{masa inicial}} = \\underbrace{\\frac{1}{4}\\sum_{y\\sim x} u_i(y)}_{\\text{masa que entra}} - \\underbrace{u_i(x)}_{\\text{masa que sale}} = \\tfrac{1}{4}\\Delta u(x) \\] Esta puede ser demostrada por un argumento inductivo que dejamos de ejercicio. Volviendo al modelo del barrendero, vemos que si \\(\\mu_i \\to \\mu_\\infty\\) entonces \\(u_i\\) también converge a una función \\(u:\\mathbb Z^2\\to[0,\\infty)\\)11 tal que \\(\\tfrac{1}{4}\\Delta u = \\mu_\\infty - \\mu_0 = \\mu_\\infty-\\mu\\). Si el plan barre a \\(\\Omega\\) recuperamos el siguiente sistema de ecuaciones lineales \\[ \\begin{cases} -\\tfrac{1}{4}\\Delta u = -\\mu \\text{ en } \\Omega,\\\\ u = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\tag{6.1} \\] Veamos a grandes rasgos las ideas en la demostración del Teorema 6.1 a partir de estas construcciones. Si el sistema que satisface \\(u\\) tiene una solución, entonces esta función queda determinada por \\(\\mu\\) y \\(\\Omega\\) y es independientemente del plan. Usando que \\(\\mu_\\infty = \\mu + \\lim_{i\\to\\infty} \\tfrac{1}{4}\\Delta u_i = \\mu+\\tfrac{1}{4}\\Delta u\\) vemos que también \\(\\mu_\\infty\\) es independientemente del plan, lo cual concluiría la demostración. Ejercicio 6.1 Asumiendo la estrategia esbozada en esta sección, calcula la distribución final \\(\\mu_\\infty\\) si \\(\\Omega = \\{(0,0),(1,0),(0,1)\\}\\) y \\(\\mu= 1_\\Omega\\). Solución 6.2 Existencia y unicidad de soluciones El principio del mínimo nos permitirá demostrar que el sistema dado por (6.1) no tiene más de una solución. Para problemas lineales con igual número (finito) de ecuaciones e incógnitas, esto equivale a decir que el sistema de hecho siempre tiene solución. 6.2.1 Principio del mínimo La idea consiste en el siguiente principio general: Si \\(u:V\\to\\mathbb R\\) es no-negativa en \\(V\\setminus \\Omega\\) y satisface \\(\\Delta u\\leq 0\\) en \\(\\Omega\\) entonces \\(u\\) es necesariamente no-negativa en \\(\\Omega\\). Como veremos en la siguiente demostración, esto es una manifestación del criterio de la segunda derivada (discreto): \\(\\Delta u(x^*)\\geq 0\\) si \\(u\\) alcanza su mínimo en \\(x^*\\). Lema 6.1 (Principio del Mínimo) Sea \\(u:V\\to\\mathbb R\\) tal que para \\(\\Omega\\subseteq V\\) finito \\(\\Delta u \\leq 0\\) en \\(\\Omega\\). Entonces \\[ \\inf_{V\\setminus\\Omega} u \\geq 0 \\qquad\\Rightarrow\\qquad \\min_{\\Omega} u\\geq 0. \\] Demostración. Asumamos por contradicción que \\(m:= \\min_{\\Omega} u &lt; 0\\) y sea \\(\\Omega&#39;=\\{x\\in \\Omega : u(x) = m\\}\\) finito y no vacío, más aún sabemos que es finito dado que \\(\\Omega&#39;\\subseteq\\Omega\\). Tomemos ahora \\(x^*\\in \\Omega&#39;\\) tal que existe \\(y\\sim x^*\\) para el cual \\(u(y)&gt;u(x^*)\\). Vemos ahora que tenemos la siguiente contradicción a partir de evaluar la ecuación \\(\\Delta u\\leq 0\\) sobre \\(x^*\\) \\[ 0 &lt; \\sum_{z\\sim x^*} (u(z) -u(x^*)) = \\Delta u(x^*) \\leq 0. \\] Corolario 6.1 (Existencia y unicidad de soluciones) Para \\(\\Omega\\subseteq V\\) finito y \\(\\mu,\\varphi:V\\to\\mathbb R\\) el siguiente sistema tiene solución única \\[ \\begin{cases} \\Delta u = \\mu \\text{ en } \\Omega,\\\\ u = \\varphi \\text{ en } V\\setminus \\Omega. \\end{cases} \\] Demostración. Basta con demostrar que el sistema lineal dado por las ecuaciones en \\(\\Omega\\), con \\(N=|\\Omega|\\) ecuaciones e incógnitas, tiene a lo sumo una solución. En otras palabras, el operador lineal asociado de \\(\\mathbb R^N\\) en si mismo es inyectivo, y por lo tanto también es biyectivo gracias al teorema fundamental del álgebra lineal. Si \\(u,v:V\\to \\mathbb R\\) son dos soluciones, entonces \\(w:=u-v\\) satisface \\(\\Delta w=0\\) en \\(\\Omega\\) y \\(w = 0\\) en \\(V\\setminus \\Omega\\). Gracias al principio del mínimo obtenemos que \\(w\\geq 0\\) en \\(\\Omega\\) y por lo tanto en todo \\(V\\). Si aplicamos el mismo razonamiento a \\(-w\\) obtenemos la otra desigualdad de donde concluimos \\(w=0\\), es decir que queda establecida la unicidad de soluciones y con ello la demostración. Ejercicio 6.2 Demuestra que si \\(\\Omega = \\{x = (x_1,x_2) \\in \\mathbb Z^2 : x_2&gt;0\\}\\) entonces existen por lo menos dos soluciones distintas del problema \\[ \\begin{cases} \\Delta u = 0 \\text{ en } \\Omega,\\\\ u = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Es decir que la hipótesis de que \\(\\Omega\\) sea finito es necesaria para la unicidad de soluciones. Solución Demostración (Teorema 6.1). Construimos de forma recursiva y partiendo de \\(u_0 := 0\\) las funciones \\(u_i := u_{i-1} + \\mu_{i-1} 1_{b_i}\\) las cuales verifican \\[ \\begin{cases} \\tfrac{1}{4}\\Delta u_i = \\mu_i-\\mu \\text{ en } \\Omega,\\\\ u_i = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Definimos también \\(u:\\mathbb Z^2\\to \\mathbb R\\) como la solución de \\[ \\begin{cases} \\tfrac{1}{4}\\Delta u = -\\mu \\text{ en } \\Omega,\\\\ u = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Debemos corroborar entonces los siguientes puntos: \\(\\mu_{\\infty} := \\lim_{i\\to\\infty}\\mu_i\\) está bien definido. \\(u_\\infty := \\lim_{i\\to\\infty}u_i\\) está bien definido. \\(u_\\infty = u\\). Para ver el primer punto basta con fijarse en el comportamiento de \\(\\mu_i\\) en \\(\\mathbb Z^2\\setminus \\Omega\\), ya que sabemos por hipótesis que estas tienden a cero en \\(\\Omega\\). En \\(\\mathbb Z^2\\setminus \\Omega\\) se tiene que \\(\\mu_i\\) es una sucesión no-decreciente de funciones que está mayorizada por \\(\\mu + \\sum_{x\\in\\Omega} \\mu(x)\\). Como \\(u_i\\) es no-decreciente, basta con probar que \\(u\\geq u_i\\) para demostrar el segundo punto y adicionalmente obtener \\(u\\geq u_\\infty\\). La diferencia \\(v_i := u-u_i\\) satisface \\[ \\begin{cases} \\Delta v_i = \\Delta u - \\Delta u_i = -4\\mu_i \\leq 0 \\text{ en } \\Omega,\\\\ v_i = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Gracias principio del mínimo se deduce que \\(\\min_\\Omega v_i \\geq 0\\) y por lo tanto \\(u\\geq u_i\\). Dado que \\(b_1,b_2,\\ldots\\in\\Omega\\) barre a \\(\\mu\\) de \\(\\Omega\\) tenemos que tomando \\(i\\to\\infty\\) en el sistema para \\(u_i\\) \\[ \\begin{cases} \\tfrac{1}{4}\\Delta u_\\infty = -\\mu \\text{ en } \\Omega,\\\\ u_\\infty = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Por la unicidad de soluciones del problema lineal llegamos a que necesariamente \\(u_\\infty=u\\). Finalmente para concluir la demostración podemos calcular \\(\\mu_\\infty\\) a partir de \\(\\mu_\\infty = \\mu+\\tfrac{1}{4}\\Delta u_\\infty\\). Recordemos que \\(u_\\infty=u\\) está igualmente definido por un sistema de ecuaciones lineales que depende solamente de \\(\\Omega\\) y \\(\\mu\\) y no del plan. Esto indica que \\(\\mu_\\infty\\) también está definida independientemente del plan. Nuestro teorema garantiza que para cualquier \\(\\Omega\\subseteq\\mathbb Z^2\\) finito y \\(\\mu:\\mathbb Z^2\\to [0,\\infty)\\) se tiene que si \\(\\mu\\) puede ser barrido de \\(\\Omega\\), entonces la distribución de masa que queda por fuera de \\(\\Omega\\) es independiente del plan. Queda abierta la pregunta de si podemos en todo caso barrer o no a \\(\\mu\\) de \\(\\Omega\\). Teorema 6.2 Dado \\(\\Omega\\subseteq\\mathbb Z^2\\) finito y \\(\\mu:\\mathbb Z^2\\to[0,\\infty)\\) existe un plan \\(b_1,b_2,\\ldots\\in\\Omega\\) que barre a \\(\\mu\\) de \\(\\Omega\\). Demostración. Sea \\(b_1,b_2,\\ldots\\in\\Omega\\) un plan que recorre cada baldosa un número infinito de veces. Ciertamente estos planes existen incluso si \\(\\Omega\\) es infinito (usando un argumento de diagonal de Cantor). Esta condición implica que para cada \\(x\\in\\Omega\\), existe un número infinito de sub-índices tales que \\(\\mu_i(x)=0\\). Basta probar así que \\(\\mu_\\infty = \\lim_{i\\to\\infty}\\mu_i\\) existe para deducir que necesariamente \\(\\mu_\\infty=0\\) en \\(\\Omega\\). Definimos \\(u_i\\) y \\(u\\) exactamente como en la demostración anterior. Recordemos que \\(u_i\\) es no-decreciente y (por el principio del mínimo) acotada por \\(u\\), por lo tanto \\(u_\\infty:=\\lim_{i\\to\\infty}u_i\\) está bien definida. Dado que \\(\\mu_i = \\mu + \\Delta u_i\\) tenemos que la existencia del límite para \\(\\mu_i\\) queda demostrada por la existencia del límite para \\(u_i\\). Ejercicio 6.3 Demuestra que existe un plan que barre a \\(\\mu= 1_{(1,0)}\\) de \\(\\Omega = \\mathbb Z^2\\setminus \\{(0,0)\\}\\). Solución Ejercicio 6.4 Sea \\(\\Omega\\subseteq\\mathbb Z^2\\) finito, \\(\\mu:\\mathbb Z^2\\to[0,\\infty)\\) y \\(\\mu_\\infty\\) la distribución que resulta al barrer \\(\\mu\\) de \\(\\Omega\\). Demuestra ley de conservación de masa dada por \\[ \\sum_{x\\in\\mathbb Z^2} \\mu_\\infty(x) = \\sum_{x\\in \\mathbb Z^2} \\mu(x). \\] Solución Ejercicio 6.5 Sea \\(\\mu= 1_{(1,0)}\\) y \\(\\mu_\\infty\\) la distribución que resulta al barrer \\(\\mu\\) de \\(\\Omega= \\mathbb Z^2\\setminus \\{(0,0)\\}\\). ¿Será cierto que \\(\\mu_\\infty(0,0) = 1\\), o habrá masa que escapa a infinito?12 Solución 6.2.2 Método de Balayage Poincaré propuso a finales del siglo XIX el siguiente algoritmo para resolver el sistema \\[ \\begin{cases} \\Delta u = 0 \\text{ en } \\Omega,\\\\ u = \\varphi \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases}. \\] Asumamos \\(\\Omega\\) finito y sea \\(\\partial\\Omega := \\{y \\in \\mathbb Z^2\\setminus \\Omega : \\exists x\\in \\Omega \\text{ adyacente a } y\\}\\). Comenzamos entonces a partir de \\[ u_0(x) := \\begin{cases} \\max_{\\partial\\Omega}\\varphi \\text{ si } x\\in\\Omega,\\\\ \\varphi(x) \\text{ en cualquier otro caso}. \\end{cases}, \\] tal que \\[ \\begin{cases} \\Delta u_0 \\leq 0 \\text{ en } \\Omega,\\\\ u_0 = \\varphi \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Hagamos notar que por el principio del mínimo, \\(u_0\\geq \\min_{\\partial\\Omega} \\varphi\\). Sea \\(b_1,b_2,\\ldots \\in \\Omega\\) tal que para cada \\(x\\in \\Omega\\) el conjunto de índices \\(\\{i : b_i=x\\}\\) es infinito. Definimos ahora \\(u_i\\) modificando a \\(u_{i-1}\\) en \\(b_i\\) de forma que \\(\\Delta u_i(b_i) =0\\), es decir \\[ u_i(x) := \\begin{cases} \\frac{1}{4} \\sum_{y\\sim b_i} u_{i-1}(y) \\text{ si } x = b_i,\\\\ u_{i-1}(x) \\text{ en cualquier otro caso}. \\end{cases} \\] En otras palabras, en el paso \\(i\\) estamos barriendo el Laplaciano de \\(u_{i-1}\\) en \\(b_i\\). Se puede demostrar por inducción que cada \\(u_i\\) satisface \\[ \\begin{cases} \\Delta u_i \\leq 0 \\text{ en } \\Omega,\\\\ u_i = \\varphi \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Gracias a esto observamos que la sucesión es decreciente. También, cuando la restringimos a \\(\\Omega\\), está acotada por debajo por \\(\\min_{\\partial\\Omega}\\varphi\\). Como consecuencia converge a la solución que se busca calcular. Ejercicio 6.6 Implementa el método de balayage. El programa debe recibir un conjunto \\(\\Omega\\subseteq\\mathbb Z^2\\) finito junto con \\(\\varphi:\\partial\\Omega\\to\\mathbb R\\), debe devolver la solución correspondiente del problema de Dirichlet \\(u:\\Omega\\to \\mathbb Z^2\\). Solución 6.3 Fórmulas de representación 6.3.1 La función de Green Para \\(\\Omega\\subseteq V\\) finito, definimos la función de Green \\(G_\\Omega:V^2\\to\\mathbb R\\) tal que \\(u(y)=G_\\Omega(x,y)\\) es la solución de \\[ \\begin{cases} \\Delta u = - 1_x \\text{ en } \\Omega,\\\\ u=0 \\text{ en } V\\setminus \\Omega. \\end{cases} \\] Ejemplo 6.1 Si \\(\\Omega=\\{x_0\\}\\), entonces \\[ G_\\Omega(x,y) = \\begin{cases} 1/\\deg(x_0) \\text{ si } y=x=x_0,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] donde \\(\\deg(x_0)\\) es el grado del vértice \\(x_0\\), es decir cuantas aristas llegan y salen de \\(x_0\\). Igualmente definimos \\(G_\\Omega\\) sobre una distribución \\(\\mu:V\\to\\mathbb R\\) tal que \\(u(y)=G_\\Omega(\\mu,y)\\) es la solución de \\[ \\begin{cases} \\Delta u = -\\mu \\text{ en } \\Omega,\\\\ u=0 \\text{ en } V\\setminus \\Omega. \\end{cases} \\] Es decir que en particular \\(G_\\Omega(x,\\cdot) = G_\\Omega( 1_x,\\cdot)\\). Gracias al principio de superposición tenemos que a partir de esta podemos resolver \\[ \\begin{cases} \\Delta u = -\\mu \\text{ en } \\Omega,\\\\ u=0 \\text{ en } V\\setminus \\Omega. \\end{cases} \\] usando la fórmula de representación \\[ u(y) = \\sum_{x\\in V} \\mu(x)G_\\Omega(x,y) = G_\\Omega(\\mu,y). \\] Ejemplo 6.2 Para el problema del barrendero (\\(V=\\mathbb Z^2\\)) tenemos que \\(u(y)= 4G_\\Omega(\\mu,y)\\) indica cuanta masa sale de \\(y\\) cuando se barre \\(\\mu\\) de \\(\\Omega\\). Ejemplo 6.3 Veamos como calcular la función de Green para \\(\\Omega = [1,n] \\subseteq V=\\mathbb Z\\) con \\(n\\geq 1\\) y la relación de adyacencia dada por \\(x\\sim y\\) si \\(|x-y|=1\\). Denotamos a lo largo de este ejemplo a \\(g_{i,j} := G_\\Omega(i,j)\\) con \\(i,j\\in \\{0,1,\\ldots,n,n+1\\}\\), los valores de interés (\\(G_\\Omega(x,y) = 0\\) fuera de estos casos). Para \\(j\\in[1,i-1]\\), tenemos la ecuación \\[ 2g_{i,j} = g_{i,j-1}+g_{i,j+1}, \\] la cual junto a \\(g_{i,0} = 0\\) indica que \\(g_{i,j}=\\alpha j\\) para \\(j\\in[0,i]\\). Para \\(j\\in[i+1,n]\\), tenemos también la ecuación \\[ 2g_{i,j} = g_{i,j-1}+g_{i,j+1}, \\] la cual junto a \\(g_{i,n+1} = 0\\) indica que \\(g_{i,j}=\\beta(n+1-j)\\) para \\(j\\in[i,n+1]\\). Por un lado sabemos que \\(\\alpha i = \\beta(n+1-i)\\) y adicionalmente usando la ecuación para \\(j=i\\) \\[ -1=g_{i,i-1}+g_{i,i+1}-2g_{i,i} = -\\alpha-\\beta \\] obtenemos que \\(\\alpha=(n+1-i)/(n+1)\\) y \\(\\beta=i/(n+1)\\). En conclusión \\[ g_{i,j} = \\begin{cases} (n+1-i)j/(n+1) \\text{ si } j\\in[1,i),\\\\ (n+1-j)i/(n+1) \\text{ si } j\\in(i,n],\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Ejercicio 6.7 Calcula la función de Green para \\(\\Omega = [1,n]\\times\\{0\\}\\cap \\mathbb Z^2\\). Solución Los ejemplos previos sugieren la siguiente simetría \\[ G_\\Omega(x,y)=G_\\Omega(y,x). \\] Demostración. Usaremos en repetidas ocasiones que si alguno de los nodos \\(x\\) o \\(y\\) están en \\(V\\setminus \\Omega\\) se tiene automáticamente que \\(G_\\Omega(x,y)=G_\\Omega(y,x)=0\\). Basta ver que \\((x,y) \\mapsto G_\\Omega(y,x)\\) satisface las mismas condiciones para la definición de \\(G_\\Omega\\), es decir que \\(v(y) = G_\\Omega(y,x)\\) cumple \\[ \\begin{cases} \\Delta v = - 1_x \\text{ en } \\Omega,\\\\ v = 0 \\text{ en } V\\setminus \\Omega. \\end{cases} \\] Las condición de borde ya sabemos que se satisface. Para ver la ecuación asumimos que \\(x\\in \\Omega\\) (el otro caso siendo tivial) y comprobaremos que \\(w(x) = \\Delta_1 G(y,x)+ 1_y(x) = \\Delta_1 G(y,x)+ 1_x(y)=0\\) para cualquier \\(y\\in \\Omega\\). Por un lado tenemos la condición de borde \\[ w(x) = 0+0 = 0 \\text{ si } x\\in V\\setminus \\Omega. \\] Por el otro tenemos que \\[ \\Delta w (x) = \\Delta_2\\Delta_1G(y,x)+\\Delta 1_y(x) = \\Delta_1\\Delta_2 G(y,x)+\\Delta 1_y(x) = \\Delta 1_{y}(x) - \\Delta 1_y(x)=0. \\] Gracias a la unicidad de la solución trivial podemos finalmente concluir la demostración. 6.3.2 El núcleo de Poisson Para \\(\\Omega\\subseteq V\\) finito, \\(x,y \\in V\\) definimos el núcleo de Poisson \\[ P_\\Omega(x,y) := 1_x (y) + \\Delta_2 G_\\Omega(x,y). \\] Observemos los valores no triviales de \\(P_\\Omega(x,y)\\) ocurren cuando \\(x\\in \\Omega\\) y \\(y\\in V\\setminus \\Omega\\). Si \\(x\\in V\\setminus \\Omega\\) entonces \\(G_\\Omega(x,\\cdot) = 0\\) y \\(P_\\Omega(x,y) = 1_x (y)\\). Si \\(y\\in \\Omega\\) entonces \\(\\Delta_2 G_\\Omega(x,y) = - 1_x (y)\\) y \\(P_\\Omega(x,y)=0\\). En particular, la simetría de \\(G\\) no implica la propiedad análoga para \\(P_\\Omega\\). Igualmente extendemos la construcción para \\(\\mu:V\\to \\mathbb R\\) usando \\[ P_\\Omega(\\mu,y) := \\mu(y) + \\Delta_2 G_\\Omega(\\mu,y). \\] Ejemplo 6.4 Si \\(\\Omega=\\{x_0\\}\\), entonces \\[ P_\\Omega(x,y) = \\begin{cases} 1/\\deg(x_0) \\text{ si } x=x_0,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Ejemplo 6.5 Para el problema del barrendero (\\(V=\\mathbb Z^2\\)) tenemos que al barrer \\(\\mu\\) de \\(\\Omega\\) la distribución de masa que resulta está dada por \\(P_\\Omega(\\mu)\\). De la linealidad del problema junto con la existencia y unicidad de soluciones se deduce que \\[ P_\\Omega(\\alpha\\mu+\\beta\\nu) = \\alpha P_\\Omega(\\mu) +\\beta P_\\Omega(\\nu). \\] Gracias a la interpretación de núcleo de Poisson en términos del problema del barrendero es natural pensar que dados \\(\\Omega_1\\subseteq\\Omega_2\\subseteq V\\) finitos, se tiene la siguiente propiedad \\[ P_{\\Omega_2} = P_{\\Omega_2}\\circ P_{\\Omega_1}. \\] Denominaremos a esta como la propiedad de semi-grupo. Como consecuencia de la linealidad y la propiedad de semi-grupo tenemos la siguiente interpretación dual del núcleo de Poisson: Para \\(y\\in V\\) fijo, la función \\(u(x) = P_\\Omega(x,y)\\) es la solución de \\[ \\begin{cases} \\Delta u = 0 \\text{ en } \\Omega,\\\\ u= 1_{y} \\text{ en } V\\setminus \\Omega. \\end{cases} \\] Esta formulación es más sencilla de recordar y conveniente al momento de calcular \\(P_\\Omega\\) sin necesidad de calcular la función de Green. Como consecuencia de la formulación dual de núcleo de Poisson y el principio de superposición tenemos la fórmula de representación \\[ u(x) = \\sum_{y\\in V} \\varphi(y) P_\\Omega(x,y) \\qquad\\Leftrightarrow\\qquad\\begin{cases} \\Delta u = 0 \\text{ en } \\Omega,\\\\ u= \\varphi \\text{ en } V\\setminus \\Omega. \\end{cases} \\] Más aún, si a esta añadimos la fórmula de representación para la función de Green, junto con su propia simetría, obtenemos que \\[ u(x) = \\sum_{y\\in V} \\varphi(y) P_\\Omega(x,y)+\\mu(y) G_\\Omega(x,y) \\qquad\\Leftrightarrow\\qquad \\begin{cases} \\Delta u = -\\mu \\text{ en }\\Omega,\\\\ u=\\varphi \\text{ en } V\\setminus \\Omega. \\end{cases}. \\] Ejemplo 6.6 Veamos como calcular el núcleo de Poisson para \\(\\Omega = [1,n] \\subseteq V=\\mathbb Z\\) con \\(n\\geq 1\\) y la relación de adyacencia dada por \\(x\\sim y\\) si \\(|x-y|=1\\). Denotamos a lo largo de este ejemplo a \\(p_{i,j} := P_\\Omega(i,j)\\) con \\(i,j\\in \\{0,1,\\ldots,n,n+1\\}\\), los valores de interés (\\(P_\\Omega(x,y) = 0\\) fuera de estos casos). En realidad solamente debemos calcular \\(p_{i,0}\\) y \\(p_{i,n+1}\\), los demás valores también se anulan. Para \\(j=0\\), tenemos la ecuación \\[ 2p_{i,0} = p_{i-1,0}+p_{i+1,0}, \\] la cual junto a \\(p_{0,0} = 1\\) y \\(p_{n+1,0}=0\\) indica que \\(p_{i,0}=(n+1-i)/(n+1)\\) para \\(i\\in[0,n+1]\\).\\ Para \\(j=n+1\\), tenemos también la ecuación \\[ 2p_{i,n+1} = p_{i-1,n+1}+p_{i+1,n+1}, \\] la cual junto a \\(p_{0,n+1} = 0\\) y \\(p_{n+1,n+1}=1\\) indica que \\(p_{i,n+1}=i/(n+1)\\) para \\(i\\in[0,n+1]\\). Ejercicio 6.8 Calcula el núcleo de Poisson para \\(\\Omega=[1,n]\\times \\{0\\}\\cap \\mathbb Z^2\\). Solución 6.4 Caminatas Aleatorias Consideremos ahora un problema que afinará nuestra intuición con respecto a las herramientas que hemos presentado. Volvemos a trabajar en la retícula \\(\\mathbb Z^2\\) a pesar de que el modelo es claramente generalizable a otros grafos. Un borracho parte de una posición inicial \\(x\\in\\mathbb Z^2\\) y se mueve con igual probabilidad a cualquiera de sus cuatro posiciones adyacentes. Es decir que si \\(x_i\\) es la posición (aleatoria) del borracho luego de \\(i\\) pasos, tenemos que las probabilidades de transición están dadas por \\[ \\mathbb P(x_i = y \\ | \\ x_{i-1} = x) = \\begin{cases} 1/4 \\text{ si } y \\sim x,\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\] Dado \\(\\Omega \\subseteq\\mathbb Z^2\\), sea \\(\\tau\\) el número de pasos que toma el borracho para salir de \\(\\Omega\\) por primera vez, también conocido como el tiempo de salida de la caminata \\[ \\tau := \\min\\{i \\geq 0 : x_i \\in \\mathbb Z^2\\setminus \\Omega\\}. \\] Para nuestro modelo, podemos interpretar \\(\\mathbb Z^2\\setminus \\Omega\\) como la región en la ciudad \\(\\mathbb Z^2\\) donde hay ley seca. El borracho pasea en \\(\\Omega\\) y una vez que sale de \\(\\Omega\\) se queda dormido o lo atrapa la policía. Dado \\(A \\subseteq\\mathbb Z^2\\) (quizás sea la casa del nuestro protagonista) queremos calcular la probabilidad de que el paseo en \\(\\Omega\\) termine (felizmente) en \\(A\\) dado que comienza en \\(x\\), es decir \\[ p(x) := \\mathbb P(x_\\tau \\in A \\ | \\ x_0 = x). \\] Si inicialmente \\(x \\in \\mathbb Z^2\\setminus\\Omega\\), tenemos que \\(x_\\tau =x_0=x\\) y por lo tanto \\(p= 1_A\\). Si en cambio \\(x \\in \\Omega\\), la probabilidad \\(p(x)\\) puede ser calculada si conocemos los valores de \\(p(y)\\) para \\(y\\sim x\\). Para \\(y\\sim x\\) fijo, tenemos que con probabilidad \\(1/4\\) se tiene que \\(x_1=y\\), y a partir de \\(y\\) tenemos que el paseo en \\(\\Omega\\) sale por \\(A\\) con probabilidad \\(p(y)\\). En otras palabras \\[ p(x) = \\frac{1}{4}\\sum_{y\\sim x}p(y). \\] En términos del Laplaciano podemos caracterizar a la probabilidad \\(p\\) como la solución del sistema \\[ \\begin{cases} \\Delta p = 0 \\text{ en } \\Omega,\\\\ p = 1_A \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases}. \\] Cuando \\(A=\\{y\\}\\) conseguimos interpretar al núcleo de Poisson \\(P_\\Omega(x,y) = p(x)\\) como la probabilidad de que la caminata que comienza en \\(x\\) termine en \\(y\\). Esto es una probabilidad de transición para el tiempo aleatorio \\(\\tau\\) \\[ P_\\Omega(x,y) = \\mathbb P(x_\\t=y\\ | \\ x_0=x). \\] La interpretación probabilista de la fórmula de representación para el núcleo de Poisson está dada en cambio por el valor esperado \\[ u(x) = \\mathbb E(\\varphi(x_\\tau) \\ | \\ x_0=x) \\qquad \\Leftrightarrow\\qquad \\begin{cases} \\Delta u = 0 \\text{ en }\\Omega,\\\\ u=\\varphi \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases} \\] Ejercicio 6.9 Dos borrachitos se encuentran paseando en la avenida \\(\\Omega = [1,n]\\times \\{0\\} \\cap \\mathbb Z^2\\) con \\(n\\geq 2\\). Uno parte de \\(x=(1,0)\\), el otro de \\(y = (n,0)\\), y ambos toman pasos simultáneamente en \\(\\mathbb Z^2\\) con igual probabilidad en las cuatro direcciones cardinales. Da una fórmula para la probabilidad \\(p(n)\\) de que se encuentren en \\(\\Omega\\) (es decir que ambos coinciden en la misma casilla al mismo tiempo, no vale que se crucen) antes de que alguno de ellos salga de \\(\\Omega\\). Solución Dado \\(A\\subseteq\\mathbb Z^2\\), otra variable aleatoria de interés es el número de veces que encontramos \\(x_i \\in A\\) para \\(i &lt; \\tau\\), es decir antes de salir de la región \\(\\Omega\\). Esta variable también se conoce como el tiempo de ocupación de \\(A\\) y está definida de forma precisa por \\[ N := \\sum_{i=0}^{\\tau-1} 1_A(x_i). \\] El valor esperado en función de la posición inicial de la caminata \\[ n(x) := \\mathbb E(N \\ | \\ x_0=x), \\] también satisface un sistema de ecuaciones lineales \\[ \\begin{cases} \\tfrac{1}{4}\\Delta n = - 1_A \\text{ en } \\Omega,\\\\ n = 0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases}. \\] Por un lado la condición de borde es automática puesto que si \\(x_0=x\\in \\mathbb Z^2\\setminus\\Omega\\) entonces como ya está fuera de \\(\\Omega\\), nunca puede visitar a \\(A\\) en su paseo (inexistente) por \\(\\Omega\\). Por otro lado, para \\(x\\in \\Omega\\), \\(n(x)\\) se puede obtener a partir de los valores de \\(n(y)\\) para \\(y\\sim x\\). Dado \\(y\\sim x\\), la probabilidad de que \\(x_1=y\\) es un cuarto, y a partir de acá consideramos dos casos: Si \\(x\\in A\\) entonces el tiempo de ocupación partiendo de \\(x\\) es uno más que el tiempo de ocupación partiendo de \\(y\\). Si \\(x\\in \\Omega\\setminus A\\), el tiempo de ocupación partiendo de \\(x\\) es el mismo tiempo de ocupación partiendo de \\(y\\). Tomando los valores esperados \\[ n(x) = 1_A(x) + \\frac{1}{4}\\sum_{y\\sim x} n(y). \\] Lo cual es equivalente a \\(\\tfrac{1}{4}\\Delta n = - 1_A\\) en \\(\\Omega\\). Es decir que \\(n=4G_\\Omega( 1_A)\\) está dado en términos de la función de Green. En términos probabilistas interpretamos la fórmula de representación para la función de Green como, \\[ u(x) = \\mathbb E\\left(\\sum_{i=0}^{\\tau-1}\\mu(x_i) \\ | \\ x_0=x\\right) \\qquad\\Leftrightarrow\\qquad \\begin{cases} \\frac{1}{4}\\Delta u = -\\mu \\text{ en } \\Omega,\\\\ u=0 \\text{ en } \\mathbb Z^2\\setminus \\Omega. \\end{cases}. \\] Finalmente observamos que la simetría de la función de Green se interpreta como una propiedad de reversibilidad para las caminatas aleatorias. Es decir que el número promedio de veces que una caminata que comienza en \\(x\\) visita a \\(y\\) antes de salir de \\(\\Omega\\) (\\(G_\\Omega(x,y)\\)) es igual al número promedio de veces que una caminata que comienza en \\(y\\) visita a \\(x\\) antes de salir de \\(\\Omega\\) (\\(G_\\Omega(y,x)\\)). Esto se debe a que las caminatas de \\(x\\) a \\(y\\) que permanecen en \\(\\Omega\\) están en biyección con las caminatas de \\(y\\) a \\(x\\) que permanecen en \\(\\Omega\\), simplemente cambiando la orientación. Daremos una prueba rigurosa de este hecho en la Sección Principio del Mínimo↩︎ Pista: El problema se puede reducir a verificar que \\(\\Delta u(0,0) = -\\Delta u(1,0)\\). La función \\(u\\) parece tener una simetría en el eje \\(x=1/2\\) la cual podría ser demostrada por un resultado de unicidad (Liouville): Las funciones armónicas y acotadas en \\(\\mathbb Z^2\\) son únicamente las constantes.↩︎ "],["optimización.html", "Capítulo 7 Optimización 7.1 Métrica de Sobolev 7.2 Capacitancia 7.3 Métrica dual 7.4 Cociente de Rayleigh", " Capítulo 7 Optimización Consideremos una vez más el grafo \\(G=(V,E)\\). Otra perspectiva para el Laplaciano aparece cuando consideramos la energía de Dirichlet para una función \\(u:V\\to \\mathbb R\\) \\[ \\mathcal E[u] := \\frac{1}{2}\\sum_{e\\in E} (Du(e))^2. \\] Recordemos que podemos pensar igualmente a \\(\\mathcal E\\) como una función de \\(\\mathbb R^{|V|}\\) a \\(\\mathbb R\\), y como tal podemos calcular su gradiente en una dada \\(u\\) como un vector de \\(\\mathbb R^{|V|}\\) o equivalentemente una función real sobre \\(V\\). Dado \\(x\\in V\\) \\[ D\\mathcal E[u](x) = \\left.\\frac{d}{d\\epsilon}\\right|_{\\epsilon=0}\\mathcal E[u+\\epsilon 1_{x}] = \\sum_{e\\in E} Du(e) D 1_{x}(e). \\] Dado que \\[ D 1_{x}(e) = \\begin{cases} 1 \\text{ si } e_+=x,\\\\ -1 \\text{ si } e_-=x,\\\\ 0 \\text{ en cualquier otro caso},\\\\ \\end{cases} \\] llegamos a que \\[ D\\mathcal E[u](x) = \\sum_{e_+=x} Du(e) - \\sum_{e_-=x} Du(e) = -\\operatorname{div}(Du)(x) = -\\Delta u(x). \\] Ejercicio 7.1 Sea \\(f:V\\to \\mathbb R\\) y \\(\\mathcal F:\\mathbb R^V\\to \\mathbb R\\) tal que \\[ \\mathcal F[u] = \\mathcal E[u] + \\sum_{x\\in V} f(x)u(x). \\] Demuestra que \\(\\mathcal F\\) es acotada por debajo si y solo si \\(\\sum_{x\\in V} f(x)=0\\) Solución Ejercicio 7.2 Demuestra que si \\(\\partial_t^2u=\\Delta u\\) entonces la energía total del sistema definida a continuación permanece constante \\[ E = \\underbrace{\\frac{1}{2}\\sum_{x\\in V} (\\partial_t u(x))^2}_{\\text{Cinética}} + \\underbrace{\\mathcal E[u]}_{\\text{Potencial}}. \\] Solución Ejemplo 7.1 Modelamos una imagen en blanco y negro está dada por una función \\(u:V\\to [0,1]\\) definida sobre la retícula \\(V = \\mathbb Z^2\\cap [1,N]^2\\). El problema de restauración de imágenes consiste en proponer una imagen \\(u\\) que aproxime una dada imagen \\(f\\) que quizás esté contaminada con algún tipo de ruido. Por ejemplo, podemos proponer \\(u\\) como aquella que minimiza el funcional \\[ \\mathcal F[u] = \\frac{1}{2}\\sum_{x\\in V} (u(x)-f(x))^2+\\alpha(Du(x))^2. \\] El primer término penaliza el funcional cuando \\(u\\) se aleja de la señal dada \\(f\\) y se conoce como el término de fidelidad. El segundo término penaliza las oscilaciones de \\(u\\) y se conoce como el término de regularización. El parámetro \\(\\alpha&gt;0\\) debe ser ajustado empíricamente para obtener un balance entre la fidelidad de la imagen y la regularización. Tenemos entonces la ecuación de punto crítico la cual debe satisfacerse para todo \\(x\\in V\\) \\[ 0 = D\\mathcal F[u](x) = u(x)-f(x) - \\alpha\\Delta u(x). \\] Observemos que \\(\\Delta\\) posee autovalores negativos, esto indica que el operador \\(I-\\alpha\\Delta\\) tiene autovalores estrictamente positivos, en particular la ecuación \\(u-\\alpha\\Delta u=f\\) tiene una única solución para \\(f:V\\to \\mathbb R\\) arbitraria. Ejercicio 7.3 El término de penalización dado por la energía de Dirichlet es conveniente al momento de calcular el gradiente, sin embargo en la práctica este difumina los contornos. Una mejor alternativa es usar en término de variación total \\[ \\mathcal F[u] = \\sum_{x\\in V} \\frac{1}{2}(u(x)-f(x))^2+\\alpha|Du(x)|. \\] Calcula las ecuaciones de punto crítico de \\(\\mathcal F\\). Solución Ejercicio 7.4 El término de variación total tiene la desventaja de no ser diferenciable en todos lados. Una alternativa consiste en tomar para \\(\\epsilon&gt;0\\) pequeño \\[ \\mathcal F[u] = \\sum_{x\\in V} \\frac{1}{2}(u(x)-f(x))^2+\\alpha\\sqrt{(Du(x))^2+\\epsilon^2}. \\] Calcula las ecuaciones de punto crítico de \\(\\mathcal F\\). Solución Ejemplo 7.2 Un dado conjunto de datos puede estar dado en términos de un grafo \\(G=(V,E)\\) para el cual pensamos que dos vértices adyacentes son de alguna forma semejantes. El propósito es clasificar los vértices de acuerdo a \\(k\\) etiquetas que modelamos usando los vectores canónicos \\(\\{e_1,\\ldots,e_k\\}\\in \\mathbb R^k\\). De hecho el problema está planteado en un subconjunto de vértices \\(\\Omega\\subseteq V\\), dado que en el complemento las etiquetas vienen predeterminadas por una función \\(g:V\\setminus\\Omega\\to\\{e_1,\\ldots,e_k\\}\\). Una forma de llevar a cabo esta tarea consiste en minimizar el funcional de Dirichlet bajo el dato de borde en \\(V\\setminus \\Omega\\) \\[ \\min\\{\\mathcal E[u]\\ | \\ u=g\\text{ en } V\\setminus \\Omega\\}. \\] Bajo esta condición \\(u:V\\to \\mathbb R^k\\) debe ser calculado según \\[ \\begin{cases} \\Delta u = 0 \\text{ en } \\Omega,\\\\ u=g\\text{ en } V\\setminus \\Omega. \\end{cases} \\] Dado que la solución \\(u(x)\\) no necesariamente toma valores en \\(\\{e_1,\\ldots,e_k\\}\\), tomamos la etiqueta para \\(x\\) como el \\(e_j\\) más cercano a \\(u(x)\\). Ejercicio 7.5 Dado que \\(u=(u_1,\\ldots,u_k)\\) satisface \\[ \\begin{cases} \\Delta u = 0 \\text{ en } \\Omega,\\\\ u=g\\text{ en } V\\setminus \\Omega. \\end{cases} \\] con \\(g\\) tomando valores en \\(\\{e_1,\\ldots,e_k\\}\\), demuestra que para todo \\(x\\in V\\) \\[ u(x) \\in \\{y\\in [0,1]^k \\ | \\ y_1+\\ldots+y_k=1\\}. \\] Solución 7.1 Métrica de Sobolev Consideremos para \\(G = (V,E)\\) conexo \\[ \\dot H^1 := \\left\\{u:V\\to\\mathbb R\\ | \\ \\sum_V u = 0\\right\\}. \\] Este espacio vectorial admite el producto interno, \\[ \\langle u,v\\rangle_{\\dot H^1} := \\sum_{e\\in E} Du(e)Dv(e). \\] Recordemos rápidamente las propiedades que verifica para poder ser efectivamente un producto: Simétrico: \\(\\langle u,v\\rangle_{\\dot H^1}=\\langle v,u\\rangle_{\\dot H^1}\\), Lineal: \\(\\langle \\alpha u+\\beta v,w\\rangle_{\\dot H^1} = \\alpha\\langle u,w\\rangle_{\\dot H^1} +\\beta\\langle v,w\\rangle_{\\dot H^1}\\). Positivo: \\(\\|u\\|_{\\dot H^1}^2 := \\langle u,u\\rangle_{\\dot H^1}\\geq 0\\) No degenerado: \\(\\|u\\|_{\\dot H^1} = 0\\) si y solo si \\(u=0\\). De todas estas propiedades, la no degeneración es la más delicada. De \\(\\|u\\|_{\\dot H^1} = 0\\) se deduce que \\(u\\) es constante (\\(G\\) es conexo). Dado que \\(\\sum u=0\\) se llega a que necesariamente dicha constante es cero. 7.2 Capacitancia Dado \\(\\Omega\\subseteq V\\) con \\(V\\setminus \\Omega\\neq \\emptyset\\), definimos la capacitancia de \\(\\Omega&#39;\\subseteq\\Omega\\) con respecto de \\(\\Omega\\) como \\[ \\operatorname{Cap}(\\Omega&#39;|\\Omega) := \\min\\{2\\mathcal E[u] \\ | \\ \\text{$u=1$ en $\\Omega&#39;$, y $u=0$ en $V\\setminus\\Omega$}\\}. \\] Un minimizante \\(u\\) de dicho problema es la función armónica en \\(\\Omega\\setminus \\Omega&#39;\\) que satisface los datos de borde prescritos \\[ \\begin{cases} \\Delta u = 0 \\text{ in } \\Omega\\setminus \\Omega&#39;,\\\\ u=0 \\text{ on } V\\setminus \\Omega,\\\\ u=1 \\text{ on } \\Omega&#39;. \\end{cases} \\] Gracias al teorema de la divergencia13 \\[ \\operatorname{Cap}(\\Omega&#39;|\\Omega) = -\\sum_{x\\in V} u\\Delta u(x) = -\\sum_{x\\in \\Omega&#39;} \\Delta u(x) = -\\sum_{e\\in E} Du(e)n_{\\Omega&#39;}(e). \\] En términos de redes eléctricas obtenemos la corriente total que atraviesa la red cuando se mantiene una diferencia potencial de un voltio entre \\(\\Omega&#39;\\) y \\(V\\setminus \\Omega\\). La resistencia efectiva entre dos nodos distintos \\(x_0\\) y \\(x_1\\) puede ser definida así según \\[ R(x_0,x_1) = \\frac{1}{\\operatorname{Cap}(\\{x_1\\}|V\\setminus\\{x_0\\})}. \\] Equivalentemente se puede definir la capacitancia en términos de dos desigualdades sobre \\(\\Omega&#39;\\) y \\(V\\setminus \\Omega\\) \\[ \\operatorname{Cap}(\\Omega&#39;|\\Omega) = \\min\\{\\mathcal E[u] \\ | \\ \\text{$u\\geq 1$ en $\\Omega&#39;$, y $u\\leq 0$ en $V\\setminus\\Omega$}\\}. \\] Es claro que el lado derecho es menor o igual que el lado izquierdo, dado que el conjunto que considera el mínimo es más grande. Por el otro lado tenemos que para cualquier \\(u\\) tal que \\(u\\geq 1\\) en \\(\\Omega&#39;\\), y \\(u\\leq 0\\) en \\(V\\setminus\\Omega\\), la truncación dada por \\[ v(x) := \\max(\\min(u(x),1),0) = \\begin{cases} 1 \\text{ si } x\\in \\Omega&#39;,\\\\ u(x) \\text{ si } x\\in \\Omega\\setminus\\Omega&#39;,\\\\ 0 \\text{ si } x\\in V\\setminus \\Omega. \\end{cases} \\] disminuye la energía de Dirichlet \\(\\mathcal E[v]\\leq \\mathcal E[u]\\), lo cual concluye la igualdad que habíamos anunciado. Ejercicio 7.6 Calcula \\(\\operatorname{Cap}(\\{a\\}|V\\setminus \\{b\\})\\) Solución: Ejercicio 7.7 Demuestra que para \\(\\Omega_1\\subseteq\\Omega_2\\subseteq\\Omega_3\\subseteq V\\): \\(\\operatorname{Cap}(\\Omega_1|\\Omega_2)= \\operatorname{Cap}(V\\setminus\\Omega_2|V\\setminus \\Omega_1)\\). \\(\\operatorname{Cap}(\\Omega_1|\\Omega_3) \\leq \\operatorname{Cap}(\\Omega_2|\\Omega_3)\\). \\(\\operatorname{Cap}(\\Omega_1|\\Omega_2) \\geq \\operatorname{Cap}(\\Omega_1|\\Omega_3)\\). Solución: Ejercicio 7.8 Demuestra que para \\(\\Omega_1,\\Omega_2\\subseteq\\Omega\\subseteq V\\)14: \\[ \\operatorname{Cap}(\\Omega_1\\cup\\Omega_2|\\Omega) \\leq \\operatorname{Cap}(\\Omega_1|\\Omega)+\\operatorname{Cap}(\\Omega_2|\\Omega). \\] Solución: Ejercicio 7.9 Sea \\(\\Omega&#39;\\subseteq\\Omega\\subseteq V\\), \\(u\\) la solución de \\[ \\begin{cases} \\Delta u = 0 \\text{ in } \\Omega\\setminus \\Omega&#39;,\\\\ u=0 \\text{ on } V\\setminus \\Omega,\\\\ u=1 \\text{ on } \\Omega&#39;. \\end{cases} \\] y sean \\(\\mu=(\\Delta u)_-\\) y \\(\\nu=(\\Delta u)_+\\). Demuestra que \\[ P_\\Omega(\\mu)=\\nu \\qquad \\text{ y } \\qquad P_{V\\setminus \\Omega&#39;}(\\nu)=\\mu. \\] Solución: 7.3 Métrica dual De forma dual proponemos el siguiente problema. Decimos que un flujo \\(i:E\\to\\mathbb R\\) transporta a la distribución (de cargas) \\(\\mu:V\\to [0,\\infty)\\) en \\(\\nu:V\\to\\mathbb R\\) si satisface \\[ \\operatorname{div} i = \\mu-\\nu. \\] Recordemos que tal problema tiene solución si y solo si (y asumiendo \\(G\\) conexo) \\[ \\sum_{x\\in V}\\mu(x) = \\sum_{x\\in V}\\nu(x). \\] Dada la energía del flujo \\(i\\) como \\[ \\mathcal K[i] := \\frac{1}{2}\\sum_{e\\in E} i(e)^2, \\] nos preguntamos entonces cuál es la menor energía posible que se requiere para transportar a \\(\\mu\\) en \\(\\nu\\) \\[ \\mathcal D^2[\\mu,\\nu] := \\min\\{ 2\\mathcal K[i] \\ | \\ \\operatorname{div} i = \\mu-\\nu\\}. \\] Si \\(i\\) minimiza \\(\\mathcal K\\) y \\(j\\) es un flujo tal que \\(\\operatorname{div} j=0\\), entonces \\[ 0=\\left.\\frac{d}{dt}\\right|_{t=0}\\mathcal K[i+tj] = \\sum_{e\\in E}i(e)j(e). \\] Es decir que el mínimo \\(i\\) debe ser perpendicular al núcleo de la divergencia. Por la descomposición de Helmholtz debe ser necesariamente un gradiente \\(i=-Du\\) por lo que \\[ \\mathcal D^2[\\mu,\\nu] = 2\\mathcal E[u]\\text{ para cualquier solución de $\\Delta u=\\nu-\\mu$}. \\] Ejercicio 7.10 Calcula \\(\\mathcal D^2(\\mu,\\nu)\\) Solución: Ejercicio 7.11 La función \\(\\mathcal D\\), es decir la raíz cuadrada del mínimo de la energía, se conoce como la distancia dual. Demuestra que efectivamente satisface los axiomas correspondientes: \\(\\mathcal D(\\mu,\\nu) = \\mathcal D(\\nu,\\mu)\\), \\(\\mathcal D(\\mu,\\nu) \\geq 0\\) y la igualdad se cumple exclusivamente si \\(\\mu=\\nu\\), \\(\\mathcal D(\\mu,\\nu) \\leq \\mathcal D(\\mu,\\omega)+\\mathcal D(\\omega,\\nu)\\). Solución: Ejercicio 7.12 Definimos la norma dual en \\(\\dot H^1\\) como \\[ \\|u\\|_{\\dot H^{-1}} := \\sup\\{ \\langle u,v\\rangle_{\\dot H^1}\\ | \\ \\|v\\|_{\\dot H^1}=1\\}. \\] Demuestra que si \\(\\sum_V \\mu = \\sum_V\\nu\\), entonces \\[ \\|\\mu-\\nu\\|_{\\dot H^{-1}} = \\mathcal D(\\mu,\\nu). \\] Solución: Dados \\(\\Omega&#39;\\subseteq\\Omega\\subseteq V\\) con \\(\\Omega&#39;\\) y \\(V\\setminus \\Omega\\) no triviales consideramos las distribuciones \\(\\mu\\) y \\(\\nu\\) tales que \\[ \\begin{aligned} \\mathcal M(\\Omega&#39;|\\Omega) = \\{(\\mu,\\nu):V\\to \\mathbb R^2\\ | \\ &amp;\\operatorname{spt} \\mu \\in \\Omega&#39;,\\\\ &amp;\\operatorname{spt}\\nu \\subseteq V\\setminus\\Omega,\\\\ &amp;\\left.\\sum_{x\\in V}\\mu(x) = \\sum_{x\\in V}\\nu(x)=1\\right\\}. \\end{aligned} \\] Bajos estas condiciones buscamos minimizar la distancia entre \\(\\mu\\) y \\(\\nu\\). Teorema 7.1 Para \\(G\\) conexo y finito, \\[ \\min_{(\\mu,\\nu) \\in \\mathcal M(\\Omega&#39;|\\Omega)} \\mathcal D^2[\\mu,\\nu] = \\frac{1}{\\operatorname{Cap}(\\Omega&#39;|\\Omega)}. \\] Es decir que el problema de minimización para \\(\\mathcal D^2[\\mu,\\nu]\\) bajo las restricciones \\((\\mu,\\nu) \\in \\mathcal M(\\Omega&#39;|\\Omega)\\) generaliza la noción de resistencia efectiva entre dos conjuntos. Demostración. Sean \\(\\mu&#39;,\\nu&#39;:V\\to [0,\\infty)\\) tales que \\[ \\operatorname{spt}\\mu&#39;\\subseteq\\Omega&#39;, \\qquad \\operatorname{spt} \\nu&#39;\\subseteq V\\setminus \\Omega. \\] Obtenemos de esta forma que \\[ \\max_{\\mu&#39;,\\nu&#39;} \\sum_{x\\in V} ((1-u)\\mu&#39;+u\\nu&#39;)(x) = \\begin{cases} 0 \\text{ si $u\\geq 1$ en $\\Omega&#39;$ y $u\\leq 0$ en $V\\setminus\\Omega$,}\\\\ \\infty \\text{ en cualquier otro caso}. \\end{cases} \\] De modo que sin necesidad de imponer restricciones para \\(u:V\\to\\mathbb R\\) obtenemos que \\[ \\operatorname{Cap}(\\Omega&#39;|\\Omega) = \\min_u \\max_{\\mu&#39;,\\nu&#39;} L[u,\\mu&#39;,\\nu&#39;], \\qquad L[u,\\mu&#39;,\\nu&#39;] := 2\\mathcal E[u] + \\sum_{x\\in V} ((1-u)\\mu&#39;+u\\nu&#39;)(x). \\] Procedemos entonces a analizar el problema dual para el cual sabemos que15 \\[ \\operatorname{Cap}(\\Omega&#39;|\\Omega)\\geq \\max_{\\mu&#39;,\\nu&#39;} \\mathcal J[\\mu&#39;,\\nu&#39;], \\qquad \\mathcal J[\\mu&#39;,\\nu&#39;] := \\min_u L[u,\\mu&#39;,\\nu&#39;]. \\] Por un lado vemos que si \\[ \\sum_{x\\in V}\\mu&#39;(x) \\neq \\sum_{x\\in V}\\nu&#39;(x) \\] entonces \\(\\mathcal J[\\mu&#39;,\\nu&#39;] = -\\infty\\), dado que para \\(u=c\\) constante podemos hacer \\(L[u,\\mu&#39;,\\nu&#39;]\\) arbitrariamente negativo \\[ L[c,\\mu&#39;,\\nu&#39;] = \\sum_{x\\in V}\\mu&#39;(x) + c\\sum_{x\\in V}(\\nu&#39;-\\mu&#39;)(x). \\] Asumamos entonces que las sumas son iguales, en cuyo caso la forma cuadrática convexa \\(u\\mapsto L[u,\\mu&#39;,\\nu&#39;]\\) alcanza su mínimo en las soluciones de \\[ 2\\Delta u = \\nu&#39;-\\mu&#39;. \\] Estas están bien definidas por la hipótesis para el lado derecho, además dos soluciones cualesquiera difieren por constantes, gracias a la conexidad de \\(G\\). Por lo tanto \\[ \\sum_{x\\in V} (\\nu&#39;-\\mu&#39;)u(x) = 2\\sum_{x\\in V} u\\Delta u(x) = -4\\mathcal E[u] \\] y entonces \\[ \\mathcal J[\\mu&#39;,\\nu&#39;] = \\sum_{x\\in V} \\mu&#39;(x)-2\\mathcal E[u]. \\] Denotemos por \\(M:= \\sum_{x\\in V} \\mu&#39;(x)\\) y consideremos las renormalizaciones dadas por \\(\\mu&#39;=M\\mu\\), \\(\\nu&#39;=M\\nu\\) y \\(2u=Mv\\) tales que \\((\\mu,\\nu) \\in \\mathcal M(\\Omega&#39;|\\Omega)\\), \\(\\Delta v = \\nu-\\mu\\), y \\(4\\mathcal E[u] = M^2\\mathcal E[v]\\). Por lo tanto \\[ \\mathcal J[\\mu&#39;,\\nu&#39;] = M - \\frac{M^2}{2} \\mathcal E[v] \\] Vemos que \\(M\\) y \\(v\\) son independientes bajo las restricciones dadas. Si maximizamos primero en \\(M\\) obtenemos que \\(M=1/\\mathcal E[v]\\) y por lo tanto \\[ \\operatorname{Cap}(\\Omega&#39;|\\Omega) \\geq \\max_{\\mu&#39;,\\nu&#39;} \\mathcal J[\\mu&#39;,\\nu&#39;] = \\max_{\\substack{\\Delta v = \\nu-\\mu\\\\(\\mu,\\nu)\\in \\mathcal M(\\Omega&#39;|\\Omega)}} \\frac{1}{\\mathcal E[v]} = \\max_{(\\mu,\\nu)\\in \\mathcal M(\\Omega&#39;|\\Omega)} \\frac{1}{\\mathcal D^2[\\mu,\\nu]}. \\] Para concluir la demostración veremos que cuando \\(u\\) es la solución de \\[ \\begin{cases} \\Delta u = 0 \\text{ in } \\Omega\\setminus \\Omega&#39;,\\\\ u=0 \\text{ on } V\\setminus \\Omega,\\\\ u=1 \\text{ on } \\Omega&#39;, \\end{cases} \\] y además \\((\\Delta u)_- = M\\mu\\), \\((\\Delta u)_+ = M\\nu\\), \\(u=Mv\\), tales que \\((\\mu,\\nu)\\in \\mathcal M(\\Omega&#39;|\\Omega)\\), entonces \\[ \\operatorname{Cap}(\\Omega&#39;|\\Omega) = 2\\mathcal E[u] \\overset{?}{=} \\frac{1}{2\\mathcal E[v]} = \\frac{1}{\\mathcal D^2[\\mu,\\nu]}. \\] Esto se debe a la fórmula de integración por partes y la homogeneidad de \\(\\mathcal E\\) \\[ 2\\mathcal E[u] = M = 2M^2\\mathcal E[v] \\qquad\\mathbb Rightarrow\\qquad M= \\frac{1}{2\\mathcal E[v]} \\qquad\\mathbb Rightarrow\\qquad 2\\mathcal E[u] = \\frac{1}{2\\mathcal E[v]}. \\] En los siguientes ejercicios consideramos para \\(\\Omega\\subseteq V\\) \\[ \\mathcal M(\\Omega):= \\left\\{\\mu:V\\to [0,1] \\ | \\ \\operatorname{spt}\\mu\\subseteq\\Omega \\text{ y } \\sum_{x\\in V}\\mu(x)=1\\right\\}. \\] Ejercicio 7.13 Sea \\(\\Omega&#39;\\subseteq\\Omega\\subseteq V\\). Demuestra que para \\(\\mu\\in \\mathcal M(\\Omega&#39;)\\) se tiene que \\[ \\mathcal D(\\mu,P_\\Omega(\\mu)) = \\min_{\\nu \\in \\mathcal M(V\\setminus \\Omega)}\\mathcal D(\\mu,\\nu) \\] Solución: Ejercicio 7.14 Sea \\(\\Omega&#39;\\subseteq\\Omega\\subseteq V\\). Demuestra que \\(T:= P_{V\\setminus \\Omega&#39;}\\circ P_\\Omega\\) es un mapeo no expansivo \\(\\mathcal M(\\Omega&#39;)\\) en si mismo con respecto de la métrica de Wasserstein, es decir que \\[ \\mathcal D(T(\\mu_1),T(\\mu_2))\\leq \\mathcal D(\\mu_1,\\mu_2). \\] Solución: 7.4 Cociente de Rayleigh Sea \\(A\\in \\mathbb R^{N\\times N}\\) simétrica. Sabemos por el teorema espectral que existe una base ortogonal de autovectores de \\(L\\) con autovalores reales. Tendremos en mente aplicar los resultados de esta sección para \\(A=-L\\) para la cual sabemos adicionalmente que sus autovalores son no-negativos. La ecuación \\(A\\xi = \\lambda\\xi\\) que determina los autovectores puede pensarse también como una ecuación de punto crítico con restricciones, siendo \\(\\lambda\\) el multiplicador de Lagrange. En este caso el gradiente de la función objetivo es \\(A\\xi\\), mientras que el gradiente de la restricción es \\(\\xi\\). Esto quiere decir que la función objetivo puede ser tomada como la forma cuadrática \\(f(\\xi)=A\\xi\\cdot \\xi\\), mientras que la restricción es \\(g(\\xi) = \\|\\xi\\|^2 = \\xi\\cdot\\xi\\). A lo largo de esta sección asumimos que \\(A\\in \\mathbb R^{N\\times N}\\) es simétrica y denotamos por \\(\\lambda_0\\leq\\ldots\\leq \\lambda_{N-1}\\) sus autovalores y \\(\\xi_0,\\ldots,\\xi_{N-1}\\) una base ortogonal de autovectores. Ejercicio 7.15 Demuestra que el mínimo de \\(f(\\xi)=A\\xi\\cdot \\xi\\) sobre la esfera unitaria es el menor autovalor de \\(A\\) y que los puntos donde se realiza el mínimo general el autoespacio de dicho autovalor. ¿Sucede algo similar para el problema de maximización? Solución: Ejercicio 7.16 Considera el grafo Calcula el mínimo y máximo de \\[ \\sum_{e\\in E} (Du(e))^2 \\] sobre todas las funciones \\(u:V\\to \\mathbb R\\) tales que \\(\\sum_V u^2=1\\). Solución: Ejercicio 7.17 Considera el grafo Calcula el mínimo y máximo de \\[ \\sum_{e\\in E} (Du(e))^2 \\] sobre todas las funciones \\(u:V\\to \\mathbb R\\) tales que \\(\\sum_V u^2=1\\) y \\(u(A)=u(B)=0\\). Solución: Una forma alternativa del problema de optimización consiste en tomar el cociente de Rayleigh \\[ R(\\xi) := \\frac{A\\xi \\cdot \\xi}{\\|\\xi\\|^2}, \\] y minimizar o maximizar esta función fuera del origen. Ejercicio 7.18 Demuestra que \\[ \\lambda_k = \\min\\{R(\\xi)\\ | \\ \\xi \\in \\operatorname{span}\\{\\xi_0,\\ldots,\\xi_{k-1}\\}^\\perp \\setminus \\{0\\}\\} \\] Solución: Teorema 7.2 (Courant–Fischer–Weyl) \\[ \\lambda_k = \\max\\{\\min\\{R(\\xi)\\ | \\ \\xi \\in S\\setminus\\{0\\}\\} \\ | \\ S \\text{ es un sub-espacio de $\\mathbb R^N$ con $\\dim S=N-k$}\\} \\] En otras palabras, dado un sub-espacio \\(S\\) de dimensión \\(N-k\\), el mínimo de \\(R\\) sobre \\(S\\cap \\partial B_1\\) es a lo sumo \\(\\lambda_k\\). La igualdad se alcanza cuando \\(S=\\operatorname{span}\\{\\xi_k,\\ldots,\\xi_{N-1}\\}\\). Demostración. Denotemos \\[ \\mu_k := \\max\\{\\min\\{R(\\xi)\\ | \\ \\xi \\in S\\setminus\\{0\\}\\} \\ | \\ S \\text{ es un sub-espacio de $\\mathbb R^N$ con $\\dim S=N-k$}\\}. \\] Para demostrar que \\(\\lambda_k\\leq \\mu_k\\) basta con conseguir un sub-espacio \\(S\\) de dimensión \\(N-k\\) tal que el mínimo de \\(R\\) sobre \\(S\\setminus\\{0\\}\\) es por lo menos \\(\\lambda_k\\). Sea \\(S_{N-k} = \\operatorname{span}\\{\\xi_{k},\\ldots,\\xi_{N-1}\\}\\) tal que \\(\\dim S_{N-k} = N-k\\). Por un lado tenemos que para \\(\\xi = \\alpha_{k}\\xi_{k}+\\ldots+\\alpha_{N-1}\\xi_{N-1}\\in S_{N-k}\\setminus \\{0\\}\\) \\[ R(\\xi) = \\frac{\\lambda_{k}\\alpha_{k}^2+\\ldots+\\lambda_{N-1}\\alpha_{N-1}^2}{\\alpha_{k}^2+\\ldots+\\alpha_{N-1}^2} \\geq \\lambda_k \\] cuyo mínimo es de hecho \\(\\lambda_{k}\\) y se alcanza por ejemplo cuando \\(\\alpha_k=1\\) y los demás coeficientes se anulan. Es decir que hemos probado que \\(\\lambda_k \\leq \\mu_k\\). La desigualdad \\(\\lambda_k \\geq \\mu_k\\) quiere decir que para cualquier sub-espacio \\(S\\) de dimensión \\(N-k\\), existe \\(\\xi \\in S\\setminus\\{0\\}\\) tal que \\(R(\\xi)\\leq \\lambda_k\\). Tomemos \\(\\xi = \\alpha_0\\xi_0+\\ldots+\\alpha_k\\xi_k \\in S\\setminus\\{0\\}\\), sabemos que tal vector existe puesto que \\[ \\dim S + \\dim\\operatorname{span}\\{\\xi_0,\\ldots,\\xi_k\\} = N+1. \\] Luego \\[ R(\\xi) = \\frac{\\lambda_{0}\\alpha_{0}^2+\\ldots+\\lambda_{k}\\alpha_{k}^2}{\\alpha_{0}^2+\\ldots+\\alpha_{k}^2} \\leq \\lambda_k. \\] Ejercicio 7.19 Si \\(A\\leq A&#39;\\), i.e. \\((A&#39;-A)\\) es positiva semi-definida, entonces sus correspondientes autovalores también están ordenados, es decir \\(\\lambda_k\\leq \\lambda_k&#39;\\). Solución: Ejercicio 7.20 Sea \\(G&#39;\\) un sub-grafo de \\(G\\)16. Demuestra que para los correspondientes autovalores del Laplaciano se tiene que \\(\\lambda_k&#39;\\geq \\lambda_k\\). Solución: Recordemos que \\[ n_{\\Omega&#39;}(e) = \\begin{cases} 1 \\text{ si $e_-\\in \\Omega&#39;$ y $e_+\\in V\\setminus \\Omega$},\\\\ -1 \\text{ si $e_+\\in \\Omega&#39;$ y $e_-\\in V\\setminus \\Omega$},\\\\ 0 \\text{ en cualquier otro caso}. \\end{cases} \\]↩︎ El minimizante \\(u\\) correspondiente a \\(\\Omega_1\\cup\\Omega_2\\) es puntualmente mayor o igual a \\(\\max(u_1,u_2)\\) donde \\(u_1\\) y \\(u_2\\) son los minimizantes para \\(\\Omega_1\\) y \\(\\Omega_2\\) respectivamente.↩︎ En general, \\(\\min_x\\max_\\lambda L(x,\\lambda) \\geq \\max_\\lambda\\min_x L(x,\\lambda)\\).↩︎ \\(V&#39;\\subseteq V\\) y \\(E&#39;\\subseteq E\\cap V&#39;\\times V&#39;\\).↩︎ "],["cantidades-conservadas.html", "Capítulo 8 Cantidades conservadas 8.1 Problemas homogéneos 8.2 Problemas no-homogéneos 8.3 Problemas semi-lineales 8.4 Problemas cuasi-lineales", " Capítulo 8 Cantidades conservadas 8.1 Problemas homogéneos Sea \\(v:\\mathbb R^n\\to \\mathbb R^n\\) un campo vectorial suave y acotado, como tal genera un flujo \\(\\phi:\\mathbb R^n\\times\\mathbb R\\to \\mathbb R^n\\) definido por medio del problema de valores iniciales \\[ \\begin{cases} \\partial_t\\phi(x,t) = v(\\phi(x,t)),\\\\ \\phi(x,0)=x. \\end{cases} \\] Una función \\(u:\\mathbb R^n\\to \\mathbb R\\) se dice que es una cantidad conservada de \\(v\\), si \\(u\\) permanece constante a lo largo del flujo \\(\\phi\\). Es decir \\[ u(\\phi(x,t)) = u(x) \\qquad \\forall \\, t\\in\\mathbb R. \\] Si \\(u\\) es además diferenciable esto equivale a la ecuación parcial lineal de primer orden \\[ v \\cdot Du = 0. \\tag{8.1} \\] Por un lado, conocer una cantidad conservada \\(u\\) nos ayuda a resolver las EDOs \\(x&#39;=v(x)\\), dado que las trayectorias permanecen en los conjuntos de nivel de \\(u\\). Por otro lado, la EDO asociada a la EDP (8.1) se conoce como la ecuación característica y nos ayudan a calcular la solución de la EDP dado que \\(u\\) debe permanecer constante a lo largo de estas trayectorias. Geométricamente, la ecuación \\(v\\cdot Du=0\\) quiere decir que las curvas de nivel de \\(u\\) deben ser perpendiculares al campo \\(v\\) en todo punto. En otras palabras, \\(v\\) es paralelo a los conjuntos de nivel de \\(u\\). Ejemplo 8.1 Dado un vector constante \\(v = (v_1,\\ldots,v_n)\\in \\mathbb R\\), consideremos el problema \\[ v\\cdot Du = 0. \\] Este tiene asociada la ecuación característica \\(x&#39;=v\\) (es decir el sistema \\(x_i&#39;=v_i\\)) cuya solución es \\(x(t)=x_0+tv\\). Dada que cualquier solución de la EDP debe permanecer constante a lo largo de esta trayectoria tenemos que \\[ u(x_0+tv) = u(x_0). \\] Si \\(u\\) estuviese predeterminada en una región \\(F\\subseteq \\mathbb R^n\\) dada como la función \\(u_0\\), entonces es conveniente tomar la posición inicial \\(x_0\\) en dicha región. Por ejemplo, si \\(F = \\{x_1=0\\}\\) y \\(v=(v_1,\\ldots,v_n)\\) no es paralelo a \\(F\\), es decir \\(v_1\\neq0\\), entonces podemos conectar cualquier punto \\(x=(x_1,\\ldots,x_n)\\in\\mathbb R^n\\) con algún punto \\(x_0=(0,x_{0,2},\\ldots,x_{0,n})\\in F\\) tal que \\(x_0+tv = x\\) y por lo tanto \\(u(x) = u_0(x_0)\\). En este caso particular podemos simplemente calcular \\(x_0\\) y \\(t\\) y obtener una fórmula explícita para la solución \\[ \\begin{aligned} tv_1 = x_1 \\qquad&amp;\\Rightarrow\\qquad t=x_1/v_1,\\\\ x_{0,i} + tv_i = x_i \\text{ si } i\\geq 2 \\qquad&amp;\\Rightarrow\\qquad x_{0,i} = x_i - x_1v_i/v_1,\\\\ u(x) = u_0(x_0) \\qquad&amp;\\Rightarrow\\qquad u(x) = u_0(0,x_2 - x_1v_2/v_1,\\ldots,x_n - x_1v_n/v_1) \\end{aligned} \\] Ejercicio 8.1 Calcula \\(u:\\mathbb R^2\\to \\mathbb R\\) tal que \\[ \\begin{cases} y\\partial_x u = x\\partial_y u \\text{ en } \\mathbb R^2\\setminus\\{y=0,x\\geq 0\\},\\\\ u = u_0 \\text{ en } \\{y=0,x\\geq 0\\}. \\end{cases} \\] Solución EDO característica \\[ x&#39;=y, \\qquad y&#39;=-x \\] Flujo característico \\[ x(t) = x_0 \\cos t + y_0 \\sin t, \\qquad y(t) = - x_0 \\sin t + y_0\\cos t \\] Condición de borde: \\(t=0\\), \\(y_0=0\\), y \\(x_0&gt;0\\) \\[ u(x_0 \\cos t + y_0 \\sin t,- x_0 \\sin t + y_0\\cos t) = u_0(x_0) \\] Invertimos: \\((x,y)=x_0 \\cos t + y_0 \\sin t,- x_0 \\sin t + y_0\\cos t\\) tal que en \\(t=0\\), \\(x_0 \\cos t + y_0 \\sin t,- x_0 \\sin t + y_0\\cos t = (x_0,0) \\in \\{y=0,x\\geq 0\\}\\). Por lo tanto \\(x_0=\\sqrt{x^2+y^2}\\), \\(y_0=0\\), y \\[ u(x,y) = u_0\\left(\\sqrt{x^2+y^2}\\right) \\] Verificamos: Para la condición de frontera es claro que \\[ \\partial_x u = u_0&#39;\\left(\\sqrt{x^2+y^2}\\right)\\frac{x}{\\sqrt{x^2+y^2}}, \\qquad \\partial_y u = u_0&#39;\\left(\\sqrt{x^2+y^2}\\right)\\frac{y}{\\sqrt{x^2+y^2}}. \\] Por lo tanto, \\[ y\\partial_x u - x\\partial_y u = u_0&#39;\\left(\\sqrt{x^2+y^2}\\right)\\frac{yx-xy}{\\sqrt{x^2+y^2}}=0. \\] Ejercicio 8.2 Explica como se podría extender la teoría al problema de Cauchy donde \\(u:\\mathbb R^n\\times[0,\\infty)\\to \\mathbb R\\) depende de una variable espacial \\(x\\in\\mathbb R^n\\) y una temporal \\(t\\in[0,\\infty)\\) y satisface en cambio el problema de valores iniciales \\[ \\begin{cases} \\partial_t u + v\\cdot Du = 0 \\text{ en } \\mathbb R^n,\\\\ u = u_0 \\text{ en } \\{t= 0\\} \\end{cases} \\] Solución Consideramos a \\(t=x_0\\) como una variable adicional, es decir tomamos el espacio de fase extendido. Por lo tanto \\[ \\partial_t u + v\\cdot Du = (1,v)\\cdot(\\partial_t u,Du) = (1,v)D_{x_0,x_1,\\ldots,x_n}u. \\] En el caso evolutivo \\(u=u(x,t)\\), dado un campo vectorial \\(v\\), la derivada \\[ D_vu = \\partial_tu+ v \\cdot Du \\] se conoce como la derivada material de \\(u\\) y describe la tasa de cambio de \\(u\\) a lo largo de las trayectorias generadas por \\(v\\). 8.1.1 Leyes de conservación en mecánica Ejemplo 8.2 Ley de conservación de la energía Un sistema mecánico se dice conservativo si la fuerza es menos el gradiente un potencial \\(U\\) \\[ mv&#39; = -DU(x), \\qquad v=x&#39;. \\] La energía del sistema es la suma de la cinética y potencial \\[ E(x,v) = \\frac{1}{2}m|v|^2 + U(x). \\] La ley de la conservación de la energía dice que la energía total es constante. Comprobémoslo calculando la derivada temporal de \\(E\\). \\[ \\frac{d}{dt}E(x(t),v(t)) = x&#39;\\partial_x E + v&#39;\\partial_v E=v\\cdot DU + \\frac{(-DU)}{m}\\cdot m v = 0. \\] Dicho de otra forma, la energía total satisface la ecuación \\((v,-DU/m)\\cdot DE=0\\). Ejercicio 8.3 Considera el sistema mecánico de fuerzas centrales, \\[ mx&#39;&#39; = f(|x|)x. \\] Demuestra que el momento angular \\(L_{ij} := x_ix_j&#39;-x_jx_i&#39;\\) es una cantidad conservada del sistema. Solución Sea \\(v_i=x_i&#39;\\). Tenemos así \\(L_{ij} = x_iv_j-x_jv_i\\) y el sistema de primer orden \\[ x&#39;=v, \\qquad v&#39;=\\frac{1}{m}f(|x|)x. \\] Basta ver entonces que la siguiente derivada se anula \\[ \\begin{aligned} (v,\\frac{1}{m}f(|x|)x)\\cdot (D_xL_{ij},D_vL_{ij}) &amp;= \\sum_{k=1}^n v_k\\partial_{x_k}L_{ij}+\\frac{1}{m}f_k(|x|)x_k\\partial_{v_k}L_{ij},\\\\ &amp;= v_iv_j-v_jv_i + \\frac{1}{m}f_i(|x|)(x_ix_j-x_jx_i),\\\\ &amp;= 0. \\end{aligned} \\] 8.1.2 Ecuaciones exactas y conjugados armónicos Ejemplo 8.3 Consideremos el sistema de ecuaciones \\[ x&#39; = f(x,y),\\qquad y&#39; = g(x,y). \\] La trayectoria del sistema consiste del lugar geométrico trazado por la solución. La ecuación se dice exacta si las trayectorias son el conjunto de nivel de una función \\(u\\), equivalentemente el campo \\((f,g)\\) debe ser perpendicular a \\((\\partial_xu,\\partial_y u)\\). Es decir que \\(u\\) debe satisfacer la ecuación homogénea \\[ (f,g)\\cdot Du=0. \\] Ejemplo 8.4 Un función \\(f = (u(x,y),v(x,y)):\\mathbb{C}\\to\\mathbb{C}\\) es holomorfa si satisface las ecuaciones de Cauchy-Riemann \\[ \\partial_x u = \\partial_y v, \\qquad \\partial_y u = - \\partial_x v. \\] Estas implican que \\(u\\) y \\(v\\) son funciones armónicas \\[ (\\partial_x^2+\\partial_y^2)u=(\\partial_x^2+\\partial_y^2)v=0, \\] y adicionalmente sus conjuntos de nivel son ortogonales entre si. Sus gradientes son exactamente rotaciones de 90 grados uno del otro. Es decir que \\(v\\) debe satisfacer la ecuación homogénea \\[ Du\\cdot Dv=0. \\] En la siguiente sección veremos como encontrar soluciones para el problema de ecuaciones exactas y el problema del conjugado armónico resolviendo el problema de la prescripción del gradiente (un sistema de ecuaciones no-homogéneas). En el caso de las ecuaciones exactas este resulta en \\[ \\partial_x u = -g, \\qquad \\partial_y u = f. \\] En el caso del conjugado armónico el sistema es en cambio el dado por las ecuaciones de Cauchy-Riemann con \\(u\\) dado y \\(v\\) variable \\[ \\partial_x v = -\\partial_y u, \\qquad \\partial_y v = \\partial_x u. \\] 8.1.3 El teorema de Frobenius Podemos también considerar sistemas de ecuaciones homogéneas de primer orden. Es decir, dados \\(k\\) campos \\(v^{(1)},v^{(2)},\\ldots,v^{(k)}:\\mathbb R^n\\to\\mathbb R^n\\), buscamos una función \\(u:\\mathbb R^n\\) que satisfaga simultáneamente \\[ \\begin{cases} v^{(1)}\\cdot Du = 0,\\\\ v^{(2)}\\cdot Du = 0,\\\\ \\vdots\\\\ v^{(k)}\\cdot Du = 0. \\end{cases} \\] Es decir que cada uno de los vectores \\(v^{(j)}\\) son tangentes a los conjuntos de nivel de \\(u\\). Cuando los campos son linealmente independientes, tenemos que estos asocian en cada punto un sub-espacio de dimensión \\(k\\) que estos generan, esto se conoce como una distribución. Geométricamente, el sistema de EDPs quiere decir que los planos tangentes de los conjuntos de nivel de \\(u\\) contienen a la distribución dada por los campos \\(v^{(1)},\\ldots,v^{(k)}\\). Si el sistema tiene solución entonces necesariamente se debe cumplir que \\[ [v^{(i)},v^{(j)}] := \\sum_{l=1}^n (v^{(i)}\\cdot Dv^{(j)}_l-v^{(j)}\\cdot Dv^{(i)}_l)e_l \\perp Du. \\] Para justificar este hecho basta ver que \\[ [v^{(i)},v^{(j)}]\\cdot Du = v^{(i)}\\cdot D(v^{(j)}\\cdot Du) - v^{(j)}\\cdot D(v^{(i)}\\cdot Du) = 0. \\] Ejercicio 8.4 Verifica las identidades previas. Solución \\[ v^{(i)}\\cdot D(v^{(j)}\\cdot Du) = \\sum_{a=1}^n v^{(i)}_a\\partial_a\\left(\\sum_{b=1}^n v^{(j)}_b\\partial_bu\\right) = \\sum_{a,b=1}^n v^{(i)}_a\\partial_a v^{(j)}_b \\partial_bu+ v^{(i)}_a v^{(j)}_b\\partial_a\\partial_bu. \\] Por tanto \\[ v^{(i)}\\cdot D(v^{(j)}\\cdot Du) - v^{(j)}\\cdot D(v^{(i)}\\cdot Du) = \\sum_{a,b=1}^n \\left(v^{(i)}_a\\partial_a v^{(j)}_b - v^{(j)}_a\\partial_a v^{(i)}_b\\right) \\partial_bu = [v^{(i)},v^{(j)}]\\cdot Du \\] Asumiendo que \\(Du\\) es perpendicular a los campos \\(v^{(i)}\\) y \\(v^{(j)}\\) obtenemos que \\(v^{(i)}\\cdot Du=v^{(j)}\\cdot Du=0\\), por lo tanto también \\([v^{(i)},v^{(j)}]\\cdot Du=0\\). Esto implica en particular que (a menos de que \\(u\\) sea constante, lo cual es la solución trivial), \\(\\{v^{(i)}\\}_{i=1}^k\\cup\\{[v^{(i)},v^{(j)}]\\}_{i,j=1}^k\\) genera a lo sumo un espacio de dimensión \\(n-1\\). Esta es una restricción no trivial. En general, el Teorema de Frobenius nos permite dar condiciones necesarias y suficientes para encontrar la solución general del sistema homogéneo. 8.2 Problemas no-homogéneos Puede darse también el caso de que la función \\(u\\) no sea necesariamente constante a lo largo de las trayectorias de la EDO \\(x&#39;=v(x)\\), pero que sin embargo sus variaciones sean conocidas en función de la posición en la trayectoria. Ejemplo 8.5 Si \\(u(x_0)\\) denota el tiempo que tarda la trayectoria que parte de la posición inicial \\(x_0\\) en llegar a un dado conjunto \\(F\\), entonces a lo largo de una solución \\(z(t) := u(x(t))\\) tiene derivada igual a \\(-1\\). Es decir que satisface la ecuación no-homogénea \\[ v\\cdot Du = -1. \\] En general podemos aplicar un razonamiento similar a la ecuación no-homogénea \\[ v\\cdot Du = f(x). \\tag{8.2} \\] La ecuación característica de (8.2) sigue siendo \\(x&#39;=v(x)\\), sin embargo \\(z(t) = u(x(t))\\) ahora no es constante a lo largo de una curva característica. En cambio \\(z\\) satisface \\(z&#39;=f(x)\\). Podemos decir así que las ecuaciones características están dadas en verdad por un sistema débilmente acoplado \\[ \\begin{cases} x&#39;= v(x),\\\\ z&#39; = f(x). \\end{cases} \\] Se dice que es débilmente acoplado porque por lo menos la ecuación \\(x&#39;=v(x)\\) es independiente de \\(z\\). Para resolver el sistema uno puede comenzar resolviendo el problema para \\(x\\) y luego substituir este resultado en la ecuación para \\(z\\) la cual se puede resolver por medio de una integración \\[ z(t) = z_0 + \\int_{0}^t f(x(s))ds. \\] Ejercicio 8.5 Calcula el tiempo que se toma la curva \\((x(t),y(t))\\) que parte de \\((x_0,y_0) \\in \\mathbb R^2\\setminus F\\) en llegar a \\(F:=\\{y=0,x\\geq0\\}\\) si esta se mueve según la ecuación diferencial \\[ x&#39;=y, \\qquad y&#39;=-x. \\] Usa esta información para encontrar una solución de \\[ y\\partial_xu-x\\partial_yu=1 \\text{ en } \\mathbb R^2\\setminus F,\\\\ u=0 \\text{ en } F \\] ¿Tiene sentido que \\(u\\) sea discontinua en \\(F\\)? ¿Es la solución de este problema de frontera única? Solución Las características se integran en \\[ x(t) = x_0\\cos t + y_0 \\sin t, \\qquad y(t) = -x_0\\sin t + y_0\\cos t. \\] Esta curva alcanza el semi-eje positivo de las \\(x\\)’s cuando \\(t=\\theta\\), el ángulo polar para el punto \\((x_0,y_0)\\), es decir \\[ t=\\begin{cases} \\pi/2 - \\arctan(x_0/y_0) \\text{ si } y_0 &gt; 0,\\\\ 3\\pi/2 - \\arctan(x_0/y_0) \\text{ si } y_0&lt;0,\\\\ \\pi \\text{ si } x_0&lt;0, y_0 = 0. \\end{cases} \\] Sospechamos así que una solución de la EDP debe estar dada por \\[ u(x,y) = \\begin{cases} \\arctan(x/y)-\\pi/2 \\text{ si } y &gt; 0,\\\\ \\arctan(x/y)-3\\pi/2 \\text{ si } y&lt;0,\\\\ -\\pi \\text{ si } x&lt;0, y = 0,\\\\ 0 \\text{ si } x&gt;0, y = 0,\\\\ \\end{cases} \\] Claramente esta función es continua en todos lados con la excepción de \\(F\\) donde tiene una discontinuidad de salto. Además satisface la condición de borde \\(u=0\\) en \\(F\\). Para verificar la ecuación diferencial consideramos tres escenarios: Si \\(y&gt;0\\), \\[ \\partial_x u = \\frac{y}{x^2+y^2},\\qquad \\partial_y u = \\frac{x}{x^2+y^2} \\] Por lo tanto es inmediato ver que \\(y\\partial_xu-x\\partial_y u=1\\). El cálculo para \\(y&lt;0\\) es similar y lo omitimos. Si \\(y=0\\) y \\(x&lt;0\\) es fácil ver que \\(u\\) es continua y los gradientes que se calculan en las regiones \\(y\\geq0\\) y \\(y\\leq0\\) son en ambos casos \\((0,1/x)\\). En conclusión, también se cumple la EDP esperada. La solución no es continua sobre \\(F\\), los puntos que aproximan \\(F\\) en el cuadrante positivo tardan poco tiempo en llegar a \\(F\\), mientra que los puntos que aproximan \\(F\\) por el cuarto cuadrante tardan aproximadamente \\(2\\pi\\) unidades de tiempo en alcanzar \\(F\\). Una forma de conseguir otra solución del problema de valores de frontera consiste en recorrer en cambio la característica en la dirección opuesta, con esto obtenemos que \\[ v(x,y) = \\begin{cases} \\arctan(x/y)+3\\pi/2 \\text{ si } y &gt; 0,\\\\ \\arctan(x/y)+\\pi/2 \\text{ si } y&lt;0,\\\\ \\pi \\text{ si } x&lt;0, y = 0,\\\\ 0 \\text{ si } x&gt;0, y = 0,\\\\ \\end{cases} \\] también satisface el problema de valores iniciales. 8.2.1 Sistemas lineales no homogéneos En esta sección ilustramos algunos ejemplos de sistemas lineales no-homogéneos. Es decir de la forma \\[ \\begin{cases} v^{(1)}\\cdot Du = f_1,\\\\ v^{(2)}\\cdot Du = f_2,\\\\ \\vdots\\\\ v^{(k)}\\cdot Du = f_k. \\end{cases} \\] La teoría general pasa por entender los sistemas homogéneos (Teorema de Frobenius) y la posibilidad de encontrar una solución particular. En el caso donde \\(k=n\\) y \\(v^{(i)}=e_i\\) (idénticamente la base canónica), tenemos que el problema a la mano es la prescripción del gradiente de \\(u\\), es decir \\[ Du=f. \\] El Lema de Poincaré17 dice que si planteamos esta ecuación en un dominio simplemente conexo \\(\\Omega\\) con \\(f \\in C^1(\\Omega)\\), entonces esta tiene solución si y sólo si \\(f\\) satisface la condición \\[ \\partial_i f_j = \\partial_j f_i. \\] Es decir que la matriz Jacobiana \\(Df\\) es simétrica, lo cual tiene sentido si esperamos que esta sea la Hessiana de la función \\(u\\). En el caso que se cumpla la condición anterior para la \\(f\\), podemos calcular \\(u\\) de la siguiente forma: Fijamos \\(x_0 \\in \\Omega\\) y para \\(x\\in \\Omega\\) arbitrario tomamos una curva \\(\\gamma\\in C^1([0,1]\\to \\Omega)\\) que vaya de \\(\\gamma(0)=x_0\\) a \\(\\gamma(1)=x\\) y hacemos \\[ u(x) = \\int_\\gamma f = \\int_0^1 f(\\gamma(t))\\cdot \\gamma&#39;(t)dt. \\] Ejemplo 8.6 Recordemos que para el sistema de ecuaciones en el plano \\[ x&#39; = f(x,y),\\qquad y&#39; = g(x,y), \\] las trayectorias se pueden calcular a partir de la siguiente ecuación diferencial (aunque no necesariamente la parametrización de la trayectoria, solo el lugar geométrico) \\[ gdx - fdy = 0. \\] Esta es exacta si \\(\\partial_y g = -\\partial_x f\\), es decir la misma condición que aparece en el Lema de Poincaré para que exista la función escalar \\(u\\) tal que \\(Du = (g,-f)\\). Veamos que efectivamente \\(u\\) es constante a lo largo de las trayectorias del sistema original \\[ \\frac{d}{dt}u(x(t),y(t)) = x&#39;\\partial_xu + y&#39;\\partial_yu = f(x,y)g(x,y) - g(x,y)f(x,y) = 0. \\] Por ejemplo calculemos las trayectorias para el sistema Lotka-Volterra \\[ \\begin{cases} x&#39;=\\alpha x - \\beta xy,\\\\ y&#39;= \\delta xy - \\gamma y. \\end{cases} \\] Para las trayectorias en el cuadrante estrictamente positivo tenemos que \\[ (\\delta xy - \\gamma y)dx-(\\alpha x - \\beta xy)dy=0 \\qquad \\Leftrightarrow \\qquad \\frac{\\delta x - \\gamma}{x}dx-\\frac{\\alpha - \\beta y}{y}dy=0, \\] siendo la segunda ecuación exacta. Buscamos así \\(u\\) tal que \\[ \\begin{cases} \\partial_x u = \\frac{\\delta x - \\gamma}{x},\\\\ \\partial_y u = \\frac{\\beta y - \\alpha}{y}. \\end{cases} \\] De la primera ecuación del sistema obtenemos \\[ u(x,y) = \\int \\frac{\\delta x - \\gamma}{x} dx = \\delta x - \\gamma\\ln x + C(y). \\] Tomando \\(\\partial_y\\) y usando la segunda ecuación del sistema obtenemos que \\[ C&#39;(y) = \\frac{\\beta y - \\alpha}{y} \\qquad\\Rightarrow\\qquad C(y) = \\beta y - \\alpha \\ln y + C. \\] Es decir que podemos tomar finalmente \\[ u(x,y) = \\delta x - \\gamma\\ln x + \\beta y-\\alpha \\ln y. \\] Los conjuntos de nivel de \\(u\\) para ciertos valores de los parámetros \\(\\alpha\\), \\(\\beta\\), \\(\\delta\\) y \\(\\gamma\\) quedan ilustrados a continuación Ejemplo 8.7 Dada una función \\(u \\in C^2(\\mathbb R^2)\\), armónica (\\(\\Delta u=0\\)), tenemos que la posibilidad de encontrar su conjugado armónico \\(v\\) se reduce al sistema de ecuaciones de Cauchy-Riemann \\[ \\begin{cases} \\partial_x v = -\\partial_y u,\\\\ \\partial_y v = \\partial_x u. \\end{cases} \\] La armonicidad de \\(u\\) es justamente la condición en el Lema de Poincaré. Por ejemplo, tomemos la función armónica \\(u(x,y) = x^2-y^2\\). Debemos así resolver \\[ \\begin{cases} \\partial_x v = 2y,\\\\ \\partial_y v=2x. \\end{cases} \\] De la primera ecuación obtenemos \\(v = 2xy+\\varphi(y)\\) y por lo tanto \\(2x=2x+C&#39;(y)\\) lo cual implica que \\(C\\) es constante. Concluimos así que \\(v(x,y) = 2xy+C\\) es conjugado armónico de \\(u\\) para cualquier constante real \\(C\\). Es decir que para \\(C=0\\) tenemos la función holomorfa \\[ u(x,y) = (x^2-y^2) + 2ixy = (x+iy)^2. \\] Ejercicio 8.6 Calcula el conjugado armónico de las siguientes funciones: \\(u(x,y) = x^3-3xy^2\\), \\(u(x,y) = e^{x}\\cos y\\), \\(u(x,y) = \\ln(x^2+y^2)\\). Solución \\(v(x,y) = 3x^2y-y^3+C\\), \\(v(x,y) = e^x\\sin y + C\\), En este caso el conjugado está definido en una rama del logaritmo, por ejemplo en \\(\\mathbb R^2\\setminus \\{y=0, x\\leq 0\\}\\). Tenemos \\[ v(x,y) = \\begin{cases} \\pi/2-\\arctan(x/y)+C \\text{ si } y&gt;0,\\\\ 3\\pi/2 - \\arctan(y/x)+C \\text{ si } y&lt;0,\\\\ C \\text{ si } y=0, x&gt;0. \\end{cases} \\] 8.3 Problemas semi-lineales Generalizando la idea de las ecuaciones no-homogéneas, puede darse el caso de que las variaciones de \\(z(t) = u(x(t))\\) dependan de \\(x\\) y también de la misma \\(z=u(x)\\). Por ejemplo, la ecuación \\(z&#39;=-cz\\) aparece cuando \\(z\\) representa una ganancia descontada con taza \\(c\\) que se obtiene cuando la trayectoria llega a una dada región \\(F\\). Consideremos la ecuación \\[ v\\cdot Du = f(u,x). \\] Se dice que es semi-lineal dado que el operador asociado a las derivadas de orden mayor (en este caso uno) es lineal y solamente depende de \\(x\\), sin embargo el problema puede presentar combinaciones no-lineales en \\(u\\) dadas por \\(f\\). Las ecuaciones características vuelven a ser un sistema débilmente acoplado dado por \\[ \\begin{cases} x&#39;= v(x),\\\\ z&#39; = f(z,x). \\end{cases} \\] En este caso, también se puede proceder resolviendo primero la ecuación para \\(x\\) y sustituyendo el resultado en la ecuación para \\(z\\). Sin embargo, el último paso requiere resolver una ecuación no-homogénea para \\(z\\) y no simplemente calcular una integral. Ejercicio 8.7 Dado el campo vectorial \\(v=(ax+by,cx+dy)\\) en el plano, resuelve el problema de valores iniciales \\[ \\begin{cases} \\partial_t u + \\operatorname{div}(vu) =0 \\text{ en }\\mathbb R^2\\times (0,\\infty),\\\\ u=u_0 \\text{ en } \\{t=0\\} \\end{cases} \\] Demuestra que si \\(\\int_{\\mathbb R^2}u_0(x,y)dxdy&lt;\\infty\\), entonces \\(m(t) := \\int_{\\mathbb R^2}u(x,y,t)dxdy\\) permanece constante. Solución Distribuyendo la divergencia \\[ \\partial_t u + v\\cdot Du = -\\operatorname{div}(v)u = -(a+d)u. \\] Características: \\[ \\begin{pmatrix} x\\\\ y \\end{pmatrix} = \\exp\\left(At\\right)\\begin{pmatrix} x_0\\\\ y_0 \\end{pmatrix}, \\qquad A:= \\begin{pmatrix}a&amp;b\\\\c&amp;d\\end{pmatrix}, \\qquad z=e^{-(a+d)t}z_0. \\] Por lo tanto \\[ u(\\exp(At)(x_0,y_0)^T) = e^{-(a+d)t}u_0(x_0,y_0). \\] Devolviendo el cambio de variables \\[ u(x,y) = e^{-(a+d)t}u_0(\\exp(-At)(x,y)^T). \\] 8.4 Problemas cuasi-lineales Finalmente consideramos el caso donde el campo \\(v\\) también depende de \\(u\\). Esto hace que la EDO y la EDP estén estrechamente acopladas. Ejemplo 8.8 La ecuación de Burgers modela la ley de inercia de un fluído (incompresible y de densidad uniforme) con velocidad \\(u(x,t)\\) en la posición \\(x \\in \\mathbb R\\) y en tiempo \\(t \\in \\mathbb R\\). Para decir que el momento es una cantidad conservada a lo largo del flujo usamos que \\[ \\partial_t u + u \\partial_x u =0. \\] En el caso general \\[ v(u,x)\\cdot Du = f(u,x) \\] decimos que la ecuación es cuasi-lineal. Esto quiere decir que el operador asociado a las derivadas de orden mayor es lineal, pero puede depender en este caso de \\(u\\). Como es de esperarse la ecuación característica es ahora un sistema fuertemente acoplado \\[ \\begin{cases} x&#39;= v(z,x),\\\\ z&#39;=f(z,x). \\end{cases} \\] Ejercicio 8.8 ¿Qué relación guarda la ecuación de Burgers (EDP: \\(\\partial_t u + u \\partial_x u =f\\)) con la ley de Newton (EDO: \\(x&#39;&#39; = f\\))? Solución Las ecuaciones características para Burgers son \\[ x&#39;=z, \\qquad z&#39;=f \\qquad \\Leftrightarrow\\qquad x&#39;&#39; = f \\quad \\text{(Newton)}. \\] En los casos de las ecuaciones semi-lineales encontramos que las curvas características que se corresponden a la ecuación \\(x&#39;=v(x)\\) fibran el dominio, es decir lo cubren de forma disjunta bajo hipótesis regularidad y crecimiento para el campo vectorial. El caso de las ecuaciones características para problemas estrictamente cuasi-lineales, es decir de la forma \\[ \\begin{cases} x&#39;= v(z,x),\\\\ z&#39;=f(z,x), \\end{cases} \\] es radicalmente distinto. El teorema de unicidad garantiza que las trayectorias son disjuntas, pero en el sistema de coordenadas \\((x,z)\\), las proyecciones en el hiper-plano de las \\(x\\)’s puede tener intersecciones. Esto implica que las soluciones de la EDP pasan a ser funciones multi-valuadas. En la práctica decimos que las soluciones están definidas hasta el primer momento en que ocurre una colisión en las características. Para concluir esta sección daremos la demostración del teorema de las características en el caso más general que hemos visto hasta ahora. Teorema 8.1 Sean \\((v,f) \\in C^1(\\mathbb R\\times\\mathbb R^n\\to \\mathbb R^n\\times \\mathbb R)\\). Sean \\(u \\in C^1(\\mathbb R^n)\\) y \\((x,z)\\in C^1(\\mathbb R\\to \\mathbb R^{n}\\times \\mathbb R)\\) tales que por un lado \\(u\\) satisface la EDP cuasi-lineal \\[ v(u,x)\\cdot Du = f(u,x) \\] mientras que \\((x,z)\\) satisface el sistema característico de EDOs \\[ \\begin{cases} x&#39;=v(z,x),\\\\ z&#39;= f(z,x). \\end{cases} \\] Si además se cumplen la condiciónes inicial \\[ z(0) = u(x(0)), \\] entonces necesariamente se cumple que para todo \\(t\\in \\mathbb R\\) \\[ z(t) = u(x(t)). \\] Demostración. Sea \\(\\bar x\\in C^1(I\\to \\mathbb R^n)\\) la solución del siguiente problema de valores iniciales en su correspondiente intervalo maximal \\(I\\) \\[ \\begin{cases} \\bar x&#39; = v(u(\\bar x),\\bar x),\\\\ \\bar x(0) = x(0). \\end{cases} \\] El teorema de existencia y unicidad local se aplica en este caso garantizando que \\(\\bar x\\) está bien definida. Veremos que \\(\\bar x=x\\) en el intervalo maximal \\(I\\). Esto implicaría que \\(I=\\mathbb R\\). De hecho sabemos que \\(I\\) es un intervalo abierto gracias al teorema de existencia y unicidad local. Por otro lado, y asumiendo que ya se demostró \\(\\bar x = x\\) en \\(I\\), tendríamos que si \\(I=(a,b)\\) con \\(b&lt;\\infty\\), podemos entonces plantear el PVI a partir de \\(t=b\\) con dato dado por \\(x(b)\\), \\[ \\begin{cases} y&#39; = v(u(y),y),\\\\ y(0) = x(b). \\end{cases} \\] Esta solución se puede usar para extender a \\(\\bar x\\) más allá de \\(t=b\\) lo cual contradice que \\(I\\) haya sido el intervalo maximal, con \\(b&lt;\\infty\\). Sea \\(\\bar z=u(\\bar x)\\) también definida sobre \\(I\\) y de clase \\(C^1\\). Veamos que \\((x,z)\\) y \\((\\bar x,\\bar z)\\) satisfacen el mismo problema de valores iniciales. Por el teorema de unicidad esto implicaría que son necesariamente iguales. Para las condiciones iniciales tenemos que \\(\\bar x(0)=x(0)\\) por definición y \\(\\bar z(0) = u(\\bar x(0)) = u(x(0)) = z(0)\\) por hipótesis del teorema. Ejercicio 8.9 (Dificil, tomado del libro de V. I. Arnold de EDOs) Encuentra el valor más grande posible para \\(T\\) tal que el siguiente problema de valores iniciales tiene solución en el intervalo \\([0,T)\\) \\[ \\begin{cases} \\partial_tu + u\\partial_x u = -\\sin x \\text{ en } \\mathbb R\\times(0,T)\\\\ u=0 \\text{ en } \\{t=0\\} \\end{cases} \\] Solución Ver la ley de ciclos en el caso discreto↩︎ "],["leyes-de-conservación.html", "Capítulo 9 Leyes de conservación 9.1 Teorema de transporte 9.2 Reacción y difusión 9.3 Mecánica de medios continuos 9.4 Ecuaciones de Maxwell 9.5 Distancia de Wasserstein", " Capítulo 9 Leyes de conservación En la sección previa hablamos de cantidades conservadas, estas quieren decir funciones que permanecen constantes a lo largo de las trayectorias del sistema. Por leyes de conservación entendemos concepto distinto. En este caso la idea tiene que ver con el comportamiento colectivo de una EDO, es decir como el flujo que ella genera transporta densidades. El flujo \\(\\phi\\) generado por el campo \\(v\\) ayuda a entender la evolución puntual del sistema. Es decir, una posición inicial \\(x_0\\) se traslada por la curva \\(t\\mapsto \\phi(x_0,t)\\). Esto nos permite también describir la evolución de una colección finita de puntos. Cuando pasamos al continuo tenemos que considerar la evolución de una distribución \\(\\mu:\\mathbb R^n\\times\\mathbb R\\to\\mathbb R\\). Nos referiremos a \\(\\mu\\) y sus integrales en dominios dados de \\(\\mathbb R^n\\) como la masa. La mejor forma de entender la dinámica en este caso es apelando a la ley de conservación de masa. Fijemos una bola \\(B_r(x_0)\\), la masa contenida en ella en un tiempo dado es \\[ m(t) = \\int_{B_r(x_0)}\\mu(x,t)dx. \\] Dado que en nuestro modelo, \\(v\\) mueve a la distribución \\(\\mu\\) conservando la masa tenemos que la variación de \\(m\\) debe estar determinada por la cantidad neta que entra y sale por la esfera (Figura 9.1). Esta cantidad está determinada por el flujo \\(f = \\mu v\\) (flux18) \\[ m&#39;(t) = -\\int_{\\partial B_r(x_0)} \\frac{x-x_0}{r}\\cdot f(x,t) \\, dx \\] Es decir que \\[ \\int_{B_r(x_0)}\\partial_t\\mu(x,t)dx + \\int_{\\partial B_r(x_0)} \\frac{x-x_0}{r}\\cdot f(x,t) \\, dx = 0. \\] Figura 9.1: Ley de conservación A partir de esta identidad podemos apelar al teorema de la divergencia o usar la expansión de Taylor para llegar al siguiente resultado cuando \\(r\\to0^+\\). Procedamos con la segunda estrategia, un poco más larga pero más elemental a su vez. Tenemos que \\[\\begin{align*} \\int_{\\partial B_r(x_0)} \\frac{x-x_0}{r}\\cdot f(x,t) \\, dx &amp;= \\frac{1}{r}\\int_{\\partial B_r(x_0)} \\sum_{i=1}^n (x-x_0)_i\\left(f_i(x_0) +\\sum_{j=1}^n \\partial_j f_i(x_0)(x-x_0)_j + o(r)\\right) dx,\\\\ &amp;= \\frac{1}{r}\\sum_{i,j=1}^n \\partial_jf_i(x_0) \\int_{\\partial B_r(x_0)} (x-x_0)_i(x-x_0)_j dx + o(r^{n}),\\\\ &amp;= r^{n}\\sum_{i,j=1}^n \\partial_jf_i(x_0) \\int_{\\partial B_1} \\theta_i\\theta_jd\\theta + o(r^{n}) \\end{align*}\\] Hemos usado que la integral \\(\\int_{\\partial B_r(x_0)} (x-x_0)_idx = 0\\) dada la simetría impar del integrando. Las integrales cuadráticas también tienen simetría impar cuando \\(i\\neq j\\) y por lo tanto vuelven a cancelarse. Para el caso \\(i=j\\) en cambio tenemos que \\[ \\int_{\\partial B_1} \\theta_1^2d\\theta = \\ldots = \\int_{\\partial B_1} \\theta_n^2d\\theta = \\frac{1}{n}\\int_{\\partial B_1} (\\theta_1^2 + \\ldots+\\theta_n^2)d\\theta = \\frac{|\\partial B_1|}{n} = |B_1|. \\] En conclusión \\[ \\int_{\\partial B_r(x_0)} \\frac{x-x_0}{r}\\cdot f(x,t) \\, dx = |B_r|\\operatorname{div} f(x_0) + o(r^{n}). \\] Volviendo a la ley de conservación de masa obtenemos que dividiendo por \\(|B_r|\\) y tomando el límite \\(r\\to0^+\\) \\[ \\partial_t\\mu + \\operatorname{div} f = \\partial_t\\mu + \\operatorname{div}(\\mu v) = 0. \\] Ejercicio 9.1 Verifica que para \\(u:\\mathbb R^n\\to\\mathbb R\\) de clase \\(C^2\\), \\[ \\lim_{r\\to0^+} \\frac{1}{r^2|\\partial B_r|}\\int_{\\partial B_r} (u(x)-u(0))dx = \\frac{1}{2n}\\Delta u(0). \\] Solución 9.1 Teorema de transporte Dicho de otra forma, la ley de conservación dicta que el flujo \\(\\phi_t := \\phi(\\cdot,t)\\) generado por \\(v\\) empuja a la densidad inicial \\(\\mu_0 := \\mu(0) := \\mu(\\cdot,0)\\) en la densidad \\(\\mu_t := \\mu(t) := \\mu(\\cdot,t)\\). Para ser precisos, definimos que un mapeo \\(T:\\mathbb R^n\\to\\mathbb R^n\\) empuja19 a \\(\\mu_0\\) en \\(\\mu_1 =: T_\\#\\mu_0\\) si preserva las medidas según la siguiente identidad (Figura 9.2) \\[ \\int_{T^{-1}(B_r(y_0))} \\mu_0(x)dx = \\int_{B_r(y_0)} \\mu_1(y)dy \\qquad\\forall \\, B_r(y_0)\\subseteq\\mathbb R^n. \\] Equivalentemente, gracias a la fórmula de cambio de variables \\[ (\\mu_1\\circ T)\\det DT = \\mu_0. \\] Figura 9.2: Push-foward Nuestro objetivo en esta sección consiste así en demostrar que si \\(\\mu\\) satisface la ley de conservación \\(\\mu_t\\) y \\(\\phi\\) es el flujo generado por \\(v\\), entonces \\[ \\mu(\\phi_t(x),t)\\det(D\\phi_t) = \\mu(x,0). \\] El escenario en una dimensión es una ilustrativa aplicación de la regla de la cadena en varias variables. Sea \\(I=[a,b]\\) un intervalo arbitrario. El flujo manda este intervalo a el intervalo \\(I_t = [a(t),b(t)]\\) donde \\(a(t) = \\phi(a,t)\\) y \\(b(t) = \\phi(b,t)\\). Queremos verificar entonces que si \\(\\mu\\) satisface la ley de conservación, entonces \\[ \\int_{a(t)}^{b(t)} \\mu(x,t)dx = \\int_{a}^{b} \\mu(x,0)dx. \\] Basta ver que el lado izquierdo es constante en \\(t\\). Cuando tomamos la derivada debemos tener cuidado en que la expresión debe involucrar tanto el teorema fundamental del cálculo como también la linealidad de la integral (es decir que podemos pasar la derivada dentro de la integral). Para ser precisos definimos \\[ \\psi(\\alpha,\\beta,\\gamma) := \\int_{\\alpha}^{\\beta} \\mu(x,\\gamma)dx, \\] por lo que la expresión que buscamos diferenciar es la composición \\(\\psi(a(t),b(t),t)\\). Por la regla de la cadena seguida del teorema fundamental del cálculo \\[\\begin{align*} \\frac{d}{dt}\\int_{a(t)}^{b(t)} \\mu(x,t)dx &amp;= \\partial_\\alpha\\psi \\alpha&#39;+\\partial_\\beta\\psi \\beta&#39;+\\partial_\\gamma\\psi \\gamma&#39;,\\\\ &amp;= -\\mu(x,a(t))v(a(t),t) + \\mu(x,b(t))v(b(t),t) + \\int_{a(t)}^{b(t)} \\partial_t\\mu(x,t)dx,\\\\ &amp;= -\\mu(x,a(t))v(a(t),t) + \\mu(x,b(t))v(b(t),t) - \\int_{a(t)}^{b(t)} \\partial_x(\\mu(x,t)v(x,t))dx,\\\\ &amp;= 0. \\end{align*}\\] Esto demuestra así la propiedad geométrica anunciada. Ejercicio 9.2 Verifica que para \\(f:\\mathbb R\\to\\mathbb R\\) continua, \\[ y(t) = \\int_0^t f(s)\\sin(t-s)ds \\] es una solución particular de la ecuación \\(y&#39;&#39; + y = f\\). Solución En el caso de dimensión general procedemos a verificar que \\((\\mu_t\\circ\\phi_t)\\det D\\phi_t\\) no depende de \\(t\\). Derivamos así, \\[ \\frac{d}{dt}[(\\mu_t\\circ\\phi_t)\\det D\\phi_t] = (\\partial_t\\mu+v\\cdot D\\mu)\\det D\\phi_t + \\mu \\frac{d}{dt}\\det D\\phi_t \\] Usando ahora la identidad para la derivada del determinante \\[ (\\ln \\det M(t))&#39; = \\operatorname{tr}(M(t)^{-1}M&#39;(t)) \\] obtenemos que \\[ \\begin{aligned} \\frac{d}{dt}[(\\mu_t\\circ\\phi_t)\\det D\\phi_t] &amp;= (\\partial_t\\mu+v\\cdot D\\mu+\\mu \\operatorname{div} v)\\det D\\phi_t\\\\ &amp;= (\\partial_t\\mu+\\operatorname{div}(\\mu v))\\det D\\phi_t\\\\ &amp;= 0. \\end{aligned} \\] Tenemos así que \\[ (\\mu_t\\circ\\phi_t)\\det D\\phi_t=(\\mu_0\\circ\\phi_0)\\det D\\phi_0=\\mu_0, \\] con lo cual concluimos \\(\\mu_t = (\\phi_t)_\\#\\mu_0\\). Margen de cálculo La derivada logarítmica del determinante o el teorema de Liouville. El determinante es una función multilineal en las columnas, como tal satisface la regla del producto (misma demostración) \\[ \\frac{d}{dt}\\det (m_1(t),\\ldots,m_n(t)) = \\det (m_1&#39;(t),\\ldots,m_n(t)) + \\ldots + \\det (m_1(t),\\ldots,m_n&#39;(t)) \\] Si \\(M(t_0) = I\\) entonces \\[ \\left.\\frac{d}{dt}\\right|_{t=t_0}\\det (m_1(t),\\ldots,m_n(t)) = \\operatorname{tr} M&#39;(t_0). \\] Para \\(M(t_0)=M_0\\) invertible usamos que \\(M(t) = M_0 N(t)\\) tal que \\[ \\left.\\frac{d}{dt}\\right|_{t=t_0}\\det (m_1(t),\\ldots,m_n(t)) = \\det(M_0) \\operatorname{tr} N&#39;(t_0) = \\det(M_0) \\operatorname{tr} (M_0^{-1}M&#39;(t_0)). \\] Ejercicio 9.3 Sea \\(\\phi\\) el flujo generado por \\(v\\) y \\(E_t=\\phi_t(E)\\) donde \\(E\\subseteq\\mathbb R^n\\) tiene frontera regular. Demuestra que para \\(f:\\mathbb R^n\\times\\mathbb R\\to\\mathbb R\\) de clase \\(C^1\\) \\[ \\frac{d}{dt}\\int_{E_t}f = \\int_{E_t}\\partial_t f + \\int_{\\partial E_t}f(v\\cdot n_t), \\] donde \\(n_t\\) es el vector normal exterior de \\(E_t\\) Solución Ejercicio 9.4 Grafica \\(\\mu(\\cdot,t)\\) para \\(t\\in \\{0,0.2,0.4,0.6,0.8,1\\}\\) si \\[ \\partial_t\\mu + \\partial_x(x^2\\mu) = 0, \\qquad \\mu(x,0) = \\exp(-(x-1)^2)+5\\exp(-10(x+2)^2). \\] Solución Un modelo razonable para el tráfico en una dimensión consiste en considerar que el flujo está dado por \\(f(\\mu) = \\mu v(\\mu)\\) y que la velocidad es una función con la siguiente características: Es no-negativa y decreciente. Es decir que los agentes se mueven de izquierda a derecha y que a mayor densidad, menor la velocidad y viceversa. Si \\(\\mu\\) toma valores en el intervalo \\([0,\\mu_{max}]\\) tenemos por ejemplo el modelo logístico \\[ f(\\mu) = v_m\\mu(1-\\mu/\\mu_{max}) \\] donde \\(v_m&gt;0\\) es la velocidad máxima. La ley de conservación correspondiente se conoce como la ecuación de tráfico \\[ \\partial_t \\mu + v_m\\partial_x(\\mu(1-\\mu/\\mu_{max})) = 0 \\text{ en } \\mathbb R\\times(0,\\infty) \\] Para los siguiente ejercicios consideramos el problema de tráfico con configuración inicial \\[ \\mu(x,0) = \\begin{cases} \\mu_{max} \\text{ si } x&lt;0\\\\ 0 \\text{ si } x\\geq0 \\end{cases} \\] Esto modela el escenario donde los carros pueden estar detenidos inicialmente por un semáforo que luego cambia a tener luz verde. Ejercicio 9.5 Calcula las soluciones de las ecuaciones características. Observa que existe una región de \\(\\mathbb R\\times(0,\\infty)\\) que no pareciera estar cubierta por las trayectorias. Calcula la cantidad de tiempo que debe esperar un agente inicialmente ubicado en \\(x_0&lt;0\\) para comenzar a moverse (es decir tener velocidad positiva) luego de que el semáforo ha cambiado a verde. Solución Ejercicio 9.6 Aproxima la condición inicial por \\(\\mu_\\varepsilon(x,0) = \\mu_{max} (1/2-\\arctan(x/\\varepsilon)/\\pi)\\) (para \\(\\varepsilon&gt;0\\)) y observa que este caso el método de las características si permite definir una solución. ¿Qué sucede en el límite cuando \\(\\varepsilon\\to0^+\\)? Solución 9.2 Reacción y difusión Los modelos con reacciones son extensiones a la ecuación de conservación, en este caso se considera una función \\(f\\) que según el problema de interés se puede considerar como una fuente o sumidero para la densidad \\(\\mu\\) \\[\\partial_t \\mu + \\operatorname{div}(\\mu v)=f\\] En su forma integral \\[ \\frac{d}{dt} \\int_E \\mu=-\\int_{\\partial E}\\mu v \\cdot n+\\int_E f. \\] Nótese que esta forma integral no es más que un balance de masa en el conjunto de prueba \\(E\\). El término \\(\\int_E f\\) indica la cantidad de materia que se produce o consume en \\(E\\). Las leyes de Darcy, Fick o Fourier proponen la misma hipótesis aunque en distintos contextos (fluídos, difusiones y calor respectivamente). Cada una de ellas prescribe que el flujo es proporcional al gradiente de la concentración, es decir \\[ \\mu v=-kD \\mu \\hspace{1cm} (k &gt; 0). \\] Como tal describe el transporte de regiones de mayor a menos concentraciones de \\(\\mu\\). Junto con la ley de conservación esta describe la ecuación de difusión o calor \\[\\partial_t \\mu =k \\Delta \\mu\\] Ejemplo 9.1 Un modelo de quimiotaxis describe la evolución de una densidad de bacterias \\(\\rho\\) y una densidad química \\(\\varphi\\) que atrae dicha población. Esto puede ser representado por las siguientes ecuaciones \\[ \\begin{aligned} &amp;\\partial_t \\rho+\\operatorname{div}(\\alpha \\rho D \\varphi)=0,\\\\ &amp;\\partial_t \\varphi=\\beta \\rho-k \\varphi. \\end{aligned} \\] La población de bacterias busca moverse en la dirección donde \\(\\varphi\\) crece, es decir tiene un flujo proporcional a \\(D\\varphi\\), lo cual está reflejado en la primera ecuación. A su vez las bacterias son productoras de la misma sustancia \\(\\varphi\\) que además tiene un decaimiento exponencial, esto es lo que refleja la segunda ecuación del sistema. Ejemplo 9.2 Recordemos el modelo básico epidemiológico para dos tipos de poblaciones, suseptibles (\\(S\\)) e infectados (\\(I\\)) \\[ \\begin{aligned} S&#39;&amp;=-\\beta IS\\\\ I&#39;&amp;= \\beta IS-\\gamma I. \\end{aligned} \\] Una extensión a este modelo es considerar el efecto de las migraciones con flujos \\(v_S\\) y \\(v_I\\) respectivamente, es decir \\[ \\begin{aligned} \\begin{cases} \\partial_t S +\\operatorname{div}(Sv_s) = -\\beta IS,\\\\ \\partial_t I +\\operatorname{div}(Iv_I) = \\beta IS-\\gamma I. \\end{cases} \\end{aligned} \\] 9.3 Mecánica de medios continuos Consideremos las ecuaciones de Newton para un sistema de \\(N\\) partículas en \\(\\mathbb R^d\\) cuyas masas y posiciones denotamos por \\(m=(m_1,\\ldots,m_N) \\in \\mathbb R^N\\) y \\(x=(x_1,\\ldots,x_N) \\in \\mathbb R^{dN}\\) respectivamente \\[ mx&#39;&#39;=f(x). \\] Equivalentemente presentamos al sistema como uno de primer orden cuando tomamos las velocidades \\(v\\in \\mathbb R^{dN}\\) tales que \\[ \\begin{cases} x&#39;=v,\\\\ mv&#39;=f(x). \\end{cases} \\] De forma alternativa, si tomamos \\(y:=(x,v)\\), \\(F(y) := (v,a(x))\\) y \\(a(x):= m^{-1}f(x)\\) (aceleración), entonces \\(y&#39;=F(y)\\). Cuando \\(N\\) es muy grande es prácticamente imposible describir las trayectorias individuales del sistema. Sin embargo es posible comprender el comportamiento colectivo modelado por medio de una densidad \\(\\rho=\\rho(y,t) = \\rho(x,v,t)\\) en el espacio de configuraciones para las posiciones y velocidades. Tomaremos como hipótesis que \\(\\rho\\) además de ser una función suficientemente suave decae a cero suficientemente rápido cuando \\(|(x,v)|\\to \\infty\\). Consideraremos a su vez la distribución de partículas en espacio dada por la marginal de \\(\\rho\\) sobre las posiciones en \\(x\\in\\mathbb R^d\\), \\[ \\mu(x) = \\int_{\\mathbb R^d}\\rho(x,v)dv. \\] Sobre el conjunto donde \\(\\mu&gt;0\\) consideramos la velocidad promedio \\[ u := \\frac{1}{\\mu} \\int_{\\mathbb R^d} v\\rho dv. \\] y su tensor de covarianza \\[ T := \\frac{1}{\\mu} \\int_{\\mathbb R^d} (v-u)\\otimes(v-u) \\rho dv = \\frac{1}{\\mu} \\int_{\\mathbb R^d} (v\\otimes v) \\rho dv - u\\otimes u. \\] Observemos que \\(\\mu T\\) tiene unidades de energía, este es el tensor de tensión. 9.3.1 Ecuación de Liouville y conservación de masa Asumamos que para una partícula en \\(x\\in\\mathbb R^d\\) de masa unitaria, la aceleración queda determinada por \\(a=a(x,\\mu)\\), es decir una función que depende de la distribución de las demás partículas en espacio. Consideremos por un momento que \\(\\mu = \\int \\rho dv\\) ya está determinada, y por lo tanto la aceleración \\(a=a(x,\\mu(\\cdot,t))\\), es una función conocida de \\((x,t)\\). Dado el campo vectorial \\(F(x,v,t) = (v,a)\\), tenemos la siguiente ley de conservación para la distribución \\(\\rho\\) \\[ \\partial_t\\rho + \\operatorname{div}(\\rho F) = 0 \\] Esta se simplifica en la ecuación de Liouville usando que \\(\\operatorname{div} F = \\operatorname{div}_x v + \\operatorname{div}_v a = 0\\), \\[ \\partial_t\\rho + v\\cdot D_x\\rho + a\\cdot D_v\\rho=0. \\] Cuando integramos la ecuación de Liouville con respecto a \\(v\\) obtenemos la ley de conservación de masa \\[ 0=\\partial_t \\mu + D_x\\int_{\\mathbb R^d}\\rho vdv +a\\cdot \\int_{\\mathbb R^d} D_v \\rho dv = \\partial_t \\mu + \\operatorname{div}(\\mu u). \\] Recordemos que \\(u\\) es el promedio de las velocidades. El término de aceleración se cancela gracias al teorema de la divergencia \\[ \\int_{\\mathbb R^d} \\partial_{v_j} \\rho dv = \\int_{\\mathbb R^d} \\operatorname{div}_v(\\rho e_j) dv = 0. \\] Cuando \\(\\mu\\) es constante decimos que el material en cuestión es incompresible y la ecuación de conservación de masa se reduce a \\[ \\operatorname{div} u = 0. \\] Retomando que la aceleración \\(a=a(x,\\mu)\\) depende de \\(\\mu\\) debemos considerar que la ecuación de Liouville viene acoplada a la ley de conservación de masa \\[ \\begin{cases} \\partial_t\\rho + v\\cdot D_x\\rho + a(\\mu)\\cdot D_v\\rho=0,\\\\ \\partial_t \\mu + \\operatorname{div}(\\mu u) = 0,\\\\ u=\\frac{1}{\\mu}\\int \\rho vdv. \\end{cases} \\] Ejemplo 9.3 Asumamos ahora que las partículas interactúan a pares por medio de una misma fuerza conservativa con potencial \\(U:\\mathbb R^d\\to \\mathbb R\\) de clase \\(C^1\\). Es decir que la partícula en \\(y\\) de masa unitaria ejerce una fuerza igual a \\(-DU(x-y)\\) sobre una partícula en \\(x\\), también de masa unitaria.\\ Dada la distribución \\(\\mu\\) de partículas, tenemos que por el principio de superposición la aceleración neta sobre la posición \\(x\\) está dada según \\[ a(x) = -\\int DU(x-y)\\mu(y)dy = -(DU\\ast \\mu)(x). \\] El problema de Liouville en este caso se conoce como la ecuación de Vlasov \\[ \\partial_t \\rho + v\\cdot D_x\\rho = (DU\\ast \\mu)\\cdot D_v\\rho. \\] Ejemplo 9.4 Para \\(d=3\\) y \\(U(x) = |x|^{-1}\\) estamos modelando las fuerzas gravitatorias y \\(U\\) se conoce como el potencial de Newton. En este caso la convolución \\(U_\\mu := U\\ast \\mu\\) es la solución de la ecuación de Poisson \\(\\Delta u = -\\mu\\) en \\(\\mathbb R^3\\) con decaimiento en infinito. Tenemos así las ecuaciones de Vlasov-Poisson dadas por \\[ \\begin{cases} \\partial_t \\rho + v\\cdot D_x\\rho = D_x u \\cdot D_v\\rho,\\\\ \\Delta u = -\\int \\rho dv. \\end{cases} \\] Bajo la perspectiva Hamiltoniana de la mecánica, las ecuaciones de Newton toman la siguiente forma \\[ x&#39; = D_pH, \\qquad p&#39;= -D_xH, \\qquad H(x,p) = \\frac{1}{2m}|p|^2 + U(x). \\] Es decir que el par \\((x,p)\\) evoluciona de acuerdo al gradiente de la energía \\(H\\), pero modulado de la siguiente forma \\[ \\frac{d}{dt}\\begin{pmatrix} x\\\\p \\end{pmatrix} = \\begin{pmatrix} 0&amp;I\\\\ -I&amp;0 \\end{pmatrix}DH. \\] El lado derecho se conoce como el gradiente simpléctico de \\(H\\). Las ecuaciones de Liouville para \\(\\rho=\\rho(x,p)\\)20 pueden escribirse así en términos de \\(H\\) por medio del corchete de Poisson como \\[ \\partial_t \\rho + \\{H,\\rho\\} = 0, \\qquad \\{f,g\\} := \\begin{pmatrix} 0&amp;I\\\\ -I&amp;0 \\end{pmatrix}Df \\cdot Dg = D_xf \\cdot D_p g - D_p f D_xg. \\] Ejemplo 9.5 Cuando \\(\\{H,\\rho\\}=0\\) entonces \\(f\\) es una cantidad conservada del sistema mecánico dado que el flujo simpléctico generado por \\(H\\) deja a \\(\\rho\\) invariante. El teorema de Noether establece que esto ocurre si y solo si los flujos generados por los gradientes simplécticos de \\(H\\) y \\(\\rho\\) conmutan. Al flujo simpléctico generado por \\(\\rho\\) se le conoce así como una simetría del sistema mecánico. Ejercicio 9.7 Verifica las siguiente propiedades del corchete de Poisson las cuales dan una estructura de álgebra de Lie al espacio de funciones en \\(\\mathbb R^{2N}\\): Anti-simetría: \\(\\{f,g\\}=-\\{g,f\\}\\), Jacobi (ley del producto): \\(\\{f,\\{g,h\\}\\} = \\{\\{f,g\\},h\\}+\\{g,\\{f,h\\}\\}\\) Solución Ejercicio 9.8 Verifica las siguientes funciones son cantidades conservadas con respecto de \\(H\\) para \\(\\phi\\) y \\(\\psi\\) funciones reales de clase \\(C^1\\) arbitrarias: \\(\\rho=\\phi(H)\\), \\(\\rho = \\psi(|DH|^2)\\). Casos particulares de los ejercicios anteriores son el ensamble canónico y micro-canónico de la mecánica estadística. Solución 9.3.2 Conservación del momento Buscamos ahora obtener una ecuación que describa la dinámica de la velocidad \\(u\\). Al igual que antes seguimos asumiendo que la aceleración es independiente de \\(v\\). Cuando multiplicamos la ecuación de Liouville por \\(v\\) e integramos con respecto de \\(v\\) obtenemos la ley de conservación del momento \\[ \\begin{aligned} 0 &amp;= \\partial_t(\\mu u) + \\int_{\\mathbb R^d} (v\\cdot D_x\\rho+a\\cdot D_v\\rho)vdv,\\\\ &amp;= \\partial_t(\\mu u) + \\operatorname{div} \\int_{\\mathbb R^d} (v\\otimes v) \\rho dv + \\int_{\\mathbb R^d}(v\\otimes D_v\\rho)adv,\\\\ &amp;= \\partial_t(\\mu u) + \\operatorname{div}(\\mu(u\\otimes u) + T) - \\mu a.\\\\ \\end{aligned} \\] En la última igualdad hemos usado integración por partes para llegar a que \\(\\int (v\\otimes D_v\\rho)dv=-\\mu I\\). Fijémonos que sucede con la \\(j\\)-ésima fila de dicha matriz \\[ \\int_{\\mathbb R^d}v_jD_v\\rho dv = -\\int_{\\mathbb R^d} e_j\\rho dv = -e_j\\mu. \\] Usando la ley de conservación de masa en el término \\(\\partial_t(\\mu u)\\) obtenemos que \\[ \\begin{aligned} \\partial_t(\\mu u) &amp;= \\mu\\partial_t u - \\operatorname{div}(\\mu u)u,\\\\ &amp;= \\mu(\\partial_tu+ u\\cdot Du) - \\operatorname{div}(\\mu(u\\otimes u)) \\end{aligned} \\] Por lo tanto, la ecuación de Euler se escribe también como \\[ \\mu(\\partial_t u+u\\cdot Du) = -\\operatorname{div} T + f. \\] En distintas aplicaciones se separa a \\(T\\) como un múltiplo de la identidad y una matriz libre de traza. Definimos de esta forma la presión y el tensor de estrés (unidades de energía) respectivamente según \\[ p := \\frac{\\mu}{d} \\operatorname{tr} T, \\qquad \\sigma := \\mu T- p I. \\] por lo que llegamos a la siguiente presentación de las ecuaciones de Euler \\[ \\mu(\\partial_t u+u\\cdot Du) = -Dp - \\operatorname{div}\\sigma + f. \\] Notemos que el lado izquierdo representa el transporte de la velocidad (multiplicado por la densidad \\(\\mu\\)), mientras que en el lado derecho aparecen tres tipos de fuerzas, siendo las dos primeras internas al medio. Ejemplo 9.6 Las ecuaciones de Euler resultan cuando complementamos las ecuaciones de conservación de momento con la ley constitutiva \\(\\sigma=0\\), sin forzamento externo. Resultando así el sistema \\[ \\partial_t u+u\\cdot Du = -Dp. \\] Ejemplo 9.7 Las ecuaciones de Navier-Stokes resultan cuando complementamos las ecuaciones de conservación de momento con la ley constitutiva \\(\\sigma=\\nu Du\\) donde \\(\\nu\\) es un coeficiente de viscosidad, sin forzamento externo. Resulta así el sistema \\[ \\partial_t u+u\\cdot Du = -Dp + \\nu\\Delta u. \\] Tanto en el sistema de ecuaciones de Euler como de Navier Stokes contamos con \\(d\\) ecuaciones y \\(d+1\\) incógnitas (\\(u\\) y \\(p\\)). Estas son usualmente complementadas de dos formas distintas: Para flujos incompresibles agregamos la ecuación \\(\\operatorname{div} u=0\\). Para flujos barotrópicos compresibles tenemos la ley de conservación de masa \\(\\partial_t \\mu+\\operatorname{div}(\\mu u) = 0\\) y una ley de estado para la presión \\(p=g(\\mu)\\) de carácter termodinámico. La función \\(g\\) es una función conocida que además es positiva, creciente y convexa. Ejercicio 9.9 Ley de Bernoulli: Demuestra que si \\(u\\) la ecuación de flujo estacionario \\[ u\\cdot Du = -Dp \\] entonces la energía total \\[ E = \\frac{1}{2}|u|^2 + p \\] es constante a lo largo de las curvas integrales de \\(u\\), también conocidas como las líneas de corriente. Solución Ejercicio 9.10 Teorema de circulación de Kelvin: Sea \\(u\\) una solución de \\[ \\partial_t u + u \\cdot Du = -Dp, \\] la familia de mapeos \\(\\phi_t\\) se corresponden con el flujo generado por \\(u\\) y \\(\\gamma_t=\\phi_t(\\gamma)\\) donde \\(\\gamma:[0,1]\\to \\mathbb R^n\\) es una curva cerrada de clase \\(C^1\\). Demuestra que la circulación de \\(u\\) alrededor de \\(\\gamma_t\\) es constante, es decir \\[ \\int_{\\gamma_t} u(t) = \\int_\\gamma u(0). \\] Solución 9.3.3 Teoría cinética En el modelo propuesto por las ecuaciones de Boltzmann las partículas interactúan a pares por medio de colisiones y sin forzamento externo adicional \\[ \\partial_t \\rho + v\\cdot D_x\\rho = Q(\\rho). \\] El lado izquierdo representa el transporte inercial de la densidad de partículas \\(\\rho=\\rho(x,v,t)\\). El lado derecho es un término de reacción y representa la producción neta de partículas que resultan a partir de las colisiones: Sea \\(k(v&#39;,v)\\geq 0\\) la frecuencia con la que ocurre una transformación de la velocidad \\(v&#39;\\) a la velocidad \\(v\\) por una colisión. Es decir que \\[ Q(\\rho)(v) = \\int_{\\mathbb R^d} k(v&#39;,v)\\rho(v&#39;)dv&#39; - \\sigma(v)\\rho(v), \\qquad \\sigma(v) = \\int_{\\mathbb R^d} k(v,v&#39;)dv&#39;. \\] Si asumimos que \\(k\\) y \\(\\sigma\\) son independientes de \\(\\rho\\) conseguimos la ecuación de Boltzmann lineal. Ejemplo 9.8 La hipótesis de monocinética, quiere decir que las velocidades tienen norma constante (digamos \\(c\\)). Bajo la condición de dispersión isotrópica tenemos que \\(k\\) es constante y por lo tanto \\(\\sigma=k|\\partial B_c|\\). Llegamos así a la ecuación \\[ \\partial_t \\rho + v\\cdot D_x\\rho = k\\int_{\\partial B_c} (\\rho(v&#39;)-\\rho(v))dv&#39;. \\] Para la ecuación de Boltzmann no lineal modelamos las transiciones para pares de velocidades, es decir dos partículas con velocidades \\((v&#39;,v_*&#39;)\\) colisionan y como resultado de la interacción salen con velocidades \\(v\\) y \\(v_*\\). Dicha interacción está naturalmente restringida por las leyes de conservación de momento y energía, es decir que \\[ v&#39;+v_*&#39;=v+v_*, \\qquad |v&#39;|^2+|v_*&#39;|^2 = |v|^2+|v_*|^2. \\] Equivalentemente \\[ r:= |v&#39;- w| = |v-w|, \\qquad 2w := v+v_* = v&#39;+v_*&#39; \\] por lo que conseguimos parametrizar a las velocidades previas a la colisión \\(v&#39;\\) y \\(v_*&#39;\\), usando adicionalmente un vector unitario \\(\\theta\\) el cual caracteriza la dispersión de la colisión \\[ v&#39; = w+r\\theta, \\qquad v_*&#39;=w+r\\theta. \\] Las velocidades \\(v&#39;\\) y \\(v_*&#39;\\) aparecen con frecuencia proporcional a \\(\\rho(v&#39;)\\rho(v_*&#39;)\\), es decir que modelamos la tasa en la que ocurren colisiones de la forma \\((v&#39;,v_*&#39;) \\mapsto (v,v_*)\\) según \\[ \\rho(w+r\\theta)\\rho(w-r\\theta)B(r,\\theta) \\] Para algún núcleo \\(B\\geq0\\). En conclusión \\[ Q(\\rho)(v) = \\int_{\\mathbb R^d}\\int_{\\partial B_1} (\\rho(v&#39;)\\rho(v_*&#39;)-\\rho(v)\\rho(v_*))B(w,\\theta)d\\theta dv_*. \\] modela la tasa de producción de partículas con velocidad \\(v\\) dada la distribución de velocidades dada por \\(\\rho\\). Ejemplo 9.9 Colisiones elásticas… 9.3.4 La jerarquía de Bogoliubov-Born-Green-Kirkwood-Yvon Consideremos un gas con \\(N\\gg 1\\) partículas idénticas. La densidad \\(\\rho_1=\\rho_1(x,v):\\mathbb R^d\\times\\mathbb R^d\\to \\mathbb R\\) es la fracción de las \\(N\\) partículas que esperamos encontrar en la configuración \\((x,v)\\). Como tal asumimos que \\(\\rho_1\\) es una distribución de probabilidad sobre \\(\\mathbb R^d\\times\\mathbb R^d\\) (\\(\\rho_1\\geq0\\) y \\(\\int\\rho_1dvdx=1\\)). A partir de \\(j\\geq 2\\) tenemos \\(\\binom{N}{j}\\) formas distintas de escoger \\(j\\) partículas de las \\(N\\) posibles. Modelamos por medio de las densidades \\(\\rho_j=\\rho_j(x_1,\\ldots,x_j,v_1,\\ldots,v_j)\\) la fracción de estas \\(\\binom{N}{j}\\) combinaciones que esperamos encontrar en la configuración \\((x_1,\\ldots,x_j,v_1,\\ldots,v_j)\\). Observemos que \\(\\rho_j\\) además de ser una distribución de probabilidad sobre \\(\\mathbb R^{dj}\\times\\mathbb R^{dj}\\) también debe satisfacer la siguiente relación de simetría: Para cualquier permutación \\(\\sigma:\\{1,\\ldots,j\\}\\longleftrightarrow \\{1,\\ldots,j\\}\\) \\[ \\rho_j(x_{\\sigma(1)},\\ldots,x_{\\sigma(j)},v_{\\sigma(1)},\\ldots,v_{\\sigma(j)})=\\rho_j(x_1,\\ldots,x_j,v_1,\\ldots,v_j). \\] Una última relación de consistencia que debemos asumir en la colección de distribuciones es que para \\(j&lt;k\\leq N\\) se tiene que \\[ \\rho_j(x_1,\\ldots,x_j,v_1,\\ldots,v_j) = \\int \\rho_k(x_1,\\ldots,x_k,v_1,\\ldots,v_k)dv_{j+1}\\ldots dv_kdx_{j+1}\\ldots dx_k. \\] En particular, cada una de las distribuciones se pueden definir a partir de marginales de \\(\\rho_N\\). Esta última distribución es la jerarquía más alta y describe la dinámica de todas las partículas. Consideraremos que la dinámica de las \\(N\\) partículas están dadas por dos tipos de fuerzas: Las externas que dependen solamente de la posición y las de interacciones que dependen de las posiciones relativas de las partículas \\[ mx_j&#39;&#39; = f_j(x) = f_{ext}(x_j) + \\sum_{k\\neq j}f_{int}(x_k-x_j) \\] Tengamos en cuenta que \\(\\rho_N\\) satisface la ecuación de Liouville \\[ m\\partial_t \\rho_N + mv\\cdot D_x\\rho_N + f\\cdot D_v\\rho_N = 0. \\] Pasaremos ahora a deducir las ecuaciones para \\(\\rho_j\\) tomando marginales de la ecuación anterior. Para esto usamos que \\[ \\iint mv_k\\cdot D_{x_k}\\rho_N + f_k\\cdot D_{v_k}\\rho_N dv_kdx_k = \\iint \\operatorname{div}_{x_k,v_k} ((mv_k,f_k)\\rho_N)dv_kdx_k = 0. \\] Por lo tanto \\[ \\begin{aligned} m\\partial_t \\rho_j + mv\\cdot D_x\\rho_j + f\\cdot D_v\\rho_j &amp;= -\\sum_{k=1}^j\\sum_{l=j+1}^N \\int f_{int}(x_l-x_k) \\cdot D_{v_k} \\rho_Ndv_{j+1}\\ldots dv_kdx_{j+1}\\ldots dx_k,\\\\ &amp;= -(N-j) \\int \\sum_{k=1}^j f_{int}(y-x_k) D_{v_k} \\cdot \\rho_{j+1}(x,y,v,w) dydw, \\end{aligned} \\] donde \\((x,y) = (x_1,\\ldots,x_j,y) \\in \\mathbb R^{d(j+1)}\\) y de forma similar para \\((v,w)= (v_1,\\ldots,v_j,w) \\in \\mathbb R^{d(j+1)}\\). En el caso particular \\(j=1\\) se tiene la ecuación de transporte para una partícula bajo el forzamento externo, con un término de reacción que modela las interacciones entre pares de partículas modeladas por \\(\\rho_2\\) \\[ m\\partial_t \\rho_1 + mv\\cdot D_x\\rho_1 + f_{ext} \\cdot D_v\\rho_1 = -(N-1)\\int f_{int}(y-x) \\cdot D_v \\rho_2(x,y,v,w) dydw, \\] 9.4 Ecuaciones de Maxwell 9.5 Distancia de Wasserstein Hemos visto que las leyes de conservación nos permiten extender dinámicas puntuales a modelos continuos. La noción de velocidad dada por \\(v=x&#39;\\) encuentra así su generalización en la ecuación \\(\\partial_t\\mu + \\operatorname{div}(\\mu v) = 0\\). Para ser precisos, dado \\(\\mu:\\mathbb R^n\\times (a,b)\\to \\mathbb R\\) decimos que la familia de campos \\(v:\\mathbb R^n\\times(a,b)\\to\\mathbb R^n\\) representa su velocidad si \\[ \\partial_t \\mu + \\operatorname{div}(\\mu v) = 0. \\] Observemos que \\(v\\) no está necesariamente definida de forma única, por ejemplo \\(v\\) puede ser arbitraria fuera del soporte de \\(\\mu\\). En general, si \\(w\\) satisface \\(\\operatorname{div}(\\mu w)=0\\), entonces \\((v+w)\\) también es una velocidad para \\(\\mu\\). Otro ejemplo en tres dimensiones sucede si \\(w=D\\times z\\) donde el campo \\(z\\) tiene soporte en una región de espacio tiempo donde \\(v\\) es constante (en general podemos tomar el dual de la derivada exterior de una forma diferencial de co-dimensión dos). Esto es consistente con la noción puntual que hemos aprendido en cálculo y EDOs si identificamos los puntos con distribuciones delta. Es decir que si \\(\\mu(t) = \\delta_{x(t)}\\), entonces su velocidad está dada por cualquier familia de campos \\(v(t)\\) tales que \\(v(x(t),t) = x&#39;(t)\\). Dado el campo \\(v\\), el flujo \\(\\phi\\) que este genera, y una densidad inicial \\(\\mu_0\\) obtenemos la curva de densidades \\(\\mu_t = (\\phi_t)_\\#\\mu_0\\) para la cual \\(v\\) es su velocidad. Ejemplo 9.10 Si \\(T:\\mathbb R^n\\to\\mathbb R^n\\) es un mapeo y \\(v(x)=T(x)-x\\) entonces \\(\\phi_t(x) = (1-t)x+tT(x)\\) y \\(\\mu_t(x) = (\\phi_t)_\\#\\mu_0\\) puede verse como una interpolación horizontal entre \\(\\mu_0\\) y \\(\\mu_1 = T_\\#\\mu_0\\). Ejercicio 9.11 Calcula una velocidad de las siguientes curvas de Gaussianas en \\(\\mathbb R^n\\) en función de \\(m:\\mathbb R\\to\\mathbb R^n\\) y \\(\\sigma:\\mathbb R\\to(0,\\infty)\\): \\(\\mu(x,t) := \\exp(-|x-m(t)|^2)\\). \\(\\mu(x,t) := \\sigma(t)^{-n}\\exp(-|x|^2/\\sigma(t)^2)\\). \\(\\mu(x,t) := \\sigma(t)^{-n}\\exp(-(|x-m(t)|^2/\\sigma(t)^2)\\). Solución Así como tenemos una noción de velocidad, podemos ahora definir la energía cinética para una curva de distribuciones. Es decir que para \\(\\mu:\\mathbb R^n\\times [0,1]\\to \\mathbb R\\) \\[ K[\\mu] = \\frac{1}{2}\\int_0^1 \\int_{\\mathbb R^n} \\mu|v|^2 dx dt \\] Ejercicio 9.12 Calcula la energía cinética para cada una de las Gaussianas en el ejercicio anterior, en el intervalo \\([0,1]\\). Solución A partir de la energía cinética podemos definir las curvas geodésicas a partir de un problema de minimización. Dadas dos distribuciones \\(\\mu_0\\) y \\(\\mu_1\\) tales que \\(\\int_{\\mathbb R^n}\\mu_0dx=\\int_{\\mathbb R^n}\\mu_1dx&lt;\\infty\\), la idea es dar con una curva que minimice la energía cinética con las restricciones \\(\\mu(0)=\\mu_0\\) y \\(\\mu(1)=\\mu_1\\). La condición en las integrales es necesaria puesto que la ley de conservación preserva la masa. A partir de esta construcción definimos la métrica de Wasserstein \\[ \\mathcal W^2(\\mu_0,\\mu_1) := \\inf\\left\\{ \\int_0^1 \\int_{\\mathbb R^n} \\mu|v|^2dxdt \\ | \\ \\mu(0)=\\mu_0, \\mu(1)=\\mu_1, \\partial_t\\mu+\\operatorname{div}(\\mu v) = 0\\right\\}. \\] Ejercicio 9.13 Sea \\(\\mu:\\mathbb R^n\\times[0,1]\\to\\mathbb R\\) una curva de distribuciones, \\(\\phi:\\mathbb R^n\\times[0,1]\\to\\mathbb R^n\\) un flujo generado por la velocidad \\(v\\) para \\(\\mu\\), y sea \\(\\bar\\phi_t(x) := (1-t)x+t\\phi_1(x)\\). Demuestra que para \\(\\bar\\mu := (\\bar\\phi_t)_\\#\\mu_0\\), cuya velocidad es \\(\\bar v(x) := \\phi_1(x)-x\\) se tiene que \\[ \\int_0^1\\int_{\\mathbb R^n} \\mu|v|^2dxdt \\geq \\int_0^1\\int_{\\mathbb R^n} \\bar\\mu|\\bar v|^2dxdt = \\int_{\\mathbb R^n} |\\phi_1(x)-x|^2dx \\] Solución El ejercicio anterior es el análogo a decir que los segmentos rectos recorridos de forma uniforme disminuyen la energía cinética (Figura 9.3. Figura 9.3: Transporte por segmentos El problema que consiste en minimizar el costo cuadrático \\(\\int_{\\mathbb R^n} |T(x)-x|^2dx\\), sobre todas los mapeos \\(T\\) que mandan a \\(\\mu_0\\) en \\(\\mu_1\\) se conoce como el problema de transporte óptimo cuadrático. Es conocido que que bajo ciertas hipótesis \\(T=Du\\) para una función convexa \\(u\\) que satisface la ecuación de Monge-Ampère \\[ \\det D^2u = \\frac{\\mu_0}{\\mu_1\\circ T} \\] Ejercicio 9.14 Calcula \\(\\mathcal W^2(\\mu_0,\\mu_1)\\) para las siguientes distribuciones en \\(\\mathbb R^2\\) \\[ \\mu_0=\\delta_{(0,0)}+\\delta_{(0,1)}, \\qquad \\mu_1=\\delta_{(1,0)}+\\delta_{(1,1)}. \\] ¿Puedes generalizar este resultado para un número arbitrario de puntos? Solución Ejercicio 9.15 Calcula \\(\\mathcal W^2(\\mu_0,\\mu_1)\\) para las siguientes distribuciones en \\(\\mathbb R\\) \\[ \\mu_0=\\chi_{(0,2)}, \\qquad \\mu_1=\\chi_{(1,3)}. \\] ¿Puedes generalizar este resultado para distribuciones arbitrarias en \\(\\mathbb R\\)? Solución Ejercicio 9.16 Calcula \\(\\mathcal W^2(\\mu_0,\\mu_1)\\) para las siguientes distribuciones en \\(\\mathbb R^n\\) \\(\\mu_0(x) = \\exp(-|x-m_0|^2)\\), \\(\\mu_1(x) = \\exp(-|x-m_1|^2)\\). \\(\\mu_0(x) = \\sigma_0^{-n}\\exp(-|x|^2/\\sigma_0^2)\\), \\(\\mu_1(x) = \\sigma_1^{-n}\\exp(-|x|^2/\\sigma_1^2)\\). \\(\\mu_0(x) = \\sigma_0^{-n}\\exp(-|x-m_0|^2/\\sigma_0^2)\\), \\(\\mu_1(x) = \\sigma_1^{-n}\\exp(-|x-m_1|^2/\\sigma_1^2)\\). Solución En inglés se distinguen dos nociones de flujo. Flow se traduce como el flujo \\(\\phi\\) dado por la familia de mapeos generados por el campo \\(v\\). Flux también se traduce como flujo pero se refiere a la cantidad de masa que está atravesando una región en una dirección dada.↩︎ Push-foward↩︎ Este caso es ligeramente distinto puesto que \\(\\rho\\) es la distribución de posiciones y momento, no velocidades.↩︎ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
