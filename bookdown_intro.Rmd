--- 
title: "M√©todos de matem√°ticas aplicadas"
author: "H√©ctor Andr√©s Chang-Lara"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  This is a minimal example of using the bookdown package to write a book.
  The HTML output format for this example is bookdown::gitbook,
  set in the _output.yml file.
link-citations: yes
github-repo: rstudio/bookdown-demo
---

# Prefacio {-}

Hola

<!--chapter:end:index.Rmd-->

# (PART\*) Modelos discretos {-}

# Entramados

La siguiente figura ilustra cuatro puntos masivos unidos por tres barras de longitudes conocidas $\ell_{01}, \ell_{12}, \ell_{23}$, y masas despreciables. Los extremos etiquetados por $0$ y $3$ tienen posiciones fijas y los nodos intermedios de masas $m_1$ y $m_2$ ocupan posiciones de equilibrio. ¬øA partir de cuales ecuaciones se podr√≠an determinar las posiciones $q_i=(x_i,y_i)$ de estos nodos?

<iframe src="https://www.geogebra.org/classic/psru5cr9?embed" width="800" height="600" allowfullscreen style="border: 1px solid #e4e4e4;border-radius: 4px;" frameborder="0"></iframe>

<!--
```{python, echo=FALSE}

import matplotlib.pyplot as plt

plt.plot([0,1,3,4], [0,-2,-3,0],[0,1,3,4], [0,-2,-3,0],'ro')

ts = 14

plt.text(0.1,-0.1,'0',fontsize=ts)
plt.text(1.05,-1.9,'1',fontsize=ts)
plt.text(3.1,-3,'2',fontsize=ts)
plt.text(3.8,-0.1,'3',fontsize=ts)


plt.text(0.6,-1,'$\ell_{01}$',fontsize=ts)
plt.text(1.7,-2.6,'$\ell_{12}$',fontsize=ts)
plt.text(3.55,-1.7,'$\ell_{23}$',fontsize=ts)

plt.show()
```
-->

Antes de proceder a plantear el sistema de ecuaciones recordemos que por lo general el n√∫mero de ecuaciones e inc√≥gnitas deben ser iguales para que este est√© bien planteado, es decir que existan soluciones y que sean √∫nicas (al menos localmente). En nuestro caso tenemos cuatro inc√≥gnitas, los dos pares de coordenadas de cada nodo libre. Adem√°s debemos considerar las restricciones impuestas por las distancias entre los nodos, es decir tres ecuaciones. Hasta el momento el sistema es indeterminado, tiene m√°s inc√≥gnitas (4) que ecuaciones (3), sin embargo a√∫n nos falta incorporar la informaci√≥n del fen√≥meno de equilibrio.

$$
\begin{cases}
(x_1-0)^2 + (y_1-0)^2 = \ell_{01}^2\\
(x_1-x_2)^2 + (y_1-y_2)^2 = \ell_{12}^2\\
(x_2-3)^2 + (y_2-0)^2 = \ell_{23}^2
\end{cases}
$$

En cada nodo libre act√∫an tres fuerzas: dos tensiones y la gravedad $(= -m_ige_y)$. Por ejemplo, la tensi√≥n $T_{12}$ sobre el nodo 1 y que se produce sobre el segmento que une los nodos 1 y 2 es proporcional al vector $q_2-q_1$, es decir $T_{12} = \lambda_{12} (q_2-q_1)$ para un cierto escalar $\lambda_{12}$. Similarmente podemos razonar sobre las dem√°s interacciones, introduciendo as√≠ cuatro nuevas variables $\lambda_{10}, \lambda_{12}, \lambda_{21}$, y $\lambda_{23}$. Para que el sistema se encuentre en equilibrio, la suma de las fuerzas sobre cada nodo debe anularse, lo cual nos da igualmente cuatro ecuaciones:

$$
\begin{cases}
\lambda_{10}(x_{0}-x_{1})+\lambda_{12}(x_{2}-x_{1}) = 0\\
\lambda_{10}(y_{0}-y_{1})+\lambda_{12}(y_{2}-y_{1}) = m_{1}g\\
\lambda_{23}(x_{3}-x_{2})+\lambda_{21}(x_{1}-x_{2}) = 0\\
\lambda_{23}(y_{3}-y_{2})+\lambda_{21}(y_{1}-y_{2}) = m_{2}g
\end{cases}
$$

Pareciera que no hemos logrado mucho en t√©rminos del sistema que sigue siendo indeterminado con ocho inc√≥gnitas (2 $x$'s, 2 $y$'s y 4 $\lambda$'s) y siete ecuaciones (3 distancias y 4 balances de fuerzas). Sin embargo, la tercera ley de Newton nos dice que las interacciones entre pares de nodos guarda una simetr√≠a: toda acci√≥n produce una reacci√≥n opuesta de la misma magnitud. En nuestro modelo esto se refleja en $T_{12} = -T_{21}$, de donde obtenemos la √∫ltima ecuaci√≥n

$$
\lambda_{12}=\lambda_{21}.
$$

De hecho es m√°s sencillo eliminar una de las inc√≥gnitas ($\lambda_{21}$) que a√±adir otra ecuaci√≥n. En conclusi√≥n obtenemos el siguiente sistema con siete ecuaciones e inc√≥gnitas

$$
\begin{cases}
\lambda_{10}(x_{0}-x_{1})+\lambda_{12}(x_{2}-x_{1}) = 0\\
\lambda_{10}(y_{0}-y_{1})+\lambda_{12}(y_{2}-y_{1}) = m_{1}g\\
\lambda_{23}(x_{3}-x_{2})+\lambda_{12}(x_{1}-x_{2}) = 0\\
\lambda_{23}(y_{3}-y_{2})+\lambda_{12}(y_{1}-y_{2}) = m_{2}g\\
(x_1-0)^2 + (y_1-0)^2 = \ell_{01}^2\\
(x_1-x_2)^2 + (y_1-y_2)^2 = \ell_{12}^2\\
(x_2-3)^2 + (y_2-0)^2 = \ell_{23}^2
\end{cases}
$$

Una forma de obtener soluci√≥n a este sistema es el m√©todo de Newton. Por ejemplo, para los valores $\ell_{01}=\sqrt{5}, \ell_{12}=\sqrt{5}, \ell_{23}=\sqrt{10}, m_1=1, m_2=2, q_0=(0,0), q_3=(4,0)$ la siguiente implementaci√≥n ilustra como obtener la soluci√≥n usando Python^[**Advertencia:** El c√≥digo es sensible a las condiciones iniciales para la iteraci√≥n y no siempre converge.].

```{python}
#Librer√≠as

import matplotlib.pyplot as plt
import numpy as np
from scipy.optimize import fsolve

#Par√°metros

l01=np.sqrt(5)
l12=np.sqrt(5)
l23=np.sqrt(10)
x3,y3=4,0
m1=1
m2=2

#Sistema de ecuaciones y gr√°fica

def f(x):
  x1,y1,x2,y2,lambda01,lambda12,lambda23 = x
  f=np.zeros(7)
  f[0] = x1**2+y1**2-l01**2
  f[1] = (x2-x1)**2+(y2-y1)**2-l12**2
  f[2] = (x3-x2)**2+(y3-y2)**2-l23**2
  f[3] = -lambda01*x1+lambda12*(x2-x1)
  f[4] = -lambda01*y1+lambda12*(y2-y1)-m1
  f[5] = lambda12*(x1-x2)+lambda23*(x3-x2)
  f[6] = lambda12*(y1-y2)+lambda23*(y3-y2)-m2
  return f

r = fsolve(f,[1,-1,3,-2,0,0,0])

x1,y1=r[0],r[1]
x2,y2=r[2],r[3]

fig, ax = plt.subplots()
ax.plot([0,r[0],r[2],x3], [0,r[1],r[3],y3])
ax.plot(0,0,color='tab:blue', marker='o', label='$q_0=(0,0)$')
ax.plot(x1,y1,color='tab:orange', marker='o', label="$q_1=({:.4f},{:.4f})$".format(x1, y1))
ax.plot(x2,y2,color='tab:green', marker='o', label="$q_1=({:.4f},{:.4f})$".format(x2, y2))
ax.plot(x3,y3,color='tab:red', marker='o', label="$q_1=({},{})$".format(x3, y3))
leg = ax.legend();

plt.show()
```

Estas ideas son f√°cilmente generalizables a configuraciones lineales con m√°s nodos. En el l√≠mite se obtiene el *problema de la catenaria*. Tambi√©n podemos considerar estructuras m√°s complejas, por ejemplo un pa√±uelo sujeto por las esquinas. Para poder dar una generalizaci√≥n de estos modelos presentamos en la siguiente secci√≥n algunas nociones b√°sicas de teor√≠a de grafos. Una referencia entretenida con aplicaciones en arquitectura est√° en el siguiente enlace:


![[Dise√±ar estructuras... ¬øsin c√°lculos? ü§î La magia de la CATENARIA](https://youtu.be/KXP_kPPc7LY)](./0.jpg){width=70%}

---

::: {.exercise}
Calcula $m_2$ para que el entramado est√© en equilibrio dado que los nodos en $(0,0)$ y $(13,0)$ est√°n fijos

![](./eje_1.png){width=70%}
:::

<details>
  <summary>Soluci√≥n</summary>
Las fuerzas en el nodo $1$ est√°n dadas por
$$
\begin{cases}
5\lambda_{01}=6\lambda_{12},\\
8\lambda_{01}+\lambda_{12}=g
\end{cases} \qquad\Rightarrow\qquad \lambda_{01}=\frac{6g}{53}, \lambda_{12}=\frac{5g}{53}
$$
Las fuerzas en el nodo $2$ est√°n dadas por
$$
\begin{cases}
6\lambda_{12}=2\lambda_{23},\\
-\lambda_{12}+7\lambda_{23}=m_2g
\end{cases} \qquad\Rightarrow\qquad \lambda_{23}=\frac{15g}{53}, m_2=\frac{100}{53}.
$$
</details>

---

::: {.exercise}
Demuestra que si un dado entramado como en la figura, y con extremos en el eje horizontal, est√° en equilibro, entonces su correspondiente reflexi√≥n en el eje horizontal tambi√©n est√° en equilibrio. ¬øSer√° posible generalizar este principio a un entramado general?

![](./eje2.png){width=70%} 
:::

<details>
  <summary>Soluci√≥n</summary>
Denotamos por $\lambda_i=\lambda_{i,i-1} = -\lambda_{i-1,i}$.

En cada nodo del entramado original se tiene el balance de fuerzas est√° dado por
$$
\begin{cases}
(x_i-x_{i-1})\lambda_i=(x_{i+1}-x_{i})\lambda_{i+1},\\
(y_{i-1}-y_{i})\lambda_i+(y_{i+1}-y_{i})\lambda_{i+1}=m_ig
\end{cases}
$$
Al tomar la reflexi√≥n en el eje horizontal las coordenadas de los nodos pasan a ser $(x_i,y_i)\mapsto (x_i',y_i') = (x_i,-y_i)$. Gracias a las relaciones previas, se observa que estas coordenadas satisfacen igualmente las ecuaciones de balance de fuerzas cuando igualmente reemplazamos $\lambda_i\mapsto \lambda_i' =-\lambda_i$
$$
\begin{cases}
(x_i'-x_{i-1}')\lambda_i'=(x_{i+1}'-x_{i}')\lambda_{i+1}',\\
(y_{i-1}'-y_{i}')\lambda_i'+(y_{i+1}'-y_{i}')\lambda_{i+1}'=m_ig.
\end{cases}
$$
Este principio se generaliza a un entramado general con una notaci√≥n adecuada.
</details>

<!--chapter:end:01-entramado.Rmd-->

# C√°lculo discreto

Una grafo dirigido $G = (V,E)$ consiste de un conjunto de v√©rtices $V$, tambi√©n llamados nodos, y un conjunto de aristas $E \subseteq V^2$, es decir pares ordenados de $V$.

Dado $e = (a,b)\in E$, denotamos por $e_-=a$ y $e_+=b$ los nodos de partida y llegada de $e$ respectivamente y decimos que $e$ est√° orientado del nodo de salida $a$ al nodo de llegada $b$.

En general trabajaremos con grafos con aristas simples, es decir que a lo sumo existe una arista que conecta dos v√©rtices en cualquier orientaci√≥n. Sin embargo, cuando $e=(a,b)\in E$ podr√≠amos hacer referencia a la arista $-e:=(b,a)$ como la arista $e$ pero con el sentido opuesto. Denotaremos $-E = \{-e \in V^2:e\in E\}$.

Finalmente, podemos considerar tambi√©n conjuntos de aristas no orientadas en cuyo caso decimos que el grafo es no dirigido.

---

::: {.exercise}
Dibuja el grafo $G=(V,E)$ para
$$
V = \{1,2,3,a,b,c\}, \qquad E = \{(1,a),(1,b),(1,c),(2,a),(2,b),(2,c),(3,a),(3,b),(3,c)\}.
$$
:::

<details>
  <summary>Soluci√≥n</summary>

<iframe src="https://www.geogebra.org/classic/xtjh7atb?embed" width="800" height="600" allowfullscreen style="border: 1px solid #e4e4e4;border-radius: 4px;" frameborder="0"></iframe>
</details>

---

Las redes el√©ctricas son uno de los modelos m√°s conocidos que se pueden formular en t√©rminos de grafos. Sobre el grafo podemos caracterizar por ejemplo el potencial o voltaje como una funci√≥n $u:V\to \mathbb R$ y la corriente como una funci√≥n $i:E\to \mathbb R$. Siguiendo un poco la nomenclatura que sugiere este modelo, distinguimos dos tipos de funciones en $G$:

1. **Potencial:** Es una funci√≥n sobre el conjunto de v√©rtices $u: V \to \mathbb R$.
1. **Flujo:** Es una funci√≥n sobre el conjunto de aristas $f: E \to \mathbb R$.

En algunos casos tambi√©n podr√≠amos considerar que dichas funciones tomen valores en $\mathbb C$, $\mathbb R^n$ √≥ $\mathbb C^n$.

Tambi√©n denominamos como flujos a funciones que est√°n definidas en $E\cup -E$, es decir que consideran ambas orientaciones de las aristas. Decimos que $f:E\cup -E\to\mathbb R$ es **par** cuando no depende de la orientaci√≥n $f(-e) = f(e)$, y decimos que **impar** si en cambio $f(-e) = -f(e)$. Una funci√≥n $f:E\to\mathbb R$ en un grafo no dirigido es equivalente a una funci√≥n par en el mismo grafo y con cualquier orientaci√≥n sobre las aristas.
 
---

:::{.example}
En el modelo de [entramados](#entramados) en la secci√≥n anterior, el grafo no dirigido $G=(V,E)$ con $V = \{0,1,2,3\}$ y $E=\{\{0,1\},\{1,2\},\{2,3\}\}$ nos proporciona la informaci√≥n sobre cuales nodos est√°n conectados entre si. Las posiciones de los nodos se caracterizan por $q:V\to \mathbb R^2$ y las longitudes de los enlaces est√°n determinadas por $\ell:E\to\mathbb R$.

![](./eje_1.png){width=70%}

Para modelar las tensiones es conveniente considerar el grafo dirigido $G=(V,E')$ de alguna forma arbitraria, quiz√°s $E'=\{(0,1),(1,2),(2,3)\}$. De esta forma contamos con la funci√≥n par $\lambda:E'\to\mathbb R$ y la funci√≥n impar $T: E' \to \mathbb R^2$ tales que
$$
T(e) = \lambda(e)(q(e_+)-q(e_-))
$$
es la tensi√≥n sobre el nodo $e_-$ a lo largo de $e$. A su vez y gracias a la ley de acci√≥n y reacci√≥n, $T(-e) = -T(e)$ es la tensi√≥n sobre el nodo $e_+$ a lo largo de $e$ pero en la orientaci√≥n opuesta, es decir $-e$.
:::

---

:::{.example}
Un potencial $u:V\to\mathbb R$ sobre una red de resistencia genera una corriente $i:E\to \mathbb R$ que modelamos usando la ley de Ohm para una dada resistencia $R:E\to (0,\infty)$ (funci√≥n par). Esto quiere decir que la corriente $i(e)$ que atraviesa una arista $e = (e_-,e_+)$ es proporcional a la diferencia de los potenciales en los extremos de la arista
$$
i(e) = \frac{u(e_+) - u(e_-)}{R(e)}, \qquad R(e) >0: \text{ Resistencia.}
$$
:::

---

## Gradiente

Tanto en la construcci√≥n de las tensiones $T$, como en la de la corriente el√©ctrica $i$, estamos considerando la variaci√≥n de una dada funci√≥n (las posiciones $q$ √≥ el potencial $u$) a lo largo de una arista dada. Esto es una versi√≥n discreta de la derivada direccional. En este caso requerimos que el grafo sea orientado.

:::{.definition}
Dado potencial $u:V\to\mathbb R$ sobre un grafo dirigido $G=(V,E)$, definimos el gradiente $Du: E\cup -E \to \mathbb R$ tal que
$$
Du(e) = u(e_{+})-u(e_{-}).
$$
:::

En particular, el gradiente es una funci√≥n impar.

---

:::{.exercise}
Calcula el gradiente de la funci√≥n dada en los v√©rtices del siguiente grafo


![](./gradeje.png){width=70%}
:::

<details>
  <summary>Soluci√≥n</summary>
![](./gradsol.png){width=70%}
</details>

---

:::{.exercise}
Verifica que el gradiente satisface la identidad de Leibniz
$$
D(u_1u_2) = u_1^+ Du_2 + u_2^-Du_1
$$
donde $u^\pm:E\to\mathbb R$ se define a partir de $u:V\to\mathbb R$ como $u^\pm(e) = u(e_\pm)$.
:::

<details>
  <summary>Soluci√≥n</summary>
  $$
  \begin{aligned}
  D(u_1u_2)(e) &= u_1(e_+)u_2(e_+) - u_1(e_-)u_2(e_-),\\
               &= u_1(e_+)u_2(e_+) - u_1(e_+)u_2(e_-) + u_1(e_+)u_2(e_-) - u_1(e_-)u_2(e_-),\\
               &= u_1(e_+)(u_2(e_+)-u_2(e_-)) + u_2(e_-)(u_1(e_+)-u_1(e_-)),\\
               &= u_1(e_+)Du_2(e) + u_2(e_-)Du_1(e),\\
               &= (u_1^+Du_2 + u_2^-Du_1)(e).
  \end{aligned}
  $$
</details>
---

### Ley de ciclos

No toda funci√≥n (impar) $f:E\cup -E \to \mathbb R$ es necesariamente un gradiente. Una condici√≥n necesaria y suficiente es la **ley de ciclos**. Para poder enunciar esta ley es conveniente dar algunas definiciones previas para un dado grafo dirigido $G=(V,E)$.

:::{.definition}
Un **camino no orientado** es una sucesi√≥n de v√©rtices $x_0,x_1, \dots, x_n \in V$ tal que $(x_j,x_{j+1}) \in E\cup -E$ para todo $j\in\{0,1,\ldots,(n-1)\}$. Se dice que el camino es un **ciclo** si adem√°s $x_n=x_0$.
:::

:::{.definition}
Una **componente conexa** de $G$ es un subconjunto $V'\subseteq V$ tal que:
  
- Todos los v√©rtices en $V'$ est√°n conectados entre si por alg√∫n camino.
    
- Ning√∫n v√©rtice de $V'$ est√° conectado con ning√∫n v√©rtice de $V\setminus V'$.

Decimos que $G$ es **conexo** si tiene una √∫nica componente conexa.
:::

:::{.theorem name="Ley de ciclos"}
Sea $G=(V,E)$ un grafo dirigido finito. Una funci√≥n impar $f:E\cup -E\to\mathbb R$ es igual al gradiente de una funci√≥n $u:V\to \mathbb R$ si y solo si para todo ciclo $x_0,x_1, \dots, x_n=x_0$ se tiene que
$$
\sum_{j=0}^{n-1} f(x_j,x_{j+1}) = 0.
$$
:::

:::{.proof}
Por un lado es f√°cil verificar la identidad para flujos gradientes usando la propiedad telesc√≥pica. Dado un ciclo $x_0,x_1, \dots, x_n=x_0$
$$
\sum_{j=0}^{n-1} Du(x_j,x_{j+1}) = \sum_{j=0}^{n-1} (u(x_{j+1})-u(x_j)) = u(x_n)-u(x_0)=0.
$$

Podemos construir $u:V'\to \mathbb R$ sobre cada una de las componentes conexas de $G$ de la siguiente forma: Fijemos $x_0 \in V'$ y definimos
$$
u(x) := \sum_{j=0}^{n-1} f(x_j,x_{j+1})
$$
donde $x_0,x_1, \dots, x_n=x$ es un camino no orientado que conecta $x_0$ con $x\in V'$.

La hip√≥tesis dada por la ley de ciclos garantiza que esta construcci√≥n no depende del camino escogido, es decir que est√° bien definida sin posible ambig√ºedad: Dados dos caminos $x_0,\ldots,x_n=x$ y $y_0=x_0,\ldots,y_m=x$ se tiene que $z_0=x_0,\ldots,z_n=x_n,z_{n+1}=y_{m-1},\ldots,z_{n+m}=y_0$ es un ciclo y por lo tanto
$$
0 = \sum_{j=0}^{n+m-1} f(z_j,z_{j+1}) = \sum_{j=0}^{n-1} f(x_j,x_{j+1}) - \sum_{j=0}^{m-1} f(y_j,y_{j+1}).
$$

Veamos finalmente que $Du = f$. Dado $e\in E$ con $e_\pm$ en la misma componente que $x_0$, tomamos un camino $x_0,x_1,\ldots, x_n=e_-$ de $x_0$ a $e_-$ y luego a√±adimos $x_{n+1}=e_+$ para formar un camino de $x_0$ a $e_+$. Por lo tanto
$$
Du(e) = u(e_+)-u(e_-) = \sum_{j=0}^{n} f(x_j,x_{j+1})-\sum_{j=0}^{n-1} f(x_j,x_{j+1}) = f(e),
$$
con lo cual conclu√≠mos la demostraci√≥n.
:::

Este argumento nos permite apreciar que $u$ est√° √∫nicamente determinado salvo potenciales constantes en cada componente conexa de $G$. Las constantes son los valores arbitrarios que dar√≠amos a $u$ sobre el nodo $x_0$, que en nuestra demostraci√≥n fue cero. En otras palabras, la nulidad del gradiente captura el n√∫mero de compnentes conexas del grafo.

---

:::{.exercise}
Calcula los potenciales que generan el flujo dado en la siguiente figura

![](./eje_3.png){width=70%}
:::

<details>
  <summary>Soluci√≥n</summary>
  
  El flujo satisface la ley de ciclos. Por ejemplo en el tri√°ngulo de la izquierda la suma correspondiente es $-3+1+2=0$ y de igual forma podemos verificar en el tri√°ngulo de la derecha ($2+(-1)+(-1)=0$) o en el cuadrado exterior ($(-3)+1-(-1)-(-1)=0$). Si tomamos $u(A)=0$ sin p√©rdida de generalidad tenemos que
  $$
  \begin{cases}
  u(B) = 1 + u(A) = 1,\\
  u(C) = 3 + u(A) = 3,\\
  u(D) = -1 + u(C) = 2.
  \end{cases}
  $$
  Verificamos adem√°s que con estos valores se obtiene el gradiente prescrito
  $$
  \begin{cases}
  Du(AB) = u(B)-u(A) = 1-0 = 1,\\
  Du(BC) = u(C)-u(B) = 3-1 = 2,\\
  Du(CA) = u(A)-u(C) = 0-3 = -3,\\
  Du(CD) = u(D)-u(C) = 2-3 = -1,\\
  Du(DB) = u(B)-u(D) = 1-2 = -1.
  \end{cases}
  $$
  En general, $u$ tiene el gradiente prescrito si y solo si
  $$
  u(A) = C, \qquad u(B) = 1+C, \qquad u(C) = 3+C, \qquad u(D)=2+C.
  $$
</details>

---

<details>
  <summary>**Margen de c√°lculo:** El lema de Poincar√©</summary>
Como ya el lector habr√° notado, estas construcciones y propiedades encuentran paralelos en c√°lculo multivariable, y de hecho las demostraciones reproducen las mismas ideas: Los caminos son curvas, los ciclos son lazos o curvas cerradas y la expresi√≥n $\sum_{j=0}^{n-1} f(x_j,x_{j+1})$ es an√°loga a la integral de l√≠nea o el trabajo de un campo vectorial sobre una curva.

El resultado que acabamos de enunciar se conoce como el **Lema de Poincar√© global**. Recordemos su enunciado junto con el resultado local.

**Lema de Poincar√© (global):** Un campo vectorial $f \in C(\Omega\subseteq\mathbb R^n\to\mathbb R^n)$ es el gradiente de alg√∫n potencial $u\in C^1(\Omega\to\mathbb R)$ si y s√≥lo si para cualquier curva cerrada $\gamma \in C^1([a,b]\to\Omega)$ (i.e. $\gamma(b)=\gamma(a)$) se tiene que el trabajo que ejerce $f$ sobre la curva $\gamma$ se anula
$$
\int_\gamma f = \int_a^b f(\gamma(t))\cdot \gamma'(t)dt = 0.
$$

**Lema de Poincar√© (local):** Si $\Omega\subseteq\mathbb R^n$ es simplemente conexo^[es decir que cualquier ciclo puede ser deformado continuamente a un punto. Por ejemplo, si $n=2$ dice que $\Omega$ no tiene hoyos.] entonces $f \in C^1(\Omega\to\mathbb R^n)$ es un gradiente si y solo si $\partial_if_j = \partial_jf_i$.
</details>

## Divergencia

Otro operador diferencial que tiene su an√°logo en grafos es la divergencia. Heur√≠sticamente, la divergencia de un campo vectorial mide cuando es positiva la cantidad de flujo que sale o diverge del nodo dado, mientras que cuando es negativa mide la cantidad de flujo que recibe o converge en el nodo.

:::{.definition}
Dado $f: E \to \mathbb R$ denotamos por $\operatorname{div} f:V\to \mathbb R$ a la divergencia de $f$ donde
$$
\operatorname{div} f(v) = \sum_{e_-=v}f(e)-\sum_{e_+=v}f(e)
$$
:::

---

:::{.example}
En la siguiente figura se calcul√≥ la divergencia de la funci√≥n dada en las aristas

![](./div.png){width=70%}
:::

---

:::{.example}
Las ecuaciones de balance para un entramado se escriben en t√©rminos de la divergencia de las tensiones sobre los nodos libres como
$$
\operatorname{div} T = -mge_y
$$
:::

---

:::{.example}
La ley de Kirchhoff dice que en en un nodo que no est√° conectado a la bater√≠a, la corriente que entra y sale de este son iguales. En t√©rminos de la divergencia quiere decir que
$$
\operatorname{div} i = 0
$$
:::

---

### F√≥rmula de la divergencia

Al igual que antes, podr√≠amos preguntarnos si todo potencial es la divergencia de alg√∫n campo. Esto no es necesariamente cierto, la divergencia satisface la **ley de conservaci√≥n**, an√°loga al teorema de la divergencia. Un caso particular ilustrativo de esta ley postula que la suma de la divergencia sobre un grafo finito es igual a cero
$$
\sum_{v\in V} \operatorname{div} f(v) = 0.
$$
Una vez m√°s la justificaci√≥n se basa en una propiedad telesc√≥pica para la suma: Cada arista aparece dos veces en la suma con signos opuestos dependiendo si se considera su v√©rtice origen o de llegada.

Para dar una versi√≥n discreta del teorema de la divergencia consideramos el campo normal exterior $n_\Omega:E\to \mathbb R$ tal que
$$
n_\Omega(e) = \begin{cases}
+1 \text{ si $e_-\in \Omega$ y $e_+\in V\setminus \Omega$},\\
-1 \text{ si $e_-\in V\setminus \Omega$ y $e_+\in \Omega$},\\
0 \text{ en cualquier otro caso}
\end{cases}
$$
en este caso el signo de $n_\Omega(e)$ indica cuando la arista orientada conecta a $\Omega$ con su complemento o viceversa.

---

:::{.exercise}
El campo normal es el gradiente de una dada funci√≥n ¬øCu√°l?.
:::

<details>
  <summary>Soluci√≥n</summary>
  $n_\Omega = D1_{V\setminus \Omega}$ donde
  $$
  1_{V\setminus \Omega}(x) = \begin{cases}
  1 \text{ si } x\in V\setminus \Omega,\\
  0 \text{ en cualquier otro caso}.
  \end{cases}
  $$
</details>

---

:::{.theorem name="F√≥rmula de la divergencia"}
Sea $G=(V,E)$ un grafo dirigido finito. La divergencia de $f:E\to \mathbb R$ verifica
\begin{equation}
\sum_{v\in \Omega} \operatorname{div} f(v) = \sum_{e\in E} f(e)n_\Omega(e)
(\#eq:div)
\end{equation}
:::

De hecho la suma en el lado derecho ocurre en realidad sobre un subconjunto de aristas que podemos definir como el borde de $\partial\Omega$
$$
\partial \Omega := \{e\in E\ | \ \{e_+,e_-\} \cap \Omega \neq \emptyset \text{ y } \{e_+,e_-\} \cap E\setminus \Omega \neq \emptyset\}
$$
es decir las aristas que conectan $\Omega$ con su complemento en cualquier orientaci√≥n.

La cantidad $f(e)n_\Omega(e)$ es positiva cuando $e_-\in \Omega$, $e_+\in V\setminus \Omega$ y $f(e)>0$; o bien cuando $e_-\in V\setminus \Omega$, $e_+\in \Omega$ y $f(e)<0$. En cualquier caso, $f(e)n_\Omega(e)$ se interpreta como la cantidad de masa que escapa de $\Omega$ por medio de $e$. Un razonamiento similar se d√° cuando $f(e)n_\Omega(e)$ es negativo para la masa que entra. El balance total nos dice que la masa que se produce o absorbe en $\Omega$ se puede medir de dos formas, sumando las divergencias en $\Omega$ u observando las contribuciones que escapan o entran por las aristas que conectan a $\Omega$ con su complemento $V\setminus \Omega$ en cualquier orientaci√≥n.

:::{.proof}
Sean $1_\pm:V\times E\to \mathbb R$ definidas seg√∫n
$$
1_\pm(v,e) := \begin{cases}
1 \text{ si } e_\pm = v,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$
En particular usaremos que
$$
\sum_{v\in \Omega} 1_\pm(v,e) = \begin{cases}
1 \text{ si } e_\pm \in \Omega,\\
0 \text{ encualquier otro caso}
\end{cases}
$$

Tenemos as√≠ que
$$
\begin{aligned}
\sum_{v\in \Omega} \operatorname{div} f(v) &= \sum_{v\in \Omega} \sum_{e_-=v} f(e) - \sum_{v\in \Omega} \sum_{e_+=v} f(e),\\
&= \sum_{v\in \Omega} \sum_{e \in E} f(e)1_-(v,e) - \sum_{v\in \Omega} \sum_{e \in E} f(e)1_+(v,e),\\
&= \sum_{e \in E} \sum_{v\in \Omega}f(e)1_-(v,e) - \sum_{e \in E} \sum_{v\in \Omega}f(e)1_+(v,e),\\
&= \sum_{e_-\in \Omega} f(e) -\sum_{e_+\in \Omega} f(e),\\
&= \sum_{\substack{e_-\in \Omega\\e_+\in V\setminus \Omega}} f(e) + \sum_{e_-, e_+\in \Omega} f(e) - \sum_{\substack{e_+\in \Omega\\e_-\in V\setminus \Omega}} f(e) - \sum_{e_-, e_+\in \Omega} f(e),\\
&= \sum_{\substack{e_-\in \Omega\\e_+\in V\setminus \Omega}} f(e) - \sum_{\substack{e_+\in \Omega\\e_-\in V\setminus \Omega}} f(e)
\end{aligned}
$$

Esta √∫ltima expresi√≥n es por definici√≥n de $n_\Omega$ igual a
$$
\sum_{e\in E} f(e)n_\Omega(e),
$$
con lo cual se concluye la demostraci√≥n.
:::

<details>
  <summary>**Margen de c√°lculo:** El teorema de la divergencia</summary>
  El teorema de la divergencia nos dice que dado un subconjunto $\Omega \subset\mathbb R^n$ con frontera localmente de clase $C^1$ a trozos, y campo $v\in C^1(\overline{\Omega}\to\mathbb R^n)$, entonces
$$
\int_\Omega \operatorname{div} v = \int_{\partial \Omega} v\cdot n
$$
donde $n$ es el vector normal exterior a $\Omega$.

El lado derecho integra el flujo que escapa o entra en $\Omega$ a trav√©s de su borde. En concreto, si en un punto dado del borde  $v\cdot n >0$ entonces $v$ apunta en la direcci√≥n de $n$ y el flujo escapa con una tasa igual a $v\cdot n$,  si en cambio  $v\cdot n < 0$ el flujo estar√≠a entrando, y si $v\cdot n=0$ se tiene que $v$ es tangente y el flujo apenas roza la superficie. El lado izquierdo de la expresi√≥n es una integral sobre $\Omega$ que representa la producci√≥n/absorci√≥n de flujo por el campo $v$.
</details>

### Lema de Poincar√© para la divergencia

:::{.theorem}
Sea $G=(V,E)$ un grafo dirigido finito y conexo. Para cualquier $\mu:V\to\mathbb R$ tal que
$$
\sum_{x\in V}\mu(x)=0
$$
existe por lo menos una soluci√≥n $f:E\to\mathbb R$ de
$$
\operatorname{div} f = \mu.
$$
:::

:::{.proof}
Tomemos un nodo arbitrario $x_0\in V$ y consideremos inductivamente caminos no orientados que vayan conectando a $x_0$ con cada uno de los nodos restantes y de tal forma que nunca se formen ciclos en esta construcci√≥n. Es decir, estamos proponiendo un **√°rbol generador** del grafo con ra√≠z en el nodo $x_0$, en otras palabras un sub-grafo $T_0 := (V_0=V,E_0\subseteq E)$ libre de ciclos y conexo. Fijamos $f=0$ en las aristas de $E\setminus E_0$ y en los dem√°s ajustaremos $f$ para que satisfaga la ecuaci√≥n dada.

En la siguiente construcci√≥n estaremos definiendo a $f:E\cup-E\to \mathbb R$ como una funci√≥n impar.

La idea consiste en ir podando las ramas del √°rbol a medida que asignamos $f$ convenientemente. Si $|V_0|=1$ el problema ser√≠a trivial, asumamos as√≠ que $|V_0|>1$. En el primer paso tomamos una hoja de $T_0$, es decir un $x\in V_0$ con un √∫nico nodo $y \sim_{T_0} x$. Declaramos as√≠ $f(x,y) = \mu(x)$ de modo que se tiene que $\operatorname{div}f(x) = \mu(x)$ ($f$ es distinto de cero en a lo sumo una arista en esta suma). Una vez declarado $f$ en la arista $e=(x,y)$ procedemos a considerar el √°rbol $T_1 = (V_0\setminus \{x\},E_1:=E_0\setminus \{(x,y),(y,x)\})$.

Asumamos de forma inductiva que luego de $k$ pasos contamos con los √°rboles
$$
T_k = (V_k,E_k) \subset T_{k-1} := (V_{k-1},E_{k-1}) \subset \ldots \subset T_0
$$
tales que $f$ ha sido definida en $E\setminus E_k$ tal que $\operatorname{div}f=\mu$ se satisface sobre $V\setminus V_k$. Para el siguiente paso tomamos una hoja $x \in V_k$ y fijamos $f$ sobre la (√∫nica) arista $(x,y) \in E_k\cup-E_k$ de modo que la ecuaci√≥n ahora se satisfaga sobre el nodo $x$. Para el siguiente paso podamos a $x$ de $T_k$, es decir que
$$
T_{k+1}:= (V_{k+1}=V_k\setminus\{x\},E_{k+1}:=E_k\setminus\{(x,y),(y,x)\}).
$$
Claramente esta construcci√≥n garantiza que las hip√≥tesis inductivas se siguen cumpliendo en el siguiente paso.

Una vez terminado este algoritmo garantizamos que $\operatorname{div} f=\mu$ se cumple en $V\setminus \{x_0\}$ (la ra√≠z del √°rbol). Como √∫ltima observaci√≥n tenemos que la ecuaci√≥n tambi√©n debe cumplirse en $x_0$ gracias a que $\sum_{x\in V} \operatorname{div} f(x)=\sum_{x\in V} \mu(x)=0$.
:::

Notemos que si $x_0,\ldots,x_k=x_0$ es un dado ciclo del grafo, entonces si tomamos $f=1$ en las aristas del ciclo y cero por fuera de estas, obtenemos una soluci√≥n de $\operatorname{div} f=0$. De hecho, todas las soluciones homog√©neas se obtienen por superposiciones de este ejemplo. El n√∫cleo de la divergencia es un espacio vectorial generado por los ciclos independientes del grafo y su dimensi√≥n es un importante invariante topol√≥gico conocido como el **primer n√∫mero de Betti**.

:::{.exercise}
Calcula los flujos $f:E\to \mathbb R$ tal que $\operatorname{div} f=\mu$ para la funci√≥n $\mu$ dada sobre los nodos del siguiente grafo.

![](./div2.png){width=70%}
:::

<details>
  <summary>Soluci√≥n</summary>
  Verificamos primero que la suma de los valores en los nodos se anula.
  
  Para calcular una soluci√≥n particular tomamos el √°rbol generador con aristas $a$, $b$, $-e$ y definimos as√≠
  $$
  f(c)=f(d)=0, \qquad f(a)=1, \qquad f(e)=2, \qquad f(b)=0
  $$
  el cual verifica f√°cilmente la ecuaci√≥n de divergencia esperada en todos los nodos.
  
  Cualquier otra soluci√≥n se obtiene como la superposici√≥n de la soluci√≥n previa con las del sistema homog√©neo
  $$
  \begin{cases}
  f(a)+f(b)-f(e)=0,\\
  -f(a)+f(c)=0,\\
  -f(b)+f(d)=0,\\
  -f(c)-f(d)+f(e)=0.
  \end{cases}
  $$
  Dos soluciones linealmente independientes se obtienen por ejemplo de los ciclos $a,c,e$ y $b,d,e$ respectivamente
  $$
  \begin{aligned}
  &f(a)=f(c)=f(e)=1,\qquad f(b)=f(d)=0,\\
  &f(a)=f(c)=0, \qquad f(b)=f(d)=f(e)=1.
  \end{aligned}
  $$
  Si usamos la reducci√≥n de Gauss-Jordan podemos verificar que esta es adem√°s una base de las soluciones homog√©neas.
</details>

---

## Integraci√≥n por partes

En esta secci√≥n identificamos a las funciones $u:V\to \mathbb R$ con vectores de $\mathbb R^{|V|}$. Igualmente identificamos a las funciones $f:E\to \mathbb R$ con vectores de $\mathbb R^{|E|}$. Eventualmente tambi√©n podr√≠amos considerar funciones complejas.

El gradiente $D:\mathbb R^{|V|}\to\mathbb R^{|E|}$ se representa as√≠ por la matriz $(D_{e,x}) \in \mathbb R^{|E|\times |V|}$ tal que
$$
D_{e,x} = \begin{cases}
1 \text{ si } x=e_+,\\
-1 \text{ si } x=e_-,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$
Mientras que la divergencia $\operatorname{div}:\mathbb R^{|E|}\to\mathbb R^{|V|}$ se representa por la matriz $(\operatorname{div}_{x,e}) \in \mathbb R^{M\times N}$ tal que
$$
\operatorname{div}_{x,e} = \begin{cases}
-1 \text{ si } e_+=x,\\
1 \text{ si } e_-=x,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$
Descubrimos de esta forma que $D^T = -\operatorname{div}$ o equivalentemente la f√≥rmula de **integraci√≥n por partes**
$$
\sum_{e\in E} (fDu)(e) = f\cdot Du = -u\cdot \operatorname{div} f = -\sum_{x\in V} (u\operatorname{div} f)(x).
$$

---

:::{.exercise}

Calcula las matrices asociadas con el gradiente y la divergencia para el siguiente grafo

![](./k3.png){width=70%}
:::

<details>
  <summary>Soluci√≥n</summary>
  $$
  D = \begin{pmatrix}
  -1 &  1 &  0 &  0\\
   0 & -1 &  1 &  0\\
   1 &  0 & -1 &  0\\
  -1 &  0 &  0 &  1\\
   0 &  0 &  1 & -1
  \end{pmatrix} \qquad \operatorname{div} = -D^T = \begin{pmatrix}
  1 & 0 & -1 & 1 & 0\\
  -1 & 1 & 0 & 0 & 0\\
  0 & -1 & 1 & 0 & -1\\
  0 & 0 & 0 & -1 & 1
  \end{pmatrix}.
  $$
</details>

---

:::{.exercise}
Demuestra la f√≥rmula de integraci√≥n por partes sobre un dominio $\Omega \subseteq V$
\begin{equation}
\sum_{\Omega} u\operatorname{div}f = \sum_{E} u^-fn_\Omega - \sum_{e_+\in \Omega} fDu.
(\#eq:ipv)
\end{equation}
En particular, si $u=1$ recuperamos la f√≥rmula de la divergencia \@ref(eq:div).
:::

<details>
  <summary>Soluci√≥n</summary>
  Basta con usar que $Dv\cdot f = - v\cdot \operatorname{div} f$ para $v := u 1_{\Omega}$.
</details>

---

<details>
  <summary>**Margen de c√°lculo:** Integraci√≥n por partes</summary>
La f√≥rmula de integraci√≥n por partes nos dice que dado un subconjunto $\Omega \subset\mathbb R^n$ con frontera localmente de clase $C^1$ a trozos, un campo *vectorial* $v\in C^1(\overline{\Omega}\to\mathbb R^n)$, y un campo *escalar* $u\in C^1(\overline{\Omega}\to\mathbb R^n)$ entonces
$$
\int_\Omega u \operatorname{div} v = \int_{\partial \Omega} u v\cdot n - \int_\Omega Du\cdot v
$$
donde $n$ es el vector normal exterior a $\Omega$.
</details>

### Descomposici√≥n de Helmholtz

La relaci√≥n $D^T=-\operatorname{div}$ nos permite dar la descomposici√≥n ortogonal
$$
\mathbb R^{|E|} = D(\mathbb R^{|V|}) + \ker(\operatorname{div}).
$$
tambi√©n conocida como la **descomposici√≥n de Helmholtz**. Es decir que cualquier $f:E\to\mathbb R$ puede escribirse de forma *√∫nica*^[Dado $f:E\to \mathbb R$, el potencial $u$ no es √∫nico pero su gradiente $Du$ s√≠.] como
$$
f = Du + g
$$
tal que
$$
\operatorname{div} g = 0,
$$
y como corolario $Du \perp g$.

En t√©rminos f√≠sicos, cualquier flujo se descompone en una parte que preserva la masa ($g$) y en un flujo gradiente ($Du$).

<details>
  <summary>**Margen de √°lgebra lineal:** El teorema fundamental de √°lgebra lineal</summary>
Dado $A:\mathbb R^M\to \mathbb R^{N}$ se tiene que
$$
A(\mathbb R^{M})^\perp = \ker(A^T).
$$
Si $x \perp A(\mathbb R^M)$ entonces $0 = x\cdot AA^Tx = \|A^T x\|^2$, lo cual implica $A^Tx=0$. Por otro lado si $A^Tx=0$ entonces para $y\in \mathbb R^M$ arbitrario $x\cdot Ay = A^Tx\cdot y=0$.
</details>

---

:::{.exercise}

Calcula la descomposici√≥n de Helmholtz para el siguiente flujo

![](./helmhotz.png){width=70%}
:::

<details>
  <summary>Soluci√≥n</summary>
Sea $f:E\to \mathbb R$ los valores que se muestran en la gr√°fica. Buscamos calcular $u:V\to \mathbb R$ y $g:E\to \mathbb R$ tales que $f=Du+g$ y $\operatorname{div}g=0$. Si tomamos as√≠ la divergencia en la expresi√≥n $f=Du+g$ encontramos que $u$ satisface
$$
\begin{cases}
-2u(A)+u(B)+u(C)=3,\\
u(A)-3u(B)+u(C)+u(D)=4,\\
u(A)+u(B)-3u(C)+u(D)=-7,\\
u(B)+u(C)-2u(D)=0.
\end{cases}
$$
Las soluciones homog√©neas del sistema son los potenciales constantes^[Esto puede verificarse de la reducci√≥n de Gauss-Jordan en este caso, y adem√°s ser√° demostrado con mayor generalidad.]. Ajustando esta constante de forma que $u(A)=0$ obtenemos un sistema que podemos resolver num√©ricamente
```{python}
import numpy as np

A = np.array([[ 1, 1, 0],
              [-3, 1, 1],
              [ 1,-3, 1]])
B = np.array([3, 4, -7])
X = np.linalg.inv(A).dot(B)

Du = [X[0],X[1]-X[0],-X[1],X[2]-X[1],X[0]-X[2]]
f = np.array([1,5,-2,0,0])
g = f-Du

print("[Du(AB), Du(BC), Du(CA), Du(CD), Du(DB)] = {}.".format(Du))
print("[g(AB), g(BC), g(CA), g(CD), g(DB)] = {}.".format(g))
```
</details>

## Laplaciano

El Laplaciano es un operador diferencial que se construye aplicando sucesivamente el gradiente y la divergencia. Es decir que mide la producci√≥n de masa del gradiente. Adem√°s, luego de una manipulaci√≥n algebraica, observamos que es proporcional a la diferencia entre el promedio en los v√©rtices adyacentes y el valor en el centro.

:::{.definition}
Dado $u: V \to \mathbb R$, el Laplaciano $\Delta u: V \to \mathbb R$ se define tal que
$$
\Delta u(v) = \operatorname{div}(D u)(v) = \sum_{w \sim v} (u(w)-u(v)).
$$
donde $w \sim v$ si existe una arista que une a $v$ y $w$ en cualquier orientaci√≥n.
:::

A pesar de que tanto el gradiente como la divergencia requieren que el grafo tenga una orientaci√≥n, **el Laplaciano est√° bien definido en grafos no dirigidos**.

Cuando $u: V \to \mathbb R$ es un potencial tal que $\Delta u=0$ en $\Omega \subseteq V$, decimos que $u$ es una funci√≥n **arm√≥nica** sobre $\Omega$.

---

:::{.example}
Considera una red el√©ctrica con resistencias de un Ohm ($R(e)=1$) la cual modelamos como una grafo dirigido de forma arbitraria. Una bater√≠a de un voltio entre dos nodos $v_+,v_-\in V$ genera un potencial el√©ctrico $u:V\to \mathbb R$ que se puede determinar a partir de la ley de Ohm y la ley de Kirchhoff.

Seg√∫n la ley de Ohm tenemos que la corriente se calcula seg√∫n
$$
i=Du.
$$

Seg√∫n la ley de Kirchhoff tenemos que fuera de los nodos donde se conecta la bateria, la corriente se conserva, es decir
$$
0=\operatorname{div}i = \Delta u \text{ en } V\setminus\{v_\pm\}
$$

Junto con las condiciones de borde en los nodos donde se conecta la bater√≠a
$$
\qquad u(v_+) = 1, \qquad u(v_-) = 0,
$$
obtenemos un sistema de ecuaciones lineales con igual n√∫mero de ecuaciones que de inc√≥gnitas.
:::

---

:::{.exercise}
Calcula el potencial el√©ctrico que se genera en un cubo de resistencias de un Ohm, cuando se conecta una bater√≠a de un voltio entre dos nodos opuestos del cubo

![](./cube.png){with=70%}
:::

<details>
  <summary>Soluci√≥n</summary>
  Asumamos sin p√©rdida de generalidad que se conecta la bateria de los nodos $A$ a $D$ tal que $v(A)=1$ y $v(D)=0$. Tenemos un sistema de ecuaciones lineales de dimensiones 6 por 6. De existir una √∫nica soluci√≥n^[Una vez m√°s, esto puede chequearse a mano o con una herramienta num√©rica.] observamos que por simetr√≠a se debe cumplir que $v(B)=v(F)=v(H)=\alpha$ (los nodos adyacentes a $A$) y $v(C)=v(E)=v(G)=\beta$ (los nodos adyacentes a $E$). Esto reduce el sistema a uno de 2 por 2
  $$
  \begin{cases}
  -9\alpha+6\beta = -3,\\
  6\alpha -9\beta = 0
  \end{cases} \qquad\Rightarrow\qquad \alpha = \frac{3}{5}, \qquad \beta = \frac{2}{5}.
  $$
</details>

---

:::{.exercise}
Calcula la matriz asociada al Laplaciano para el grafo a continuaci√≥n

![](./k3.png){width=70%}
:::

<details>
  <summary>Soluci√≥n</summary>
  $$
  \Delta = \operatorname{div} D = \begin{pmatrix}
  1 & 0 & -1 & 1 & 0\\
  -1 & 1 & 0 & 0 & 0\\
  0 & -1 & 1 & 0 & -1\\
  0 & 0 & 0 & -1 & 1
  \end{pmatrix}\begin{pmatrix}
  -1 &  1 &  0 &  0\\
   0 & -1 &  1 &  0\\
   1 &  0 & -1 &  0\\
  -1 &  0 &  0 &  1\\
   0 &  0 &  1 & -1
  \end{pmatrix} = \begin{pmatrix}
  -3 & 1 & 1 & 1\\
  1 & -2 & 1 & 0\\
  1 & 1& -3 & 1\\
  1 & 0 & 1 & -2
  \end{pmatrix}
  $$
</details>

---

:::{.exercise}
Da un an√°logo discreto para la f√≥rmula de Green
$$
\int_\Omega (u_1\Delta u_2 - u_2\Delta u_1) = \int_{\partial\Omega} (u_1Du_2 - u_2 Du_1)\cdot n
$$
:::

<details>
  <summary>Soluci√≥n</summary>
De la f√≥rmula de integraci√≥n por partes \@ref(eq:ipv)
$$
\sum_\Omega u_i \Delta u_j = \sum_{E} u_i^- Du_j n_\Omega - \sum_{e_+\in \Omega} Du_iDu_j
$$
Por lo tanto al tomar la resta se cancelan el segundo t√©rmino a la deracha quedando as√≠
$$
\sum_\Omega (u_1 \Delta u_2-u_2 \Delta u_1) = \sum_{E} (u_1^- Du_2 - u_2^- Du_1)n_\Omega.
$$
</details>

---

En general podemos a√±adir una operaci√≥n intermedia entre el gradiente y la divergencia. Esto genera operadores con caracter√≠sticas similares al Laplaciano.

---

:::{.example}
Considera ahora una red el√©ctrica con resistencias variables. La ley de Ohm consiste en tomar el gradiente del potencial y luego dividir por las resistencias para obtener la corriente. Al rec√≠proco de la resistencia tambi√©n se le conoce como la capacitancia y puede ser m√°s conveniente de usar en este ejemplo. En este caso las ecuaciones de balance para el potencial el√©ctrico tienen la forma
$$
\operatorname{div} (CDu) = 0 \qquad C = 1/R : \text{Capacitancia}
$$
(fuera de los nodos donde se conecta la bater√≠a).

En el caso particular de las resistencias dadas en la siguiente gr√°fica,

![](capa.png){width=70%}

obtenemos el operador lineal asociado a la siguiente matriz
```{python}
import numpy as np

# Gradiente
D = np.array([[-1, 1, 0, 0],
              [0, -1, 1, 0],
              [1, 0, -1, 0],
              [-1, 0, 0, 1],
              [0, 0, 1, -1]])
              
# Capacitancia (C=1/R)
C = np.array([[1, 0, 0, 0, 0],
              [0, 1/4, 0, 0, 0],
              [0, 0, 1/2, 0, 0],
              [0, 0, 0, 1/5, 0],
              [0, 0, 0, 0, 1/3]])

# Operador L = div(CD)
L = -np.matmul(D.T,np.matmul(C,D))

print(L)
```
:::

---

:::{.example}
Las ecuaciones de balance en los [entramados](#entramados) se implementan en tres pasos:

1. Se toman las posiciones relativas entre nodos adyacentes, es decir el gradiente de las posiciones $q:V\to\mathbb R^2$.

1. Se forman las tensiones a partir de las posiciones relativas y los multiplicadores $\lambda:E\to \mathbb R$.

1. Se propone el balance de fuerzas en t√©rminos de la divergencia de la tensi√≥n.

En s√≠ntesis se obtiene que en los nodos libres
$$
\operatorname{div} (\lambda D q) = mge_2
$$
A diferencia de los problemas de redes el√©ctricas, tanto $q$ como $\lambda$ son variables por ser determinadas lo cual hace que el problema sea no-lineal en dichas inc√≥gnitas. 
:::

<!--chapter:end:02-calculo.Rmd-->

# Din√°mica

<!--  
```{python}
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import animation
from matplotlib.animation import PillowWriter

def f(x,t):
  return np.exp(-(x-5*t)**2)*np.sin(10*x-5*t)

x = np.linspace(0,10*np.pi,1000)

fig, ax = plt.subplots(1,1,figsize=(8,4))
ln, = plt.plot([],[])
ax.set_xlim(0,10*np.pi);
ax.set_ylim(-1.5,1.5);

def animate(i):
  ln.set_data(x,f(x,i/50))

ani = animation.FuncAnimation(fig, animate, frames=240, interval = 50)
ani.save('anim.gif',writer='pillow',fps=50,dpi=100)
plt.clf()
```

![](anim.gif)
-->

## Transporte

Consideremos un grafo dirigido $G=(V,E)$ y una familia de densidades $u(x,t)$ que toma valores reales para cada v√©rtice $x\in V$ en tiempo $t\in\mathbb R$. Decimos que un flujo $f(e,t)$ transporta a $u$ si en cada instante salen $f(e,t)$ unidades de masa de $e_-$ hacia $e_+$ por la arista $e$. Es decir que sobre cada $x\in V$ se tiene que
$$
\partial_t u(x,t) = \sum_{e_+=x} f(e,t) - \sum_{e_-=x} f(e,t) = -\operatorname{div} f(x,t).
$$

Observamos que si en un dado nodo $x\in V$ se tiene que $\operatorname{div} f(x)>0$ entonces $u$ es decreciente. Esto quiere decir que el flujo hace que la densidad se esparza o diverja sobre  dicho nodo. De igual forma, si $\operatorname{div} f(x)<0$, $u$ es creciente y el flujo hace que la densidad en cambio converga en dicho nodo.

---

:::{.example}
Consideremos una densidad $u:V\times \mathbb R\to \mathbb R$ transportada por un flujo $f := \mu u^-$ donde $\mu:E\to \mathbb R$ son tazas de movilidad dadas sobre las aristas en el grafo a continuaci√≥n y recordemos que $u^-(e)=u(e_-)$

![](./flow1.png)

Comenzando de la distribuci√≥n de densidades
$$
u(0) = (1,0,0,0)
$$
integramos numericamente las cuatro ecuaciones dadas por
$$
\partial_t u = -\operatorname{div}(\mu u^-) \qquad\Leftrightarrow \qquad \begin{cases}
u(1)' = -3u(1)+3u(3),\\
u(2)' = u(1) - u(2),\\
u(3)' = u(2) - 3u(3) + 2u(4),\\
u(4)' = 2u(1)-2u(4).
\end{cases}
$$
y obtenemos lo siguiente:

```{python}
import numpy as np
import matplotlib.pyplot as plt
import scipy as sp
from scipy.integrate import odeint

A = np.array([[-3, 0, 3, 0],
              [1, -1, 0, 0],
              [0, 1, -3, 2],
              [2, 0, 0, -2]])

def dudt(u,t):
  return np.matmul(A,u)

u0 = np.array([1,0,0,0])

t = np.linspace(0,2,1000)
sol = odeint(dudt,u0,t)

plt.plot(t,sol[:,0], label='1')
plt.plot(t,sol[:,1], label='2')
plt.plot(t,sol[:,2], label='3')
plt.plot(t,sol[:,3], label='4')
plt.legend()
plt.show()
```
:::

---

Adicionalmente podemos considerar modelos donde adem√°s del fen√≥meno de transporte, una o m√°s densidades tienen distintas reacciones en cada uno de los nodos.

---

:::{.example}
Las funciones $S,I:V\to \mathbb R$ representan poblaciones de individuos susceptibles e infectados para una dada epidemia modelada geogr√°ficamente sobre un grafo dirigido $G=(V,E)$. Cada una de estas poblaciones se mueve sobre las aristas por flujos dados por
$$
f_S := \mu_S S^-, \qquad f_I := \mu_I I^-.
$$
donde $\mu_S,\mu_I: E\to \mathbb R$ son tazas de movilidad sobre las aristas.

La din√°mica de la epidemia en cada nodo est√° dada por las tazas de transmisi√≥n ($\beta$) y recuperaci√≥n ($\gamma$). En espec√≠fico planteamos el modelo de $2|V|$ ecuaciones de primer orden no-lineales
$$
\partial_t S = -\beta SI + \operatorname{div}(\mu_S S^-), \qquad \partial_t I = \beta SI - \gamma I + \operatorname{div}(\mu_I I^-),\\
$$
:::

---

:::{.exercise}
Demuestra que el total de la poblaci√≥n susceptible o infectada es una funci√≥n decreciente. 
:::

<details>
  <summary>Soluci√≥n</summary>
  $$
  \partial_t \sum_{V} (S+I) = \sum_{V} (-\gamma I + \operatorname{div} f_S+\operatorname{div}f_I) = - \gamma \sum_{V} I \leq 0.
  $$
</details>

---

:::{.exercise}
Considera una epidemia dada en la siguiente red con los par√°metros dados. En las aristas se muestran ciertas tasas de movilidad, para los susceptibles estas deben multiplicarse por $10^{-2}$ y para los infectados por $10^{-4}$. Implementa num√©ricamente y grafica las soluciones en el intervalo $[0,160]$ con condiciones iniciales
$$
S(0) = (1,1,1,1), \qquad I(0) = (0, 10^{-6},0,0).
$$

![](./sir2.png){width=70%}
:::

<details>
  <summary>Soluci√≥n</summary>
```{python}
import numpy as np
import matplotlib.pyplot as plt
import scipy as sp
from scipy.integrate import odeint

beta = 0.5
gamma = 0.3

L = np.array([[-5, 1, 2, 1],
              [2, -3, 1, 0],
              [1, 2, -4, 2],
              [2, 0, 1, -3]])


def dSIdt(SI,t):
  S = SI[:4]
  I = SI[4:]
  dS = -beta*S*I + 0.01*np.matmul(L,S)
  dI = beta*S*I - gamma*I + 0.0001*np.matmul(L,I)
  return np.concatenate((dS,dI))

S0 = np.array([1,1,1,1])
I0 = np.array([0,0.00000001,0,0])
SI0 = np.concatenate((S0,I0))

t = np.linspace(0,160,1000)
sol = odeint(dSIdt,SI0,t)

fig, ax = plt.subplots(2,2,figsize=(10,5))

ax[0,0].plot(t,sol[:,0], label='S1')
ax[0,0].plot(t,sol[:,4], label='I1')
ax[0,0].legend()

ax[1,0].plot(t,sol[:,1], label='S2')
ax[1,0].plot(t,sol[:,5], label='I2')
ax[1,0].legend()

ax[0,1].plot(t,sol[:,2], label='S3')
ax[0,1].plot(t,sol[:,6], label='I3')
ax[0,1].legend()

ax[1,1].plot(t,sol[:,3], label='S4')
ax[1,1].plot(t,sol[:,7], label='I4')
ax[1,1].legend()
```
</details>

## Difusi√≥n

As√≠ como vimos en los ejemplos anteriores donde el flujo era proporcional a $u^-$, en general puede darse el caso de que $f$ est√© determinada por alguna otra funci√≥n de $u$, esto se conoce como una **ley constitutiva**. Un caso muy com√∫n es que $f$ sea proporcional a $-Du$, en el cual obtenemos un modelo de **difusi√≥n**.

---

:::{.example}
Sea $G=(V,E)$ un grafo que modela una red de habitaciones en renta y $u:V\times \mathbb R\to\mathbb R$ la poblaci√≥n que vive en dicha red. Asumiendo la ley de oferta y demanda, el precio de renta $p=p(x,t)$ de una habitaci√≥n $x$ en el instante $t$ debe ser proporcional a la demanda, la cual podemos considerar en nuestro caso proporcional a la poblaci√≥n que habita dicho nodo, digamos por ejemplo que $p = k_1u$. La poblaci√≥n busca moverse entre nodos adyacentes si percibe que el precio le es favorable, por ejemplo $f=-k_2Dp$. Llegamos as√≠ a la ecuaci√≥n
$$
\partial_t u = -\operatorname{div} f = \operatorname{div}(k_2Dp) = \operatorname{div}(aDu), \qquad a := k_1k_2.
$$
:::

---

El problema $\partial_t u = \operatorname{div}(aDu)$, tambi√©n conocido como la **ecuaci√≥n de calor** o **difusi√≥n**, representa un sistema de EDOs lineales y de primer orden con tantas ecuaciones e inc√≥gnitas como la cardinalidad de $V$.

---

:::{.exercise}
Considera una difusi√≥n de la forma $\partial_t u = \Delta u$ sobre el siguiente grafo. Calcula $u$ para todo tiempo dadas las condiciones iniciales ilustradas en la figura. ¬øConverge la soluci√≥n a alg√∫n punto fijo?

![](./dif.png){width=70%}
:::

<details>
  <summary>Soluci√≥n</summary>
  El sistema de 4 EDOs se presenta como
  $$
  \frac{d}{dt}\begin{pmatrix}
  u(a)\\
  u(b)\\
  u(c)\\
  u(d)
  \end{pmatrix} = \begin{pmatrix}
  -3 & 1 & 1 & 1\\
  1 & -2 & 1 & 0\\
  1 & 1 & -3 & 1\\
  1 & 0 & 1 & -2
  \end{pmatrix}\begin{pmatrix}
  u(a)\\
  u(b)\\
  u(c)\\
  u(d)
  \end{pmatrix}
  $$
  Dada que la condici√≥n inicial es $(1,0,0,0)^T$ buscamos la primera columna de la matriz exponencial. El siguiente resultado se obtuvo con la ayuda de [sympy](https://live.sympy.org/), una librer√≠a de c√°lculo simb√≥lico de python
  
```{python, results='asis'}
from sympy import *
  
t = Symbol('t')
mt = Matrix([[-3, 1, 1, 1],
             [1, -2, 1, 0],
             [1, 1, -3, 1],
             [1, 0, 1, -2]]) * t
mexp = mt.exp()
print('$$' + latex(mexp) + '$$')
```

Observamos que cuando $t\to\infty$ la soluci√≥n converge exponencialemente al vector $(1/4,1/4,1/4,1/4)^T$. De hecho **esto sucede para cualquier condici√≥n incial**.
</details>

---

:::{.exercise}
Sea $G=(V,E)$ un grafo lineal con 100 v√©rtices
$$
V=\{1,2,\ldots,100\}, \qquad E = \{(1,2),(2,3),\ldots,(99,100)\}.
$$
Sea $u$ soluci√≥n de la ecuaci√≥n de calor $\partial_t u=\Delta u$ en $G$ con condici√≥n inicial
$$
u(0) = e_{50} = (0,\ldots,0,1,0,\ldots,0).
$$
Calcula el primer $t>0$ tal que $u(50,t)\leq 0.1$. 
:::

<details>
  <summary>Soluci√≥n</summary>
  En este caso la dificultad est√° en c√≥mo implementar el Laplaciano y encontrar el primer √≠ndice donde la soluci√≥n baje de $0.1$.
```{python}
import numpy as np
import matplotlib.pyplot as plt
from scipy.integrate import odeint

Delta = -2*np.eye(100)+np.eye(100,k=1)+np.eye(100,k=-1)
Delta[0,0] = -1
Delta[99,99] = -1

def dudt(u,t):
  return np.matmul(Delta,u)

u0 = np.zeros(100)
u0[49] = 1

t = np.linspace(0,20,1000)

sol = odeint(dudt,u0,t)
index = np.where(sol[:,49]<0.1)[0][0]
plt.plot(t,sol[:,49])
plt.plot(t[index],sol[index,49],'ro',label="({:.2f},{:.2f})".format(t[index],sol[index,49]))
plt.legend()
plt.title("u(50,t)")
plt.show()
```
</details>


## Oscilaci√≥n

El sistema de EDOs lineales y de segundo orden dado por
$$
\partial_t^2 u = \operatorname{div}(aDu)
$$
tambi√©n es com√∫n en distintos modelos. Esta se conoce como la **ecuaci√≥n de onda**.

---

:::{.example}
Un grafo $G=(V,E)$ modela las conexiones en un sistema de masas $m:V\to (0,\infty)$ unidas por resortes con constantes $k:E\to[0,\infty)$. Sea $q:V\to \mathbb R^n$ los desplazamientos de las masas a partir de una configuraci√≥n dada de equilibrio. A partir de la ley de Hooke planteamos el sistema $n\times|V|$ ecuaciones e inc√≥gnitas,
$$
m\partial_t^2 q = \operatorname{div}(kDq).
$$
:::

Recordemos que cualquier sistema de segundo orden puede ser llevado a un sistema de primer orden tomando a las velocidades como inc√≥gnitas del sistema. Por ejemplo,
$$
\partial_t^2 u = \operatorname{div}(aDu) \qquad \Leftrightarrow\qquad \begin{cases}
\partial_t u = v,\\
\partial_t v = \operatorname{div}(aDu).
\end{cases}
$$

---

:::{.example}
El grafo $G=(V,E)$ vuelve a modelar una red de habitaciones en renta, $u:V\times \mathbb R\to\mathbb R$ la poblaci√≥n que vive en dicha red y $p:V\times \mathbb R\to\mathbb R$ los precios. Una vez m√°s asumimos que la poblaci√≥n se mueve seg√∫n el flujo $f = -Dp$. Por otro lado los precios se modifican gradualmente dependiendo de la demanda en relaci√≥n a los nodos adyacentes.

Esto √∫ltimo puede ser reflejado por ejemplo en la ecuaci√≥n $\partial_t p = -\Delta u$, es decir que el precio disminuye si el promedio de la poblaci√≥n vecina es mayor la poblaci√≥n en el nodo en consideraci√≥n, con la intenci√≥n de atraerla.

En resumen obtenemos el sistema de ecuaciones
$$
\partial_t u = \Delta p, \qquad \partial_t p = -\Delta u.
$$
Estas implican las ecuaciones de onda desacopladas para el bilaplaciano
$$
\partial_t^2 u = -\Delta^2 u, \qquad \partial_t^2 p = -\Delta^2p.
$$
:::

---

:::{.exercise}
Considera una oscilaci√≥n de la forma $\partial_t^2 u = -\Delta^2 u$ sobre el siguiente grafo. Calcula $u$ para todo tiempo dadas las condiciones iniciales ilustradas en la figura, partiendo del reposo. Grafica la soluci√≥n en el intervalo $[0,6]$.

![](./oscila.png){width=70%}
:::

<details>
  <summary>Soluci√≥n</summary>
  El sistema de 4 EDOs se presenta como
  $$
  \frac{d}{dt}\begin{pmatrix}
  u(a)\\
  u(b)\\
  u(c)\\
  u(d)\\
  u'(a)\\
  u'(b)\\
  u'(c)\\
  u'(d)
  \end{pmatrix} = \begin{pmatrix}
  0_4 & I_4\\
  -\Delta^2 & 0_4
  \end{pmatrix}\begin{pmatrix}
  u(a)\\
  u(b)\\
  u(c)\\
  u(d)\\
  u'(a)\\
  u'(b)\\
  u'(c)\\
  u'(d)
  \end{pmatrix}, \qquad \Delta = \begin{pmatrix}
  -3 & 1 & 1 & 1\\
  1 & -2 & 1 & 0\\
  1 & 1 & -3 & 1\\
  1 & 0 & 1 & -2
  \end{pmatrix}
  $$
  
  Para calcular la soluci√≥n anal√≠tica usamos el paquete simb√≥lico de python.
  
```{python, results='asis'}
import numpy as np
import matplotlib.pyplot as plt
import sympy as smp
from sympy.plotting import plot

Delta = smp.Matrix([[-3,1,1,1],
              [1,-2,1,0],
              [1,1,-3,1],
              [1,0,1,-2]])

t = smp.symbols('t',real='True')

B = smp.Matrix(smp.BlockMatrix([[smp.ZeroMatrix(4,4),smp.Identity(4)],
            [-Delta*Delta,smp.ZeroMatrix(4,4)]]))*t
eB = smp.re(B.exp())
y0 = smp.Matrix([0,1,2,3,0,0,0,0])
y_s = eB*y0
print('$$' + smp.latex(y_s[:4]) + '$$')
```

Las gr√°ficas est√°n dadas por

```{python}
eB_f = smp.lambdify(t,eB)

t = np.linspace(0,6,600)
y0 = np.array([0,1,2,3,0,0,0,0])
y = np.einsum('ijk,j->ik',eB_f(t),y0)
plt.plot(t,y[0,:],label='a')
plt.plot(t,y[1,:],label='b')
plt.plot(t,y[2,:],label='c')
plt.plot(t,y[3,:],label='d')
plt.legend(loc='lower right')
```
</details>
<!--



\begin{center}
\colorbox[HTML]{E5F3CC}{
\begin{minipage}[c]{450px}
\begin{ejemplo}
Demuestra que la poblaci√≥n total, la suma de los precios, y $\sum(u^2+p^2)$ permanecen constantes.
\end{ejemplo}
\end{minipage}}
\end{center}
-->

<!--chapter:end:03-dinamica.Rmd-->

# Implementaci√≥n del entramado

En esta secci√≥n veremos como poner en pr√°ctica los conceptos aprendidos para modelar una red cuadrada sujetada por sus cuatro esquinas. Recordemos que a pesar de que podemos dar una forma expl√≠cita de las ecuaciones que se deben resolver, el m√©todo de Newton parece ser muy sensible a las condiciones iniciales, por lo que hay que ingeniarse una forma alternativa.

La idea que tenemos en mente es proponer que las conexiones entre nodos el√°sticas. Con esto proponemos un modelo el√°stico que gracias a un t√©rmino de viscosidad podemos llevar al reposo. Con estas configuraciones terminales podemos luego ir haciendo la dureza (stiffness) de los resortes cada vez m√°s y m√°s grande, aproximando as√≠ la configuraci√≥n de equilibrio cuando las barras son r√≠gidas.

## Librer√≠as y datos

Para fijar ideas proponemos una red con $N$ por $N$ nodos de masa $m>0$ como la ilustrada a continuaci√≥n. La esquinas ser√°n colgadas en los puntos $(0,0,0)$, $(1,0,0)$, $(1,1,0)$, y $(0,1,0)$.

![](./red.png){width=70%}

Entre cada par de nodos adyacentes se ubica un resorte cuya longitud natural es $l > 1/(N-1)$, dureza $k\gg 1$, y amortiguaci√≥n $\gamma > 0$. Es decir que si dos nodos adyacentes est√°n a distancia $d$, la magnitud de la fuerza que ejerce el resorte entre ellos es $k|d-l|$. Esta fuerza es paralela a la l√≠nea que contiene a estos nodos y la direcci√≥n (o el signo) dependen de como se compare $d$ respecto de $l$: Para $d>l$ el resorte atrae a los nodos entre si, y para $d<l$ el resorte los repele.

```{python}
import numpy as np
from numpy import linalg as la
import matplotlib.pyplot as plt
import scipy as sp
import scipy.sparse as sps
from scipy.integrate import odeint

N = 10        # Longitud de la red
m = 0.1       # Masa de los nodos
gamma = 1     # Coeficiente de amortiguaci√≥n
k = 100       # Coeficiente de dureza
l = 1.1/(N-1) # Longitud natural del resorte

fijos = [0, N-1, N**2-N, N**2-1] # Esquinas fijas

# Listas para enumerar las aristas de la red

# Aristas verticales

ini_v = list(range(N**2-N))
fin_v = list(range(N,N**2))

# Aristas horizontales

ini_h = list(range(N**2))
del ini_h[slice(N-1,N**2,N)]
fin_h = list(range(1,N**2+1))
del fin_h[slice(N-1,N**2,N)]

ini = ini_h + ini_v     # Nodos de salida
fin = fin_h + fin_v     # Nodos de llegada
Ne = len(ini)           # N√∫mero de aristas
```

## Ecuaci√≥n diferencial

La ecuaci√≥n diferencial que buscamos modelar para la posici√≥n $p=(x,y,z)$ de cada nodo est√° dada por las leyes de Newton:
$$
mp'' = \text{gravedad} + \text{tensi√≥n} + \text{amortiguaci√≥n}
$$

De estos tres tr√©minos la gravedad y la tensi√≥n son f√°ciles de calcular. Respectivamente son $-mge_z$ y $-\gamma p'$. Asumiendo el sistema internacional de unidades tomamos $g = 9.8$. La dificultad reside ahora en implementar el c√°lculo de las tensiones.

Recordemos adem√°s que para poder resolver nuestra EDO usando la librer√≠a de integraci√≥n num√©rica de Scipy (odeint) debemos transformar el sistema a uno de primer orden. Esto significa que las velocidades pasan a ser parte de las inc√≥gnitas. Codificamos en la curva $s=s(t)$ las configuraciones de nuestro sistema de la siguiente forma
$$
s = (pos,vel) = ((x,y,z),(vx,vy,vz)) \in (\mathbb R^{N^2}\times\mathbb R^{N^2}\times\mathbb R^{N^2})\times(\mathbb R^{N^2}\times\mathbb R^{N^2}\times\mathbb R^{N^2})
$$
Dadas las posiciones $p_{ini}$ y $p_{fin}$ de dos nodos extremos sobre una arista dada tenemos que la tensi√≥n sobre dicha arista se calcula por
$$
T := k(d-l)\theta, \qquad d := |p_{fin}-p_{ini}|, \qquad \theta := \frac{p_{fin}-p_{ini}}{d}
$$
Esta es justamente la tensi√≥n que se ejerce sobre el nodo inicial de la arista, siendo la fuerza opuesta en el otro nodo gracias a la tercera ley de Newton. Un paso t√©cnico a partir de ac√° consiste en transferir est√° informaici√≥n dada sobre las aristas a los nodos.

Estas consideraciones te√≥ricas quedan reflejadas en la siguiente funci√≥n:

```{python}
def dsdt(s,t):
  pos = np.reshape(s[:3*N**2],(3,N**2)).T
  vel = np.reshape(s[3*N**2:],(3,N**2)).T

  pos_rel = pos[fin] - pos[ini]
  lon_rel = np.tile(la.norm(pos_rel,axis=1),(3,1)).T   # d
  dir_rel = pos_rel/lon_rel                            # theta
  ten_esc = k*(lon_rel-l*np.ones((Ne,3)))              # Magnitud de la tensi√≥n (signada)
  ten_ari = ten_esc*dir_rel                            # Tensi√≥n sobre el nodo inicial
  
  # Tensi√≥n total sobre cada nodo. Usamos una estructura de matrices ralas (sparse) para codificarlas eficientemente.
  
  data = np.concatenate((ten_ari.T.reshape(-1),-ten_ari.T.reshape(-1)))
  fila = 3*ini+3*fin
  colu = 2*(Ne*[0]+Ne*[1]+Ne*[2])
  ten_nod = sps.coo_matrix((data, (fila, colu))).toarray()
  
  # Fuerzas y aceleraci√≥n
  
  fue_gra = -9.8*m*np.tile(np.array([0,0,1]),(N**2,1)) # Gravedad
  visc = -gamma*vel                                     # Amortiguaci√≥n
  acel = (ten_nod + fue_gra + visc)/m                   # Aceleraci√≥n

  acel[fijos,:] = [0,0,0]                               # Esquinas fijas
  
  return np.concatenate((s[3*N**2:],acel.T.reshape(-1)))
```

## Integraci√≥n y graficaci√≥n

Una vez modelada la ecuaci√≥n diferencial ya podemos proceder a integrarla usando por ejemplo el comando odeint de la librer√≠a Scipy. Para ello necesitamos dar adicionalmente un intervalo de tiempo discreto y una condici√≥n inicial.

```{python}
px, py = np.meshgrid(np.linspace(0,1,N),np.linspace(0,1,N))
s0 = np.concatenate((px.reshape(-1), py.reshape(-1),np.zeros(N**2),np.zeros(3*N**2)))
t = np.linspace(0,10,2000)

sol = odeint(dsdt,s0,t)
```

Visualizaci√≥n del √∫ltimo instante

```{python}
fig = plt.figure()
ax = plt.axes(projection='3d')
ax.axes.set_xlim3d(left=0, right=1);
ax.axes.set_ylim3d(bottom=0, top=1);
ax.axes.set_zlim3d(bottom=-1, top=0);
ax.view_init(60, 80);

sol_fin = sol[-1,:]
pos = np.reshape(sol_fin[:3*N**2],(3,N**2)).T
for i in range(N):
  ax.plot3D(pos[i*N:(i+1)*N,0], pos[i*N:(i+1)*N:,1], pos[i*N:(i+1)*N,2],'bo-')
  ax.plot3D(pos[i:N**2:N,0], pos[i:N**2:N,1], pos[i:N**2:N,2],'b-')
```

<!--chapter:end:04-entramado.Rmd-->

# Espectro del Laplaciano

\section{Espectro del Laplaciano}

Hemos visto tres familias de problemas relacionados con el operador lineal $u \mapsto Lu = \operatorname{div}(aDu)$:

- **El√≠ptico:** $\operatorname{div}(aDu) = f$,

- **Parab√≥lico:** $\partial_t u = \operatorname{div}(aDu) + f$,

- **Hiperb√≥lico:** $\partial_t^2 u = \operatorname{div}(aDu) + f$.

Como tales, la descomposici√≥n espectral de $L$ trivializa el c√°lculo de las soluciones. A continuaci√≥n daremos un breve recorrido a la teor√≠a discreta de Fourier con la cual podemos clarificar como resolver cada uno de estos problemas.

Para $a:E\to (0,\infty)$ la composici√≥n dada por $Lu = \operatorname{div}(aDu)$ es un operador sim√©trico, negativo semi-definido. La simetr√≠a es una aplicaci√≥n de la f√≥rmula de integraci√≥n por partes, bien sea usando que
$$
(\operatorname{div} \operatorname{diag}(a) D)^T = D^T \operatorname{diag}(a)^T \operatorname{div}^T = (-\operatorname{div})  \operatorname{diag}(a)(-D) = \operatorname{div}\operatorname{diag}(a)D,
$$
o en t√©rminos de las sumas
$$
\sum_{x\in V} v(x)\operatorname{div}(aDu)(x) = -\sum_{e\in E} Dv(e)Du(e)a(e) = \sum_{x\in V} u(x)\operatorname{div}(aDv)(x).
$$
La no-positividad la verificamos tomando $v=u$ tal que
$$
\sum_{x\in V} u(x)\operatorname{div}(aDu)(x) = -\sum_{e\in E} (Du(e))^2a(e) \leq 0.
(\#eq:neg)
$$

Gracias al teorema espectral sabemos que $L$ es diagonalizable, sus autovalores son reales no-positivos y adem√°s posee una base de autofunciones ortogonales. Denotemos por $\phi_0,\ldots,\phi_{M-1}$ a una base ortogonal con autovalores $-\lambda_0,\ldots,-\lambda_{M-1}$ respectivamente.

<details>
  <summary>**Margen de √°lgebra lineal:** El teorema espectral</summary>
  El teorema espectral dice que si $L\in \mathbb R^{N\times N}$ es sim√©trica, entonces sus autovectores son reales y existe una base ortogonal de autovectores.

Para ver que un dado autovector $\lambda$ es real consideramos un correspondiente autovector $\xi$ (posiblemente complejo) tal que
$$
\lambda\|\xi\|^2 = L\xi\cdot \overline{\xi} = \xi\cdot L\overline{\xi} = \xi\cdot \overline{L\xi} = \overline{\lambda}\|\xi\|^2.
$$
Dado que $\xi\neq0$ la √∫nica opci√≥n posible es que $\lambda=\overline{\lambda}$, es decir $\lambda\in \mathbb R$. M√°s a√∫n, podemos considerar de ahora en adelante que $\xi$ tambi√©n es real dado que las partes real e imaginarias de un dado autovector son tambi√©n autovectores (dado que $L$ es real).

Autovectores $\xi$, $\xi'$ con autovalores distintos $\lambda$, $\lambda'$ (respectivamente) son ortogonales dado que
$$
\lambda (\xi\cdot\overline{\xi'}) = L\xi\cdot \overline{\xi'} = \xi\cdot L\overline{\xi'} = \xi\cdot \overline{L\xi'} = \overline{\lambda'} (\xi\cdot\overline{\xi'}) = \lambda' (\xi\cdot\overline{\xi'}).
$$

Para ver que existe una base de autovectores se puede proceder por inducci√≥n. Si $\lambda$ es un autovalor con autovector $\xi$, entonces podemos descomponer $\mathbb R^N$ como la suma directa de la l√≠nea $\operatorname{vspan}\{\xi\}$ y su complemento ortogonal $S = \operatorname{vspan}\{\xi\}^\perp$. El operador $L|_S$ tiene rango en $S$, dado que para $x\in S$
$$
Lx\cdot \overline{\xi} = x\cdot L\overline{\xi} = x\cdot \overline{L\xi} = \overline{\lambda} (x\cdot \overline{\xi}) = 0.
$$
Adem√°s vuelve a ser sim√©trico (con respecto al producto interno). Tenemos de esta forma el paso para llevar adelante un argumento por inducci√≥n.

Finalmente, cuando $L$ se corresponde con una forma cuadr√°tica negativa semi-definida tenemos que los autovalores son no-positivos dado que
$$
0\geq L\xi\cdot \xi = \lambda\|\xi\|^2.
$$
</details>

---

Gracias a la identidad \@ref(eq:neg) vemos adem√°s que $\operatorname{div}(aDu)=0$ si y solo si $Du=0$. Si $G$ es conexo entonces esto solamente se cumple para las funciones constantes. En otras palabras, $\lambda=0$ es un autovalor simple cuyo autoespacio consiste de las funciones constantes. En general, $\lambda=0$ es un autovalor de $L$ cuya multiplicidad geom√©trica es igual al n√∫mero de componentes conexas de $G$.

**Asumiremos adem√°s de ahora en adelante que $G$ es conexo y $\phi_0=1$ es la autofunci√≥n asociada a $\lambda_0=0$, siendo los dem√°s autovalores estrictamente negativos (es decir que $\lambda_j>0$ para $j\neq 0$).**

---

:::{.exercise}
Demuestra que para cualquier autofunci√≥n $\phi_j$ para $j\neq 0$ se tiene que $\phi_j$ cambia de signo. Es decir que ninguno conjuntos $\{\phi_j>0\}$, $\{\phi_j<0\}$ es vac√≠o.
:::

<details>
<summary>**Soluci√≥n**</summary>
Dado que $\phi_0=1$ es ortogonal a $\phi_j$ tenemos que $\sum\phi_j=0$. Como $\phi_j\neq 0$, necesariamente debe tener tanto valores positivos como negativos.
</details>
---

Gracias a la ortogonalidad podemos calcular la descomposici√≥n de una funci√≥n arbitraria usando productos internos. Esta se conoce como la **transformada de Fourier discreta**.

Dado que
$$
u = \sum_{j=0}^{|V|-1} \hat u_j \phi_j
$$
tenemos que tomando en ambos lados el producto interno con $\phi_j$ obtenemos que
$$
\hat u_j = \frac{1}{\|\phi_j\|^2}\sum_{x\in V} u(x) \overline{\phi_j(x)}.
$$
Los coeficientes $\hat u_j$ se conocen como los **coeficientes de Fourier**.

---

:::{.example}
Consideremos el grafo c√≠clico con $M$ v√©rtices los cuales identificamos con los enteros m√≥dulo $M$. En este caso
$$
\Delta u(x) = u(x+1) - 2u(x) + u(x-1).
$$
Para calcular el espectro de $\Delta$ debemos encontrar las soluciones $M$-peri√≥dicas de la recurrencia
$$
\phi(x+1) - 2\phi(x) + \phi(x-1) = -\lambda \phi(x).
$$

Sean $r_\pm$ las ra√≠ces del polinomio caracter√≠stico $p(r) = r^2-(2-\lambda)r+1$. Tenemos as√≠ que^[Salvo en el caso de que $r_+=r_-$ que podemos analizar m√°s adelante si hiciese falta... No har√° falta.]
$$
\phi(x) = A_+r_+^x+A_-r_-^x.
$$
Observamos que para obtener soluciones $M$-peri√≥dicas basta con tomar a $r_\pm$ como ra√≠ces $M$-√©simas de la unidad, conjugadas entre si (dado que $r_+r_-=1$), de hecho la condici√≥n tambi√©n terminar√° siendo necesaria. Es decir que
$$
r_\pm = \omega^{\pm j}, \qquad \omega := e^{2\pi i/M}, \qquad j\in\{0,1,\ldots,M-1\}.
$$
A partir de estas encontramos las autofunciones
$$
\phi_{j}(x) := \omega^{jx}
$$
cuyos autovalores son $-\lambda_j$ donde
$$
\lambda_j := \omega^{j}+\omega^{-j}-2 = 2\cos(2\pi j/M)-2 = 4\sin^2(\pi j/M).
$$

La colecci√≥n $\phi_0,\ldots,\phi_{M-1}$ forma una base ortogonal de $\mathbb C^M$ conocida como la **base de Fourier**
$$
\sum_{x\in V} \phi_k(x)\overline{\phi_l(x)} = \sum_{j=0}^{M-1} \omega^{(k-l)j} = \begin{cases}
M \text{ si } k=l,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$

Observa que $\lambda_j = \lambda_{M-j}$, por lo que si $j$ no es divisible por $M/2$, el autovalor $\lambda_j$ tiene multiplicidad dos. En los dem√°s casos el autovalor tiene multiplicidad uno.
:::

---

:::{.exercise}
Demuestra que a partir de
$$
\varphi_j(x) := \cos(2\pi j x/M), \qquad \psi_j(x) := \sin(2\pi j x/M)
$$
tambi√©n se puede construir una base ortogonal de autovectores para el ejemplo anterior. Ac√° debes prestar atenci√≥n de lo que sucede cuando $j=M/2$ en caso de que $M$ sea par.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.exercise}
Calcula las normas de $\varphi_j$ y $\psi_{j}$.
:::

<details>
<summary>Soluci√≥n</summary>
$\|\varphi_j\|^2=\|\psi_{j}\|^2=M/2$
</details>

---

:::{.exercise #espectro}
Calcula el espectro del Laplaciano en los siguientes casos:

- S√≥lidos plat√≥nicos: tetraedro, cubo, octaedro, dodecaedro, icosaedro,

- Grafo completo,

- Grafo bipartito completo,

- Grafo lineal,

- Grafo producto^[El producto de $G_1$ y $G_2$ tiene como v√©rtices $V_1\times V_2$ siendo $((x_1,x_2),(y_1,y_2))$ una arista en este grafo si alguna de las siguientes dos condiciones se cumplen: $x_1=y_1$ y $(x_2,y_2)$ es una arista en $G_1$, o bien $x_2=y_2$ y $(x_1,y_1)$ es una arista en $G_2$.] en t√©rminos del espectro de sus factores (que asumimos conocido). Por ejemplo un toro puede verse como el producto de grafos c√≠clicos.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

## Problema el√≠ptico

Dada la descomposici√≥n
$$
f = \sum_{j=0}^{|V|-1} \hat f_j\phi_j, \qquad \hat f_j = \frac{1}{\|\phi_j\|^2}\sum_{x\in V} f(x)\overline{\phi_j(x)},
$$
tenemos que $u = \sum_{j=0}^{|V|-1} \hat u_j\phi_j$ satisface $Lu=f$ si y solo si para todo $j\in\{0,\ldots,(|V|-1)\}$
$$
-\lambda_j \hat u_j = \hat f_j. 
$$

Recordemos la hip√≥tesis de conexidad para $G$ la cual garantiza que $\lambda_0=0$ es un autovalor simple cuyo autoespacio son las funciones constantes generadas por $\phi_0=1$. Para $j\neq 0$ tenemos $\lambda_j > 0$ por lo cual $\hat u_j = -\hat f_j/\lambda_j$. Para $j=0$ tenemos sin embargo que $\lambda_0=0$ en cuyo caso la ecuaci√≥n tiene soluci√≥n solamente si se da la condici√≥n de ortogonalidad $f\perp \phi_0$, equivalente a decir que^[Tambi√©n puede verse como consecuencia del Teorema de la divergencia]
$$
\sum_{x\in V} f(x) = 0.
$$
Bajo esta hip√≥tesis, el correspondiente coeficiente $\hat u_0$ es arbitrario.

Bajo la condici√≥n anterior para $f$, tenemos que las soluciones de $Lu=f$ est√°n dadas por
$$
u(x) = c - \sum_{j=1}^{|V|-1} \frac{\hat f_j}{\lambda_j}\phi_j(x) = c - \sum_{j=1}^{|V|-1} \frac{1}{\lambda_j\|\phi_j\|^2}\left(\sum_{y\in V} f(y)\overline{\phi_j(y)}\right)\phi_j(x).
$$
El t√©rmino constante es la soluci√≥n homog√©nea del sistema. El segundo es una soluci√≥n particular la cual podemos reescribir como
$$
u_p(x) := -\sum_{y\in V} G(x,y)f(y), \qquad G(x,y) := \sum_{j=1}^{|V|-1} \frac{\phi_j(x)\overline{\phi_j(y)}}{\|\phi_j\|^2}\lambda_j^{-1}.
$$

---

:::{.exercise}
Demuestra que^[Como $G$ es una funci√≥n en $V^2$, definimos a $\Delta_1$ y $\Delta_2$ como los Laplacianos en la primera o segunda entrada respectivamente.]
$$
\Delta_1 G(x,y) = \Delta_2 G(x,y) = \frac{1}{|V|}- 1_y(x)=\frac{1}{|V|}- 1_x(y).
$$
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.exercise}
Demuestra que
$$
\sum_{x\in V} G(x,x) = \sum_{j=1}^{|V|-1} \lambda_j^{-1}.
$$
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.exercise}
Demuestra que $G$ es independiente de la base de Fourier.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.exercise}
Demuestra que $G(x,y)=G(y,x)$.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.exercise}
Demuestra que para $x\in[0,M]$
$$
\sum_{j=1}^{M-1} \frac{e^{2\pi i j x}-1}{\sin^2(\pi j/M)} = 2x(x-M)
$$
:::

<details>
<summary>Soluci√≥n</summary>
</details>

## Problema parab√≥lico

El sistema $\partial_t u = Lu+f$ se reduce a un sistema de ecuaciones diferenciales ordinarias desacopladas
$$
\hat u_j' = -\lambda_j \hat u_j + \hat f_j
$$
Usando por ejemplo la t√©cnica del factor integrante obtenemos
$$
\begin{aligned}
\hat u_j(t) &= \hat u_j(0)e^{-\lambda_j t} + \int_0^t \hat f_j(s)e^{-\lambda_j(t-s)}ds\\
&= \frac{1}{\|\phi_j\|^2}\sum_{y=1}^{|V|} \left(u(y,0)\overline{\phi_j(y)}e^{-\lambda_j t} + \int_0^t f(y,s)\overline{\phi_j(y)}e^{-\lambda_j(t-s)}ds\right)
\end{aligned}
$$

Agrupando los t√©rminos para la soluci√≥n concluimos que
$$
u(x,t) = \sum_{y\in V} u(y,0)H(x,y,t) + \int_0^t\sum_{y\in V} f(y,s)H(x,y,t-s)ds
$$
donde
$$
H(x,y,t) := \sum_{j=0}^{|V|-1} \frac{\phi_j(x)\overline{\phi_j(y)}}{\|\phi_j\|^2}e^{-\lambda_j t} = \frac{1}{|V|} + \sum_{j=1}^{|V|-1} \frac{\phi_j(x)\overline{\phi_j(y)}}{\|\phi_j\|^2}e^{-\lambda_j t}.
$$

---

:::{.exercise}
Demuestra que $H(y,x,t) = H(x,y,t)$.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.exercise}
Demuestra que $H$ es la soluci√≥n del problema de valores iniciales
$$
\begin{cases}
\partial_t H = \Delta_1 H = \Delta_2 H,\\
H =  1_y(x)= 1_x(y) \text{ para $t=0$}.
\end{cases}
$$
Concluye a partir de esto que $H$ es independiente de la base de Fourier.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.exercise}
Sea $u$ tal que $\partial_t u = \Delta u$. Calcula $\lim_{t\to\infty} u(t)$ en t√©rminos de $u(0)$.
:::

<details>
<summary>Soluci√≥n</summary>
$\lim_{t\to\infty} u(t) = \frac{1}{M}\sum_{x\in V}u(x,0)$
</details>

---

:::{.exercise}
Para $G$ conexo demuestra que se da la siguiente expresi√≥n asint√≥tica cuando $t\to\infty$
$$
\int_0^t H(x,y,s)ds = \frac{t}{|V|} + G(x,y) + O(e^{-\lambda_1 t})
$$
:::

<details>
<summary>Soluci√≥n</summary>
</details>

## Problema hiperb√≥lico

El sistema $\partial_t^2 u = Lu+f$ tambi√©n se reduce a un sistema de ecuaciones desacopladas de segundo orden
$$
\hat u_j'' = -\lambda_j \hat u_j + \hat f_j
$$
Tenemos as√≠ que $\hat u_j(t)$ se puede calcular en t√©rminos de su posici√≥n y velocidad inicial.

Para $j=0$
\begin{align*}
\hat u_0(t) &= \hat u_0(0) + \hat u_0'(0) t + \int_0^t \hat f_0(s)(t-s)ds.
\end{align*}

Para $j\neq0$ denotamos la frecuencia $\omega_j=\sqrt{\lambda_j}$ tal que
\begin{align*}
\hat u_j(t) &= \hat u_j(0)\cos(\omega_j t) + \hat u_j'(0)\frac{\sin(\omega_j t)}{\omega_j} + \int_0^t \hat f_j(s)\frac{\sin(\omega_j(t-s))}{\omega_j}ds.
\end{align*}

Agrupando los t√©rminos para la soluci√≥n concluimos que
$$
u(x,t) = \sum_{j=0}^{|V|-1} u(y,0)W_1(x,y,t)+\partial_t u(y,0)W_2(x,y,t) + \int_0^t f(y,s)W_2(x,y,t-s)ds
$$
donde
\begin{align*}
W_1(x,y,t) &:= \sum_{j=0}^{|V|-1} \frac{\phi_j(x)\overline{\phi_j(y)}}{\|\phi_j\|^2}\cos(\omega_j t), \\
W_2(x,y,t) &:= \frac{t}{|V|} + \sum_{j=1}^{|V|-1} \frac{\phi_j(x)\overline{\phi_j(y)}}{\|\phi_j\|^2}\frac{\sin(\omega_j t)}{\omega_j}.
\end{align*}

---

:::{.exercise}
(Ley de Stokes) Demuestra que si
$$
\begin{cases}
\partial_t^2u = Lu,\\
u|_{t=0} = 0,\\
\partial_t u|_{t=0} = v_0,
\end{cases} \qquad\Leftrightarrow\qquad u(x,t) = \sum_{j=0}^{M-1} v_0(y)W_2(x,y,t)
$$
entonces $v = \partial_tu$ satisface
$$
\begin{cases}
\partial_t^2v = Lv,\\
v|_{t=0} = v_0,\\
\partial_t v|_{t=0} = 0,
\end{cases} \qquad\Leftrightarrow\qquad v(x,t) = \sum_{j=0}^{M-1} v_0(y)W_1(x,y,t).
$$
:::

<details>
<summary>Soluci√≥n</summary>
</details>

## Nerd sniping

En esta secci√≥n veremos como resolver el problema presentado en la siguiente caricatura de Randall Munroe autor de [XKCD](https://xkcd.com/356/).

![](./nerd_sniping.png){width=70%}

La resistencia efectiva se define de la siguiente forma. Etiquetemos primero los nodos de la red por $(x,y) \in \mathbb Z^2$ tales que los nodos marcados son el origen $(0,0)$ y $(2,1)$. Se fija un potencial $u$ sobre la red tal que $u(0,0)=0$, $u(2,1)=1$, mientras que en los dem√°s nodos $u$ es arm√≥nica, es decir que para $(x,y) \in \mathbb Z^2 \setminus \{(0,0),(2,1)\}$
$$
\Delta u(x,y) = u(x-1,y) + u(x+1,y) + u(x,y-1) + u(x,y+1) - 4u(x,y) = 0.
$$
Para que $u$ est√© definida de forma un√≠voca hay que pedir adicionalmente que $u\to 0$ cuando $|(x,y)|\to \infty$. Desde una perspectiva f√≠sica esta condici√≥n en infinito es la m√°s natural.

La corriente $i$ que sale del origen es la divergencia de $u$ en dicho punto, $i= \operatorname{div} u(0,0)$. Este es a su vez la corriente que entra en el v√©rtice $(2,1)$ la cual se calcula de igual forma como $i = -\operatorname{div} u(2,1)$. Si buscamos simplificar la red por el caso m√°s sencillo que conecta a $(0,0)$ y $(2,1)$, es decir el grafo con solamente estos dos v√©rtices y una arista entre ellos, entonces la resistencia efectiva $R$ es aquella que debemos dar a esta √∫nica conexi√≥n para que la corriente siga siendo $i$ bajo el mismo potencial. En otras palabras $R = 1/i$.

Como primer paso veremos como calcular el potencial an√°logo en el toro $V_{N} = (\mathbb Z/N\mathbb Z)^2$, es decir un problema peri√≥dico donde identificamos las coordenadas enteras m√≥dulo $N\gg1$. Cuando $N\to \infty$ el potencial el√©ctrico converge al potencial en $\mathbb Z^2$. Este l√≠mite, a pesar de ser intuitivo, amerita una demostraci√≥n que no presentaremos dado que buscamos enfatizar otras ideas por el momento. La ventaja de esta aproximaci√≥n es que ahora nuestra ecuaci√≥n es un problema de √°lgebra lineal en un espacio de dimensi√≥n $N^2-2$
$$
\Delta u = 0 \text{ en } V_{N}\setminus \{(0,0),(2,1)\}, \qquad u(0,0)=0,\qquad u(2,1)=1.
$$

De las discusiones previas sabemos que a partir de la descomposici√≥n espectral del Laplaciano en $V_{N}$ podr√≠amos calcular en cambio una soluci√≥n particular de
$$
\Delta v =   1_{(0,0)}-  1_{(2,1)} \text{ en } V_{N}.
$$
Notemos que el lado derecho es de hecho perpendicular a las constantes, lo cual garantiza la existencia de soluciones. Para obtener $u$ a partir de $v$ verificamos que
$$
u(x,y) = \frac{v(x,y)-v(0,0)}{v(2,1)-v(0,0)}
$$
satisface la ecuaci√≥n requerida y entonces
$$
R_N = \frac{1}{\operatorname{div} u(0,0)} = \frac{v(2,1)-v(0,0)}{\operatorname{div} v(0,0)} = v(2,1)-v(0,0).
$$
Nuestra estrategia ser√° entonces calcular el l√≠mite de esta expresi√≥n cuando $N\to\infty$.

Procedamos a calcular el espectro del Laplaciano sobre el toro (Ejercicio \@ref(exr:espectro)). Asumamos la hip√≥tesis de \textbf{separaci√≥n de variables}
$$
\phi(x,y) = \alpha(x)\beta(y).
$$
Este tipo de funciones toman ventaja de la simetr√≠a del problema con lo cual el Laplaciano se simplifica como operadores discretos m√°s sencillos para cada factor
$$
\Delta \phi(x,y) = \alpha(x)(\beta(y-1)-2\beta(y)+\beta(y+1)) + (\alpha(x-1)-2\alpha(x)+\alpha(x+1))\beta(y).
$$

Si $\alpha$ y $\beta$ son autofunciones del Laplaciano en el grafo c√≠clico de tama√±o $N$, entonces $\phi$ es una autofunci√≥n en el toro. Tomemos de esta forma la base de Fourier
$$
\phi_{k,l}(x,y) = \omega^{kx+ly}, \qquad \omega = e^{2\pi i/N}, \qquad (k,l)\in\{0,1,\ldots,(N-1)\}^2,
$$
con autovalores $-\lambda_{k,l}$ tal que
$$
\lambda_{k,l} := 4(\sin^2(\pi k/N)+\sin^2(\pi l/N)),
$$
y normas
$$
\|\phi_{k,l}\|^2=\sum_{(x,y)\in V_N} \phi_{k,l}(x,y)\overline{\phi_{k,l}(x,y)} = N^2.
$$

---

:::{.exercise}
Verifica que a partir de las siguientes funciones tambi√©n se puede formar una base ortogonal del Laplaciano
\begin{align*}
\cos(2\pi kx/N)\cos(2\pi ly/N),\quad \cos(2\pi kx/N)\sin(2\pi ly/N),\quad \sin(2\pi kx/N)\sin(2\pi ly/N).    
\end{align*}
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

Finalmente reconstruimos la soluci√≥n particular usando la f√≥rmula de representaci√≥n

\begin{align*}
v(x,y) &= -\sum_{(x',y') \in V_N} K(x,y;x',y')( 1_{(0,0)}- 1_{(2,1)})(x',y') = K(x,y;2,1)-K(x,y;0,0).
\end{align*}
donde para $\omega = e^{2\pi i/N}$
$$
K(x,y;x',y') = \frac{1}{N^2}\sum_{(k,l)\neq (0,0)} \frac{\phi_{k,l}(x,y)\overline{\phi_{k,l}(x',y')}}{\lambda_{k,l}} = \frac{1}{4N^2}\sum_{(k,l)\neq (0,0)} \frac{\omega^{k(x-x')+l(y-y')}}{\sin^2(\pi k/N)+\sin^2(\pi l/N)}.
$$

La resistencia efectiva es calculada as√≠ por
\begin{align*}
R &= v(2,1)-v(0,0),\\
&= K(2,1;2,1)-K(2,1;0,0) - K(0,0;2,1)+K(0,0;0,0),\\
&= \frac{1}{2N^2} \sum_{(k,l)\neq (0,0)} \frac{1-\cos((2k+l)2\pi/N)}{\sin^2(\pi k/N)+\sin^2(\pi l/N)},\\
&= \frac{1}{N^2} \sum_{(k,l)\neq (0,0)} \frac{\sin^2((2k+l)\pi/N)}{\sin^2(\pi k/N)+\sin^2(\pi l/N)}.
\end{align*}
En el l√≠mite podemos entonces calcular $R$ por la integral de Riemann
$$
R = \frac{1}{\pi^2}\int_0^\pi\int_0^\pi \frac{\sin^2(2x+y)}{\sin^2x+\sin^2y}dydx
$$
Evaluamos numericamente la integral usando

```{python}
import numpy as np
from scipy.integrate import dblquad

integrando = lambda x, y : np.sin(2*x+y)**2/(np.sin(x)**2+np.sin(y)**2)
integral, error = dblquad(integrando,0,np.pi,0,np.pi)
R = integral/np.pi**2
print(R)
```

De forma alternativa es posible [calcular anal√≠ticamente la integral](https://physics.stackexchange.com/questions/2072/on-this-infinite-grid-of-resistors-whats-the-equivalent-resistance) dando como resultado
$$
R = \frac{4}{\pi}-\frac{1}{2}
$$

---

:::{.exercise}
Sea
$$
R(m,n) = \int_0^\pi\int_0^\pi \frac{\sin^2(mx+ny)}{\sin^2x+\sin^2y}dydx.
$$
Demuestra que $R:\mathbb Z^2\to \mathbb R$ es una funci√≥n arm√≥nica en $\mathbb Z^2\setminus\{(0,0)\}$.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

<!--chapter:end:05-espectro.Rmd-->

# El problema de Dirichlet

Un barrendero tiene la tarea de limpiar una dada regi√≥n (acotada) en cuarto cubierto de baldosas. Cada vez que este barre una baldosa, toda la masa que se encuentra en ella se distribuye en porciones iguales entre las cuatro baldosas adyacentes. En general, limpiar la regi√≥n es un proceso que entendemos en el l√≠mite de un n√∫mero infinito de pasos.

![](./barrendero-1.png){width=70%}

El orden en que se barren las baldosas no es conmutativo, v√©ase por ejemplo la figura a continuaci√≥n. Sin embargo, descubrimos que en el l√≠mite se recupera una cierta propiedad Abeliana: Una vez limpia la regi√≥n, la distribuci√≥n de masa alrededor de ella es independiente de como se haya barrido.

![](./barrendero2-1.png){width=70%}

El problema lo podemos modelar en un grafo general pero con la intenci√≥n de ilustrar un caso concreto pensemos en la ret√≠cula $\mathbb Z^2$ con la relaci√≥n de adyacencia $x\sim y$ cuando $\|x-y\| = 1$. Es decir que cada baldosa tiene exactamente cuatro baldosas adyacentes en cada una de las direcciones cardinales.

Sea $\mu:\mathbb Z^2\to [0,\infty)$ la distribuci√≥n de masa inicial que buscamos barrer de alg√∫n $\Omega\subseteq\mathbb Z^2$. Un plan de barridas est√° dado por una lista de baldosas $b_1,b_2,\ldots \in \Omega$, las que iremos barriendo en el orden respectivo. Si $\infty_i:\mathbb Z^2\to [0,\infty)$ denota la distribuci√≥n de masa luego del $i^{mo}$ paso, se tiene entonces la siguiente f√≥rmula recursiva comenzando de $\mu_0:=\mu$,
$$
\mu_i(x) := 
\begin{cases}
0 \text{ si } x=b_i\\
\mu_{i-1}(x) + \tfrac{1}{4}\mu_{i-1}(b_i) \text{ si } x\sim b_i\\
\mu_{i-1}(x) \text{  en cualquier otro caso}.
\end{cases}
$$

Decimos que el plan plan $b_1,b_2,\ldots \in \Omega$ barre a $\mu$ de $\Omega$ si
$$
\lim_{i\to\infty} \mu_i(x) = 0, \qquad \forall x\in \Omega.
$$

Nuestro teorema puede ser entonces formulado de la siguiente manera.

:::{.theorem #tma1}
Dado $\Omega\subseteq\mathbb Z^2$ finito y $\mu:\mathbb Z^2\to [0,\infty)$ se tiene que cualesquiera dos planes $b_1,b_2,\ldots \in \Omega$ y $b_1',b_2',\ldots \in \Omega$ que barren a $\mu$ de $\Omega$ satisfacen que los siguientes l√≠mites existen para todo $x\in \mathbb Z^2$ y
$$
\lim_{i\to \infty} \mu_i(x) = \lim_{i\to \infty} \mu'_i(x).
$$
:::

Daremos la demostraci√≥n del teorema en la Secci√≥n [Principio del m√≠nimo](#principio-del-m√≠nimo) luego de presentar y motivar algunas construcciones auxiliares.

## Ley de conservaci√≥n

Una idea √∫til es llevar el registro de cu√°nta masa ha salido de una dada baldosa $x$ hasta una dada iteraci√≥n. Para ser precisos definimos para cada sub√≠ndice $i\geq 0$ las funciones $u_i:\mathbb Z^2\to [0,\infty)$ comenzando por $u_0=0$ y de forma inductiva seg√∫n
$$
u_i := u_{i-1} + \mu_{i-1}(b_i) 1_{b_i}
$$
Observemos que para cualquier plan $b_1,b_2,\ldots \in \Omega$ se tiene necesariamente que $u_i=0$ en $\mathbb Z^2\setminus \Omega$.

La funci√≥n $u_i$ nos permite dar una f√≥rmula para la **ley de conservaci√≥n de masas**: En los primeros $i$ pasos, la masa que entra menos la que sale de una baldosa $x$ es justamente la diferencia entre las distribuciones $\mu_i$ menos $\mu_0$ en $x$
$$
\underbrace{\mu_i(x)}_{\text{masa final}}-\underbrace{\mu_0(x)}_{\text{masa inicial}} = \underbrace{\frac{1}{4}\sum_{y\sim x} u_i(y)}_{\text{masa que entra}} - \underbrace{u_i(x)}_{\text{masa que sale}} = \tfrac{1}{4}\Delta u(x)
$$
Esta puede ser demostrada por un argumento inductivo que dejamos de ejercicio.

Volviendo al modelo del barrendero, vemos que si $\mu_i \to \mu_\infty$ entonces $u_i$ tambi√©n converge a una funci√≥n $u:\mathbb Z^2\to[0,\infty)$^[Daremos una prueba rigurosa de este hecho en la Secci√≥n [Principio del M√≠nimo](#principio-del-m√≠nimo)] tal que $\tfrac{1}{4}\Delta u = \mu_\infty - \mu_0 = \mu_\infty-\mu$. Si el plan barre a $\Omega$ recuperamos el siguiente sistema de ecuaciones lineales
$$
\begin{cases}
-\tfrac{1}{4}\Delta u = -\mu \text{ en } \Omega,\\
u = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
(\#eq:lap)
$$

Veamos a grandes rasgos las ideas en la demostraci√≥n del Teorema \@ref(thm:tma1) a partir de estas construcciones. Si el sistema que satisface $u$ tiene una \underline{√∫nica} soluci√≥n, entonces esta funci√≥n queda determinada por $\mu$ y $\Omega$ y es independientemente del plan. Usando que $\mu_\infty = \mu + \lim_{i\to\infty} \tfrac{1}{4}\Delta u_i = \mu+\tfrac{1}{4}\Delta u$ vemos que tambi√©n $\mu_\infty$ es independientemente del plan, lo cual concluir√≠a la demostraci√≥n.

---

:::{.exercise}
Asumiendo la estrategia esbozada en esta secci√≥n, calcula la distribuci√≥n final $\mu_\infty$ si $\Omega = \{(0,0),(1,0),(0,1)\}$ y $\mu= 1_\Omega$.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

## Existencia y unicidad de soluciones

El principio del m√≠nimo nos permitir√° demostrar que el sistema dado por \@ref(eq:lap) no tiene m√°s de una soluci√≥n. Para problemas lineales con igual n√∫mero (finito) de ecuaciones e inc√≥gnitas, esto equivale a decir que el sistema de hecho siempre tiene soluci√≥n.

### Principio del m√≠nimo

La idea consiste en el siguiente principio general: Si $u:V\to\mathbb R$ es no-negativa en $V\setminus \Omega$ y satisface $\Delta u\leq 0$ en $\Omega$ entonces $u$ es necesariamente no-negativa en $\Omega$. Como veremos en la siguiente demostraci√≥n, esto es una manifestaci√≥n del criterio de la segunda derivada (discreto): $\Delta u(x^*)\geq 0$ si $u$ alcanza su m√≠nimo en $x^*$.

:::{.lemma name="Principio del M√≠nimo"}
Sea $u:V\to\mathbb R$ tal que para $\Omega\subseteq V$ finito $\Delta u \leq 0$ en $\Omega$. Entonces
$$
\inf_{V\setminus\Omega} u \geq 0 \qquad\Rightarrow\qquad \min_{\Omega} u\geq 0.
$$
:::

:::{.proof}
Asumamos por contradicci√≥n que $m:= \min_{\Omega} u < 0$ y sea $\Omega'=\{x\in \Omega : u(x) = m\}$ finito y no vac√≠o, m√°s a√∫n sabemos que es finito dado que $\Omega'\subseteq\Omega$. Tomemos ahora $x^*\in \Omega'$ tal que existe $y\sim x^*$ para el cual $u(y)>u(x^*)$. Vemos ahora que tenemos la siguiente contradicci√≥n a partir de evaluar la ecuaci√≥n $\Delta u\leq 0$ sobre $x^*$
$$
0 < \sum_{z\sim x^*} (u(z) -u(x^*)) = \Delta u(x^*) \leq 0.
$$
:::

:::{.corollary name="Existencia y unicidad de soluciones"}
Para $\Omega\subseteq V$ finito y $\mu,\varphi:V\to\mathbb R$ el siguiente sistema tiene soluci√≥n √∫nica
$$
\begin{cases}
\Delta u = \mu \text{ en } \Omega,\\
u = \varphi \text{ en } V\setminus \Omega.
\end{cases}
$$
:::

:::{.proof}
Basta con demostrar que el sistema lineal dado por las ecuaciones en $\Omega$, con $N=|\Omega|$ ecuaciones e inc√≥gnitas, tiene a lo sumo una soluci√≥n. En otras palabras, el operador lineal asociado de $\mathbb R^N$ en si mismo es inyectivo, y por lo tanto tambi√©n es biyectivo gracias al teorema fundamental del √°lgebra lineal.

Si $u,v:V\to \mathbb R$ son dos soluciones, entonces $w:=u-v$ satisface $\Delta w=0$ en $\Omega$ y $w = 0$ en $V\setminus \Omega$. Gracias al principio del m√≠nimo obtenemos que $w\geq 0$ en $\Omega$ y por lo tanto en todo $V$. Si aplicamos el mismo razonamiento a $-w$ obtenemos la otra desigualdad de donde concluimos $w=0$, es decir que queda establecida la unicidad de soluciones y con ello la demostraci√≥n.
:::

---

:::{.exercise}
Demuestra que si $\Omega = \{x = (x_1,x_2) \in \mathbb Z^2 : x_2>0\}$ entonces existen por lo menos dos soluciones distintas del problema
$$
\begin{cases}
\Delta u = 0 \text{ en } \Omega,\\
u = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$
Es decir que la hip√≥tesis de que $\Omega$ sea finito es necesaria para la unicidad de soluciones.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.proof name="Teorema \@ref(thm:tma1)"}
Construimos de forma recursiva y partiendo de $u_0 := 0$ las funciones $u_i := u_{i-1} + \mu_{i-1} 1_{b_i}$ las cuales verifican
$$
\begin{cases}
\tfrac{1}{4}\Delta u_i = \mu_i-\mu \text{ en } \Omega,\\
u_i = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$
Definimos tambi√©n $u:\mathbb Z^2\to \mathbb R$ como la soluci√≥n de
$$
\begin{cases}
\tfrac{1}{4}\Delta u = -\mu \text{ en } \Omega,\\
u = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$

Debemos corroborar entonces los siguientes puntos:

1. $\mu_{\infty} := \lim_{i\to\infty}\mu_i$ est√° bien definido.

1. $u_\infty := \lim_{i\to\infty}u_i$ est√° bien definido.

1. $u_\infty = u$.

Para ver el primer punto basta con fijarse en el comportamiento de $\mu_i$ en $\mathbb Z^2\setminus \Omega$, ya que sabemos por hip√≥tesis que estas tienden a cero en $\Omega$. En $\mathbb Z^2\setminus \Omega$ se tiene que $\mu_i$ es una sucesi√≥n no-decreciente de funciones que est√° mayorizada por $\mu + \sum_{x\in\Omega} \mu(x)$.

Como $u_i$ es no-decreciente, basta con probar que $u\geq u_i$ para demostrar el segundo punto y adicionalmente obtener $u\geq u_\infty$. La diferencia $v_i := u-u_i$ satisface
$$
\begin{cases}
\Delta v_i = \Delta u - \Delta u_i = -4\mu_i \leq 0 \text{ en } \Omega,\\
v_i = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$
Gracias principio del m√≠nimo se deduce que $\min_\Omega v_i \geq 0$ y por lo tanto $u\geq u_i$.

Dado que $b_1,b_2,\ldots\in\Omega$ barre a $\mu$ de $\Omega$ tenemos que tomando $i\to\infty$ en el sistema para $u_i$
$$
\begin{cases}
\tfrac{1}{4}\Delta u_\infty = -\mu \text{ en } \Omega,\\
u_\infty = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$
Por la unicidad de soluciones del problema lineal llegamos a que necesariamente $u_\infty=u$.

Finalmente para concluir la demostraci√≥n podemos calcular $\mu_\infty$ a partir de $\mu_\infty = \mu+\tfrac{1}{4}\Delta u_\infty$. Recordemos que $u_\infty=u$ est√° igualmente definido por un sistema de ecuaciones lineales que depende solamente de $\Omega$ y $\mu$ y no del plan. Esto indica que $\mu_\infty$ tambi√©n est√° definida independientemente del plan.
:::

Nuestro teorema garantiza que para cualquier $\Omega\subseteq\mathbb Z^2$ finito y $\mu:\mathbb Z^2\to [0,\infty)$ se tiene que si $\mu$ puede ser barrido de $\Omega$, entonces la distribuci√≥n de masa que queda por fuera de $\Omega$ es independiente del plan. Queda abierta la pregunta de si podemos en todo caso barrer o no a $\mu$ de $\Omega$.

:::{.theorem}
Dado $\Omega\subseteq\mathbb Z^2$ finito y $\mu:\mathbb Z^2\to[0,\infty)$ existe un plan $b_1,b_2,\ldots\in\Omega$ que barre a $\mu$ de $\Omega$.
:::

:::{.proof}
Sea $b_1,b_2,\ldots\in\Omega$ un plan que recorre cada baldosa un n√∫mero infinito de veces. Ciertamente estos planes existen incluso si $\Omega$ es infinito (usando un argumento de diagonal de Cantor). Esta condici√≥n implica que para cada $x\in\Omega$, existe un n√∫mero infinito de sub-√≠ndices tales que $\mu_i(x)=0$. Basta probar as√≠ que $\mu_\infty = \lim_{i\to\infty}\mu_i$ existe para deducir que necesariamente $\mu_\infty=0$ en $\Omega$.

Definimos $u_i$ y $u$ exactamente como en la demostraci√≥n anterior. Recordemos que $u_i$ es no-decreciente y (por el principio del m√≠nimo) acotada por $u$, por lo tanto $u_\infty:=\lim_{i\to\infty}u_i$ est√° bien definida. Dado que $\mu_i = \mu + \Delta u_i$ tenemos que la existencia del l√≠mite para $\mu_i$ queda demostrada por la existencia del l√≠mite para $u_i$.
:::

---

:::{.exercise}
Demuestra que existe un plan que barre a $\mu= 1_{(1,0)}$ de $\Omega = \mathbb Z^2\setminus \{(0,0)\}$.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.exercise}
Sea $\Omega\subseteq\mathbb Z^2$ finito, $\mu:\mathbb Z^2\to[0,\infty)$ y $\mu_\infty$ la distribuci√≥n que resulta al barrer $\mu$ de $\Omega$. Demuestra ley de conservaci√≥n de masa dada por
$$
\sum_{x\in\mathbb Z^2} \mu_\infty(x) = \sum_{x\in \mathbb Z^2} \mu(x).
$$
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.exercise}
Sea $\mu= 1_{(1,0)}$ y $\mu_\infty$ la distribuci√≥n que resulta al barrer $\mu$ de $\Omega= \mathbb Z^2\setminus \{(0,0)\}$. ¬øSer√° cierto que $\mu_\infty(0,0) = 1$, o habr√° masa que escapa a infinito?^[**Pista:** El problema se puede reducir a verificar que $\Delta u(0,0) = -\Delta u(1,0)$. La funci√≥n $u$ parece tener una simetr√≠a en el eje $x=1/2$ la cual podr√≠a ser demostrada por un resultado de unicidad (Liouville): Las funciones arm√≥nicas y acotadas en $\mathbb Z^2$ son √∫nicamente las constantes.]
:::

<details>
<summary>Soluci√≥n</summary>
</details>

### M√©todo de Balayage

Poincar√© propuso a finales del siglo XIX el siguiente algoritmo para resolver el sistema
$$
\begin{cases}
\Delta u = 0 \text{ en } \Omega,\\
u = \varphi \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}.
$$

Asumamos $\Omega$ finito y sea $\partial\Omega := \{y \in \mathbb Z^2\setminus \Omega : \exists x\in \Omega \text{ adyacente a } y\}$. Comenzamos entonces a partir de
$$
u_0(x) := \begin{cases}
\max_{\partial\Omega}\varphi \text{ si } x\in\Omega,\\
\varphi(x) \text{ en cualquier otro caso}.
\end{cases},
$$
tal que
$$
\begin{cases}
\Delta u_0 \leq 0 \text{ en } \Omega,\\
u_0 = \varphi \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$
Hagamos notar que por el principio del m√≠nimo, $u_0\geq \min_{\partial\Omega} \varphi$.

Sea $b_1,b_2,\ldots \in \Omega$ tal que para cada $x\in \Omega$ el conjunto de √≠ndices $\{i : b_i=x\}$ es infinito. Definimos ahora $u_i$ modificando a $u_{i-1}$ en $b_i$ de forma que $\Delta u_i(b_i) =0$, es decir
$$
u_i(x) := \begin{cases}
\frac{1}{4} \sum_{y\sim b_i} u_{i-1}(y) \text{ si } x = b_i,\\ 
u_{i-1}(x) \text{ en cualquier otro caso}.
\end{cases}
$$
En otras palabras, en el paso $i$ estamos barriendo el Laplaciano de $u_{i-1}$ en $b_i$.

Se puede demostrar por inducci√≥n que cada $u_i$ satisface
$$
\begin{cases}
\Delta u_i \leq 0 \text{ en } \Omega,\\
u_i = \varphi \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$
Gracias a esto observamos que la sucesi√≥n es decreciente. Tambi√©n, cuando la restringimos a $\Omega$, est√° acotada por debajo por $\min_{\partial\Omega}\varphi$. Como consecuencia converge a la soluci√≥n que se busca calcular.

---

:::{.exercise}
Implementa el m√©todo de balayage. El programa debe recibir un conjunto $\Omega\subseteq\mathbb Z^2$ finito junto con $\varphi:\partial\Omega\to\mathbb R$, debe devolver la soluci√≥n correspondiente del problema de Dirichlet $u:\Omega\to \mathbb Z^2$.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

## F√≥rmulas de representaci√≥n

### La funci√≥n de Green

Para $\Omega\subseteq V$ finito, definimos la **funci√≥n de Green** $G_\Omega:V^2\to\mathbb R$ tal que $u(y)=G_\Omega(x,y)$ es la soluci√≥n de
$$
\begin{cases}
\Delta u = - 1_x \text{ en } \Omega,\\
u=0 \text{ en } V\setminus \Omega.
\end{cases}
$$

---

:::{.example}
Si $\Omega=\{x_0\}$, entonces
$$
G_\Omega(x,y) = \begin{cases}
1/\deg(x_0) \text{ si } y=x=x_0,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$
donde $\deg(x_0)$ es el grado del v√©rtice $x_0$, es decir cuantas aristas llegan y salen de $x_0$.
:::

Igualmente definimos $G_\Omega$ sobre una distribuci√≥n $\mu:V\to\mathbb R$ tal que $u(y)=G_\Omega(\mu,y)$ es la soluci√≥n de
$$
\begin{cases}
\Delta u = -\mu \text{ en } \Omega,\\
u=0 \text{ en } V\setminus \Omega.
\end{cases}
$$
Es decir que en particular $G_\Omega(x,\cdot) = G_\Omega( 1_x,\cdot)$.

Gracias al principio de superposici√≥n tenemos que a partir de esta podemos resolver 
$$
\begin{cases}
\Delta u = -\mu \text{ en } \Omega,\\
u=0 \text{ en } V\setminus \Omega.
\end{cases}
$$
usando la f√≥rmula de representaci√≥n
$$
u(y) = \sum_{x\in V} \mu(x)G_\Omega(x,y) = G_\Omega(\mu,y).
$$

---

:::{.example}
Para el problema del barrendero ($V=\mathbb Z^2$) tenemos que $u(y)= 4G_\Omega(\mu,y)$ indica cuanta masa sale de $y$ cuando se barre $\mu$ de $\Omega$.
:::

---

:::{.example}
Veamos como calcular la funci√≥n de Green para $\Omega = [1,n] \subseteq V=\mathbb Z$ con $n\geq 1$ y la relaci√≥n de adyacencia dada por $x\sim y$ si $|x-y|=1$. Denotamos a lo largo de este ejemplo a $g_{i,j} := G_\Omega(i,j)$ con $i,j\in \{0,1,\ldots,n,n+1\}$, los valores de inter√©s ($G_\Omega(x,y) = 0$ fuera de estos casos).

Para $j\in[1,i-1]$, tenemos la ecuaci√≥n
$$
2g_{i,j} = g_{i,j-1}+g_{i,j+1},
$$
la cual junto a $g_{i,0} = 0$ indica que $g_{i,j}=\alpha j$ para $j\in[0,i]$.

Para $j\in[i+1,n]$, tenemos tambi√©n la ecuaci√≥n
$$
2g_{i,j} = g_{i,j-1}+g_{i,j+1},
$$
la cual junto a $g_{i,n+1} = 0$ indica que $g_{i,j}=\beta(n+1-j)$ para $j\in[i,n+1]$.

Por un lado sabemos que $\alpha i = \beta(n+1-i)$ y adicionalmente usando la ecuaci√≥n para $j=i$
$$
-1=g_{i,i-1}+g_{i,i+1}-2g_{i,i} = -\alpha-\beta
$$
obtenemos que $\alpha=(n+1-i)/(n+1)$ y $\beta=i/(n+1)$. En conclusi√≥n
$$
g_{i,j} = \begin{cases}
(n+1-i)j/(n+1) \text{ si } j\in[1,i),\\
(n+1-j)i/(n+1) \text{ si } j\in(i,n],\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$
:::

---

:::{.exercise}
Calcula la funci√≥n de Green para $\Omega = [1,n]\times\{0\}\cap \mathbb Z^2$.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

Los ejemplos previos sugieren la siguiente simetr√≠a
$$
G_\Omega(x,y)=G_\Omega(y,x).
$$

:::{.proof}
Usaremos en repetidas ocasiones que si alguno de los nodos $x$ o $y$ est√°n en $V\setminus \Omega$ se tiene autom√°ticamente que $G_\Omega(x,y)=G_\Omega(y,x)=0$.

Basta ver que $(x,y) \mapsto G_\Omega(y,x)$ satisface las mismas condiciones para la definici√≥n de $G_\Omega$, es decir que $v(y) = G_\Omega(y,x)$ cumple
$$
\begin{cases}
\Delta v = -  1_x \text{ en } \Omega,\\
v = 0 \text{ en } V\setminus \Omega.
\end{cases}
$$

Las condici√≥n de borde ya sabemos que se satisface. Para ver la ecuaci√≥n asumimos que $x\in \Omega$ (el otro caso siendo tivial) y comprobaremos que $w(x) = \Delta_1 G(y,x)+ 1_y(x) = \Delta_1 G(y,x)+ 1_x(y)=0$ para cualquier $y\in \Omega$. Por un lado tenemos la condici√≥n de borde
$$
w(x) = 0+0 = 0 \text{ si } x\in V\setminus \Omega.
$$
Por el otro tenemos que 
$$
\Delta w (x) = \Delta_2\Delta_1G(y,x)+\Delta  1_y(x) = \Delta_1\Delta_2 G(y,x)+\Delta  1_y(x) = \Delta  1_{y}(x) - \Delta  1_y(x)=0.
$$
Gracias a la unicidad de la soluci√≥n trivial podemos finalmente concluir la demostraci√≥n.
:::

### El n√∫cleo de Poisson

Para $\Omega\subseteq V$ finito, $x,y \in V$ definimos el **n√∫cleo de Poisson**
$$
P_\Omega(x,y) :=  1_x (y) + \Delta_2 G_\Omega(x,y).
$$
Observemos los valores no triviales de $P_\Omega(x,y)$ ocurren cuando $x\in \Omega$ y $y\in V\setminus \Omega$. Si $x\in V\setminus \Omega$ entonces $G_\Omega(x,\cdot) = 0$ y $P_\Omega(x,y) =  1_x (y)$. Si $y\in \Omega$ entonces $\Delta_2 G_\Omega(x,y) = - 1_x (y)$ y $P_\Omega(x,y)=0$.

En particular, la simetr√≠a de $G$ **no** implica la propiedad an√°loga para $P_\Omega$.

Igualmente extendemos la construcci√≥n para $\mu:V\to \mathbb R$ usando
$$
P_\Omega(\mu,y) :=  \mu(y) + \Delta_2 G_\Omega(\mu,y).
$$

---

:::{.example}
Si $\Omega=\{x_0\}$, entonces
$$
P_\Omega(x,y) = \begin{cases}
1/\deg(x_0) \text{ si } x=x_0,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$
:::

---

:::{.example}
Para el problema del barrendero ($V=\mathbb Z^2$) tenemos que al barrer $\mu$ de $\Omega$ la distribuci√≥n de masa que resulta est√° dada por $P_\Omega(\mu)$.
:::

---

De la linealidad del problema junto con la existencia y unicidad de soluciones se deduce que
$$
P_\Omega(\alpha\mu+\beta\nu) = \alpha P_\Omega(\mu) +\beta P_\Omega(\nu).
$$

Gracias a la interpretaci√≥n de n√∫cleo de Poisson en t√©rminos del problema del barrendero es natural pensar que dados $\Omega_1\subseteq\Omega_2\subseteq V$ finitos, se tiene la siguiente propiedad
$$
P_{\Omega_2} = P_{\Omega_2}\circ P_{\Omega_1}.
$$
Denominaremos a esta como la **propiedad de semi-grupo**.

\begin{proof}
Sea $\mu:V\to[0,\infty)$ arbitraria y $u,v,w:V\to\mathbb R$ tales que
$$
\begin{cases}
\Delta u = -\mu \text{ en }\Omega_1,\\
u=0 \text{ en } V\setminus \Omega_1.
\end{cases}\qquad
\begin{cases}
\Delta v = -P_{\Omega_1}(\m) \text{ en }\Omega_2,\\
v=0 \text{ en } V\setminus \Omega_2.
\end{cases}\qquad
\begin{cases}
\Delta w = -\mu \text{ en }\Omega_2,\\
w=0 \text{ en } V\setminus \Omega_2.
\end{cases}
$$
por definici√≥n sabemos as√≠ que
$$
P_{\Omega_1}(\m) = \mu + \Delta u, \qquad P_{\Omega_2}(P_{\Omega_1}(\m)) = P_{\Omega_1}(\m)+\Delta v,\qquad P_{\Omega_2}(\m) = \mu+\Delta w.
$$
Basta con demostrar que $w=u+v$ para obtener de esta forma que
$$
P_{\Omega_2}(\m) = \mu+\Delta w = \mu+\Delta u+\Delta v = P_{\Omega_1}(\m)+\Delta v = P_{\Omega_2}(P_{\Omega_1}(\m)).
$$

Ambas funciones $w$ y $u+v$ se anulan en $V\setminus \Omega$, veamos entonces que $\Delta (u+v) = \Delta w = -\mu$ en $\Omega_2$ para concluir por unicidad la identidad esperada. En $\Omega_1\subseteq\Omega_2$ tenemos que $P_{\Omega_1}(\m) = 0$ y por lo tanto $\Delta(u+v) = -\mu + P_{\Omega_1}(\m) = -\mu$. En el complemento $\Omega_2\setminus \Omega_1$ usamos que $\Delta v = -P_{\Omega_1}(\m) = -(\mu + \Delta u)$ y por lo tanto $\Delta(u+v) = -\mu$. Esto concluye la demostraci√≥n.
\end{proof}

Como consecuencia de la linealidad y la propiedad de semi-grupo tenemos la siguiente **interpretaci√≥n dual del n√∫cleo de Poisson**: Para $y\in V$ fijo, la funci√≥n $u(x) = P_\Omega(x,y)$ es la soluci√≥n de
$$
\begin{cases}
\Delta u = 0 \text{ en } \Omega,\\
u= 1_{y} \text{ en } V\setminus \Omega.
\end{cases}
$$
Esta formulaci√≥n es m√°s sencilla de recordar y conveniente al momento de calcular $P_\Omega$ sin necesidad de calcular la funci√≥n de Green.

\begin{proof}
La condici√≥n de borde se sigue de la definici√≥n de $P_\Omega$ sin mucho problema. Preferimos en cambio dar una justificaci√≥n en t√©rminos del problema del barrendero. Cuando $x\in V\setminus \Omega$ entonces no hay que hacer nada para barrer $\mu= 1_x$ de $\Omega$, por lo tanto $P_\Omega(x,y)= 1_x(y) =  1_y(x)$ es el dato de borde esperado.

Para verificar la ecuaci√≥n usamos la propiedad de semi-grupo con $\Omega_1=\{x\}\subseteq\Omega$ y $\mu= 1_x$ tal que
$$
P_\Omega( 1_x) = P_\Omega(P_{\{x\}}( 1_x)) = P_\Omega\1\sum_{y\sim x} \frac{1}{\deg(x)} 1_y\2 = \frac{1}{\deg(x)}\sum_{y\sim x} P_\Omega( 1_y).
$$
En otras palabras $\Delta_x P_\Omega(x,y) = 0$.
\end{proof}

Como consecuencia de la formulaci√≥n dual de n√∫cleo de Poisson y el principio de superposici√≥n tenemos la **f√≥rmula de representaci√≥n**
$$
u(x) = \sum_{y\in V} \varphi(y) P_\Omega(x,y) \qquad\Leftrightarrow\qquad\begin{cases}
\Delta u = 0 \text{ en } \Omega,\\
u= \varphi \text{ en } V\setminus \Omega.
\end{cases}
$$
M√°s a√∫n, si a esta a√±adimos la f√≥rmula de representaci√≥n para la funci√≥n de Green, junto con su propia simetr√≠a, obtenemos que
$$
u(x) = \sum_{y\in V} \varphi(y) P_\Omega(x,y)+\mu(y) G_\Omega(x,y) \qquad\Leftrightarrow\qquad \begin{cases}
\Delta u = -\mu \text{ en }\Omega,\\
u=\varphi \text{ en } V\setminus \Omega.
\end{cases}.
$$

---

:::{.example}
Veamos como calcular el n√∫cleo de Poisson para $\Omega = [1,n] \subseteq V=\mathbb Z$ con $n\geq 1$ y la relaci√≥n de adyacencia dada por $x\sim y$ si $|x-y|=1$. Denotamos a lo largo de este ejemplo a $p_{i,j} := P_\Omega(i,j)$ con $i,j\in \{0,1,\ldots,n,n+1\}$, los valores de inter√©s ($P_\Omega(x,y) = 0$ fuera de estos casos). En realidad solamente debemos calcular $p_{i,0}$ y $p_{i,n+1}$, los dem√°s valores tambi√©n se anulan.

Para $j=0$, tenemos la ecuaci√≥n
$$
2p_{i,0} = p_{i-1,0}+p_{i+1,0},
$$
la cual junto a $p_{0,0} = 1$ y $p_{n+1,0}=0$ indica que $p_{i,0}=(n+1-i)/(n+1)$ para $i\in[0,n+1]$.\\

Para $j=n+1$, tenemos tambi√©n la ecuaci√≥n
$$
2p_{i,n+1} = p_{i-1,n+1}+p_{i+1,n+1},
$$
la cual junto a $p_{0,n+1} = 0$ y $p_{n+1,n+1}=1$ indica que $p_{i,n+1}=i/(n+1)$ para $i\in[0,n+1]$.
:::

---

:::{.exercise}
Calcula el n√∫cleo de Poisson para $\Omega=[1,n]\times \{0\}\cap \mathbb Z^2$.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

## Caminatas Aleatorias

Consideremos ahora un problema que afinar√° nuestra intuici√≥n con respecto a las herramientas que hemos presentado. Volvemos a trabajar en la ret√≠cula $\mathbb Z^2$ a pesar de que el modelo es claramente generalizable a otros grafos.

Un borracho parte de una posici√≥n inicial $x\in\mathbb Z^2$ y se mueve con igual probabilidad a cualquiera de sus cuatro posiciones adyacentes. Es decir que si $x_i$ es la posici√≥n (aleatoria) del borracho luego de $i$ pasos, tenemos que las **probabilidades de transici√≥n** est√°n dadas por
$$
\mathbb P(x_i = y \ | \ x_{i-1} = x) = \begin{cases}
1/4 \text{ si } y \sim x,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$

Dado $\Omega \subseteq\mathbb Z^2$, sea $\tau$ el n√∫mero de pasos que toma el borracho para salir de $\Omega$ por primera vez, tambi√©n conocido como el **tiempo de salida** de la caminata
$$
\tau := \min\{i \geq 0 : x_i \in \mathbb Z^2\setminus \Omega\}.
$$
Para nuestro modelo, podemos interpretar $\mathbb Z^2\setminus \Omega$ como la regi√≥n en la ciudad $\mathbb Z^2$ donde hay ley seca. El borracho pasea en $\Omega$ y una vez que sale de $\Omega$ se queda dormido o lo atrapa la polic√≠a.

Dado $A \subseteq\mathbb Z^2$ (quiz√°s sea la casa del nuestro protagonista) queremos calcular la probabilidad de que el paseo en $\Omega$ termine (felizmente) en $A$ dado que comienza en $x$, es decir
$$
p(x) := \mathbb P(x_\tau \in A \ | \ x_0 = x).
$$

![](./drunk-1.png)

Si inicialmente $x \in \mathbb Z^2\setminus\Omega$, tenemos que $x_\tau =x_0=x$ y por lo tanto $p=  1_A$. Si en cambio $x \in \Omega$, la probabilidad $p(x)$ puede ser calculada si conocemos los valores de $p(y)$ para $y\sim x$. Para $y\sim x$ fijo, tenemos que con probabilidad $1/4$ se tiene que $x_1=y$, y a partir de $y$ tenemos que el paseo en $\Omega$ sale por $A$ con probabilidad $p(y)$. En otras palabras
$$
p(x) = \frac{1}{4}\sum_{y\sim x}p(y).
$$

En t√©rminos del Laplaciano podemos caracterizar a la probabilidad $p$ como la soluci√≥n del sistema
$$
\begin{cases}
\Delta p = 0 \text{ en } \Omega,\\
p =  1_A \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}.
$$
Cuando $A=\{y\}$ conseguimos interpretar al n√∫cleo de Poisson $P_\Omega(x,y) = p(x)$ como la probabilidad de que la caminata que comienza en $x$ termine en $y$. Esto es una probabilidad de transici√≥n para el tiempo aleatorio $\tau$
$$
P_\Omega(x,y) = \mathbb P(x_\t=y\ | \ x_0=x).
$$
La interpretaci√≥n probabilista de la f√≥rmula de representaci√≥n para el n√∫cleo de Poisson est√° dada en cambio por el valor esperado
$$
u(x) = \mathbb E(\varphi(x_\tau) \ | \ x_0=x) \qquad \Leftrightarrow\qquad \begin{cases}
\Delta u = 0 \text{ en }\Omega,\\
u=\varphi \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$

---

:::{.exercise}
Dos borrachitos se encuentran paseando en la avenida $\Omega = [1,n]\times \{0\} \cap \mathbb Z^2$ con $n\geq 2$. Uno parte de $x=(1,0)$, el otro de $y = (n,0)$, y ambos toman pasos simult√°neamente en $\mathbb Z^2$ con igual probabilidad en las cuatro direcciones cardinales. Da una f√≥rmula para la probabilidad $p(n)$ de que se encuentren en $\Omega$ (es decir que ambos coinciden en la misma casilla al mismo tiempo, no vale que se crucen) antes de que alguno de ellos salga de $\Omega$.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

Dado $A\subseteq\mathbb Z^2$, otra variable aleatoria de inter√©s es el n√∫mero de veces que encontramos $x_i \in A$ para $i < \tau$, es decir antes de salir de la regi√≥n $\Omega$. Esta variable tambi√©n se conoce como el **tiempo de ocupaci√≥n** de $A$ y est√° definida de forma precisa por
$$
N := \sum_{i=0}^{\tau-1}  1_A(x_i). 
$$

El valor esperado en funci√≥n de la posici√≥n inicial de la caminata
$$
n(x) := \mathbb E(N \ | \ x_0=x),
$$
tambi√©n satisface un sistema de ecuaciones lineales
$$
\begin{cases}
\tfrac{1}{4}\Delta n = - 1_A \text{ en } \Omega,\\
n = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}.
$$

Por un lado la condici√≥n de borde es autom√°tica puesto que si $x_0=x\in \mathbb Z^2\setminus\Omega$ entonces como ya est√° fuera de $\Omega$, nunca puede visitar a $A$ en su paseo (inexistente) por $\Omega$. Por otro lado, para $x\in \Omega$, $n(x)$ se puede obtener a partir de los valores de $n(y)$ para $y\sim x$. Dado $y\sim x$, la probabilidad de que $x_1=y$ es un cuarto, y a partir de ac√° consideramos dos casos:

- Si $x\in A$ entonces el tiempo de ocupaci√≥n partiendo de $x$ es uno m√°s que el tiempo de ocupaci√≥n partiendo de $y$.

- Si $x\in \Omega\setminus A$, el tiempo de ocupaci√≥n partiendo de $x$ es el mismo tiempo de ocupaci√≥n partiendo de $y$.

Tomando los valores esperados
$$
n(x) =  1_A(x) + \frac{1}{4}\sum_{y\sim x} n(y).
$$
Lo cual es equivalente a $\tfrac{1}{4}\Delta n = - 1_A$ en $\Omega$. Es decir que $n=4G_\Omega( 1_A)$ est√° dado en t√©rminos de la funci√≥n de Green.

En t√©rminos probabilistas interpretamos la f√≥rmula de representaci√≥n para la funci√≥n de Green como,
$$
u(x) = \mathbb E\left(\sum_{i=0}^{\tau-1}\mu(x_i) \ | \ x_0=x\right) \qquad\Leftrightarrow\qquad \begin{cases}
\frac{1}{4}\Delta u = -\mu \text{ en } \Omega,\\
u=0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}.
$$

Finalmente observamos que la simetr√≠a de la funci√≥n de Green se interpreta como una propiedad de reversibilidad para las caminatas aleatorias. Es decir que el n√∫mero promedio de veces que una caminata que comienza en $x$ visita a $y$ antes de salir de $\Omega$ ($G_\Omega(x,y)$) es igual al n√∫mero promedio de veces que una caminata que comienza en $y$ visita a $x$ antes de salir de $\Omega$ ($G_\Omega(y,x)$). Esto se debe a que las caminatas de $x$ a $y$ que permanecen en $\Omega$ est√°n en biyecci√≥n con las caminatas de $y$ a $x$ que permanecen en $\Omega$, simplemente cambiando la orientaci√≥n.

<!--chapter:end:06-prob_dirchlet.Rmd-->

# Optimizaci√≥n

Consideremos una vez m√°s el grafo $G=(V,E)$. Otra perspectiva para el Laplaciano aparece cuando consideramos la **energ√≠a de Dirichlet** para una funci√≥n $u:V\to \mathbb R$
$$
\mathcal E[u] := \frac{1}{2}\sum_{e\in E} (Du(e))^2.
$$
Recordemos que podemos pensar igualmente a $\mathcal E$ como una funci√≥n de $\mathbb R^{|V|}$ a $\mathbb R$, y como tal podemos calcular su gradiente en una dada $u$ como un vector de $\mathbb R^{|V|}$ o equivalentemente una funci√≥n real sobre $V$. Dado $x\in V$
$$
D\mathcal E[u](x) = \left.\frac{d}{d\epsilon}\right|_{\epsilon=0}\mathcal E[u+\epsilon 1_{x}] = \sum_{e\in E} Du(e) D 1_{x}(e).
$$

Dado que
$$
D 1_{x}(e) = \begin{cases}
1 \text{ si } e_+=x,\\
-1 \text{ si } e_-=x,\\
0 \text{ en cualquier otro caso},\\
\end{cases}
$$
llegamos a que
$$
D\mathcal E[u](x) = \sum_{e_+=x} Du(e) - \sum_{e_-=x} Du(e) = -\operatorname{div}(Du)(x) = -\Delta u(x).
$$

---

:::{.exercise}
Sea $f:V\to \mathbb R$ y $\mathcal F:\mathbb R^V\to \mathbb R$ tal que
$$
\mathcal F[u] = \mathcal E[u] + \sum_{x\in V} f(x)u(x).
$$
Demuestra que $\mathcal F$ es acotada por debajo si y solo si $\sum_{x\in V} f(x)=0$
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.exercise}
Demuestra que si $\partial_t^2u=\Delta u$ entonces la energ√≠a total del sistema definida a continuaci√≥n permanece constante
$$
E = \underbrace{\frac{1}{2}\sum_{x\in V} (\partial_t u(x))^2}_{\text{Cin√©tica}} + \underbrace{\mathcal E[u]}_{\text{Potencial}}.
$$
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.example}
Modelamos una imagen en blanco y negro est√° dada por una funci√≥n $u:V\to [0,1]$ definida sobre la ret√≠cula $V = \mathbb Z^2\cap [1,N]^2$. El problema de restauraci√≥n de im√°genes consiste en proponer una imagen $u$ que aproxime una dada imagen $f$ que quiz√°s est√© contaminada con alg√∫n tipo de ruido.

Por ejemplo, podemos proponer $u$ como aquella que minimiza el funcional
$$
\mathcal F[u] = \frac{1}{2}\sum_{x\in V} (u(x)-f(x))^2+\alpha(Du(x))^2.
$$
El primer t√©rmino penaliza el funcional cuando $u$ se aleja de la se√±al dada $f$ y se conoce como el t√©rmino de fidelidad. El segundo t√©rmino penaliza las oscilaciones de $u$ y se conoce como el t√©rmino de regularizaci√≥n. El par√°metro $\alpha>0$ debe ser ajustado emp√≠ricamente para obtener un balance entre la fidelidad de la imagen y la regularizaci√≥n.

Tenemos entonces la ecuaci√≥n de punto cr√≠tico la cual debe satisfacerse para todo $x\in V$
$$
0 = D\mathcal F[u](x) = u(x)-f(x) - \alpha\Delta u(x).
$$
Observemos que $\Delta$ posee autovalores negativos, esto indica que el operador $I-\alpha\Delta$ tiene autovalores estrictamente positivos, en particular la ecuaci√≥n $u-\alpha\Delta u=f$ tiene una √∫nica soluci√≥n para $f:V\to \mathbb R$ arbitraria.
:::

---

:::{.exercise}
El t√©rmino de penalizaci√≥n dado por la energ√≠a de Dirichlet es conveniente al momento de calcular el gradiente, sin embargo en la pr√°ctica este difumina los contornos. Una mejor alternativa es usar en t√©rmino de **variaci√≥n total**
$$
\mathcal F[u] = \sum_{x\in V} \frac{1}{2}(u(x)-f(x))^2+\alpha|Du(x)|.
$$
Calcula las ecuaciones de punto cr√≠tico de $\mathcal F$.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.exercise}
El t√©rmino de variaci√≥n total tiene la desventaja de no ser diferenciable en todos lados. Una alternativa consiste en tomar para $\epsilon>0$ peque√±o
$$
\mathcal F[u] = \sum_{x\in V} \frac{1}{2}(u(x)-f(x))^2+\alpha\sqrt{(Du(x))^2+\epsilon^2}.
$$
Calcula las ecuaciones de punto cr√≠tico de $\mathcal F$.
:::


<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.example}
Un dado conjunto de datos puede estar dado en t√©rminos de un grafo $G=(V,E)$ para el cual pensamos que dos v√©rtices adyacentes son de alguna forma semejantes. El prop√≥sito es clasificar los v√©rtices de acuerdo a $k$ etiquetas que modelamos usando los vectores can√≥nicos $\{e_1,\ldots,e_k\}\in \mathbb R^k$. De hecho el problema est√° planteado en un subconjunto de v√©rtices $\Omega\subseteq V$, dado que en el complemento las etiquetas vienen predeterminadas por una funci√≥n $g:V\setminus\Omega\to\{e_1,\ldots,e_k\}$.

Una forma de llevar a cabo esta tarea consiste en minimizar el funcional de Dirichlet bajo el dato de borde en $V\setminus \Omega$
$$
\min\{\mathcal E[u]\ | \ u=g\text{ en } V\setminus \Omega\}.
$$
Bajo esta condici√≥n $u:V\to \mathbb R^k$ debe ser calculado seg√∫n
$$
\begin{cases}
\Delta u = 0 \text{ en } \Omega,\\
u=g\text{ en } V\setminus \Omega.
\end{cases}
$$
Dado que la soluci√≥n $u(x)$ no necesariamente toma valores en $\{e_1,\ldots,e_k\}$, tomamos la etiqueta para $x$ como el $e_j$ m√°s cercano a $u(x)$.
:::

---

:::{.exercise}
Dado que $u=(u_1,\ldots,u_k)$ satisface
$$
\begin{cases}
\Delta u = 0 \text{ en } \Omega,\\
u=g\text{ en } V\setminus \Omega.
\end{cases}
$$
con $g$ tomando valores en $\{e_1,\ldots,e_k\}$, demuestra que para todo $x\in V$
$$
u(x) \in \{y\in [0,1]^k \ | \ y_1+\ldots+y_k=1\}.
$$
:::

<details>
<summary>Soluci√≥n</summary>
</details>

## M√©trica de Sobolev

Consideremos para $G = (V,E)$ conexo
$$
\dot H^1 := \left\{u:V\to\mathbb R\ | \ \sum_V u = 0\right\}.
$$
Este espacio vectorial admite el producto interno,
$$
\langle u,v\rangle_{\dot H^1} := \sum_{e\in E} Du(e)Dv(e).
$$
Recordemos r√°pidamente las propiedades que verifica para poder ser efectivamente un producto:

- Sim√©trico: $\langle u,v\rangle_{\dot H^1}=\langle v,u\rangle_{\dot H^1}$,

- Lineal: $\langle \alpha u+\beta v,w\rangle_{\dot H^1} = \alpha\langle u,w\rangle_{\dot H^1}
    +\beta\langle v,w\rangle_{\dot H^1}$.

- Positivo: $\|u\|_{\dot H^1}^2 := \langle u,u\rangle_{\dot H^1}\geq 0$

- No degenerado: $\|u\|_{\dot H^1} = 0$ si y solo si $u=0$.

De todas estas propiedades, la no degeneraci√≥n es la m√°s delicada. De $\|u\|_{\dot H^1} = 0$ se deduce que $u$ es constante ($G$ es conexo). Dado que $\sum u=0$ se llega a que necesariamente dicha constante es cero.

## Capacitancia

Dado $\Omega\subseteq V$ con $V\setminus \Omega\neq \emptyset$, definimos la capacitancia de $\Omega'\subseteq\Omega$ con respecto de $\Omega$ como
$$
\operatorname{Cap}(\Omega'|\Omega) := \min\{2\mathcal E[u] \ | \ \text{$u=1$  en $\Omega'$, y $u=0$ en $V\setminus\Omega$}\}.
$$

Un minimizante $u$ de dicho problema es la funci√≥n arm√≥nica en $\Omega\setminus \Omega'$ que satisface los datos de borde prescritos
$$
\begin{cases}
\Delta u = 0 \text{ in } \Omega\setminus \Omega',\\
u=0 \text{ on } V\setminus \Omega,\\
u=1 \text{ on } \Omega'.
\end{cases}
$$
Gracias al teorema de la divergencia^[Recordemos que
$$
n_{\Omega'}(e) = \begin{cases}
1 \text{ si $e_-\in \Omega'$ y $e_+\in V\setminus \Omega$},\\
-1 \text{ si $e_+\in \Omega'$ y $e_-\in V\setminus \Omega$},\\
0 \text{ en cualquier otro caso}. 
\end{cases}
$$]
$$
\operatorname{Cap}(\Omega'|\Omega) = -\sum_{x\in V} u\Delta u(x) = -\sum_{x\in \Omega'} \Delta u(x) = -\sum_{e\in E} Du(e)n_{\Omega'}(e).
$$
En t√©rminos de redes el√©ctricas obtenemos la corriente total que atraviesa la red cuando se mantiene una diferencia potencial de un voltio entre $\Omega'$ y $V\setminus \Omega$. La resistencia efectiva entre dos nodos distintos $x_0$ y $x_1$ puede ser definida as√≠ seg√∫n
$$
R(x_0,x_1) = \frac{1}{\operatorname{Cap}(\{x_1\}|V\setminus\{x_0\})}.
$$

Equivalentemente se puede definir la capacitancia en t√©rminos de dos desigualdades sobre $\Omega'$ y $V\setminus \Omega$
$$
\operatorname{Cap}(\Omega'|\Omega) = \min\{\mathcal E[u] \ | \ \text{$u\geq 1$  en $\Omega'$, y $u\leq 0$ en $V\setminus\Omega$}\}.
$$
Es claro que el lado derecho es menor o igual que el lado izquierdo, dado que el conjunto que considera el m√≠nimo es m√°s grande. Por el otro lado tenemos que para cualquier $u$ tal que $u\geq 1$  en $\Omega'$, y $u\leq 0$ en $V\setminus\Omega$, la truncaci√≥n dada por
$$
v(x) := \max(\min(u(x),1),0) = \begin{cases}
1 \text{ si } x\in \Omega',\\
u(x) \text{ si } x\in \Omega\setminus\Omega',\\
0 \text{ si } x\in V\setminus \Omega.
\end{cases}
$$
disminuye la energ√≠a de Dirichlet $\mathcal E[v]\leq \mathcal E[u]$, lo cual concluye la igualdad que hab√≠amos anunciado.

---

:::{.exercise}
Calcula $\operatorname{Cap}(\{a\}|V\setminus \{b\})$

![](./capa2.png)
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

---

:::{.exercise}
Demuestra que para $\Omega_1\subseteq\Omega_2\subseteq\Omega_3\subseteq V$:

- $\operatorname{Cap}(\Omega_1|\Omega_2)= \operatorname{Cap}(V\setminus\Omega_2|V\setminus \Omega_1)$.

- $\operatorname{Cap}(\Omega_1|\Omega_3) \leq \operatorname{Cap}(\Omega_2|\Omega_3)$.

- $\operatorname{Cap}(\Omega_1|\Omega_2) \geq \operatorname{Cap}(\Omega_1|\Omega_3)$.
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

---

:::{.exercise}
Demuestra que para $\Omega_1,\Omega_2\subseteq\Omega\subseteq V$^[El minimizante $u$ correspondiente a $\Omega_1\cup\Omega_2$ es puntualmente mayor o igual a $\max(u_1,u_2)$ donde $u_1$ y $u_2$ son los minimizantes para $\Omega_1$ y $\Omega_2$ respectivamente.]:
$$
\operatorname{Cap}(\Omega_1\cup\Omega_2|\Omega) \leq \operatorname{Cap}(\Omega_1|\Omega)+\operatorname{Cap}(\Omega_2|\Omega).
$$
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

---

:::{.exercise}
Sea $\Omega'\subseteq\Omega\subseteq V$, $u$ la soluci√≥n de
$$
\begin{cases}
\Delta u = 0 \text{ in } \Omega\setminus \Omega',\\
u=0 \text{ on } V\setminus \Omega,\\
u=1 \text{ on } \Omega'.
\end{cases}
$$
y sean $\mu=(\Delta u)_-$ y $\nu=(\Delta u)_+$. Demuestra que
$$
P_\Omega(\mu)=\nu \qquad \text{ y } \qquad P_{V\setminus \Omega'}(\nu)=\mu.
$$
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

## M√©trica dual

De forma dual proponemos el siguiente problema. Decimos que un flujo $i:E\to\mathbb R$ transporta a la distribuci√≥n (de cargas) $\mu:V\to [0,\infty)$ en $\nu:V\to\mathbb R$ si satisface
$$
\operatorname{div} i = \mu-\nu.
$$
Recordemos que tal problema tiene soluci√≥n si y solo si (y asumiendo $G$ conexo)
$$
\sum_{x\in V}\mu(x) = \sum_{x\in V}\nu(x).
$$

Dada la energ√≠a del flujo $i$ como
$$
\mathcal K[i] := \frac{1}{2}\sum_{e\in E} i(e)^2,
$$
nos preguntamos entonces cu√°l es la menor energ√≠a posible que se requiere para transportar a $\mu$ en $\nu$
$$
\mathcal D^2[\mu,\nu] := \min\{ 2\mathcal K[i] \ | \ \operatorname{div} i = \mu-\nu\}.
$$

Si $i$ minimiza $\mathcal K$ y $j$ es un flujo tal que $\operatorname{div} j=0$, entonces
$$
0=\left.\frac{d}{dt}\right|_{t=0}\mathcal K[i+tj] = \sum_{e\in E}i(e)j(e).
$$
Es decir que el m√≠nimo $i$ debe ser perpendicular al n√∫cleo de la divergencia. Por la descomposici√≥n de Helmholtz debe ser necesariamente un gradiente $i=-Du$ por lo que
$$
\mathcal D^2[\mu,\nu] = 2\mathcal E[u]\text{ para cualquier soluci√≥n de $\Delta u=\nu-\mu$}.
$$

---

:::{.exercise}
Calcula $\mathcal D^2(\mu,\nu)$

![](./wasser.png)
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

---

:::{.exercise}
La funci√≥n $\mathcal D$, es decir la ra√≠z cuadrada del m√≠nimo de la energ√≠a, se conoce como la **distancia dual**. Demuestra que efectivamente satisface los axiomas correspondientes:

- $\mathcal D(\mu,\nu) = \mathcal D(\nu,\mu)$,

- $\mathcal D(\mu,\nu) \geq 0$ y la igualdad se cumple exclusivamente si $\mu=\nu$,

- $\mathcal D(\mu,\nu) \leq \mathcal D(\mu,\omega)+\mathcal D(\omega,\nu)$.
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

---

:::{.exercise}
Definimos la norma dual en $\dot H^1$ como
$$
\|u\|_{\dot H^{-1}} := \sup\{ \langle u,v\rangle_{\dot H^1}\ | \ \|v\|_{\dot H^1}=1\}.
$$
Demuestra que si $\sum_V \mu = \sum_V\nu$, entonces
$$
\|\mu-\nu\|_{\dot H^{-1}} = \mathcal D(\mu,\nu).
$$
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

---

Dados $\Omega'\subseteq\Omega\subseteq V$ con $\Omega'$ y $V\setminus \Omega$ no triviales consideramos las distribuciones $\mu$ y $\nu$ tales que
$$
\begin{aligned}
\mathcal M(\Omega'|\Omega) = \{(\mu,\nu):V\to \mathbb R^2\ | \ &\operatorname{spt} \mu \in \Omega',\\
&\operatorname{spt}\nu \subseteq V\setminus\Omega,\\
&\left.\sum_{x\in V}\mu(x) = \sum_{x\in V}\nu(x)=1\right\}.
\end{aligned}
$$
Bajos estas condiciones buscamos minimizar la distancia entre $\mu$ y $\nu$.

:::{.theorem}
Para $G$ conexo y finito,
$$
\min_{(\mu,\nu) \in \mathcal M(\Omega'|\Omega)} \mathcal D^2[\mu,\nu] = \frac{1}{\operatorname{Cap}(\Omega'|\Omega)}.
$$
:::

Es decir que el problema de minimizaci√≥n para $\mathcal D^2[\mu,\nu]$ bajo las restricciones $(\mu,\nu) \in \mathcal M(\Omega'|\Omega)$ generaliza la noci√≥n de resistencia efectiva entre dos conjuntos.

:::{.proof}
Sean $\mu',\nu':V\to [0,\infty)$ tales que
$$
\operatorname{spt}\mu'\subseteq\Omega', \qquad \operatorname{spt} \nu'\subseteq V\setminus \Omega.
$$
Obtenemos de esta forma que
$$
\max_{\mu',\nu'} \sum_{x\in V} ((1-u)\mu'+u\nu')(x) = \begin{cases}
0 \text{ si $u\geq 1$ en $\Omega'$ y $u\leq 0$ en $V\setminus\Omega$,}\\
\infty \text{ en cualquier otro caso}.
\end{cases}
$$
De modo que sin necesidad de imponer restricciones para $u:V\to\mathbb R$ obtenemos que
$$
\operatorname{Cap}(\Omega'|\Omega) = \min_u \max_{\mu',\nu'} L[u,\mu',\nu'], \qquad L[u,\mu',\nu'] := 2\mathcal E[u] + \sum_{x\in V} ((1-u)\mu'+u\nu')(x).
$$

Procedemos entonces a analizar el problema dual para el cual sabemos que^[En general, $\min_x\max_\lambda L(x,\lambda) \geq \max_\lambda\min_x L(x,\lambda)$.]
$$
\operatorname{Cap}(\Omega'|\Omega)\geq \max_{\mu',\nu'} \mathcal J[\mu',\nu'], \qquad \mathcal J[\mu',\nu'] := \min_u L[u,\mu',\nu'].
$$

Por un lado vemos que si
$$
\sum_{x\in V}\mu'(x) \neq \sum_{x\in V}\nu'(x)
$$
entonces $\mathcal J[\mu',\nu'] = -\infty$, dado que para $u=c$ constante podemos hacer $L[u,\mu',\nu']$ arbitrariamente negativo
$$
L[c,\mu',\nu'] = \sum_{x\in V}\mu'(x) + c\sum_{x\in V}(\nu'-\mu')(x).
$$
Asumamos entonces que las sumas son iguales, en cuyo caso la forma cuadr√°tica convexa $u\mapsto L[u,\mu',\nu']$ alcanza su m√≠nimo en las soluciones de
$$
2\Delta u = \nu'-\mu'.
$$
Estas est√°n bien definidas por la hip√≥tesis para el lado derecho, adem√°s dos soluciones cualesquiera difieren por constantes, gracias a la conexidad de $G$. Por lo tanto
$$
\sum_{x\in V} (\nu'-\mu')u(x) = 2\sum_{x\in V} u\Delta u(x) = -4\mathcal E[u]
$$
y entonces
$$
\mathcal J[\mu',\nu'] = \sum_{x\in V} \mu'(x)-2\mathcal E[u].
$$

Denotemos por $M:=  \sum_{x\in V} \mu'(x)$ y consideremos las renormalizaciones dadas por $\mu'=M\mu$, $\nu'=M\nu$ y $2u=Mv$ tales que $(\mu,\nu) \in \mathcal M(\Omega'|\Omega)$, $\Delta v = \nu-\mu$, y $4\mathcal E[u] = M^2\mathcal E[v]$. Por lo tanto
$$
\mathcal J[\mu',\nu'] = M - \frac{M^2}{2} \mathcal E[v]
$$
Vemos que $M$ y $v$ son independientes bajo las restricciones dadas. Si maximizamos primero en $M$ obtenemos que $M=1/\mathcal E[v]$ y por lo tanto
$$
\operatorname{Cap}(\Omega'|\Omega) \geq \max_{\mu',\nu'} \mathcal J[\mu',\nu'] = \max_{\substack{\Delta v = \nu-\mu\\(\mu,\nu)\in \mathcal M(\Omega'|\Omega)}} \frac{1}{\mathcal E[v]} = \max_{(\mu,\nu)\in \mathcal M(\Omega'|\Omega)} \frac{1}{\mathcal D^2[\mu,\nu]}.
$$

Para concluir la demostraci√≥n veremos que cuando $u$ es la soluci√≥n de
$$
\begin{cases}
\Delta u = 0 \text{ in } \Omega\setminus \Omega',\\
u=0 \text{ on } V\setminus \Omega,\\
u=1 \text{ on } \Omega',
\end{cases}
$$
y adem√°s $(\Delta u)_- = M\mu$, $(\Delta u)_+ = M\nu$, $u=Mv$, tales que $(\mu,\nu)\in \mathcal M(\Omega'|\Omega)$, entonces
$$
\operatorname{Cap}(\Omega'|\Omega) = 2\mathcal E[u] \overset{?}{=} \frac{1}{2\mathcal E[v]} = \frac{1}{\mathcal D^2[\mu,\nu]}.
$$
Esto se debe a la f√≥rmula de integraci√≥n por partes y la homogeneidad de $\mathcal E$
$$
2\mathcal E[u] = M = 2M^2\mathcal E[v] \qquad\mathbb Rightarrow\qquad M= \frac{1}{2\mathcal E[v]} \qquad\mathbb Rightarrow\qquad 2\mathcal E[u] = \frac{1}{2\mathcal E[v]}.
$$
:::

En los siguientes ejercicios consideramos para $\Omega\subseteq V$
$$
\mathcal M(\Omega):= \left\{\mu:V\to [0,1] \ | \ \operatorname{spt}\mu\subseteq\Omega \text{ y } \sum_{x\in V}\mu(x)=1\right\}.
$$

---

:::{.exercise}
Sea $\Omega'\subseteq\Omega\subseteq V$. Demuestra que para $\mu\in \mathcal M(\Omega')$ se tiene que
$$
\mathcal D(\mu,P_\Omega(\mu)) = \min_{\nu \in \mathcal M(V\setminus \Omega)}\mathcal D(\mu,\nu)
$$
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

---

:::{.exercise}
Sea $\Omega'\subseteq\Omega\subseteq V$. Demuestra que $T:= P_{V\setminus \Omega'}\circ P_\Omega$ es un mapeo no expansivo $\mathcal M(\Omega')$ en si mismo con respecto de la m√©trica de Wasserstein, es decir que
$$
\mathcal D(T(\mu_1),T(\mu_2))\leq \mathcal D(\mu_1,\mu_2).
$$
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

## Cociente de Rayleigh

Sea $A\in \mathbb R^{N\times N}$ sim√©trica. Sabemos por el teorema espectral que existe una base ortogonal de autovectores de $L$ con autovalores reales. Tendremos en mente aplicar los resultados de esta secci√≥n para $A=-L$ para la cual sabemos adicionalmente que sus autovalores son no-negativos.

La ecuaci√≥n $A\xi = \lambda\xi$ que determina los autovectores puede pensarse tambi√©n como una ecuaci√≥n de punto cr√≠tico con restricciones, siendo $\lambda$ el multiplicador de Lagrange. En este caso el gradiente de la funci√≥n objetivo es $A\xi$, mientras que el gradiente de la restricci√≥n es $\xi$. Esto quiere decir que la funci√≥n objetivo puede ser tomada como la forma cuadr√°tica $f(\xi)=A\xi\cdot \xi$, mientras que la restricci√≥n es $g(\xi) = \|\xi\|^2 = \xi\cdot\xi$.

A lo largo de esta secci√≥n asumimos que $A\in \mathbb R^{N\times N}$ es sim√©trica y denotamos por $\lambda_0\leq\ldots\leq \lambda_{N-1}$ sus autovalores y $\xi_0,\ldots,\xi_{N-1}$ una base ortogonal de autovectores.

---

:::{.exercise}
Demuestra que el m√≠nimo de $f(\xi)=A\xi\cdot \xi$ sobre la esfera unitaria es el menor autovalor de $A$ y que los puntos donde se realiza el m√≠nimo general el autoespacio de dicho autovalor.

¬øSucede algo similar para el problema de maximizaci√≥n?
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

---

:::{.exercise}
Considera el grafo

![](./capa2.png)

Calcula el m√≠nimo y m√°ximo de
$$
\sum_{e\in E} (Du(e))^2
$$
sobre todas las funciones $u:V\to \mathbb R$ tales que $\sum_V u^2=1$.
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

---

:::{.exercise}
Considera el grafo

![](./capa2.png)

Calcula el m√≠nimo y m√°ximo de
$$
\sum_{e\in E} (Du(e))^2
$$
sobre todas las funciones $u:V\to \mathbb R$ tales que $\sum_V u^2=1$ y $u(A)=u(B)=0$.
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

---

Una forma alternativa del problema de optimizaci√≥n consiste en tomar el cociente de Rayleigh
$$
R(\xi) := \frac{A\xi \cdot \xi}{\|\xi\|^2},
$$
y minimizar o maximizar esta funci√≥n fuera del origen.

---

:::{.exercise}
Demuestra que
$$
\lambda_k = \min\{R(\xi)\ | \ \xi \in \operatorname{span}\{\xi_0,\ldots,\xi_{k-1}\}^\perp \setminus \{0\}\}
$$
:::


<details>
<summary>Soluci√≥n:</summary>
</details>

---

:::{.theorem name="Courant‚ÄìFischer‚ÄìWeyl"}
$$
\lambda_k = \max\{\min\{R(\xi)\ | \ \xi \in S\setminus\{0\}\} \ | \ S \text{ es un sub-espacio de $\mathbb R^N$ con $\dim S=N-k$}\}
$$
:::

En otras palabras, dado un sub-espacio $S$ de dimensi√≥n $N-k$, el m√≠nimo de $R$ sobre $S\cap \partial B_1$ es a lo sumo $\lambda_k$. La igualdad se alcanza cuando $S=\operatorname{span}\{\xi_k,\ldots,\xi_{N-1}\}$.

:::{.proof}
Denotemos
$$
\mu_k := \max\{\min\{R(\xi)\ | \ \xi \in S\setminus\{0\}\} \ | \ S \text{ es un sub-espacio de $\mathbb R^N$ con $\dim S=N-k$}\}.
$$

Para demostrar que $\lambda_k\leq \mu_k$ basta con conseguir un sub-espacio $S$ de dimensi√≥n $N-k$ tal que el m√≠nimo de $R$ sobre $S\setminus\{0\}$ es por lo menos $\lambda_k$.

Sea $S_{N-k} = \operatorname{span}\{\xi_{k},\ldots,\xi_{N-1}\}$ tal que $\dim S_{N-k} = N-k$. Por un lado tenemos que para $\xi = \alpha_{k}\xi_{k}+\ldots+\alpha_{N-1}\xi_{N-1}\in S_{N-k}\setminus \{0\}$
$$
R(\xi) = \frac{\lambda_{k}\alpha_{k}^2+\ldots+\lambda_{N-1}\alpha_{N-1}^2}{\alpha_{k}^2+\ldots+\alpha_{N-1}^2} \geq \lambda_k
$$
cuyo m√≠nimo es de hecho $\lambda_{k}$ y se alcanza por ejemplo cuando $\alpha_k=1$ y los dem√°s coeficientes se anulan. Es decir que hemos probado que $\lambda_k \leq \mu_k$.

La desigualdad $\lambda_k \geq \mu_k$ quiere decir que para cualquier sub-espacio $S$ de dimensi√≥n $N-k$, existe $\xi \in S\setminus\{0\}$ tal que $R(\xi)\leq \lambda_k$. Tomemos $\xi = \alpha_0\xi_0+\ldots+\alpha_k\xi_k \in S\setminus\{0\}$, sabemos que tal vector existe puesto que
$$
\dim S + \dim\operatorname{span}\{\xi_0,\ldots,\xi_k\} = N+1.
$$
Luego
$$
R(\xi) = \frac{\lambda_{0}\alpha_{0}^2+\ldots+\lambda_{k}\alpha_{k}^2}{\alpha_{0}^2+\ldots+\alpha_{k}^2} \leq \lambda_k.
$$
:::

---

:::{.exercise}
Si $A\leq A'$, i.e. $(A'-A)$ es positiva semi-definida, entonces sus correspondientes autovalores tambi√©n est√°n ordenados, es decir $\lambda_k\leq \lambda_k'$.
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

---

:::{.exercise}
Sea $G'$ un sub-grafo de $G$^[$V'\subseteq V$ y $E'\subseteq E\cap V'\times V'$.]. Demuestra que para los correspondientes autovalores del Laplaciano se tiene que $\lambda_k'\geq \lambda_k$.
:::

<details>
<summary>Soluci√≥n:</summary>
</details>

<!--chapter:end:07-optimizacion.Rmd-->

# (PART\*) Transporte y leyes de conservaci√≥n {-}

# Cantidades conservadas

## Problemas homog√©neos

Sea $v:\mathbb R^n\to \mathbb R^n$ un campo vectorial suave y acotado, como tal genera un flujo $\phi:\mathbb R^n\times\mathbb R\to \mathbb R^n$ definido por medio del problema de valores iniciales
$$
\partial_t\phi(x,t) = v(\phi(x,t)), \qquad \phi(x,0)=x.
$$

Una funci√≥n $u:\mathbb R^n\to \mathbb R$ se dice que es una **cantidad conservada** de $v$, si $u$ permanece constante a lo largo del flujo $\phi$. Es decir
$$
u(\phi(x,t)) = u(x) \qquad \forall \, t\in\mathbb R.
$$
Si $u$ es adem√°s diferenciable esto equivale a la ecuaci√≥n parcial lineal de primer orden
$$
v \cdot Du = 0.
(\#eq:eq1)
$$

Por un lado, conocer una cantidad conservada $u$ nos ayuda a resolver las EDOs $x'=v(x)$, dado que las trayectorias permanecen en los conjuntos de nivel de $u$. Por otro lado, la EDO asociada a la EDP \@ref(eq:eq1) se conoce como la **ecuaci√≥n caracter√≠stica** y nos ayudan a calcular la soluci√≥n de la EDP dado que $u$ debe permanecer constante a lo largo de estas trayectorias.

---

:::{.example}
Dado un vector constante $v = (v_1,\ldots,v_n)\in \mathbb R$, consideremos el problema
$$
v\cdot Du = 0.
$$
Este tiene asociada la ecuaci√≥n caracter√≠stica $x'=v$ (es decir el sistema $x_i'=v_i$) cuya soluci√≥n es $x(t)=x_0+tv$. Dada que cualquier soluci√≥n de la EDP debe permanecer constante a lo largo de esta trayectoria tenemos que
$$
u(x_0+tv) = u(x_0).
$$
Si $u$ estuviese predeterminada en una regi√≥n $F\subseteq \mathbb R^n$ dada como la funci√≥n $u_0$, entonces es conveniente tomar la posici√≥n inicial $x_0$ en dicha regi√≥n. Por ejemplo, si $F = \{x_1=0\}$ y $v=(v_1,\ldots,v_n)$ no es paralelo a $F$, es decir $v_1\neq0$, entonces podemos conectar cualquier punto $x=(x_1,\ldots,x_n)\in\mathbb R^n$ con alg√∫n punto $x_0=(0,x_{0,2},\ldots,x_{0,n})\in F$ tal que $x_0+tv = x$ y por lo tanto $u(x) = u_0(x_0)$. En este caso particular podemos simplemente calcular $x_0$ y $t$ y obtener una f√≥rmula expl√≠cita para la soluci√≥n
$$
\begin{aligned}
tv_1 = x_1 \qquad&\Rightarrow\qquad t=x_1/v_1,\\
x_{0,i} + tv_i = x_i \text{ si } i\geq 2 \qquad&\Rightarrow\qquad x_{0,i} = x_i - x_1v_i/v_1,\\ 
u(x) = u_0(x_0) \qquad&\Rightarrow\qquad u(x) = u_0(0,x_2 - x_1v_2/v_1,\ldots,x_n - x_1v_n/v_1)
\end{aligned}
$$
:::

---

:::{.exercise}
Calcula $u:\mathbb R^2\to \mathbb R$ tal que
$$
\begin{cases}
y\partial_x u = x\partial_y u \text{ en } \mathbb R^2\setminus\{y=0,x\geq 0\},\\
u = u_0 \text{ en } \{y=0,x\geq 0\}.
\end{cases}
$$
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.exercise}
Explica como se podr√≠a extender la teor√≠a al problema de Cauchy donde $u:\mathbb R^n\times[0,\infty)\to \mathbb R$ depende de una variable espacial $x\in\mathbb R^n$ y una temporal $t\in[0,\infty)$ y satisface en cambio el problema de valores iniciales
$$
\begin{cases}
\partial_t u + v\cdot Du = 0 \text{ en } \mathbb R^n,\\
u = u_0 \text{ en } \{t= 0\}
\end{cases}
$$
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.example}
**Ley de conservaci√≥n de la energ√≠a**

Un sistema mec√°nico se dice **conservativo** si la fuerza es menos el gradiente un potencial $U$
$$
mv' = -DU(x), \qquad v=x'.
$$
La energ√≠a del sistema es la suma de la cin√©tica y potencial
$$
E(x,v) = \frac{1}{2}m|v|^2 + U(x).
$$
La **ley de la conservaci√≥n de la energ√≠a** dice que la energ√≠a total es constante. Comprob√©moslo calculando la derivada temporal de $E$.
$$
\frac{d}{dt}E(x(t),v(t)) = x'\partial_x E + v'\partial_v E=v\cdot DU + \frac{(-DU)}{m}\cdot m v = 0.
$$
Dicho de otra forma, la energ√≠a total satisface la ecuaci√≥n $(v,-DU/m)\cdot DE=0$.
:::

---

:::{.exercise}
Considera el sistema mec√°nico de fuerzas centrales,
$$
mx'' = f(|x|)x.
$$
Demuestra que el momento angular $L_{ij} = x_ix_j'-x_jx_i'$ es una cantidad conservada del sistema.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

:::{.example}
Consideremos el sistema de ecuaciones
$$
x' = f(x,y),\qquad
y' = g(x,y).
$$
La trayectoria del sistema consiste del lugar geom√©trico trazado por la soluci√≥n. La ecuaci√≥n se dice **exacta** si las trayectorias son el conjunto de nivel de una funci√≥n $u$, equivalentemente el campo $(f,g)$ debe ser perpendicular a $(\partial_xu,\partial_y u)$. Esto sucede en particular si $(f,g) = (-\partial_y u,\partial_x u)$ lo cual implica $\operatorname{div}((f,g))= \partial_x f+\partial_y g=0$. Esta hip√≥tesis no solamente es necesaria, si no tambi√©n suficiente para encontrar $u$ tal que
$$
g(x,y) = \partial_x u \quad \text{y} \quad -f(x,y) = \partial_y u.
$$

Veamos que efectivamente $u$ es constante a lo largo de las trayectorias
$$
\frac{d}{dt}u(x(t),y(t)) = x'\partial_xu + y'\partial_yu = f(x,y)g(x,y) - g(x,y)f(x,y) = 0.
$$
:::

---

:::{.example}
Un funci√≥n $f = (u(x,y),v(x,y)):\mathbb{C}\to\mathbb{C}$ es **holomorfa** si satisface las **ecuaciones de Cauchy-Riemann**
$$
\partial_x u = \partial_y v, \qquad \partial_y u = - \partial_x v.
$$
Estas implican que $u$ y $v$ son funciones arm√≥nicas
$$
(\partial_x^2+\partial_y^2)u=(\partial_x^2+\partial_y^2)v=0,
$$
y adicionalmente sus conjuntos de nivel son ortogonales entre si. Sus gradientes son exactamente rotaciones de 90 grados uno del otro.

Dada una funci√≥n arm√≥nica $u:\mathbb{C}\to\mathbb R$, es posible construir una funci√≥n arm√≥nica $v$ tal que $Dv = (-\partial_y u,\partial_x u)$. Estas se conocen como los conjugados arm√≥nico de $u$. Cualesquiera dos conjugados de la misma funci√≥n $u$ difieren por una constante.

Por ejemplo, tomemos la funci√≥n arm√≥nica $u(x,y) = x^2-y^2$. Debemos as√≠ resolver $\partial_x v = 2y$ y $\partial_y v=2x$. De la primera ecuaci√≥n obtenemos $v = 2xy+\varphi(y)$ y por lo tanto $2x=2x+C'(y)$ lo cual implica que $C$ es constante. Conclu√≠mos as√≠ que $v(x,y) = 2xy+C$ es el conjungado arm√≥nico de $u$.
:::

---

:::{.exercise}
Calcula el conjugado arm√≥nico de las siguientes funciones:

- $u(x,y) = x^3-3xy^2$,

- $u(x,y) = e^{x}\cos y$,

- $u(x,y) = \ln(x^2+y^2)$.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

En general, dado un campo vectorial $v$, la derivada
$$
D_vu = \partial_tu+ v \cdot Du
$$
se conoce como la **derivada material** de $u$ y describe la tasa de cambio de $u$ a lo largo de las trayectorias generadas por $v$.

## Problemas no-homog√©neos

Puede darse tambi√©n el caso de que la funci√≥n $u$ no sea necesariamente constante a lo largo de las trayectorias de la EDO $x'=v(x)$, pero que sin embargo sus variaciones sean conocidas en funci√≥n de la posici√≥n en la trayectoria.

---

:::{.example}
Si $u(x_0)$ denota el tiempo que tarda la trayectoria que parte de la posici√≥n inicial $x_0$ en llegar a un dado conjunto $F$, entonces a lo largo de una soluci√≥n $z(t) := u(x(t))$ tiene derivada igual a $-1$. Es decir que satisface la ecuaci√≥n no-homog√©nea
$$
v\cdot Du = -1.
$$
:::

---

En general podemos aplicar un razonamiento similar a la ecuaci√≥n no-homog√©nea
$$
v\cdot Du = f(x).
(\#eq:eq2)
$$
La ecuaci√≥n caracter√≠stica de \@ref(eq:eq2) sigue siendo $x'=v(x)$, sin embargo $z(t) = u(x(t))$ ahora no es constante a lo largo de una curva caracter√≠stica. En cambio $z$ satisface $z'=f(x)$. Podemos decir as√≠ que las ecuaciones caracter√≠sticas est√°n dadas en verdad por un sistema d√©bilmente acoplado
$$
\begin{cases}
x'= v(x),\\
z' = f(x).
\end{cases}
$$

Se dice que es d√©bilmente acoplado porque por lo menos la ecuaci√≥n $x'=v(x)$ es independiente de $z$. Para resolver el sistema uno puede comenzar resolviendo el problema para $x$ y luego substituir este resultado en la ecuaci√≥n para $z$ la cual se puede resolver por medio de una integraci√≥n
$$
z(t) = z_0 + \int_{0}^t f(x(s))ds.
$$

---

:::{.exercise}
Calcula el tiempo que se toma la curva $(x(t),y(t))$ que parte de $(x_0,y_0)$ en llegar a $F=\{y=0,x\geq0\}$ si esta se mueve seg√∫n la ecuaci√≥n diferencial
$$
x'=-y, \qquad y'=x.
$$
Usa esta informaci√≥n para resolver
$$
y\partial_xu-x\partial_yu=1 \text{ en } \mathbb R^2\setminus F,\\
u=0 \text{ en } F
$$
¬øTiene sentido que $u$ sea discontinua en $F$?
:::

<details>
<summary>Soluci√≥n</summary>
</details>

## Problemas semi-lineales

Generalizando la idea de las ecuaciones no-homog√©neas, puede darse el caso de que las variaciones de $z(t) = u(x(t))$ dependan de $x$ y tambi√©n de la misma $z=u(x)$. Por ejemplo, la ecuaci√≥n $z'=-cz$ aparece cuando $z$ representa una ganancia descontada con taza $c$ que se obtiene cuando la trayectoria llega a una dada regi√≥n $F$.

Consideremos la ecuaci√≥n
$$
v\cdot Du = f(u,x).
$$
Se dice que es **semi-lineal** dado que el operador asociado a las derivadas de orden mayor (en este caso uno) es lineal y solamente depende de $x$, sin embargo el problema puede presentar combinaciones no-lineales en $u$ dadas por $f$.

Las ecuaciones caracter√≠sticas vuelven a ser un sistema d√©bilmente acoplado dado por
$$
\begin{cases}
x'= v(x),\\
z' = f(z,x).
\end{cases}
$$
En este caso, tambi√©n se puede proceder resolviendo primero la ecuaci√≥n para $x$ y sustituyendo el resultado en la ecuaci√≥n para $z$. Sin embargo, el √∫ltimo paso requiere resolver una ecuaci√≥n no-homog√©nea para $z$ y no simplemente calcular una integral.

---

:::{.exercise}
Dado el campo vectorial $v=(ax+by,cx+dy)$ en el plano, resuelve el problema de valores iniciales
$$
\begin{cases}
\partial_t u + \operatorname{div}(vu) =0 \text{ en }\mathbb R^2\times (0,\infty),\\
u=u_0 \text{ en } \{t=0\}
\end{cases}
$$
Demuestra que si $\int_{\mathbb R^2}u_0(x,y)dxdy<\infty$, entonces $m(t) = \int_{\mathbb R^2}u(x,y,t)dxdy$ permanece constante.
:::

<details>
<summary>Soluci√≥n</summary>
</details>

## Problemas cuasi-lineales

Finalmente consideramos el caso donde el campo $v$ tambi√©n depende de $u$. Esto hace que la EDO y la EDP est√©n estrechamente acopladas.

---

:::{.example}
La ecuaci√≥n de **Burgers** modela la ley de inercia de un flu√≠do (incompresible y de densidad uniforme) con velocidad $u(x,t)$ en la posici√≥n $x \in \mathbb R$ y en tiempo $t \in \mathbb R$. Para decir que el momento es una cantidad conservada a lo largo del flujo usamos que
$$
\partial_t u + u \partial_x u =0.
$$
:::

---

En el caso general
$$
v(u,x)\cdot Du = f(u,x)
$$
decimos que la ecuaci√≥n es **cuasi-lineal**. Esto quiere decir que el operador asociado a las derivadas de orden mayor es lineal, pero puede depender en este caso de $u$. Como es de esperarse la ecuaci√≥n caracter√≠stica es ahora un sistema fuertemente acoplado
$$
\begin{cases}
x'= v(z,x),\\
z'=f(z,x).
\end{cases}
$$

---

:::{.exercise}
¬øQu√© relaci√≥n guarda la ecuaci√≥n de Burgers (EDP: $\partial_t u + u \partial_x u =f$) con la ley de Newton (EDO: $x'' = f$)?
:::

<details>
<summary>Soluci√≥n</summary>
</details>

---

En los casos de las ecuaciones semi-lineales encontramos que las curvas caracter√≠sticas que se corresponden a la ecuaci√≥n $x'=v(x)$ fibran el dominio, es decir lo cubren de forma disjunta bajo hip√≥tesis regularidad y crecimiento para el campo vectorial.

El caso de las ecuaciones caracter√≠sticas para problemas estrictamente cuasi-lineales, es decir de la forma
$$
\begin{cases}
x'= v(z,x),\\
z'=f(z,x),
\end{cases}
$$
es radicalmente distinto. El teorema de unicidad garantiza que las trayectorias son disjuntas, ***pero en el sistema de coordenadas $(x,z)$***, las proyecciones en el hiper-plano de las $x$'s ***puede tener intersecciones***. Esto implica que las soluciones de la EDP pasan a ser funciones multi-valuadas. En la pr√°ctica decimos que las soluciones est√°n definidas hasta el primer momento en que ocurre una colisi√≥n en las caracter√≠sticas.

---

:::{.exercise}
Encuentra el valor m√°s grande posible para $T$ tal que el siguiente problema de valores iniciales tiene soluci√≥n en el intervalo $[0,T)$
$$
\begin{cases}
\partial_tu + u\partial_x u = -\sin x \text{ en } \mathbb R\times(0,T)\\
u=0 \text{ en } \{t=0\}
\end{cases}
$$
:::

<details>
<summary>Soluci√≥n</summary>
</details>

<!--chapter:end:08-contidades_conservadas.Rmd-->

