--- 
title: "M茅todos de matem谩ticas aplicadas"
author: "H茅ctor Andr茅s Chang-Lara"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  This is a minimal example of using the bookdown package to write a book.
  The HTML output format for this example is bookdown::gitbook,
  set in the _output.yml file.
link-citations: yes
github-repo: rstudio/bookdown-demo
---

# Prefacio {-}

Hola

<!--chapter:end:index.Rmd-->

# (PART\*) Modelos discretos {-}

# Entramados

La siguiente figura ilustra cuatro puntos masivos unidos por tres barras de longitudes conocidas $\ell_{01}, \ell_{12}, \ell_{23}$, y masas despreciables. Los extremos etiquetados por $0$ y $3$ tienen posiciones fijas y los nodos intermedios de masas $m_1$ y $m_2$ ocupan posiciones de equilibrio. 驴A partir de cuales ecuaciones se podr铆an determinar las posiciones $q_i=(x_i,y_i)$ de estos nodos?

<iframe src="https://www.geogebra.org/classic/psru5cr9?embed" width="800" height="600" allowfullscreen style="border: 1px solid #e4e4e4;border-radius: 4px;" frameborder="0"></iframe>

<!--
```{python, echo=FALSE}

import matplotlib.pyplot as plt

plt.plot([0,1,3,4], [0,-2,-3,0],[0,1,3,4], [0,-2,-3,0],'ro')

ts = 14

plt.text(0.1,-0.1,'0',fontsize=ts)
plt.text(1.05,-1.9,'1',fontsize=ts)
plt.text(3.1,-3,'2',fontsize=ts)
plt.text(3.8,-0.1,'3',fontsize=ts)


plt.text(0.6,-1,'$\ell_{01}$',fontsize=ts)
plt.text(1.7,-2.6,'$\ell_{12}$',fontsize=ts)
plt.text(3.55,-1.7,'$\ell_{23}$',fontsize=ts)

plt.show()
```
-->

Antes de proceder a plantear el sistema de ecuaciones recordemos que por lo general el n煤mero de ecuaciones e inc贸gnitas deben ser iguales para que este est茅 bien planteado, es decir que existan soluciones y que sean 煤nicas (al menos localmente). En nuestro caso tenemos cuatro inc贸gnitas, los dos pares de coordenadas de cada nodo libre. Adem谩s debemos considerar las restricciones impuestas por las distancias entre los nodos, es decir tres ecuaciones. Hasta el momento el sistema es indeterminado, tiene m谩s inc贸gnitas (4) que ecuaciones (3), sin embargo a煤n nos falta incorporar la informaci贸n del fen贸meno de equilibrio.

$$
\begin{cases}
(x_1-0)^2 + (y_1-0)^2 = \ell_{01}^2\\
(x_1-x_2)^2 + (y_1-y_2)^2 = \ell_{12}^2\\
(x_2-3)^2 + (y_2-0)^2 = \ell_{23}^2
\end{cases}
$$

En cada nodo libre act煤an tres fuerzas: dos tensiones y la gravedad $(= -m_ige_y)$. Por ejemplo, la tensi贸n $T_{12}$ sobre el nodo 1 y que se produce sobre el segmento que une los nodos 1 y 2 es proporcional al vector $q_2-q_1$, es decir $T_{12} = \lambda_{12} (q_2-q_1)$ para un cierto escalar $\lambda_{12}$. Similarmente podemos razonar sobre las dem谩s interacciones, introduciendo as铆 cuatro nuevas variables $\lambda_{10}, \lambda_{12}, \lambda_{21}$, y $\lambda_{23}$. Para que el sistema se encuentre en equilibrio, la suma de las fuerzas sobre cada nodo debe anularse, lo cual nos da igualmente cuatro ecuaciones:

$$
\begin{cases}
\lambda_{10}(x_{0}-x_{1})+\lambda_{12}(x_{2}-x_{1}) = 0\\
\lambda_{10}(y_{0}-y_{1})+\lambda_{12}(y_{2}-y_{1}) = m_{1}g\\
\lambda_{23}(x_{3}-x_{2})+\lambda_{21}(x_{1}-x_{2}) = 0\\
\lambda_{23}(y_{3}-y_{2})+\lambda_{21}(y_{1}-y_{2}) = m_{2}g
\end{cases}
$$

Pareciera que no hemos logrado mucho en t茅rminos del sistema que sigue siendo indeterminado con ocho inc贸gnitas (2 $x$'s, 2 $y$'s y 4 $\lambda$'s) y siete ecuaciones (3 distancias y 4 balances de fuerzas). Sin embargo, la tercera ley de Newton nos dice que las interacciones entre pares de nodos guarda una simetr铆a: toda acci贸n produce una reacci贸n opuesta de la misma magnitud. En nuestro modelo esto se refleja en $T_{12} = -T_{21}$, de donde obtenemos la 煤ltima ecuaci贸n

$$
\lambda_{12}=\lambda_{21}.
$$

De hecho es m谩s sencillo eliminar una de las inc贸gnitas ($\lambda_{21}$) que a帽adir otra ecuaci贸n. En conclusi贸n obtenemos el siguiente sistema con siete ecuaciones e inc贸gnitas

$$
\begin{cases}
\lambda_{10}(x_{0}-x_{1})+\lambda_{12}(x_{2}-x_{1}) = 0\\
\lambda_{10}(y_{0}-y_{1})+\lambda_{12}(y_{2}-y_{1}) = m_{1}g\\
\lambda_{23}(x_{3}-x_{2})+\lambda_{12}(x_{1}-x_{2}) = 0\\
\lambda_{23}(y_{3}-y_{2})+\lambda_{12}(y_{1}-y_{2}) = m_{2}g\\
(x_1-0)^2 + (y_1-0)^2 = \ell_{01}^2\\
(x_1-x_2)^2 + (y_1-y_2)^2 = \ell_{12}^2\\
(x_2-3)^2 + (y_2-0)^2 = \ell_{23}^2
\end{cases}
$$

Una forma de obtener soluci贸n a este sistema es el m茅todo de Newton. Por ejemplo, para los valores $\ell_{01}=\sqrt{5}, \ell_{12}=\sqrt{5}, \ell_{23}=\sqrt{10}, m_1=1, m_2=2, q_0=(0,0), q_3=(4,0)$ la siguiente implementaci贸n ilustra como obtener la soluci贸n usando Python^[**Advertencia:** El c贸digo es sensible a las condiciones iniciales para la iteraci贸n y no siempre converge.].

```{python}
#Librer铆as

import matplotlib.pyplot as plt
import numpy as np
from scipy.optimize import fsolve

#Par谩metros

l01=np.sqrt(5)
l12=np.sqrt(5)
l23=np.sqrt(10)
x3,y3=4,0
m1=1
m2=2

#Sistema de ecuaciones y gr谩fica

def f(x):
  x1,y1,x2,y2,lambda01,lambda12,lambda23 = x
  f=np.zeros(7)
  f[0] = x1**2+y1**2-l01**2
  f[1] = (x2-x1)**2+(y2-y1)**2-l12**2
  f[2] = (x3-x2)**2+(y3-y2)**2-l23**2
  f[3] = -lambda01*x1+lambda12*(x2-x1)
  f[4] = -lambda01*y1+lambda12*(y2-y1)-m1
  f[5] = lambda12*(x1-x2)+lambda23*(x3-x2)
  f[6] = lambda12*(y1-y2)+lambda23*(y3-y2)-m2
  return f

r = fsolve(f,[1,-1,3,-2,0,0,0])

x1,y1=r[0],r[1]
x2,y2=r[2],r[3]

fig, ax = plt.subplots()
ax.plot([0,r[0],r[2],x3], [0,r[1],r[3],y3])
ax.plot(0,0,color='tab:blue', marker='o', label='$q_0=(0,0)$')
ax.plot(x1,y1,color='tab:orange', marker='o', label="$q_1=({:.4f},{:.4f})$".format(x1, y1))
ax.plot(x2,y2,color='tab:green', marker='o', label="$q_1=({:.4f},{:.4f})$".format(x2, y2))
ax.plot(x3,y3,color='tab:red', marker='o', label="$q_1=({},{})$".format(x3, y3))
leg = ax.legend();

plt.show()
```

Estas ideas son f谩cilmente generalizables a configuraciones lineales con m谩s nodos. En el l铆mite se obtiene el *problema de la catenaria*. Tambi茅n podemos considerar estructuras m谩s complejas, por ejemplo un pa帽uelo sujeto por las esquinas. Para poder dar una generalizaci贸n de estos modelos presentamos en la siguiente secci贸n algunas nociones b谩sicas de teor铆a de grafos. Una referencia entretenida con aplicaciones en arquitectura est谩 en el siguiente enlace:


![[Dise帽ar estructuras... 驴sin c谩lculos?  La magia de la CATENARIA](https://youtu.be/KXP_kPPc7LY)](./0.jpg){width=70%}

---

::: {.exercise}
Calcula $m_2$ para que el entramado est茅 en equilibrio dado que los nodos en $(0,0)$ y $(13,0)$ est谩n fijos

![](./eje_1.png){width=70%}
:::

<details>
  <summary>Soluci贸n</summary>
Las fuerzas en el nodo $1$ est谩n dadas por
$$
\begin{cases}
5\lambda_{01}=6\lambda_{12},\\
8\lambda_{01}+\lambda_{12}=g
\end{cases} \qquad\Rightarrow\qquad \lambda_{01}=\frac{6g}{53}, \lambda_{12}=\frac{5g}{53}
$$
Las fuerzas en el nodo $2$ est谩n dadas por
$$
\begin{cases}
6\lambda_{12}=2\lambda_{23},\\
-\lambda_{12}+7\lambda_{23}=m_2g
\end{cases} \qquad\Rightarrow\qquad \lambda_{23}=\frac{15g}{53}, m_2=\frac{100}{53}.
$$
</details>

---

::: {.exercise}
Demuestra que si un dado entramado como en la figura, y con extremos en el eje horizontal, est谩 en equilibro, entonces su correspondiente reflexi贸n en el eje horizontal tambi茅n est谩 en equilibrio. 驴Ser谩 posible generalizar este principio a un entramado general?

![](./eje2.png){width=70%} 
:::

<details>
  <summary>Soluci贸n</summary>
Denotamos por $\lambda_i=\lambda_{i,i-1} = -\lambda_{i-1,i}$.

En cada nodo del entramado original se tiene el balance de fuerzas est谩 dado por
$$
\begin{cases}
(x_i-x_{i-1})\lambda_i=(x_{i+1}-x_{i})\lambda_{i+1},\\
(y_{i-1}-y_{i})\lambda_i+(y_{i+1}-y_{i})\lambda_{i+1}=m_ig
\end{cases}
$$
Al tomar la reflexi贸n en el eje horizontal las coordenadas de los nodos pasan a ser $(x_i,y_i)\mapsto (x_i',y_i') = (x_i,-y_i)$. Gracias a las relaciones previas, se observa que estas coordenadas satisfacen igualmente las ecuaciones de balance de fuerzas cuando igualmente reemplazamos $\lambda_i\mapsto \lambda_i' =-\lambda_i$
$$
\begin{cases}
(x_i'-x_{i-1}')\lambda_i'=(x_{i+1}'-x_{i}')\lambda_{i+1}',\\
(y_{i-1}'-y_{i}')\lambda_i'+(y_{i+1}'-y_{i}')\lambda_{i+1}'=m_ig.
\end{cases}
$$
Este principio se generaliza a un entramado general con una notaci贸n adecuada.
</details>

<!--chapter:end:01-entramado.Rmd-->

# C谩lculo discreto

Una grafo dirigido $G = (V,E)$ consiste de un conjunto de v茅rtices $V$, tambi茅n llamados nodos, y un conjunto de aristas $E \subseteq V^2$, es decir pares ordenados de $V$.

Dado $e = (a,b)\in E$, denotamos por $e_-=a$ y $e_+=b$ los nodos de partida y llegada de $e$ respectivamente y decimos que $e$ est谩 orientado del nodo de salida $a$ al nodo de llegada $b$.

En general trabajaremos con grafos con aristas simples, es decir que a lo sumo existe una arista que conecta dos v茅rtices en cualquier orientaci贸n. Sin embargo, cuando $e=(a,b)\in E$ podr铆amos hacer referencia a la arista $-e:=(b,a)$ como la arista $e$ pero con el sentido opuesto. Denotaremos $-E = \{-e \in V^2:e\in E\}$.

Finalmente, podemos considerar tambi茅n conjuntos de aristas no orientadas en cuyo caso decimos que el grafo es no dirigido.

---

::: {.exercise}
Dibuja el grafo $G=(V,E)$ para
$$
V = \{1,2,3,a,b,c\}, \qquad E = \{(1,a),(1,b),(1,c),(2,a),(2,b),(2,c),(3,a),(3,b),(3,c)\}.
$$
:::

<details>
  <summary>Soluci贸n</summary>

<iframe src="https://www.geogebra.org/classic/xtjh7atb?embed" width="800" height="600" allowfullscreen style="border: 1px solid #e4e4e4;border-radius: 4px;" frameborder="0"></iframe>
</details>

---

Las redes el茅ctricas son uno de los modelos m谩s conocidos que se pueden formular en t茅rminos de grafos. Sobre el grafo podemos caracterizar por ejemplo el potencial o voltaje como una funci贸n $u:V\to \mathbb R$ y la corriente como una funci贸n $i:E\to \mathbb R$. Siguiendo un poco la nomenclatura que sugiere este modelo, distinguimos dos tipos de funciones en $G$:

1. **Potencial:** Es una funci贸n sobre el conjunto de v茅rtices $u: V \to \mathbb R$.
1. **Flujo:** Es una funci贸n sobre el conjunto de aristas $f: E \to \mathbb R$.

En algunos casos tambi茅n podr铆amos considerar que dichas funciones tomen valores en $\mathbb C$, $\mathbb R^n$ 贸 $\mathbb C^n$.

Tambi茅n denominamos como flujos a funciones que est谩n definidas en $E\cup -E$, es decir que consideran ambas orientaciones de las aristas. Decimos que $f:E\cup -E\to\mathbb R$ es **par** cuando no depende de la orientaci贸n $f(-e) = f(e)$, y decimos que **impar** si en cambio $f(-e) = -f(e)$. Una funci贸n $f:E\to\mathbb R$ en un grafo no dirigido es equivalente a una funci贸n par en el mismo grafo y con cualquier orientaci贸n sobre las aristas.
 
---

:::{.example}
En el modelo de [entramados](#entramados) en la secci贸n anterior, el grafo no dirigido $G=(V,E)$ con $V = \{0,1,2,3\}$ y $E=\{\{0,1\},\{1,2\},\{2,3\}\}$ nos proporciona la informaci贸n sobre cuales nodos est谩n conectados entre si. Las posiciones de los nodos se caracterizan por $q:V\to \mathbb R^2$ y las longitudes de los enlaces est谩n determinadas por $\ell:E\to\mathbb R$.

![](./eje_1.png){width=70%}

Para modelar las tensiones es conveniente considerar el grafo dirigido $G=(V,E')$ de alguna forma arbitraria, quiz谩s $E'=\{(0,1),(1,2),(2,3)\}$. De esta forma contamos con la funci贸n par $\lambda:E'\to\mathbb R$ y la funci贸n impar $T: E' \to \mathbb R^2$ tales que
$$
T(e) = \lambda(e)(q(e_+)-q(e_-))
$$
es la tensi贸n sobre el nodo $e_-$ a lo largo de $e$. A su vez y gracias a la ley de acci贸n y reacci贸n, $T(-e) = -T(e)$ es la tensi贸n sobre el nodo $e_+$ a lo largo de $e$ pero en la orientaci贸n opuesta, es decir $-e$.
:::

---

:::{.example}
Un potencial $u:V\to\mathbb R$ sobre una red de resistencia genera una corriente $i:E\to \mathbb R$ que modelamos usando la ley de Ohm para una dada resistencia $R:E\to (0,\infty)$ (funci贸n par). Esto quiere decir que la corriente $i(e)$ que atraviesa una arista $e = (e_-,e_+)$ es proporcional a la diferencia de los potenciales en los extremos de la arista
$$
i(e) = \frac{u(e_+) - u(e_-)}{R(e)}, \qquad R(e) >0: \text{ Resistencia.}
$$
:::

---

## Gradiente

Tanto en la construcci贸n de las tensiones $T$, como en la de la corriente el茅ctrica $i$, estamos considerando la variaci贸n de una dada funci贸n (las posiciones $q$ 贸 el potencial $u$) a lo largo de una arista dada. Esto es una versi贸n discreta de la derivada direccional. En este caso requerimos que el grafo sea orientado.

:::{.definition}
Dado potencial $u:V\to\mathbb R$ sobre un grafo dirigido $G=(V,E)$, definimos el gradiente $Du: E\cup -E \to \mathbb R$ tal que
$$
Du(e) = u(e_{+})-u(e_{-}).
$$
:::

En particular, el gradiente es una funci贸n impar.

---

:::{.exercise}
Calcula el gradiente de la funci贸n dada en los v茅rtices del siguiente grafo


![](./gradeje.png){width=70%}
:::

<details>
  <summary>Soluci贸n</summary>
![](./gradsol.png){width=70%}
</details>

---

:::{.exercise}
Verifica que el gradiente satisface la identidad de Leibniz
$$
D(u_1u_2) = u_1^+ Du_2 + u_2^-Du_1
$$
donde $u^\pm:E\to\mathbb R$ se define a partir de $u:V\to\mathbb R$ como $u^\pm(e) = u(e_\pm)$.
:::

<details>
  <summary>Soluci贸n</summary>
  $$
  \begin{aligned}
  D(u_1u_2)(e) &= u_1(e_+)u_2(e_+) - u_1(e_-)u_2(e_-),\\
               &= u_1(e_+)u_2(e_+) - u_1(e_+)u_2(e_-) + u_1(e_+)u_2(e_-) - u_1(e_-)u_2(e_-),\\
               &= u_1(e_+)(u_2(e_+)-u_2(e_-)) + u_2(e_-)(u_1(e_+)-u_1(e_-)),\\
               &= u_1(e_+)Du_2(e) + u_2(e_-)Du_1(e),\\
               &= (u_1^+Du_2 + u_2^-Du_1)(e).
  \end{aligned}
  $$
</details>
---

### Ley de ciclos

No toda funci贸n (impar) $f:E\cup -E \to \mathbb R$ es necesariamente un gradiente. Una condici贸n necesaria y suficiente es la **ley de ciclos**. Para poder enunciar esta ley es conveniente dar algunas definiciones previas para un dado grafo dirigido $G=(V,E)$.

:::{.definition}
Un **camino no orientado** es una sucesi贸n de v茅rtices $x_0,x_1, \dots, x_n \in V$ tal que $(x_j,x_{j+1}) \in E\cup -E$ para todo $j\in\{0,1,\ldots,(n-1)\}$. Se dice que el camino es un **ciclo** si adem谩s $x_n=x_0$.
:::

:::{.definition}
Una **componente conexa** de $G$ es un subconjunto $V'\subseteq V$ tal que:
  
- Todos los v茅rtices en $V'$ est谩n conectados entre si por alg煤n camino.
    
- Ning煤n v茅rtice de $V'$ est谩 conectado con ning煤n v茅rtice de $V\setminus V'$.

Decimos que $G$ es **conexo** si tiene una 煤nica componente conexa.
:::

:::{.theorem name="Ley de ciclos"}
Sea $G=(V,E)$ un grafo dirigido finito. Una funci贸n impar $f:E\cup -E\to\mathbb R$ es igual al gradiente de una funci贸n $u:V\to \mathbb R$ si y solo si para todo ciclo $x_0,x_1, \dots, x_n=x_0$ se tiene que
$$
\sum_{j=0}^{n-1} f(x_j,x_{j+1}) = 0.
$$
:::

:::{.proof}
Por un lado es f谩cil verificar la identidad para flujos gradientes usando la propiedad telesc贸pica. Dado un ciclo $x_0,x_1, \dots, x_n=x_0$
$$
\sum_{j=0}^{n-1} Du(x_j,x_{j+1}) = \sum_{j=0}^{n-1} (u(x_{j+1})-u(x_j)) = u(x_n)-u(x_0)=0.
$$

Podemos construir $u:V'\to \mathbb R$ sobre cada una de las componentes conexas de $G$ de la siguiente forma: Fijemos $x_0 \in V'$ y definimos
$$
u(x) := \sum_{j=0}^{n-1} f(x_j,x_{j+1})
$$
donde $x_0,x_1, \dots, x_n=x$ es un camino no orientado que conecta $x_0$ con $x\in V'$.

La hip贸tesis dada por la ley de ciclos garantiza que esta construcci贸n no depende del camino escogido, es decir que est谩 bien definida sin posible ambig眉edad: Dados dos caminos $x_0,\ldots,x_n=x$ y $y_0=x_0,\ldots,y_m=x$ se tiene que $z_0=x_0,\ldots,z_n=x_n,z_{n+1}=y_{m-1},\ldots,z_{n+m}=y_0$ es un ciclo y por lo tanto
$$
0 = \sum_{j=0}^{n+m-1} f(z_j,z_{j+1}) = \sum_{j=0}^{n-1} f(x_j,x_{j+1}) - \sum_{j=0}^{m-1} f(y_j,y_{j+1}).
$$

Veamos finalmente que $Du = f$. Dado $e\in E$ con $e_\pm$ en la misma componente que $x_0$, tomamos un camino $x_0,x_1,\ldots, x_n=e_-$ de $x_0$ a $e_-$ y luego a帽adimos $x_{n+1}=e_+$ para formar un camino de $x_0$ a $e_+$. Por lo tanto
$$
Du(e) = u(e_+)-u(e_-) = \sum_{j=0}^{n} f(x_j,x_{j+1})-\sum_{j=0}^{n-1} f(x_j,x_{j+1}) = f(e),
$$
con lo cual conclu铆mos la demostraci贸n.
:::

Este argumento nos permite apreciar que $u$ est谩 煤nicamente determinado salvo potenciales constantes en cada componente conexa de $G$. Las constantes son los valores arbitrarios que dar铆amos a $u$ sobre el nodo $x_0$, que en nuestra demostraci贸n fue cero. En otras palabras, la nulidad del gradiente captura el n煤mero de compnentes conexas del grafo.

---

:::{.exercise}
Calcula los potenciales que generan el flujo dado en la siguiente figura

![](./eje_3.png){width=70%}
:::

<details>
  <summary>Soluci贸n</summary>
  
  El flujo satisface la ley de ciclos. Por ejemplo en el tri谩ngulo de la izquierda la suma correspondiente es $-3+1+2=0$ y de igual forma podemos verificar en el tri谩ngulo de la derecha ($2+(-1)+(-1)=0$) o en el cuadrado exterior ($(-3)+1-(-1)-(-1)=0$). Si tomamos $u(A)=0$ sin p茅rdida de generalidad tenemos que
  $$
  \begin{cases}
  u(B) = 1 + u(A) = 1,\\
  u(C) = 3 + u(A) = 3,\\
  u(D) = -1 + u(C) = 2.
  \end{cases}
  $$
  Verificamos adem谩s que con estos valores se obtiene el gradiente prescrito
  $$
  \begin{cases}
  Du(AB) = u(B)-u(A) = 1-0 = 1,\\
  Du(BC) = u(C)-u(B) = 3-1 = 2,\\
  Du(CA) = u(A)-u(C) = 0-3 = -3,\\
  Du(CD) = u(D)-u(C) = 2-3 = -1,\\
  Du(DB) = u(B)-u(D) = 1-2 = -1.
  \end{cases}
  $$
  En general, $u$ tiene el gradiente prescrito si y solo si
  $$
  u(A) = C, \qquad u(B) = 1+C, \qquad u(C) = 3+C, \qquad u(D)=2+C.
  $$
</details>

---

<details>
  <summary>**Margen de c谩lculo:** El lema de Poincar茅</summary>
Como ya el lector habr谩 notado, estas construcciones y propiedades encuentran paralelos en c谩lculo multivariable, y de hecho las demostraciones reproducen las mismas ideas: Los caminos son curvas, los ciclos son lazos o curvas cerradas y la expresi贸n $\sum_{j=0}^{n-1} f(x_j,x_{j+1})$ es an谩loga a la integral de l铆nea o el trabajo de un campo vectorial sobre una curva.

El resultado que acabamos de enunciar se conoce como el **Lema de Poincar茅 global**. Recordemos su enunciado junto con el resultado local.

**Lema de Poincar茅 (global):** Un campo vectorial $f \in C(\Omega\subseteq\mathbb R^n\to\mathbb R^n)$ es el gradiente de alg煤n potencial $u\in C^1(\Omega\to\mathbb R)$ si y s贸lo si para cualquier curva cerrada $\gamma \in C^1([a,b]\to\Omega)$ (i.e. $\gamma(b)=\gamma(a)$) se tiene que el trabajo que ejerce $f$ sobre la curva $\gamma$ se anula
$$
\int_\gamma f = \int_a^b f(\gamma(t))\cdot \gamma'(t)dt = 0.
$$

**Lema de Poincar茅 (local):** Si $\Omega\subseteq\mathbb R^n$ es simplemente conexo^[es decir que cualquier ciclo puede ser deformado continuamente a un punto. Por ejemplo, si $n=2$ dice que $\Omega$ no tiene hoyos.] entonces $f \in C^1(\Omega\to\mathbb R^n)$ es un gradiente si y solo si $\partial_if_j = \partial_jf_i$.
</details>

## Divergencia

Otro operador diferencial que tiene su an谩logo en grafos es la divergencia. Heur铆sticamente, la divergencia de un campo vectorial mide cuando es positiva la cantidad de flujo que sale o diverge del nodo dado, mientras que cuando es negativa mide la cantidad de flujo que recibe o converge en el nodo.

:::{.definition}
Dado $f: E \to \mathbb R$ denotamos por $\operatorname{div} f:V\to \mathbb R$ a la divergencia de $f$ donde
$$
\operatorname{div} f(v) = \sum_{e_-=v}f(e)-\sum_{e_+=v}f(e)
$$
:::

---

:::{.example}
En la siguiente figura se calcul贸 la divergencia de la funci贸n dada en las aristas

![](./div.png){width=70%}
:::

---

:::{.example}
Las ecuaciones de balance para un entramado se escriben en t茅rminos de la divergencia de las tensiones sobre los nodos libres como
$$
\operatorname{div} T = -mge_y
$$
:::

---

:::{.example}
La ley de Kirchhoff dice que en en un nodo que no est谩 conectado a la bater铆a, la corriente que entra y sale de este son iguales. En t茅rminos de la divergencia quiere decir que
$$
\operatorname{div} i = 0
$$
:::

---

### F贸rmula de la divergencia

Al igual que antes, podr铆amos preguntarnos si todo potencial es la divergencia de alg煤n campo. Esto no es necesariamente cierto, la divergencia satisface la **ley de conservaci贸n**, an谩loga al teorema de la divergencia. Un caso particular ilustrativo de esta ley postula que la suma de la divergencia sobre un grafo finito es igual a cero
$$
\sum_{v\in V} \operatorname{div} f(v) = 0.
$$
Una vez m谩s la justificaci贸n se basa en una propiedad telesc贸pica para la suma: Cada arista aparece dos veces en la suma con signos opuestos dependiendo si se considera su v茅rtice origen o de llegada.

Para dar una versi贸n discreta del teorema de la divergencia consideramos el campo normal exterior $n_\Omega:E\to \mathbb R$ tal que
$$
n_\Omega(e) = \begin{cases}
+1 \text{ si $e_-\in \Omega$ y $e_+\in V\setminus \Omega$},\\
-1 \text{ si $e_-\in V\setminus \Omega$ y $e_+\in \Omega$},\\
0 \text{ en cualquier otro caso}
\end{cases}
$$
en este caso el signo de $n_\Omega(e)$ indica cuando la arista orientada conecta a $\Omega$ con su complemento o viceversa.

---

:::{.exercise}
El campo normal es el gradiente de una dada funci贸n 驴Cu谩l?.
:::

<details>
  <summary>Soluci贸n</summary>
  $n_\Omega = D1_{V\setminus \Omega}$ donde
  $$
  1_{V\setminus \Omega}(x) = \begin{cases}
  1 \text{ si } x\in V\setminus \Omega,\\
  0 \text{ en cualquier otro caso}.
  \end{cases}
  $$
</details>

---

:::{.theorem name="F贸rmula de la divergencia"}
Sea $G=(V,E)$ un grafo dirigido finito. La divergencia de $f:E\to \mathbb R$ verifica
\begin{equation}
\sum_{v\in \Omega} \operatorname{div} f(v) = \sum_{e\in E} f(e)n_\Omega(e)
(\#eq:div)
\end{equation}
:::

De hecho la suma en el lado derecho ocurre en realidad sobre un subconjunto de aristas que podemos definir como el borde de $\partial\Omega$
$$
\partial \Omega := \{e\in E\ | \ \{e_+,e_-\} \cap \Omega \neq \emptyset \text{ y } \{e_+,e_-\} \cap E\setminus \Omega \neq \emptyset\}
$$
es decir las aristas que conectan $\Omega$ con su complemento en cualquier orientaci贸n.

La cantidad $f(e)n_\Omega(e)$ es positiva cuando $e_-\in \Omega$, $e_+\in V\setminus \Omega$ y $f(e)>0$; o bien cuando $e_-\in V\setminus \Omega$, $e_+\in \Omega$ y $f(e)<0$. En cualquier caso, $f(e)n_\Omega(e)$ se interpreta como la cantidad de masa que escapa de $\Omega$ por medio de $e$. Un razonamiento similar se d谩 cuando $f(e)n_\Omega(e)$ es negativo para la masa que entra. El balance total nos dice que la masa que se produce o absorbe en $\Omega$ se puede medir de dos formas, sumando las divergencias en $\Omega$ u observando las contribuciones que escapan o entran por las aristas que conectan a $\Omega$ con su complemento $V\setminus \Omega$ en cualquier orientaci贸n.

:::{.proof}
Sean $1_\pm:V\times E\to \mathbb R$ definidas seg煤n
$$
1_\pm(v,e) := \begin{cases}
1 \text{ si } e_\pm = v,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$
En particular usaremos que
$$
\sum_{v\in \Omega} 1_\pm(v,e) = \begin{cases}
1 \text{ si } e_\pm \in \Omega,\\
0 \text{ encualquier otro caso}
\end{cases}
$$

Tenemos as铆 que
$$
\begin{aligned}
\sum_{v\in \Omega} \operatorname{div} f(v) &= \sum_{v\in \Omega} \sum_{e_-=v} f(e) - \sum_{v\in \Omega} \sum_{e_+=v} f(e),\\
&= \sum_{v\in \Omega} \sum_{e \in E} f(e)1_-(v,e) - \sum_{v\in \Omega} \sum_{e \in E} f(e)1_+(v,e),\\
&= \sum_{e \in E} \sum_{v\in \Omega}f(e)1_-(v,e) - \sum_{e \in E} \sum_{v\in \Omega}f(e)1_+(v,e),\\
&= \sum_{e_-\in \Omega} f(e) -\sum_{e_+\in \Omega} f(e),\\
&= \sum_{\substack{e_-\in \Omega\\e_+\in V\setminus \Omega}} f(e) + \sum_{e_-, e_+\in \Omega} f(e) - \sum_{\substack{e_+\in \Omega\\e_-\in V\setminus \Omega}} f(e) - \sum_{e_-, e_+\in \Omega} f(e),\\
&= \sum_{\substack{e_-\in \Omega\\e_+\in V\setminus \Omega}} f(e) - \sum_{\substack{e_+\in \Omega\\e_-\in V\setminus \Omega}} f(e)
\end{aligned}
$$

Esta 煤ltima expresi贸n es por definici贸n de $n_\Omega$ igual a
$$
\sum_{e\in E} f(e)n_\Omega(e),
$$
con lo cual se concluye la demostraci贸n.
:::

<details>
  <summary>**Margen de c谩lculo:** El teorema de la divergencia</summary>
  El teorema de la divergencia nos dice que dado un subconjunto $\Omega \subset\mathbb R^n$ con frontera localmente de clase $C^1$ a trozos, y campo $v\in C^1(\overline{\Omega}\to\mathbb R^n)$, entonces
$$
\int_\Omega \operatorname{div} v = \int_{\partial \Omega} v\cdot n
$$
donde $n$ es el vector normal exterior a $\Omega$.

El lado derecho integra el flujo que escapa o entra en $\Omega$ a trav茅s de su borde. En concreto, si en un punto dado del borde  $v\cdot n >0$ entonces $v$ apunta en la direcci贸n de $n$ y el flujo escapa con una tasa igual a $v\cdot n$,  si en cambio  $v\cdot n < 0$ el flujo estar铆a entrando, y si $v\cdot n=0$ se tiene que $v$ es tangente y el flujo apenas roza la superficie. El lado izquierdo de la expresi贸n es una integral sobre $\Omega$ que representa la producci贸n/absorci贸n de flujo por el campo $v$.
</details>

### Lema de Poincar茅 para la divergencia

:::{.theorem}
Sea $G=(V,E)$ un grafo dirigido finito y conexo. Para cualquier $\mu:V\to\mathbb R$ tal que
$$
\sum_{x\in V}\mu(x)=0
$$
existe por lo menos una soluci贸n $f:E\to\mathbb R$ de
$$
\operatorname{div} f = \mu.
$$
:::

:::{.proof}
Tomemos un nodo arbitrario $x_0\in V$ y consideremos inductivamente caminos no orientados que vayan conectando a $x_0$ con cada uno de los nodos restantes y de tal forma que nunca se formen ciclos en esta construcci贸n. Es decir, estamos proponiendo un **谩rbol generador** del grafo con ra铆z en el nodo $x_0$, en otras palabras un sub-grafo $T_0 := (V_0=V,E_0\subseteq E)$ libre de ciclos y conexo. Fijamos $f=0$ en las aristas de $E\setminus E_0$ y en los dem谩s ajustaremos $f$ para que satisfaga la ecuaci贸n dada.

En la siguiente construcci贸n estaremos definiendo a $f:E\cup-E\to \mathbb R$ como una funci贸n impar.

La idea consiste en ir podando las ramas del 谩rbol a medida que asignamos $f$ convenientemente. Si $|V_0|=1$ el problema ser铆a trivial, asumamos as铆 que $|V_0|>1$. En el primer paso tomamos una hoja de $T_0$, es decir un $x\in V_0$ con un 煤nico nodo $y \sim_{T_0} x$. Declaramos as铆 $f(x,y) = \mu(x)$ de modo que se tiene que $\operatorname{div}f(x) = \mu(x)$ ($f$ es distinto de cero en a lo sumo una arista en esta suma). Una vez declarado $f$ en la arista $e=(x,y)$ procedemos a considerar el 谩rbol $T_1 = (V_0\setminus \{x\},E_1:=E_0\setminus \{(x,y),(y,x)\})$.

Asumamos de forma inductiva que luego de $k$ pasos contamos con los 谩rboles
$$
T_k = (V_k,E_k) \subset T_{k-1} := (V_{k-1},E_{k-1}) \subset \ldots \subset T_0
$$
tales que $f$ ha sido definida en $E\setminus E_k$ tal que $\operatorname{div}f=\mu$ se satisface sobre $V\setminus V_k$. Para el siguiente paso tomamos una hoja $x \in V_k$ y fijamos $f$ sobre la (煤nica) arista $(x,y) \in E_k\cup-E_k$ de modo que la ecuaci贸n ahora se satisfaga sobre el nodo $x$. Para el siguiente paso podamos a $x$ de $T_k$, es decir que
$$
T_{k+1}:= (V_{k+1}=V_k\setminus\{x\},E_{k+1}:=E_k\setminus\{(x,y),(y,x)\}).
$$
Claramente esta construcci贸n garantiza que las hip贸tesis inductivas se siguen cumpliendo en el siguiente paso.

Una vez terminado este algoritmo garantizamos que $\operatorname{div} f=\mu$ se cumple en $V\setminus \{x_0\}$ (la ra铆z del 谩rbol). Como 煤ltima observaci贸n tenemos que la ecuaci贸n tambi茅n debe cumplirse en $x_0$ gracias a que $\sum_{x\in V} \operatorname{div} f(x)=\sum_{x\in V} \mu(x)=0$.
:::

Notemos que si $x_0,\ldots,x_k=x_0$ es un dado ciclo del grafo, entonces si tomamos $f=1$ en las aristas del ciclo y cero por fuera de estas, obtenemos una soluci贸n de $\operatorname{div} f=0$. De hecho, todas las soluciones homog茅neas se obtienen por superposiciones de este ejemplo. El n煤cleo de la divergencia es un espacio vectorial generado por los ciclos independientes del grafo y su dimensi贸n es un importante invariante topol贸gico conocido como el **primer n煤mero de Betti**.

:::{.exercise}
Calcula los flujos $f:E\to \mathbb R$ tal que $\operatorname{div} f=\mu$ para la funci贸n $\mu$ dada sobre los nodos del siguiente grafo.

![](./div2.png){width=70%}
:::

<details>
  <summary>Soluci贸n</summary>
  Verificamos primero que la suma de los valores en los nodos se anula.
  
  Para calcular una soluci贸n particular tomamos el 谩rbol generador con aristas $a$, $b$, $-e$ y definimos as铆
  $$
  f(c)=f(d)=0, \qquad f(a)=1, \qquad f(e)=2, \qquad f(b)=0
  $$
  el cual verifica f谩cilmente la ecuaci贸n de divergencia esperada en todos los nodos.
  
  Cualquier otra soluci贸n se obtiene como la superposici贸n de la soluci贸n previa con las del sistema homog茅neo
  $$
  \begin{cases}
  f(a)+f(b)-f(e)=0,\\
  -f(a)+f(c)=0,\\
  -f(b)+f(d)=0,\\
  -f(c)-f(d)+f(e)=0.
  \end{cases}
  $$
  Dos soluciones linealmente independientes se obtienen por ejemplo de los ciclos $a,c,e$ y $b,d,e$ respectivamente
  $$
  \begin{aligned}
  &f(a)=f(c)=f(e)=1,\qquad f(b)=f(d)=0,\\
  &f(a)=f(c)=0, \qquad f(b)=f(d)=f(e)=1.
  \end{aligned}
  $$
  Si usamos la reducci贸n de Gauss-Jordan podemos verificar que esta es adem谩s una base de las soluciones homog茅neas.
</details>

---

## Integraci贸n por partes

En esta secci贸n identificamos a las funciones $u:V\to \mathbb R$ con vectores de $\mathbb R^{|V|}$. Igualmente identificamos a las funciones $f:E\to \mathbb R$ con vectores de $\mathbb R^{|E|}$. Eventualmente tambi茅n podr铆amos considerar funciones complejas.

El gradiente $D:\mathbb R^{|V|}\to\mathbb R^{|E|}$ se representa as铆 por la matriz $(D_{e,x}) \in \mathbb R^{|E|\times |V|}$ tal que
$$
D_{e,x} = \begin{cases}
1 \text{ si } x=e_+,\\
-1 \text{ si } x=e_-,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$
Mientras que la divergencia $\operatorname{div}:\mathbb R^{|E|}\to\mathbb R^{|V|}$ se representa por la matriz $(\operatorname{div}_{x,e}) \in \mathbb R^{M\times N}$ tal que
$$
\operatorname{div}_{x,e} = \begin{cases}
-1 \text{ si } e_+=x,\\
1 \text{ si } e_-=x,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$
Descubrimos de esta forma que $D^T = -\operatorname{div}$ o equivalentemente la f贸rmula de **integraci贸n por partes**
$$
\sum_{e\in E} (fDu)(e) = f\cdot Du = -u\cdot \operatorname{div} f = -\sum_{x\in V} (u\operatorname{div} f)(x).
$$

---

:::{.exercise}

Calcula las matrices asociadas con el gradiente y la divergencia para el siguiente grafo

![](./k3.png){width=70%}
:::

<details>
  <summary>Soluci贸n</summary>
  $$
  D = \begin{pmatrix}
  -1 &  1 &  0 &  0\\
   0 & -1 &  1 &  0\\
   1 &  0 & -1 &  0\\
  -1 &  0 &  0 &  1\\
   0 &  0 &  1 & -1
  \end{pmatrix} \qquad \operatorname{div} = -D^T = \begin{pmatrix}
  1 & 0 & -1 & 1 & 0\\
  -1 & 1 & 0 & 0 & 0\\
  0 & -1 & 1 & 0 & -1\\
  0 & 0 & 0 & -1 & 1
  \end{pmatrix}.
  $$
</details>

---

:::{.exercise}
Demuestra la f贸rmula de integraci贸n por partes sobre un dominio $\Omega \subseteq V$
\begin{equation}
\sum_{\Omega} u\operatorname{div}f = \sum_{E} u^-fn_\Omega - \sum_{e_+\in \Omega} fDu.
(\#eq:ipv)
\end{equation}
En particular, si $u=1$ recuperamos la f贸rmula de la divergencia \@ref(eq:div).
:::

<details>
  <summary>Soluci贸n</summary>
  Basta con usar que $Dv\cdot f = - v\cdot \operatorname{div} f$ para $v := u 1_{\Omega}$.
</details>

---

<details>
  <summary>**Margen de c谩lculo:** Integraci贸n por partes</summary>
La f贸rmula de integraci贸n por partes nos dice que dado un subconjunto $\Omega \subset\mathbb R^n$ con frontera localmente de clase $C^1$ a trozos, un campo *vectorial* $v\in C^1(\overline{\Omega}\to\mathbb R^n)$, y un campo *escalar* $u\in C^1(\overline{\Omega}\to\mathbb R^n)$ entonces
$$
\int_\Omega u \operatorname{div} v = \int_{\partial \Omega} u v\cdot n - \int_\Omega Du\cdot v
$$
donde $n$ es el vector normal exterior a $\Omega$.
</details>

### Descomposici贸n de Helmholtz

La relaci贸n $D^T=-\operatorname{div}$ nos permite dar la descomposici贸n ortogonal
$$
\mathbb R^{|E|} = D(\mathbb R^{|V|}) + \ker(\operatorname{div}).
$$
tambi茅n conocida como la **descomposici贸n de Helmholtz**. Es decir que cualquier $f:E\to\mathbb R$ puede escribirse de forma *煤nica*^[Dado $f:E\to \mathbb R$, el potencial $u$ no es 煤nico pero su gradiente $Du$ s铆.] como
$$
f = Du + g
$$
tal que
$$
\operatorname{div} g = 0,
$$
y como corolario $Du \perp g$.

En t茅rminos f铆sicos, cualquier flujo se descompone en una parte que preserva la masa ($g$) y en un flujo gradiente ($Du$).

<details>
  <summary>**Margen de 谩lgebra lineal:** El teorema fundamental de 谩lgebra lineal</summary>
Dado $A:\mathbb R^M\to \mathbb R^{N}$ se tiene que
$$
A(\mathbb R^{M})^\perp = \ker(A^T).
$$
Si $x \perp A(\mathbb R^M)$ entonces $0 = x\cdot AA^Tx = \|A^T x\|^2$, lo cual implica $A^Tx=0$. Por otro lado si $A^Tx=0$ entonces para $y\in \mathbb R^M$ arbitrario $x\cdot Ay = A^Tx\cdot y=0$.
</details>

---

:::{.exercise}

Calcula la descomposici贸n de Helmholtz para el siguiente flujo

![](./helmhotz.png){width=70%}
:::

<details>
  <summary>Soluci贸n</summary>
Sea $f:E\to \mathbb R$ los valores que se muestran en la gr谩fica. Buscamos calcular $u:V\to \mathbb R$ y $g:E\to \mathbb R$ tales que $f=Du+g$ y $\operatorname{div}g=0$. Si tomamos as铆 la divergencia en la expresi贸n $f=Du+g$ encontramos que $u$ satisface
$$
\begin{cases}
-2u(A)+u(B)+u(C)=3,\\
u(A)-3u(B)+u(C)+u(D)=4,\\
u(A)+u(B)-3u(C)+u(D)=-7,\\
u(B)+u(C)-2u(D)=0.
\end{cases}
$$
Las soluciones homog茅neas del sistema son los potenciales constantes^[Esto puede verificarse de la reducci贸n de Gauss-Jordan en este caso, y adem谩s ser谩 demostrado con mayor generalidad.]. Ajustando esta constante de forma que $u(A)=0$ obtenemos un sistema que podemos resolver num茅ricamente
```{python}
import numpy as np

A = np.array([[ 1, 1, 0],
              [-3, 1, 1],
              [ 1,-3, 1]])
B = np.array([3, 4, -7])
X = np.linalg.inv(A).dot(B)

Du = [X[0],X[1]-X[0],-X[1],X[2]-X[1],X[0]-X[2]]
f = np.array([1,5,-2,0,0])
g = f-Du

print("[Du(AB), Du(BC), Du(CA), Du(CD), Du(DB)] = {}.".format(Du))
print("[g(AB), g(BC), g(CA), g(CD), g(DB)] = {}.".format(g))
```
</details>

## Laplaciano

El Laplaciano es un operador diferencial que se construye aplicando sucesivamente el gradiente y la divergencia. Es decir que mide la producci贸n de masa del gradiente. Adem谩s, luego de una manipulaci贸n algebraica, observamos que es proporcional a la diferencia entre el promedio en los v茅rtices adyacentes y el valor en el centro.

:::{.definition}
Dado $u: V \to \mathbb R$, el Laplaciano $\Delta u: V \to \mathbb R$ se define tal que
$$
\Delta u(v) = \operatorname{div}(D u)(v) = \sum_{w \sim v} (u(w)-u(v)).
$$
donde $w \sim v$ si existe una arista que une a $v$ y $w$ en cualquier orientaci贸n.
:::

A pesar de que tanto el gradiente como la divergencia requieren que el grafo tenga una orientaci贸n, **el Laplaciano est谩 bien definido en grafos no dirigidos**.

Cuando $u: V \to \mathbb R$ es un potencial tal que $\Delta u=0$ en $\Omega \subseteq V$, decimos que $u$ es una funci贸n **arm贸nica** sobre $\Omega$.

---

:::{.example}
Considera una red el茅ctrica con resistencias de un Ohm ($R(e)=1$) la cual modelamos como una grafo dirigido de forma arbitraria. Una bater铆a de un voltio entre dos nodos $v_+,v_-\in V$ genera un potencial el茅ctrico $u:V\to \mathbb R$ que se puede determinar a partir de la ley de Ohm y la ley de Kirchhoff.

Seg煤n la ley de Ohm tenemos que la corriente se calcula seg煤n
$$
i=Du.
$$

Seg煤n la ley de Kirchhoff tenemos que fuera de los nodos donde se conecta la bateria, la corriente se conserva, es decir
$$
0=\operatorname{div}i = \Delta u \text{ en } V\setminus\{v_\pm\}
$$

Junto con las condiciones de borde en los nodos donde se conecta la bater铆a
$$
\qquad u(v_+) = 1, \qquad u(v_-) = 0,
$$
obtenemos un sistema de ecuaciones lineales con igual n煤mero de ecuaciones que de inc贸gnitas.
:::

---

:::{.exercise}
Calcula el potencial el茅ctrico que se genera en un cubo de resistencias de un Ohm, cuando se conecta una bater铆a de un voltio entre dos nodos opuestos del cubo

![](./cube.png){with=70%}
:::

<details>
  <summary>Soluci贸n</summary>
  Asumamos sin p茅rdida de generalidad que se conecta la bateria de los nodos $A$ a $D$ tal que $v(A)=1$ y $v(D)=0$. Tenemos un sistema de ecuaciones lineales de dimensiones 6 por 6. De existir una 煤nica soluci贸n^[Una vez m谩s, esto puede chequearse a mano o con una herramienta num茅rica.] observamos que por simetr铆a se debe cumplir que $v(B)=v(F)=v(H)=\alpha$ (los nodos adyacentes a $A$) y $v(C)=v(E)=v(G)=\beta$ (los nodos adyacentes a $E$). Esto reduce el sistema a uno de 2 por 2
  $$
  \begin{cases}
  -9\alpha+6\beta = -3,\\
  6\alpha -9\beta = 0
  \end{cases} \qquad\Rightarrow\qquad \alpha = \frac{3}{5}, \qquad \beta = \frac{2}{5}.
  $$
</details>

---

:::{.exercise}
Calcula la matriz asociada al Laplaciano para el grafo a continuaci贸n

![](./k3.png){width=70%}
:::

<details>
  <summary>Soluci贸n</summary>
  $$
  \Delta = \operatorname{div} D = \begin{pmatrix}
  1 & 0 & -1 & 1 & 0\\
  -1 & 1 & 0 & 0 & 0\\
  0 & -1 & 1 & 0 & -1\\
  0 & 0 & 0 & -1 & 1
  \end{pmatrix}\begin{pmatrix}
  -1 &  1 &  0 &  0\\
   0 & -1 &  1 &  0\\
   1 &  0 & -1 &  0\\
  -1 &  0 &  0 &  1\\
   0 &  0 &  1 & -1
  \end{pmatrix} = \begin{pmatrix}
  -3 & 1 & 1 & 1\\
  1 & -2 & 1 & 0\\
  1 & 1& -3 & 1\\
  1 & 0 & 1 & -2
  \end{pmatrix}
  $$
</details>

---

:::{.exercise}
Da un an谩logo discreto para la f贸rmula de Green
$$
\int_\Omega (u_1\Delta u_2 - u_2\Delta u_1) = \int_{\partial\Omega} (u_1Du_2 - u_2 Du_1)\cdot n
$$
:::

<details>
  <summary>Soluci贸n</summary>
De la f贸rmula de integraci贸n por partes \@ref(eq:ipv)
$$
\sum_\Omega u_i \Delta u_j = \sum_{E} u_i^- Du_j n_\Omega - \sum_{e_+\in \Omega} Du_iDu_j
$$
Por lo tanto al tomar la resta se cancelan el segundo t茅rmino a la deracha quedando as铆
$$
\sum_\Omega (u_1 \Delta u_2-u_2 \Delta u_1) = \sum_{E} (u_1^- Du_2 - u_2^- Du_1)n_\Omega.
$$
</details>

---

En general podemos a帽adir una operaci贸n intermedia entre el gradiente y la divergencia. Esto genera operadores con caracter铆sticas similares al Laplaciano.

---

:::{.example}
Considera ahora una red el茅ctrica con resistencias variables. La ley de Ohm consiste en tomar el gradiente del potencial y luego dividir por las resistencias para obtener la corriente. Al rec铆proco de la resistencia tambi茅n se le conoce como la capacitancia y puede ser m谩s conveniente de usar en este ejemplo. En este caso las ecuaciones de balance para el potencial el茅ctrico tienen la forma
$$
\operatorname{div} (CDu) = 0 \qquad C = 1/R : \text{Capacitancia}
$$
(fuera de los nodos donde se conecta la bater铆a).

En el caso particular de las resistencias dadas en la siguiente gr谩fica,

![](capa.png){width=70%}

obtenemos el operador lineal asociado a la siguiente matriz
```{python}
import numpy as np

# Gradiente
D = np.array([[-1, 1, 0, 0],
              [0, -1, 1, 0],
              [1, 0, -1, 0],
              [-1, 0, 0, 1],
              [0, 0, 1, -1]])
              
# Capacitancia (C=1/R)
C = np.array([[1, 0, 0, 0, 0],
              [0, 1/4, 0, 0, 0],
              [0, 0, 1/2, 0, 0],
              [0, 0, 0, 1/5, 0],
              [0, 0, 0, 0, 1/3]])

# Operador L = div(CD)
L = -np.matmul(D.T,np.matmul(C,D))

print(L)
```
:::

---

:::{.example}
Las ecuaciones de balance en los [entramados](#entramados) se implementan en tres pasos:

1. Se toman las posiciones relativas entre nodos adyacentes, es decir el gradiente de las posiciones $q:V\to\mathbb R^2$.

1. Se forman las tensiones a partir de las posiciones relativas y los multiplicadores $\lambda:E\to \mathbb R$.

1. Se propone el balance de fuerzas en t茅rminos de la divergencia de la tensi贸n.

En s铆ntesis se obtiene que en los nodos libres
$$
\operatorname{div} (\lambda D q) = mge_2
$$
A diferencia de los problemas de redes el茅ctricas, tanto $q$ como $\lambda$ son variables por ser determinadas lo cual hace que el problema sea no-lineal en dichas inc贸gnitas. 
:::

<!--chapter:end:02-calculo.Rmd-->

# Din谩mica

<!--  
```{python}
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import animation
from matplotlib.animation import PillowWriter

def f(x,t):
  return np.exp(-(x-5*t)**2)*np.sin(10*x-5*t)

x = np.linspace(0,10*np.pi,1000)

fig, ax = plt.subplots(1,1,figsize=(8,4))
ln, = plt.plot([],[])
ax.set_xlim(0,10*np.pi);
ax.set_ylim(-1.5,1.5);

def animate(i):
  ln.set_data(x,f(x,i/50))

ani = animation.FuncAnimation(fig, animate, frames=240, interval = 50)
ani.save('anim.gif',writer='pillow',fps=50,dpi=100)
plt.clf()
```

![](anim.gif)
-->

## Transporte

Consideremos un grafo dirigido $G=(V,E)$ y una familia de densidades $u(x,t)$ que toma valores reales para cada v茅rtice $x\in V$ en tiempo $t\in\mathbb R$. Decimos que un flujo $f(e,t)$ transporta a $u$ si en cada instante salen $f(e,t)$ unidades de masa de $e_-$ hacia $e_+$ por la arista $e$. Es decir que sobre cada $x\in V$ se tiene que
$$
\partial_t u(x,t) = \sum_{e_+=x} f(e,t) - \sum_{e_-=x} f(e,t) = -\operatorname{div} f(x,t).
$$

Observamos que si en un dado nodo $x\in V$ se tiene que $\operatorname{div} f(x)>0$ entonces $u$ es decreciente. Esto quiere decir que el flujo hace que la densidad se esparza o diverja sobre  dicho nodo. De igual forma, si $\operatorname{div} f(x)<0$, $u$ es creciente y el flujo hace que la densidad en cambio converga en dicho nodo.

---

:::{.example}
Consideremos una densidad $u:V\times \mathbb R\to \mathbb R$ transportada por un flujo $f := \mu u^-$ donde $\mu:E\to \mathbb R$ son tazas de movilidad dadas sobre las aristas en el grafo a continuaci贸n y recordemos que $u^-(e)=u(e_-)$

![](./flow1.png)

Comenzando de la distribuci贸n de densidades
$$
u(0) = (1,0,0,0)
$$
integramos numericamente las cuatro ecuaciones dadas por
$$
\partial_t u = -\operatorname{div}(\mu u^-) \qquad\Leftrightarrow \qquad \begin{cases}
u(1)' = -3u(1)+3u(3),\\
u(2)' = u(1) - u(2),\\
u(3)' = u(2) - 3u(3) + 2u(4),\\
u(4)' = 2u(1)-2u(4).
\end{cases}
$$
y obtenemos lo siguiente:

```{python}
import numpy as np
import matplotlib.pyplot as plt
import scipy as sp
from scipy.integrate import odeint

A = np.array([[-3, 0, 3, 0],
              [1, -1, 0, 0],
              [0, 1, -3, 2],
              [2, 0, 0, -2]])

def dudt(u,t):
  return np.matmul(A,u)

u0 = np.array([1,0,0,0])

t = np.linspace(0,2,1000)
sol = odeint(dudt,u0,t)

plt.plot(t,sol[:,0], label='1')
plt.plot(t,sol[:,1], label='2')
plt.plot(t,sol[:,2], label='3')
plt.plot(t,sol[:,3], label='4')
plt.legend()
plt.show()
```
:::

---

Adicionalmente podemos considerar modelos donde adem谩s del fen贸meno de transporte, una o m谩s densidades tienen distintas reacciones en cada uno de los nodos.

---

:::{.example}
Las funciones $S,I:V\to \mathbb R$ representan poblaciones de individuos susceptibles e infectados para una dada epidemia modelada geogr谩ficamente sobre un grafo dirigido $G=(V,E)$. Cada una de estas poblaciones se mueve sobre las aristas por flujos dados por
$$
f_S := \mu_S S^-, \qquad f_I := \mu_I I^-.
$$
donde $\mu_S,\mu_I: E\to \mathbb R$ son tazas de movilidad sobre las aristas.

La din谩mica de la epidemia en cada nodo est谩 dada por las tazas de transmisi贸n ($\beta$) y recuperaci贸n ($\gamma$). En espec铆fico planteamos el modelo de $2|V|$ ecuaciones de primer orden no-lineales
$$
\partial_t S = -\beta SI + \operatorname{div}(\mu_S S^-), \qquad \partial_t I = \beta SI - \gamma I + \operatorname{div}(\mu_I I^-),\\
$$
:::

---

:::{.exercise}
Demuestra que el total de la poblaci贸n susceptible o infectada es una funci贸n decreciente. 
:::

<details>
  <summary>Soluci贸n</summary>
  $$
  \partial_t \sum_{V} (S+I) = \sum_{V} (-\gamma I + \operatorname{div} f_S+\operatorname{div}f_I) = - \gamma \sum_{V} I \leq 0.
  $$
</details>

---

:::{.exercise}
Considera una epidemia dada en la siguiente red con los par谩metros dados. En las aristas se muestran ciertas tasas de movilidad, para los susceptibles estas deben multiplicarse por $10^{-2}$ y para los infectados por $10^{-4}$. Implementa num茅ricamente y grafica las soluciones en el intervalo $[0,160]$ con condiciones iniciales
$$
S(0) = (1,1,1,1), \qquad I(0) = (0, 10^{-6},0,0).
$$

![](./sir2.png){width=70%}
:::

<details>
  <summary>Soluci贸n</summary>
```{python}
import numpy as np
import matplotlib.pyplot as plt
import scipy as sp
from scipy.integrate import odeint

beta = 0.5
gamma = 0.3

L = np.array([[-5, 1, 2, 1],
              [2, -3, 1, 0],
              [1, 2, -4, 2],
              [2, 0, 1, -3]])


def dSIdt(SI,t):
  S = SI[:4]
  I = SI[4:]
  dS = -beta*S*I + 0.01*np.matmul(L,S)
  dI = beta*S*I - gamma*I + 0.0001*np.matmul(L,I)
  return np.concatenate((dS,dI))

S0 = np.array([1,1,1,1])
I0 = np.array([0,0.00000001,0,0])
SI0 = np.concatenate((S0,I0))

t = np.linspace(0,160,1000)
sol = odeint(dSIdt,SI0,t)

fig, ax = plt.subplots(2,2,figsize=(10,5))

ax[0,0].plot(t,sol[:,0], label='S1')
ax[0,0].plot(t,sol[:,4], label='I1')
ax[0,0].legend()

ax[1,0].plot(t,sol[:,1], label='S2')
ax[1,0].plot(t,sol[:,5], label='I2')
ax[1,0].legend()

ax[0,1].plot(t,sol[:,2], label='S3')
ax[0,1].plot(t,sol[:,6], label='I3')
ax[0,1].legend()

ax[1,1].plot(t,sol[:,3], label='S4')
ax[1,1].plot(t,sol[:,7], label='I4')
ax[1,1].legend()
```
</details>

## Difusi贸n

As铆 como vimos en los ejemplos anteriores donde el flujo era proporcional a $u^-$, en general puede darse el caso de que $f$ est茅 determinada por alguna otra funci贸n de $u$, esto se conoce como una **ley constitutiva**. Un caso muy com煤n es que $f$ sea proporcional a $-Du$, en el cual obtenemos un modelo de **difusi贸n**.

---

:::{.example}
Sea $G=(V,E)$ un grafo que modela una red de habitaciones en renta y $u:V\times \mathbb R\to\mathbb R$ la poblaci贸n que vive en dicha red. Asumiendo la ley de oferta y demanda, el precio de renta $p=p(x,t)$ de una habitaci贸n $x$ en el instante $t$ debe ser proporcional a la demanda, la cual podemos considerar en nuestro caso proporcional a la poblaci贸n que habita dicho nodo, digamos por ejemplo que $p = k_1u$. La poblaci贸n busca moverse entre nodos adyacentes si percibe que el precio le es favorable, por ejemplo $f=-k_2Dp$. Llegamos as铆 a la ecuaci贸n
$$
\partial_t u = -\operatorname{div} f = \operatorname{div}(k_2Dp) = \operatorname{div}(aDu), \qquad a := k_1k_2.
$$
:::

---

El problema $\partial_t u = \operatorname{div}(aDu)$, tambi茅n conocido como la **ecuaci贸n de calor** o **difusi贸n**, representa un sistema de EDOs lineales y de primer orden con tantas ecuaciones e inc贸gnitas como la cardinalidad de $V$.

---

:::{.exercise}
Considera una difusi贸n de la forma $\partial_t u = \Delta u$ sobre el siguiente grafo. Calcula $u$ para todo tiempo dadas las condiciones iniciales ilustradas en la figura. 驴Converge la soluci贸n a alg煤n punto fijo?

![](./dif.png){width=70%}
:::

<details>
  <summary>Soluci贸n</summary>
  El sistema de 4 EDOs se presenta como
  $$
  \frac{d}{dt}\begin{pmatrix}
  u(a)\\
  u(b)\\
  u(c)\\
  u(d)
  \end{pmatrix} = \begin{pmatrix}
  -3 & 1 & 1 & 1\\
  1 & -2 & 1 & 0\\
  1 & 1 & -3 & 1\\
  1 & 0 & 1 & -2
  \end{pmatrix}\begin{pmatrix}
  u(a)\\
  u(b)\\
  u(c)\\
  u(d)
  \end{pmatrix}
  $$
  Dada que la condici贸n inicial es $(1,0,0,0)^T$ buscamos la primera columna de la matriz exponencial. El siguiente resultado se obtuvo con la ayuda de [sympy](https://live.sympy.org/), una librer铆a de c谩lculo simb贸lico de python
  
```{python, results='asis'}
from sympy import *
  
t = Symbol('t')
mt = Matrix([[-3, 1, 1, 1],
             [1, -2, 1, 0],
             [1, 1, -3, 1],
             [1, 0, 1, -2]]) * t
mexp = mt.exp()
print('$$' + latex(mexp) + '$$')
```

Observamos que cuando $t\to\infty$ la soluci贸n converge exponencialemente al vector $(1/4,1/4,1/4,1/4)^T$. De hecho **esto sucede para cualquier condici贸n incial**.
</details>

---

:::{.exercise}
Sea $G=(V,E)$ un grafo lineal con 100 v茅rtices
$$
V=\{1,2,\ldots,100\}, \qquad E = \{(1,2),(2,3),\ldots,(99,100)\}.
$$
Sea $u$ soluci贸n de la ecuaci贸n de calor $\partial_t u=\Delta u$ en $G$ con condici贸n inicial
$$
u(0) = e_{50} = (0,\ldots,0,1,0,\ldots,0).
$$
Calcula el primer $t>0$ tal que $u(50,t)\leq 0.1$. 
:::

<details>
  <summary>Soluci贸n</summary>
  En este caso la dificultad est谩 en c贸mo implementar el Laplaciano y encontrar el primer 铆ndice donde la soluci贸n baje de $0.1$.
```{python}
import numpy as np
import matplotlib.pyplot as plt
from scipy.integrate import odeint

Delta = -2*np.eye(100)+np.eye(100,k=1)+np.eye(100,k=-1)
Delta[0,0] = -1
Delta[99,99] = -1

def dudt(u,t):
  return np.matmul(Delta,u)

u0 = np.zeros(100)
u0[49] = 1

t = np.linspace(0,20,1000)

sol = odeint(dudt,u0,t)
index = np.where(sol[:,49]<0.1)[0][0]
plt.plot(t,sol[:,49])
plt.plot(t[index],sol[index,49],'ro',label="({:.2f},{:.2f})".format(t[index],sol[index,49]))
plt.legend()
plt.title("u(50,t)")
plt.show()
```
</details>


## Oscilaci贸n

El sistema de EDOs lineales y de segundo orden dado por
$$
\partial_t^2 u = \operatorname{div}(aDu)
$$
tambi茅n es com煤n en distintos modelos. Esta se conoce como la **ecuaci贸n de onda**.

---

:::{.example}
Un grafo $G=(V,E)$ modela las conexiones en un sistema de masas $m:V\to (0,\infty)$ unidas por resortes con constantes $k:E\to[0,\infty)$. Sea $q:V\to \mathbb R^n$ los desplazamientos de las masas a partir de una configuraci贸n dada de equilibrio. A partir de la ley de Hooke planteamos el sistema $n\times|V|$ ecuaciones e inc贸gnitas,
$$
m\partial_t^2 q = \operatorname{div}(kDq).
$$
:::

Recordemos que cualquier sistema de segundo orden puede ser llevado a un sistema de primer orden tomando a las velocidades como inc贸gnitas del sistema. Por ejemplo,
$$
\partial_t^2 u = \operatorname{div}(aDu) \qquad \Leftrightarrow\qquad \begin{cases}
\partial_t u = v,\\
\partial_t v = \operatorname{div}(aDu).
\end{cases}
$$

---

:::{.example}
El grafo $G=(V,E)$ vuelve a modelar una red de habitaciones en renta, $u:V\times \mathbb R\to\mathbb R$ la poblaci贸n que vive en dicha red y $p:V\times \mathbb R\to\mathbb R$ los precios. Una vez m谩s asumimos que la poblaci贸n se mueve seg煤n el flujo $f = -Dp$. Por otro lado los precios se modifican gradualmente dependiendo de la demanda en relaci贸n a los nodos adyacentes.

Esto 煤ltimo puede ser reflejado por ejemplo en la ecuaci贸n $\partial_t p = -\Delta u$, es decir que el precio disminuye si el promedio de la poblaci贸n vecina es mayor la poblaci贸n en el nodo en consideraci贸n, con la intenci贸n de atraerla.

En resumen obtenemos el sistema de ecuaciones
$$
\partial_t u = \Delta p, \qquad \partial_t p = -\Delta u.
$$
Estas implican las ecuaciones de onda desacopladas para el bilaplaciano
$$
\partial_t^2 u = -\Delta^2 u, \qquad \partial_t^2 p = -\Delta^2p.
$$
:::

---

:::{.exercise}
Considera una oscilaci贸n de la forma $\partial_t^2 u = -\Delta^2 u$ sobre el siguiente grafo. Calcula $u$ para todo tiempo dadas las condiciones iniciales ilustradas en la figura, partiendo del reposo. Grafica la soluci贸n en el intervalo $[0,6]$.

![](./oscila.png){width=70%}
:::

<details>
  <summary>Soluci贸n</summary>
  El sistema de 4 EDOs se presenta como
  $$
  \frac{d}{dt}\begin{pmatrix}
  u(a)\\
  u(b)\\
  u(c)\\
  u(d)\\
  u'(a)\\
  u'(b)\\
  u'(c)\\
  u'(d)
  \end{pmatrix} = \begin{pmatrix}
  0_4 & I_4\\
  -\Delta^2 & 0_4
  \end{pmatrix}\begin{pmatrix}
  u(a)\\
  u(b)\\
  u(c)\\
  u(d)\\
  u'(a)\\
  u'(b)\\
  u'(c)\\
  u'(d)
  \end{pmatrix}, \qquad \Delta = \begin{pmatrix}
  -3 & 1 & 1 & 1\\
  1 & -2 & 1 & 0\\
  1 & 1 & -3 & 1\\
  1 & 0 & 1 & -2
  \end{pmatrix}
  $$
  
  Para calcular la soluci贸n anal铆tica usamos el paquete simb贸lico de python.
  
```{python, results='asis'}
import numpy as np
import matplotlib.pyplot as plt
import sympy as smp
from sympy.plotting import plot

Delta = smp.Matrix([[-3,1,1,1],
              [1,-2,1,0],
              [1,1,-3,1],
              [1,0,1,-2]])

t = smp.symbols('t',real='True')

B = smp.Matrix(smp.BlockMatrix([[smp.ZeroMatrix(4,4),smp.Identity(4)],
            [-Delta*Delta,smp.ZeroMatrix(4,4)]]))*t
eB = smp.re(B.exp())
y0 = smp.Matrix([0,1,2,3,0,0,0,0])
y_s = eB*y0
print('$$' + smp.latex(y_s[:4]) + '$$')
```

Las gr谩ficas est谩n dadas por

```{python}
eB_f = smp.lambdify(t,eB)

t = np.linspace(0,6,600)
y0 = np.array([0,1,2,3,0,0,0,0])
y = np.einsum('ijk,j->ik',eB_f(t),y0)
plt.plot(t,y[0,:],label='a')
plt.plot(t,y[1,:],label='b')
plt.plot(t,y[2,:],label='c')
plt.plot(t,y[3,:],label='d')
plt.legend(loc='lower right')
```
</details>
<!--



\begin{center}
\colorbox[HTML]{E5F3CC}{
\begin{minipage}[c]{450px}
\begin{ejemplo}
Demuestra que la poblaci贸n total, la suma de los precios, y $\sum(u^2+p^2)$ permanecen constantes.
\end{ejemplo}
\end{minipage}}
\end{center}
-->

<!--chapter:end:03-dinamica.Rmd-->

# Implementaci贸n del entramado

En esta secci贸n veremos como poner en pr谩ctica los conceptos aprendidos para modelar una red cuadrada sujetada por sus cuatro esquinas. Recordemos que a pesar de que podemos dar una forma expl铆cita de las ecuaciones que se deben resolver, el m茅todo de Newton parece ser muy sensible a las condiciones iniciales, por lo que hay que ingeniarse una forma alternativa.

La idea que tenemos en mente es proponer que las conexiones entre nodos el谩sticas. Con esto proponemos un modelo el谩stico que gracias a un t茅rmino de viscosidad podemos llevar al reposo. Con estas configuraciones terminales podemos luego ir haciendo la dureza (stiffness) de los resortes cada vez m谩s y m谩s grande, aproximando as铆 la configuraci贸n de equilibrio cuando las barras son r铆gidas.

## Librer铆as y datos

Para fijar ideas proponemos una red con $N$ por $N$ nodos de masa $m>0$ como la ilustrada a continuaci贸n. La esquinas ser谩n colgadas en los puntos $(0,0,0)$, $(1,0,0)$, $(1,1,0)$, y $(0,1,0)$.

![](./red.png){width=70%}

Entre cada par de nodos adyacentes se ubica un resorte cuya longitud natural es $l > 1/(N-1)$, dureza $k\gg 1$, y amortiguaci贸n $\gamma > 0$. Es decir que si dos nodos adyacentes est谩n a distancia $d$, la magnitud de la fuerza que ejerce el resorte entre ellos es $k|d-l|$. Esta fuerza es paralela a la l铆nea que contiene a estos nodos y la direcci贸n (o el signo) dependen de como se compare $d$ respecto de $l$: Para $d>l$ el resorte atrae a los nodos entre si, y para $d<l$ el resorte los repele.

```{python}
import numpy as np
from numpy import linalg as la
import matplotlib.pyplot as plt
import scipy as sp
import scipy.sparse as sps
from scipy.integrate import odeint

N = 10        # Longitud de la red
m = 0.1       # Masa de los nodos
gamma = 1     # Coeficiente de amortiguaci贸n
k = 100       # Coeficiente de dureza
l = 1.1/(N-1) # Longitud natural del resorte

fijos = [0, N-1, N**2-N, N**2-1] # Esquinas fijas

# Listas para enumerar las aristas de la red

# Aristas verticales

ini_v = list(range(N**2-N))
fin_v = list(range(N,N**2))

# Aristas horizontales

ini_h = list(range(N**2))
del ini_h[slice(N-1,N**2,N)]
fin_h = list(range(1,N**2+1))
del fin_h[slice(N-1,N**2,N)]

ini = ini_h + ini_v     # Nodos de salida
fin = fin_h + fin_v     # Nodos de llegada
Ne = len(ini)           # N煤mero de aristas
```

## Ecuaci贸n diferencial

La ecuaci贸n diferencial que buscamos modelar para la posici贸n $p=(x,y,z)$ de cada nodo est谩 dada por las leyes de Newton:
$$
mp'' = \text{gravedad} + \text{tensi贸n} + \text{amortiguaci贸n}
$$

De estos tres tr茅minos la gravedad y la tensi贸n son f谩ciles de calcular. Respectivamente son $-mge_z$ y $-\gamma p'$. Asumiendo el sistema internacional de unidades tomamos $g = 9.8$. La dificultad reside ahora en implementar el c谩lculo de las tensiones.

Recordemos adem谩s que para poder resolver nuestra EDO usando la librer铆a de integraci贸n num茅rica de Scipy (odeint) debemos transformar el sistema a uno de primer orden. Esto significa que las velocidades pasan a ser parte de las inc贸gnitas. Codificamos en la curva $s=s(t)$ las configuraciones de nuestro sistema de la siguiente forma
$$
s = (pos,vel) = ((x,y,z),(vx,vy,vz)) \in (\mathbb R^{N^2}\times\mathbb R^{N^2}\times\mathbb R^{N^2})\times(\mathbb R^{N^2}\times\mathbb R^{N^2}\times\mathbb R^{N^2})
$$
Dadas las posiciones $p_{ini}$ y $p_{fin}$ de dos nodos extremos sobre una arista dada tenemos que la tensi贸n sobre dicha arista se calcula por
$$
T := k(d-l)\theta, \qquad d := |p_{fin}-p_{ini}|, \qquad \theta := \frac{p_{fin}-p_{ini}}{d}
$$
Esta es justamente la tensi贸n que se ejerce sobre el nodo inicial de la arista, siendo la fuerza opuesta en el otro nodo gracias a la tercera ley de Newton. Un paso t茅cnico a partir de ac谩 consiste en transferir est谩 informaici贸n dada sobre las aristas a los nodos.

Estas consideraciones te贸ricas quedan reflejadas en la siguiente funci贸n:

```{python}
def dsdt(s,t):
  pos = np.reshape(s[:3*N**2],(3,N**2)).T
  vel = np.reshape(s[3*N**2:],(3,N**2)).T

  pos_rel = pos[fin] - pos[ini]
  lon_rel = np.tile(la.norm(pos_rel,axis=1),(3,1)).T   # d
  dir_rel = pos_rel/lon_rel                            # theta
  ten_esc = k*(lon_rel-l*np.ones((Ne,3)))              # Magnitud de la tensi贸n (signada)
  ten_ari = ten_esc*dir_rel                            # Tensi贸n sobre el nodo inicial
  
  # Tensi贸n total sobre cada nodo. Usamos una estructura de matrices ralas (sparse) para codificarlas eficientemente.
  
  data = np.concatenate((ten_ari.T.reshape(-1),-ten_ari.T.reshape(-1)))
  fila = 3*ini+3*fin
  colu = 2*(Ne*[0]+Ne*[1]+Ne*[2])
  ten_nod = sps.coo_matrix((data, (fila, colu))).toarray()
  
  # Fuerzas y aceleraci贸n
  
  fue_gra = -9.8*m*np.tile(np.array([0,0,1]),(N**2,1)) # Gravedad
  visc = -gamma*vel                                     # Amortiguaci贸n
  acel = (ten_nod + fue_gra + visc)/m                   # Aceleraci贸n

  acel[fijos,:] = [0,0,0]                               # Esquinas fijas
  
  return np.concatenate((s[3*N**2:],acel.T.reshape(-1)))
```

## Integraci贸n y graficaci贸n

Una vez modelada la ecuaci贸n diferencial ya podemos proceder a integrarla usando por ejemplo el comando odeint de la librer铆a Scipy. Para ello necesitamos dar adicionalmente un intervalo de tiempo discreto y una condici贸n inicial.

```{python}
px, py = np.meshgrid(np.linspace(0,1,N),np.linspace(0,1,N))
s0 = np.concatenate((px.reshape(-1), py.reshape(-1),np.zeros(N**2),np.zeros(3*N**2)))
t = np.linspace(0,10,2000)

sol = odeint(dsdt,s0,t)
```

Visualizaci贸n del 煤ltimo instante

```{python}
fig = plt.figure()
ax = plt.axes(projection='3d')
ax.axes.set_xlim3d(left=0, right=1);
ax.axes.set_ylim3d(bottom=0, top=1);
ax.axes.set_zlim3d(bottom=-1, top=0);
ax.view_init(60, 80);

sol_fin = sol[-1,:]
pos = np.reshape(sol_fin[:3*N**2],(3,N**2)).T
for i in range(N):
  ax.plot3D(pos[i*N:(i+1)*N,0], pos[i*N:(i+1)*N:,1], pos[i*N:(i+1)*N,2],'bo-')
  ax.plot3D(pos[i:N**2:N,0], pos[i:N**2:N,1], pos[i:N**2:N,2],'b-')
```

<!--chapter:end:04-entramado.Rmd-->

# Espectro del Laplaciano

\section{Espectro del Laplaciano}

Hemos visto tres familias de problemas relacionados con el operador lineal $u \mapsto Lu = \operatorname{div}(aDu)$:

- **El铆ptico:** $\operatorname{div}(aDu) = f$,

- **Parab贸lico:** $\partial_t u = \operatorname{div}(aDu) + f$,

- **Hiperb贸lico:** $\partial_t^2 u = \operatorname{div}(aDu) + f$.

Como tales, la descomposici贸n espectral de $L$ trivializa el c谩lculo de las soluciones. A continuaci贸n daremos un breve recorrido a la teor铆a discreta de Fourier con la cual podemos clarificar como resolver cada uno de estos problemas.

Para $a:E\to (0,\infty)$ la composici贸n dada por $Lu = \operatorname{div}(aDu)$ es un operador sim茅trico, negativo semi-definido. La simetr铆a es una aplicaci贸n de la f贸rmula de integraci贸n por partes, bien sea usando que
$$
(\operatorname{div} \operatorname{diag}(a) D)^T = D^T \operatorname{diag}(a)^T \operatorname{div}^T = (-\operatorname{div})  \operatorname{diag}(a)(-D) = \operatorname{div}\operatorname{diag}(a)D,
$$
o en t茅rminos de las sumas
$$
\sum_{x\in V} v(x)\operatorname{div}(aDu)(x) = -\sum_{e\in E} Dv(e)Du(e)a(e) = \sum_{x\in V} u(x)\operatorname{div}(aDv)(x).
$$
La no-positividad la verificamos tomando $v=u$ tal que
$$
\sum_{x\in V} u(x)\operatorname{div}(aDu)(x) = -\sum_{e\in E} (Du(e))^2a(e) \leq 0.
(\#eq:neg)
$$

Gracias al teorema espectral sabemos que $L$ es diagonalizable, sus autovalores son reales no-positivos y adem谩s posee una base de autofunciones ortogonales. Denotemos por $\phi_0,\ldots,\phi_{M-1}$ a una base ortogonal con autovalores $-\lambda_0,\ldots,-\lambda_{M-1}$ respectivamente.

<details>
  <summary>**Margen de 谩lgebra lineal:** El teorema espectral</summary>
  El teorema espectral dice que si $L\in \mathbb R^{N\times N}$ es sim茅trica, entonces sus autovectores son reales y existe una base ortogonal de autovectores.

Para ver que un dado autovector $\lambda$ es real consideramos un correspondiente autovector $\xi$ (posiblemente complejo) tal que
$$
\lambda\|\xi\|^2 = L\xi\cdot \overline{\xi} = \xi\cdot L\overline{\xi} = \xi\cdot \overline{L\xi} = \overline{\lambda}\|\xi\|^2.
$$
Dado que $\xi\neq0$ la 煤nica opci贸n posible es que $\lambda=\overline{\lambda}$, es decir $\lambda\in \mathbb R$. M谩s a煤n, podemos considerar de ahora en adelante que $\xi$ tambi茅n es real dado que las partes real e imaginarias de un dado autovector son tambi茅n autovectores (dado que $L$ es real).

Autovectores $\xi$, $\xi'$ con autovalores distintos $\lambda$, $\lambda'$ (respectivamente) son ortogonales dado que
$$
\lambda (\xi\cdot\overline{\xi'}) = L\xi\cdot \overline{\xi'} = \xi\cdot L\overline{\xi'} = \xi\cdot \overline{L\xi'} = \overline{\lambda'} (\xi\cdot\overline{\xi'}) = \lambda' (\xi\cdot\overline{\xi'}).
$$

Para ver que existe una base de autovectores se puede proceder por inducci贸n. Si $\lambda$ es un autovalor con autovector $\xi$, entonces podemos descomponer $\mathbb R^N$ como la suma directa de la l铆nea $\operatorname{vspan}\{\xi\}$ y su complemento ortogonal $S = \operatorname{vspan}\{\xi\}^\perp$. El operador $L|_S$ tiene rango en $S$, dado que para $x\in S$
$$
Lx\cdot \overline{\xi} = x\cdot L\overline{\xi} = x\cdot \overline{L\xi} = \overline{\lambda} (x\cdot \overline{\xi}) = 0.
$$
Adem谩s vuelve a ser sim茅trico (con respecto al producto interno). Tenemos de esta forma el paso para llevar adelante un argumento por inducci贸n.

Finalmente, cuando $L$ se corresponde con una forma cuadr谩tica negativa semi-definida tenemos que los autovalores son no-positivos dado que
$$
0\geq L\xi\cdot \xi = \lambda\|\xi\|^2.
$$
</details>

---

Gracias a la identidad \@ref(eq:neg) vemos adem谩s que $\operatorname{div}(aDu)=0$ si y solo si $Du=0$. Si $G$ es conexo entonces esto solamente se cumple para las funciones constantes. En otras palabras, $\lambda=0$ es un autovalor simple cuyo autoespacio consiste de las funciones constantes. En general, $\lambda=0$ es un autovalor de $L$ cuya multiplicidad geom茅trica es igual al n煤mero de componentes conexas de $G$.

**Asumiremos adem谩s de ahora en adelante que $G$ es conexo y $\phi_0=1$ es la autofunci贸n asociada a $\lambda_0=0$, siendo los dem谩s autovalores estrictamente negativos (es decir que $\lambda_j>0$ para $j\neq 0$).**

---

:::{.exercise}
Demuestra que para cualquier autofunci贸n $\phi_j$ para $j\neq 0$ se tiene que $\phi_j$ cambia de signo. Es decir que ninguno conjuntos $\{\phi_j>0\}$, $\{\phi_j<0\}$ es vac铆o.
:::

<details>
<summary>**Soluci贸n**</summary>
Dado que $\phi_0=1$ es ortogonal a $\phi_j$ tenemos que $\sum\phi_j=0$. Como $\phi_j\neq 0$, necesariamente debe tener tanto valores positivos como negativos.
</details>
---

Gracias a la ortogonalidad podemos calcular la descomposici贸n de una funci贸n arbitraria usando productos internos. Esta se conoce como la **transformada de Fourier discreta**.

Dado que
$$
u = \sum_{j=0}^{|V|-1} \hat u_j \phi_j
$$
tenemos que tomando en ambos lados el producto interno con $\phi_j$ obtenemos que
$$
\hat u_j = \frac{1}{\|\phi_j\|^2}\sum_{x\in V} u(x) \overline{\phi_j(x)}.
$$
Los coeficientes $\hat u_j$ se conocen como los **coeficientes de Fourier**.

---

:::{.example}
Consideremos el grafo c铆clico con $M$ v茅rtices los cuales identificamos con los enteros m贸dulo $M$. En este caso
$$
\Delta u(x) = u(x+1) - 2u(x) + u(x-1).
$$
Para calcular el espectro de $\Delta$ debemos encontrar las soluciones $M$-peri贸dicas de la recurrencia
$$
\phi(x+1) - 2\phi(x) + \phi(x-1) = -\lambda \phi(x).
$$

Sean $r_\pm$ las ra铆ces del polinomio caracter铆stico $p(r) = r^2-(2-\lambda)r+1$. Tenemos as铆 que^[Salvo en el caso de que $r_+=r_-$ que podemos analizar m谩s adelante si hiciese falta... No har谩 falta.]
$$
\phi(x) = A_+r_+^x+A_-r_-^x.
$$
Observamos que para obtener soluciones $M$-peri贸dicas basta con tomar a $r_\pm$ como ra铆ces $M$-茅simas de la unidad, conjugadas entre si (dado que $r_+r_-=1$), de hecho la condici贸n tambi茅n terminar谩 siendo necesaria. Es decir que
$$
r_\pm = \omega^{\pm j}, \qquad \omega := e^{2\pi i/M}, \qquad j\in\{0,1,\ldots,M-1\}.
$$
A partir de estas encontramos las autofunciones
$$
\phi_{j}(x) := \omega^{jx}
$$
cuyos autovalores son $-\lambda_j$ donde
$$
\lambda_j := \omega^{j}+\omega^{-j}-2 = 2\cos(2\pi j/M)-2 = 4\sin^2(\pi j/M).
$$

La colecci贸n $\phi_0,\ldots,\phi_{M-1}$ forma una base ortogonal de $\mathbb C^M$ conocida como la **base de Fourier**
$$
\sum_{x\in V} \phi_k(x)\overline{\phi_l(x)} = \sum_{j=0}^{M-1} \omega^{(k-l)j} = \begin{cases}
M \text{ si } k=l,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$

Observa que $\lambda_j = \lambda_{M-j}$, por lo que si $j$ no es divisible por $M/2$, el autovalor $\lambda_j$ tiene multiplicidad dos. En los dem谩s casos el autovalor tiene multiplicidad uno.
:::

---

:::{.exercise}
Demuestra que a partir de
$$
\varphi_j(x) := \cos(2\pi j x/M), \qquad \psi_j(x) := \sin(2\pi j x/M)
$$
tambi茅n se puede construir una base ortogonal de autovectores para el ejemplo anterior. Ac谩 debes prestar atenci贸n de lo que sucede cuando $j=M/2$ en caso de que $M$ sea par.
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.exercise}
Calcula las normas de $\varphi_j$ y $\psi_{j}$.
:::

<details>
<summary>Soluci贸n</summary>
$\|\varphi_j\|^2=\|\psi_{j}\|^2=M/2$
</details>

---

:::{.exercise #espectro}
Calcula el espectro del Laplaciano en los siguientes casos:

- S贸lidos plat贸nicos: tetraedro, cubo, octaedro, dodecaedro, icosaedro,

- Grafo completo,

- Grafo bipartito completo,

- Grafo lineal,

- Grafo producto^[El producto de $G_1$ y $G_2$ tiene como v茅rtices $V_1\times V_2$ siendo $((x_1,x_2),(y_1,y_2))$ una arista en este grafo si alguna de las siguientes dos condiciones se cumplen: $x_1=y_1$ y $(x_2,y_2)$ es una arista en $G_1$, o bien $x_2=y_2$ y $(x_1,y_1)$ es una arista en $G_2$.] en t茅rminos del espectro de sus factores (que asumimos conocido). Por ejemplo un toro puede verse como el producto de grafos c铆clicos.
:::

<details>
<summary>Soluci贸n</summary>
</details>

## Problema el铆ptico

Dada la descomposici贸n
$$
f = \sum_{j=0}^{|V|-1} \hat f_j\phi_j, \qquad \hat f_j = \frac{1}{\|\phi_j\|^2}\sum_{x\in V} f(x)\overline{\phi_j(x)},
$$
tenemos que $u = \sum_{j=0}^{|V|-1} \hat u_j\phi_j$ satisface $Lu=f$ si y solo si para todo $j\in\{0,\ldots,(|V|-1)\}$
$$
-\lambda_j \hat u_j = \hat f_j. 
$$

Recordemos la hip贸tesis de conexidad para $G$ la cual garantiza que $\lambda_0=0$ es un autovalor simple cuyo autoespacio son las funciones constantes generadas por $\phi_0=1$. Para $j\neq 0$ tenemos $\lambda_j > 0$ por lo cual $\hat u_j = -\hat f_j/\lambda_j$. Para $j=0$ tenemos sin embargo que $\lambda_0=0$ en cuyo caso la ecuaci贸n tiene soluci贸n solamente si se da la condici贸n de ortogonalidad $f\perp \phi_0$, equivalente a decir que^[Tambi茅n puede verse como consecuencia del Teorema de la divergencia]
$$
\sum_{x\in V} f(x) = 0.
$$
Bajo esta hip贸tesis, el correspondiente coeficiente $\hat u_0$ es arbitrario.

Bajo la condici贸n anterior para $f$, tenemos que las soluciones de $Lu=f$ est谩n dadas por
$$
u(x) = c - \sum_{j=1}^{|V|-1} \frac{\hat f_j}{\lambda_j}\phi_j(x) = c - \sum_{j=1}^{|V|-1} \frac{1}{\lambda_j\|\phi_j\|^2}\left(\sum_{y\in V} f(y)\overline{\phi_j(y)}\right)\phi_j(x).
$$
El t茅rmino constante es la soluci贸n homog茅nea del sistema. El segundo es una soluci贸n particular la cual podemos reescribir como
$$
u_p(x) := -\sum_{y\in V} G(x,y)f(y), \qquad G(x,y) := \sum_{j=1}^{|V|-1} \frac{\phi_j(x)\overline{\phi_j(y)}}{\|\phi_j\|^2}\lambda_j^{-1}.
$$

---

:::{.exercise}
Demuestra que^[Como $G$ es una funci贸n en $V^2$, definimos a $\Delta_1$ y $\Delta_2$ como los Laplacianos en la primera o segunda entrada respectivamente.]
$$
\Delta_1 G(x,y) = \Delta_2 G(x,y) = \frac{1}{|V|}- 1_y(x)=\frac{1}{|V|}- 1_x(y).
$$
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.exercise}
Demuestra que
$$
\sum_{x\in V} G(x,x) = \sum_{j=1}^{|V|-1} \lambda_j^{-1}.
$$
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.exercise}
Demuestra que $G$ es independiente de la base de Fourier.
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.exercise}
Demuestra que $G(x,y)=G(y,x)$.
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.exercise}
Demuestra que para $x\in[0,M]$
$$
\sum_{j=1}^{M-1} \frac{e^{2\pi i j x}-1}{\sin^2(\pi j/M)} = 2x(x-M)
$$
:::

<details>
<summary>Soluci贸n</summary>
</details>

## Problema parab贸lico

El sistema $\partial_t u = Lu+f$ se reduce a un sistema de ecuaciones diferenciales ordinarias desacopladas
$$
\hat u_j' = -\lambda_j \hat u_j + \hat f_j
$$
Usando por ejemplo la t茅cnica del factor integrante obtenemos
$$
\begin{aligned}
\hat u_j(t) &= \hat u_j(0)e^{-\lambda_j t} + \int_0^t \hat f_j(s)e^{-\lambda_j(t-s)}ds\\
&= \frac{1}{\|\phi_j\|^2}\sum_{y=1}^{|V|} \left(u(y,0)\overline{\phi_j(y)}e^{-\lambda_j t} + \int_0^t f(y,s)\overline{\phi_j(y)}e^{-\lambda_j(t-s)}ds\right)
\end{aligned}
$$

Agrupando los t茅rminos para la soluci贸n concluimos que
$$
u(x,t) = \sum_{y\in V} u(y,0)H(x,y,t) + \int_0^t\sum_{y\in V} f(y,s)H(x,y,t-s)ds
$$
donde
$$
H(x,y,t) := \sum_{j=0}^{|V|-1} \frac{\phi_j(x)\overline{\phi_j(y)}}{\|\phi_j\|^2}e^{-\lambda_j t} = \frac{1}{|V|} + \sum_{j=1}^{|V|-1} \frac{\phi_j(x)\overline{\phi_j(y)}}{\|\phi_j\|^2}e^{-\lambda_j t}.
$$

---

:::{.exercise}
Demuestra que $H(y,x,t) = H(x,y,t)$.
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.exercise}
Demuestra que $H$ es la soluci贸n del problema de valores iniciales
$$
\begin{cases}
\partial_t H = \Delta_1 H = \Delta_2 H,\\
H =  1_y(x)= 1_x(y) \text{ para $t=0$}.
\end{cases}
$$
Concluye a partir de esto que $H$ es independiente de la base de Fourier.
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.exercise}
Sea $u$ tal que $\partial_t u = \Delta u$. Calcula $\lim_{t\to\infty} u(t)$ en t茅rminos de $u(0)$.
:::

<details>
<summary>Soluci贸n</summary>
$\lim_{t\to\infty} u(t) = \frac{1}{M}\sum_{x\in V}u(x,0)$
</details>

---

:::{.exercise}
Para $G$ conexo demuestra que se da la siguiente expresi贸n asint贸tica cuando $t\to\infty$
$$
\int_0^t H(x,y,s)ds = \frac{t}{|V|} + G(x,y) + O(e^{-\lambda_1 t})
$$
:::

<details>
<summary>Soluci贸n</summary>
</details>

## Problema hiperb贸lico

El sistema $\partial_t^2 u = Lu+f$ tambi茅n se reduce a un sistema de ecuaciones desacopladas de segundo orden
$$
\hat u_j'' = -\lambda_j \hat u_j + \hat f_j
$$
Tenemos as铆 que $\hat u_j(t)$ se puede calcular en t茅rminos de su posici贸n y velocidad inicial.

Para $j=0$
\begin{align*}
\hat u_0(t) &= \hat u_0(0) + \hat u_0'(0) t + \int_0^t \hat f_0(s)(t-s)ds.
\end{align*}

Para $j\neq0$ denotamos la frecuencia $\omega_j=\sqrt{\lambda_j}$ tal que
\begin{align*}
\hat u_j(t) &= \hat u_j(0)\cos(\omega_j t) + \hat u_j'(0)\frac{\sin(\omega_j t)}{\omega_j} + \int_0^t \hat f_j(s)\frac{\sin(\omega_j(t-s))}{\omega_j}ds.
\end{align*}

Agrupando los t茅rminos para la soluci贸n concluimos que
$$
u(x,t) = \sum_{j=0}^{|V|-1} u(y,0)W_1(x,y,t)+\partial_t u(y,0)W_2(x,y,t) + \int_0^t f(y,s)W_2(x,y,t-s)ds
$$
donde
\begin{align*}
W_1(x,y,t) &:= \sum_{j=0}^{|V|-1} \frac{\phi_j(x)\overline{\phi_j(y)}}{\|\phi_j\|^2}\cos(\omega_j t), \\
W_2(x,y,t) &:= \frac{t}{|V|} + \sum_{j=1}^{|V|-1} \frac{\phi_j(x)\overline{\phi_j(y)}}{\|\phi_j\|^2}\frac{\sin(\omega_j t)}{\omega_j}.
\end{align*}

---

:::{.exercise}
(Ley de Stokes) Demuestra que si
$$
\begin{cases}
\partial_t^2u = Lu,\\
u|_{t=0} = 0,\\
\partial_t u|_{t=0} = v_0,
\end{cases} \qquad\Leftrightarrow\qquad u(x,t) = \sum_{j=0}^{M-1} v_0(y)W_2(x,y,t)
$$
entonces $v = \partial_tu$ satisface
$$
\begin{cases}
\partial_t^2v = Lv,\\
v|_{t=0} = v_0,\\
\partial_t v|_{t=0} = 0,
\end{cases} \qquad\Leftrightarrow\qquad v(x,t) = \sum_{j=0}^{M-1} v_0(y)W_1(x,y,t).
$$
:::

<details>
<summary>Soluci贸n</summary>
</details>

## Nerd sniping

En esta secci贸n veremos como resolver el problema presentado en la siguiente caricatura de Randall Munroe autor de [XKCD](https://xkcd.com/356/).

![](./nerd_sniping.png){width=70%}

La resistencia efectiva se define de la siguiente forma. Etiquetemos primero los nodos de la red por $(x,y) \in \mathbb Z^2$ tales que los nodos marcados son el origen $(0,0)$ y $(2,1)$. Se fija un potencial $u$ sobre la red tal que $u(0,0)=0$, $u(2,1)=1$, mientras que en los dem谩s nodos $u$ es arm贸nica, es decir que para $(x,y) \in \mathbb Z^2 \setminus \{(0,0),(2,1)\}$
$$
\Delta u(x,y) = u(x-1,y) + u(x+1,y) + u(x,y-1) + u(x,y+1) - 4u(x,y) = 0.
$$
Para que $u$ est茅 definida de forma un铆voca hay que pedir adicionalmente que $u\to 0$ cuando $|(x,y)|\to \infty$. Desde una perspectiva f铆sica esta condici贸n en infinito es la m谩s natural.

La corriente $i$ que sale del origen es la divergencia de $u$ en dicho punto, $i= \operatorname{div} u(0,0)$. Este es a su vez la corriente que entra en el v茅rtice $(2,1)$ la cual se calcula de igual forma como $i = -\operatorname{div} u(2,1)$. Si buscamos simplificar la red por el caso m谩s sencillo que conecta a $(0,0)$ y $(2,1)$, es decir el grafo con solamente estos dos v茅rtices y una arista entre ellos, entonces la resistencia efectiva $R$ es aquella que debemos dar a esta 煤nica conexi贸n para que la corriente siga siendo $i$ bajo el mismo potencial. En otras palabras $R = 1/i$.

Como primer paso veremos como calcular el potencial an谩logo en el toro $V_{N} = (\mathbb Z/N\mathbb Z)^2$, es decir un problema peri贸dico donde identificamos las coordenadas enteras m贸dulo $N\gg1$. Cuando $N\to \infty$ el potencial el茅ctrico converge al potencial en $\mathbb Z^2$. Este l铆mite, a pesar de ser intuitivo, amerita una demostraci贸n que no presentaremos dado que buscamos enfatizar otras ideas por el momento. La ventaja de esta aproximaci贸n es que ahora nuestra ecuaci贸n es un problema de 谩lgebra lineal en un espacio de dimensi贸n $N^2-2$
$$
\Delta u = 0 \text{ en } V_{N}\setminus \{(0,0),(2,1)\}, \qquad u(0,0)=0,\qquad u(2,1)=1.
$$

De las discusiones previas sabemos que a partir de la descomposici贸n espectral del Laplaciano en $V_{N}$ podr铆amos calcular en cambio una soluci贸n particular de
$$
\Delta v =   1_{(0,0)}-  1_{(2,1)} \text{ en } V_{N}.
$$
Notemos que el lado derecho es de hecho perpendicular a las constantes, lo cual garantiza la existencia de soluciones. Para obtener $u$ a partir de $v$ verificamos que
$$
u(x,y) = \frac{v(x,y)-v(0,0)}{v(2,1)-v(0,0)}
$$
satisface la ecuaci贸n requerida y entonces
$$
R_N = \frac{1}{\operatorname{div} u(0,0)} = \frac{v(2,1)-v(0,0)}{\operatorname{div} v(0,0)} = v(2,1)-v(0,0).
$$
Nuestra estrategia ser谩 entonces calcular el l铆mite de esta expresi贸n cuando $N\to\infty$.

Procedamos a calcular el espectro del Laplaciano sobre el toro (Ejercicio \@ref(exr:espectro)). Asumamos la hip贸tesis de \textbf{separaci贸n de variables}
$$
\phi(x,y) = \alpha(x)\beta(y).
$$
Este tipo de funciones toman ventaja de la simetr铆a del problema con lo cual el Laplaciano se simplifica como operadores discretos m谩s sencillos para cada factor
$$
\Delta \phi(x,y) = \alpha(x)(\beta(y-1)-2\beta(y)+\beta(y+1)) + (\alpha(x-1)-2\alpha(x)+\alpha(x+1))\beta(y).
$$

Si $\alpha$ y $\beta$ son autofunciones del Laplaciano en el grafo c铆clico de tama帽o $N$, entonces $\phi$ es una autofunci贸n en el toro. Tomemos de esta forma la base de Fourier
$$
\phi_{k,l}(x,y) = \omega^{kx+ly}, \qquad \omega = e^{2\pi i/N}, \qquad (k,l)\in\{0,1,\ldots,(N-1)\}^2,
$$
con autovalores $-\lambda_{k,l}$ tal que
$$
\lambda_{k,l} := 4(\sin^2(\pi k/N)+\sin^2(\pi l/N)),
$$
y normas
$$
\|\phi_{k,l}\|^2=\sum_{(x,y)\in V_N} \phi_{k,l}(x,y)\overline{\phi_{k,l}(x,y)} = N^2.
$$

---

:::{.exercise}
Verifica que a partir de las siguientes funciones tambi茅n se puede formar una base ortogonal del Laplaciano
\begin{align*}
\cos(2\pi kx/N)\cos(2\pi ly/N),\quad \cos(2\pi kx/N)\sin(2\pi ly/N),\quad \sin(2\pi kx/N)\sin(2\pi ly/N).    
\end{align*}
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

Finalmente reconstruimos la soluci贸n particular usando la f贸rmula de representaci贸n

\begin{align*}
v(x,y) &= -\sum_{(x',y') \in V_N} K(x,y;x',y')( 1_{(0,0)}- 1_{(2,1)})(x',y') = K(x,y;2,1)-K(x,y;0,0).
\end{align*}
donde para $\omega = e^{2\pi i/N}$
$$
K(x,y;x',y') = \frac{1}{N^2}\sum_{(k,l)\neq (0,0)} \frac{\phi_{k,l}(x,y)\overline{\phi_{k,l}(x',y')}}{\lambda_{k,l}} = \frac{1}{4N^2}\sum_{(k,l)\neq (0,0)} \frac{\omega^{k(x-x')+l(y-y')}}{\sin^2(\pi k/N)+\sin^2(\pi l/N)}.
$$

La resistencia efectiva es calculada as铆 por
\begin{align*}
R &= v(2,1)-v(0,0),\\
&= K(2,1;2,1)-K(2,1;0,0) - K(0,0;2,1)+K(0,0;0,0),\\
&= \frac{1}{2N^2} \sum_{(k,l)\neq (0,0)} \frac{1-\cos((2k+l)2\pi/N)}{\sin^2(\pi k/N)+\sin^2(\pi l/N)},\\
&= \frac{1}{N^2} \sum_{(k,l)\neq (0,0)} \frac{\sin^2((2k+l)\pi/N)}{\sin^2(\pi k/N)+\sin^2(\pi l/N)}.
\end{align*}
En el l铆mite podemos entonces calcular $R$ por la integral de Riemann
$$
R = \frac{1}{\pi^2}\int_0^\pi\int_0^\pi \frac{\sin^2(2x+y)}{\sin^2x+\sin^2y}dydx
$$
Evaluamos numericamente la integral usando

```{python}
import numpy as np
from scipy.integrate import dblquad

integrando = lambda x, y : np.sin(2*x+y)**2/(np.sin(x)**2+np.sin(y)**2)
integral, error = dblquad(integrando,0,np.pi,0,np.pi)
R = integral/np.pi**2
print(R)
```

De forma alternativa es posible [calcular anal铆ticamente la integral](https://physics.stackexchange.com/questions/2072/on-this-infinite-grid-of-resistors-whats-the-equivalent-resistance) dando como resultado
$$
R = \frac{4}{\pi}-\frac{1}{2}
$$

---

:::{.exercise}
Sea
$$
R(m,n) = \int_0^\pi\int_0^\pi \frac{\sin^2(mx+ny)}{\sin^2x+\sin^2y}dydx.
$$
Demuestra que $R:\mathbb Z^2\to \mathbb R$ es una funci贸n arm贸nica en $\mathbb Z^2\setminus\{(0,0)\}$.
:::

<details>
<summary>Soluci贸n</summary>
</details>

<!--chapter:end:05-espectro.Rmd-->

# El problema de Dirichlet

Un barrendero tiene la tarea de limpiar una dada regi贸n (acotada) en cuarto cubierto de baldosas. Cada vez que este barre una baldosa, toda la masa que se encuentra en ella se distribuye en porciones iguales entre las cuatro baldosas adyacentes. En general, limpiar la regi贸n es un proceso que entendemos en el l铆mite de un n煤mero infinito de pasos.

![](./barrendero-1.png){width=70%}

El orden en que se barren las baldosas no es conmutativo, v茅ase por ejemplo la figura a continuaci贸n. Sin embargo, descubrimos que en el l铆mite se recupera una cierta propiedad Abeliana: Una vez limpia la regi贸n, la distribuci贸n de masa alrededor de ella es independiente de como se haya barrido.

![](./barrendero2-1.png){width=70%}

El problema lo podemos modelar en un grafo general pero con la intenci贸n de ilustrar un caso concreto pensemos en la ret铆cula $\mathbb Z^2$ con la relaci贸n de adyacencia $x\sim y$ cuando $\|x-y\| = 1$. Es decir que cada baldosa tiene exactamente cuatro baldosas adyacentes en cada una de las direcciones cardinales.

Sea $\mu:\mathbb Z^2\to [0,\infty)$ la distribuci贸n de masa inicial que buscamos barrer de alg煤n $\Omega\subseteq\mathbb Z^2$. Un plan de barridas est谩 dado por una lista de baldosas $b_1,b_2,\ldots \in \Omega$, las que iremos barriendo en el orden respectivo. Si $\infty_i:\mathbb Z^2\to [0,\infty)$ denota la distribuci贸n de masa luego del $i^{mo}$ paso, se tiene entonces la siguiente f贸rmula recursiva comenzando de $\mu_0:=\mu$,
$$
\mu_i(x) := 
\begin{cases}
0 \text{ si } x=b_i\\
\mu_{i-1}(x) + \tfrac{1}{4}\mu_{i-1}(b_i) \text{ si } x\sim b_i\\
\mu_{i-1}(x) \text{  en cualquier otro caso}.
\end{cases}
$$

Decimos que el plan plan $b_1,b_2,\ldots \in \Omega$ barre a $\mu$ de $\Omega$ si
$$
\lim_{i\to\infty} \mu_i(x) = 0, \qquad \forall x\in \Omega.
$$

Nuestro teorema puede ser entonces formulado de la siguiente manera.

:::{.theorem #tma1}
Dado $\Omega\subseteq\mathbb Z^2$ finito y $\mu:\mathbb Z^2\to [0,\infty)$ se tiene que cualesquiera dos planes $b_1,b_2,\ldots \in \Omega$ y $b_1',b_2',\ldots \in \Omega$ que barren a $\mu$ de $\Omega$ satisfacen que los siguientes l铆mites existen para todo $x\in \mathbb Z^2$ y
$$
\lim_{i\to \infty} \mu_i(x) = \lim_{i\to \infty} \mu'_i(x).
$$
:::

Daremos la demostraci贸n del teorema en la Secci贸n [Principio del m铆nimo](#principio-del-m铆nimo) luego de presentar y motivar algunas construcciones auxiliares.

## Ley de conservaci贸n

Una idea 煤til es llevar el registro de cu谩nta masa ha salido de una dada baldosa $x$ hasta una dada iteraci贸n. Para ser precisos definimos para cada sub铆ndice $i\geq 0$ las funciones $u_i:\mathbb Z^2\to [0,\infty)$ comenzando por $u_0=0$ y de forma inductiva seg煤n
$$
u_i := u_{i-1} + \mu_{i-1}(b_i) 1_{b_i}
$$
Observemos que para cualquier plan $b_1,b_2,\ldots \in \Omega$ se tiene necesariamente que $u_i=0$ en $\mathbb Z^2\setminus \Omega$.

La funci贸n $u_i$ nos permite dar una f贸rmula para la **ley de conservaci贸n de masas**: En los primeros $i$ pasos, la masa que entra menos la que sale de una baldosa $x$ es justamente la diferencia entre las distribuciones $\mu_i$ menos $\mu_0$ en $x$
$$
\underbrace{\mu_i(x)}_{\text{masa final}}-\underbrace{\mu_0(x)}_{\text{masa inicial}} = \underbrace{\frac{1}{4}\sum_{y\sim x} u_i(y)}_{\text{masa que entra}} - \underbrace{u_i(x)}_{\text{masa que sale}} = \tfrac{1}{4}\Delta u(x)
$$
Esta puede ser demostrada por un argumento inductivo que dejamos de ejercicio.

Volviendo al modelo del barrendero, vemos que si $\mu_i \to \mu_\infty$ entonces $u_i$ tambi茅n converge a una funci贸n $u:\mathbb Z^2\to[0,\infty)$^[Daremos una prueba rigurosa de este hecho en la Secci贸n [Principio del M铆nimo](#principio-del-m铆nimo)] tal que $\tfrac{1}{4}\Delta u = \mu_\infty - \mu_0 = \mu_\infty-\mu$. Si el plan barre a $\Omega$ recuperamos el siguiente sistema de ecuaciones lineales
$$
\begin{cases}
-\tfrac{1}{4}\Delta u = -\mu \text{ en } \Omega,\\
u = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
(\#eq:lap)
$$

Veamos a grandes rasgos las ideas en la demostraci贸n del Teorema \@ref(thm:tma1) a partir de estas construcciones. Si el sistema que satisface $u$ tiene una \underline{煤nica} soluci贸n, entonces esta funci贸n queda determinada por $\mu$ y $\Omega$ y es independientemente del plan. Usando que $\mu_\infty = \mu + \lim_{i\to\infty} \tfrac{1}{4}\Delta u_i = \mu+\tfrac{1}{4}\Delta u$ vemos que tambi茅n $\mu_\infty$ es independientemente del plan, lo cual concluir铆a la demostraci贸n.

---

:::{.exercise}
Asumiendo la estrategia esbozada en esta secci贸n, calcula la distribuci贸n final $\mu_\infty$ si $\Omega = \{(0,0),(1,0),(0,1)\}$ y $\mu= 1_\Omega$.
:::

<details>
<summary>Soluci贸n</summary>
</details>

## Existencia y unicidad de soluciones

El principio del m铆nimo nos permitir谩 demostrar que el sistema dado por \@ref(eq:lap) no tiene m谩s de una soluci贸n. Para problemas lineales con igual n煤mero (finito) de ecuaciones e inc贸gnitas, esto equivale a decir que el sistema de hecho siempre tiene soluci贸n.

### Principio del m铆nimo

La idea consiste en el siguiente principio general: Si $u:V\to\mathbb R$ es no-negativa en $V\setminus \Omega$ y satisface $\Delta u\leq 0$ en $\Omega$ entonces $u$ es necesariamente no-negativa en $\Omega$. Como veremos en la siguiente demostraci贸n, esto es una manifestaci贸n del criterio de la segunda derivada (discreto): $\Delta u(x^*)\geq 0$ si $u$ alcanza su m铆nimo en $x^*$.

:::{.lemma name="Principio del M铆nimo"}
Sea $u:V\to\mathbb R$ tal que para $\Omega\subseteq V$ finito $\Delta u \leq 0$ en $\Omega$. Entonces
$$
\inf_{V\setminus\Omega} u \geq 0 \qquad\Rightarrow\qquad \min_{\Omega} u\geq 0.
$$
:::

:::{.proof}
Asumamos por contradicci贸n que $m:= \min_{\Omega} u < 0$ y sea $\Omega'=\{x\in \Omega : u(x) = m\}$ finito y no vac铆o, m谩s a煤n sabemos que es finito dado que $\Omega'\subseteq\Omega$. Tomemos ahora $x^*\in \Omega'$ tal que existe $y\sim x^*$ para el cual $u(y)>u(x^*)$. Vemos ahora que tenemos la siguiente contradicci贸n a partir de evaluar la ecuaci贸n $\Delta u\leq 0$ sobre $x^*$
$$
0 < \sum_{z\sim x^*} (u(z) -u(x^*)) = \Delta u(x^*) \leq 0.
$$
:::

:::{.corollary name="Existencia y unicidad de soluciones"}
Para $\Omega\subseteq V$ finito y $\mu,\varphi:V\to\mathbb R$ el siguiente sistema tiene soluci贸n 煤nica
$$
\begin{cases}
\Delta u = \mu \text{ en } \Omega,\\
u = \varphi \text{ en } V\setminus \Omega.
\end{cases}
$$
:::

:::{.proof}
Basta con demostrar que el sistema lineal dado por las ecuaciones en $\Omega$, con $N=|\Omega|$ ecuaciones e inc贸gnitas, tiene a lo sumo una soluci贸n. En otras palabras, el operador lineal asociado de $\mathbb R^N$ en si mismo es inyectivo, y por lo tanto tambi茅n es biyectivo gracias al teorema fundamental del 谩lgebra lineal.

Si $u,v:V\to \mathbb R$ son dos soluciones, entonces $w:=u-v$ satisface $\Delta w=0$ en $\Omega$ y $w = 0$ en $V\setminus \Omega$. Gracias al principio del m铆nimo obtenemos que $w\geq 0$ en $\Omega$ y por lo tanto en todo $V$. Si aplicamos el mismo razonamiento a $-w$ obtenemos la otra desigualdad de donde concluimos $w=0$, es decir que queda establecida la unicidad de soluciones y con ello la demostraci贸n.
:::

---

:::{.exercise}
Demuestra que si $\Omega = \{x = (x_1,x_2) \in \mathbb Z^2 : x_2>0\}$ entonces existen por lo menos dos soluciones distintas del problema
$$
\begin{cases}
\Delta u = 0 \text{ en } \Omega,\\
u = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$
Es decir que la hip贸tesis de que $\Omega$ sea finito es necesaria para la unicidad de soluciones.
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.proof name="Teorema \@ref(thm:tma1)"}
Construimos de forma recursiva y partiendo de $u_0 := 0$ las funciones $u_i := u_{i-1} + \mu_{i-1} 1_{b_i}$ las cuales verifican
$$
\begin{cases}
\tfrac{1}{4}\Delta u_i = \mu_i-\mu \text{ en } \Omega,\\
u_i = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$
Definimos tambi茅n $u:\mathbb Z^2\to \mathbb R$ como la soluci贸n de
$$
\begin{cases}
\tfrac{1}{4}\Delta u = -\mu \text{ en } \Omega,\\
u = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$

Debemos corroborar entonces los siguientes puntos:

1. $\mu_{\infty} := \lim_{i\to\infty}\mu_i$ est谩 bien definido.

1. $u_\infty := \lim_{i\to\infty}u_i$ est谩 bien definido.

1. $u_\infty = u$.

Para ver el primer punto basta con fijarse en el comportamiento de $\mu_i$ en $\mathbb Z^2\setminus \Omega$, ya que sabemos por hip贸tesis que estas tienden a cero en $\Omega$. En $\mathbb Z^2\setminus \Omega$ se tiene que $\mu_i$ es una sucesi贸n no-decreciente de funciones que est谩 mayorizada por $\mu + \sum_{x\in\Omega} \mu(x)$.

Como $u_i$ es no-decreciente, basta con probar que $u\geq u_i$ para demostrar el segundo punto y adicionalmente obtener $u\geq u_\infty$. La diferencia $v_i := u-u_i$ satisface
$$
\begin{cases}
\Delta v_i = \Delta u - \Delta u_i = -4\mu_i \leq 0 \text{ en } \Omega,\\
v_i = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$
Gracias principio del m铆nimo se deduce que $\min_\Omega v_i \geq 0$ y por lo tanto $u\geq u_i$.

Dado que $b_1,b_2,\ldots\in\Omega$ barre a $\mu$ de $\Omega$ tenemos que tomando $i\to\infty$ en el sistema para $u_i$
$$
\begin{cases}
\tfrac{1}{4}\Delta u_\infty = -\mu \text{ en } \Omega,\\
u_\infty = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$
Por la unicidad de soluciones del problema lineal llegamos a que necesariamente $u_\infty=u$.

Finalmente para concluir la demostraci贸n podemos calcular $\mu_\infty$ a partir de $\mu_\infty = \mu+\tfrac{1}{4}\Delta u_\infty$. Recordemos que $u_\infty=u$ est谩 igualmente definido por un sistema de ecuaciones lineales que depende solamente de $\Omega$ y $\mu$ y no del plan. Esto indica que $\mu_\infty$ tambi茅n est谩 definida independientemente del plan.
:::

Nuestro teorema garantiza que para cualquier $\Omega\subseteq\mathbb Z^2$ finito y $\mu:\mathbb Z^2\to [0,\infty)$ se tiene que si $\mu$ puede ser barrido de $\Omega$, entonces la distribuci贸n de masa que queda por fuera de $\Omega$ es independiente del plan. Queda abierta la pregunta de si podemos en todo caso barrer o no a $\mu$ de $\Omega$.

:::{.theorem}
Dado $\Omega\subseteq\mathbb Z^2$ finito y $\mu:\mathbb Z^2\to[0,\infty)$ existe un plan $b_1,b_2,\ldots\in\Omega$ que barre a $\mu$ de $\Omega$.
:::

:::{.proof}
Sea $b_1,b_2,\ldots\in\Omega$ un plan que recorre cada baldosa un n煤mero infinito de veces. Ciertamente estos planes existen incluso si $\Omega$ es infinito (usando un argumento de diagonal de Cantor). Esta condici贸n implica que para cada $x\in\Omega$, existe un n煤mero infinito de sub-铆ndices tales que $\mu_i(x)=0$. Basta probar as铆 que $\mu_\infty = \lim_{i\to\infty}\mu_i$ existe para deducir que necesariamente $\mu_\infty=0$ en $\Omega$.

Definimos $u_i$ y $u$ exactamente como en la demostraci贸n anterior. Recordemos que $u_i$ es no-decreciente y (por el principio del m铆nimo) acotada por $u$, por lo tanto $u_\infty:=\lim_{i\to\infty}u_i$ est谩 bien definida. Dado que $\mu_i = \mu + \Delta u_i$ tenemos que la existencia del l铆mite para $\mu_i$ queda demostrada por la existencia del l铆mite para $u_i$.
:::

---

:::{.exercise}
Demuestra que existe un plan que barre a $\mu= 1_{(1,0)}$ de $\Omega = \mathbb Z^2\setminus \{(0,0)\}$.
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.exercise}
Sea $\Omega\subseteq\mathbb Z^2$ finito, $\mu:\mathbb Z^2\to[0,\infty)$ y $\mu_\infty$ la distribuci贸n que resulta al barrer $\mu$ de $\Omega$. Demuestra ley de conservaci贸n de masa dada por
$$
\sum_{x\in\mathbb Z^2} \mu_\infty(x) = \sum_{x\in \mathbb Z^2} \mu(x).
$$
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.exercise}
Sea $\mu= 1_{(1,0)}$ y $\mu_\infty$ la distribuci贸n que resulta al barrer $\mu$ de $\Omega= \mathbb Z^2\setminus \{(0,0)\}$. 驴Ser谩 cierto que $\mu_\infty(0,0) = 1$, o habr谩 masa que escapa a infinito?^[**Pista:** El problema se puede reducir a verificar que $\Delta u(0,0) = -\Delta u(1,0)$. La funci贸n $u$ parece tener una simetr铆a en el eje $x=1/2$ la cual podr铆a ser demostrada por un resultado de unicidad (Liouville): Las funciones arm贸nicas y acotadas en $\mathbb Z^2$ son 煤nicamente las constantes.]
:::

<details>
<summary>Soluci贸n</summary>
</details>

### M茅todo de Balayage

Poincar茅 propuso a finales del siglo XIX el siguiente algoritmo para resolver el sistema
$$
\begin{cases}
\Delta u = 0 \text{ en } \Omega,\\
u = \varphi \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}.
$$

Asumamos $\Omega$ finito y sea $\partial\Omega := \{y \in \mathbb Z^2\setminus \Omega : \exists x\in \Omega \text{ adyacente a } y\}$. Comenzamos entonces a partir de
$$
u_0(x) := \begin{cases}
\max_{\partial\Omega}\varphi \text{ si } x\in\Omega,\\
\varphi(x) \text{ en cualquier otro caso}.
\end{cases},
$$
tal que
$$
\begin{cases}
\Delta u_0 \leq 0 \text{ en } \Omega,\\
u_0 = \varphi \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$
Hagamos notar que por el principio del m铆nimo, $u_0\geq \min_{\partial\Omega} \varphi$.

Sea $b_1,b_2,\ldots \in \Omega$ tal que para cada $x\in \Omega$ el conjunto de 铆ndices $\{i : b_i=x\}$ es infinito. Definimos ahora $u_i$ modificando a $u_{i-1}$ en $b_i$ de forma que $\Delta u_i(b_i) =0$, es decir
$$
u_i(x) := \begin{cases}
\frac{1}{4} \sum_{y\sim b_i} u_{i-1}(y) \text{ si } x = b_i,\\ 
u_{i-1}(x) \text{ en cualquier otro caso}.
\end{cases}
$$
En otras palabras, en el paso $i$ estamos barriendo el Laplaciano de $u_{i-1}$ en $b_i$.

Se puede demostrar por inducci贸n que cada $u_i$ satisface
$$
\begin{cases}
\Delta u_i \leq 0 \text{ en } \Omega,\\
u_i = \varphi \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$
Gracias a esto observamos que la sucesi贸n es decreciente. Tambi茅n, cuando la restringimos a $\Omega$, est谩 acotada por debajo por $\min_{\partial\Omega}\varphi$. Como consecuencia converge a la soluci贸n que se busca calcular.

---

:::{.exercise}
Implementa el m茅todo de balayage. El programa debe recibir un conjunto $\Omega\subseteq\mathbb Z^2$ finito junto con $\varphi:\partial\Omega\to\mathbb R$, debe devolver la soluci贸n correspondiente del problema de Dirichlet $u:\Omega\to \mathbb Z^2$.
:::

<details>
<summary>Soluci贸n</summary>
</details>

## F贸rmulas de representaci贸n

### La funci贸n de Green

Para $\Omega\subseteq V$ finito, definimos la **funci贸n de Green** $G_\Omega:V^2\to\mathbb R$ tal que $u(y)=G_\Omega(x,y)$ es la soluci贸n de
$$
\begin{cases}
\Delta u = - 1_x \text{ en } \Omega,\\
u=0 \text{ en } V\setminus \Omega.
\end{cases}
$$

---

:::{.example}
Si $\Omega=\{x_0\}$, entonces
$$
G_\Omega(x,y) = \begin{cases}
1/\deg(x_0) \text{ si } y=x=x_0,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$
donde $\deg(x_0)$ es el grado del v茅rtice $x_0$, es decir cuantas aristas llegan y salen de $x_0$.
:::

Igualmente definimos $G_\Omega$ sobre una distribuci贸n $\mu:V\to\mathbb R$ tal que $u(y)=G_\Omega(\mu,y)$ es la soluci贸n de
$$
\begin{cases}
\Delta u = -\mu \text{ en } \Omega,\\
u=0 \text{ en } V\setminus \Omega.
\end{cases}
$$
Es decir que en particular $G_\Omega(x,\cdot) = G_\Omega( 1_x,\cdot)$.

Gracias al principio de superposici贸n tenemos que a partir de esta podemos resolver 
$$
\begin{cases}
\Delta u = -\mu \text{ en } \Omega,\\
u=0 \text{ en } V\setminus \Omega.
\end{cases}
$$
usando la f贸rmula de representaci贸n
$$
u(y) = \sum_{x\in V} \mu(x)G_\Omega(x,y) = G_\Omega(\mu,y).
$$

---

:::{.example}
Para el problema del barrendero ($V=\mathbb Z^2$) tenemos que $u(y)= 4G_\Omega(\mu,y)$ indica cuanta masa sale de $y$ cuando se barre $\mu$ de $\Omega$.
:::

---

:::{.example}
Veamos como calcular la funci贸n de Green para $\Omega = [1,n] \subseteq V=\mathbb Z$ con $n\geq 1$ y la relaci贸n de adyacencia dada por $x\sim y$ si $|x-y|=1$. Denotamos a lo largo de este ejemplo a $g_{i,j} := G_\Omega(i,j)$ con $i,j\in \{0,1,\ldots,n,n+1\}$, los valores de inter茅s ($G_\Omega(x,y) = 0$ fuera de estos casos).

Para $j\in[1,i-1]$, tenemos la ecuaci贸n
$$
2g_{i,j} = g_{i,j-1}+g_{i,j+1},
$$
la cual junto a $g_{i,0} = 0$ indica que $g_{i,j}=\alpha j$ para $j\in[0,i]$.

Para $j\in[i+1,n]$, tenemos tambi茅n la ecuaci贸n
$$
2g_{i,j} = g_{i,j-1}+g_{i,j+1},
$$
la cual junto a $g_{i,n+1} = 0$ indica que $g_{i,j}=\beta(n+1-j)$ para $j\in[i,n+1]$.

Por un lado sabemos que $\alpha i = \beta(n+1-i)$ y adicionalmente usando la ecuaci贸n para $j=i$
$$
-1=g_{i,i-1}+g_{i,i+1}-2g_{i,i} = -\alpha-\beta
$$
obtenemos que $\alpha=(n+1-i)/(n+1)$ y $\beta=i/(n+1)$. En conclusi贸n
$$
g_{i,j} = \begin{cases}
(n+1-i)j/(n+1) \text{ si } j\in[1,i),\\
(n+1-j)i/(n+1) \text{ si } j\in(i,n],\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$
:::

---

:::{.exercise}
Calcula la funci贸n de Green para $\Omega = [1,n]\times\{0\}\cap \mathbb Z^2$.
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

Los ejemplos previos sugieren la siguiente simetr铆a
$$
G_\Omega(x,y)=G_\Omega(y,x).
$$

:::{.proof}
Usaremos en repetidas ocasiones que si alguno de los nodos $x$ o $y$ est谩n en $V\setminus \Omega$ se tiene autom谩ticamente que $G_\Omega(x,y)=G_\Omega(y,x)=0$.

Basta ver que $(x,y) \mapsto G_\Omega(y,x)$ satisface las mismas condiciones para la definici贸n de $G_\Omega$, es decir que $v(y) = G_\Omega(y,x)$ cumple
$$
\begin{cases}
\Delta v = -  1_x \text{ en } \Omega,\\
v = 0 \text{ en } V\setminus \Omega.
\end{cases}
$$

Las condici贸n de borde ya sabemos que se satisface. Para ver la ecuaci贸n asumimos que $x\in \Omega$ (el otro caso siendo tivial) y comprobaremos que $w(x) = \Delta_1 G(y,x)+ 1_y(x) = \Delta_1 G(y,x)+ 1_x(y)=0$ para cualquier $y\in \Omega$. Por un lado tenemos la condici贸n de borde
$$
w(x) = 0+0 = 0 \text{ si } x\in V\setminus \Omega.
$$
Por el otro tenemos que 
$$
\Delta w (x) = \Delta_2\Delta_1G(y,x)+\Delta  1_y(x) = \Delta_1\Delta_2 G(y,x)+\Delta  1_y(x) = \Delta  1_{y}(x) - \Delta  1_y(x)=0.
$$
Gracias a la unicidad de la soluci贸n trivial podemos finalmente concluir la demostraci贸n.
:::

### El n煤cleo de Poisson

Para $\Omega\subseteq V$ finito, $x,y \in V$ definimos el **n煤cleo de Poisson**
$$
P_\Omega(x,y) :=  1_x (y) + \Delta_2 G_\Omega(x,y).
$$
Observemos los valores no triviales de $P_\Omega(x,y)$ ocurren cuando $x\in \Omega$ y $y\in V\setminus \Omega$. Si $x\in V\setminus \Omega$ entonces $G_\Omega(x,\cdot) = 0$ y $P_\Omega(x,y) =  1_x (y)$. Si $y\in \Omega$ entonces $\Delta_2 G_\Omega(x,y) = - 1_x (y)$ y $P_\Omega(x,y)=0$.

En particular, la simetr铆a de $G$ **no** implica la propiedad an谩loga para $P_\Omega$.

Igualmente extendemos la construcci贸n para $\mu:V\to \mathbb R$ usando
$$
P_\Omega(\mu,y) :=  \mu(y) + \Delta_2 G_\Omega(\mu,y).
$$

---

:::{.example}
Si $\Omega=\{x_0\}$, entonces
$$
P_\Omega(x,y) = \begin{cases}
1/\deg(x_0) \text{ si } x=x_0,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$
:::

---

:::{.example}
Para el problema del barrendero ($V=\mathbb Z^2$) tenemos que al barrer $\mu$ de $\Omega$ la distribuci贸n de masa que resulta est谩 dada por $P_\Omega(\mu)$.
:::

---

De la linealidad del problema junto con la existencia y unicidad de soluciones se deduce que
$$
P_\Omega(\alpha\mu+\beta\nu) = \alpha P_\Omega(\mu) +\beta P_\Omega(\nu).
$$

Gracias a la interpretaci贸n de n煤cleo de Poisson en t茅rminos del problema del barrendero es natural pensar que dados $\Omega_1\subseteq\Omega_2\subseteq V$ finitos, se tiene la siguiente propiedad
$$
P_{\Omega_2} = P_{\Omega_2}\circ P_{\Omega_1}.
$$
Denominaremos a esta como la **propiedad de semi-grupo**.

\begin{proof}
Sea $\mu:V\to[0,\infty)$ arbitraria y $u,v,w:V\to\mathbb R$ tales que
$$
\begin{cases}
\Delta u = -\mu \text{ en }\Omega_1,\\
u=0 \text{ en } V\setminus \Omega_1.
\end{cases}\qquad
\begin{cases}
\Delta v = -P_{\Omega_1}(\m) \text{ en }\Omega_2,\\
v=0 \text{ en } V\setminus \Omega_2.
\end{cases}\qquad
\begin{cases}
\Delta w = -\mu \text{ en }\Omega_2,\\
w=0 \text{ en } V\setminus \Omega_2.
\end{cases}
$$
por definici贸n sabemos as铆 que
$$
P_{\Omega_1}(\m) = \mu + \Delta u, \qquad P_{\Omega_2}(P_{\Omega_1}(\m)) = P_{\Omega_1}(\m)+\Delta v,\qquad P_{\Omega_2}(\m) = \mu+\Delta w.
$$
Basta con demostrar que $w=u+v$ para obtener de esta forma que
$$
P_{\Omega_2}(\m) = \mu+\Delta w = \mu+\Delta u+\Delta v = P_{\Omega_1}(\m)+\Delta v = P_{\Omega_2}(P_{\Omega_1}(\m)).
$$

Ambas funciones $w$ y $u+v$ se anulan en $V\setminus \Omega$, veamos entonces que $\Delta (u+v) = \Delta w = -\mu$ en $\Omega_2$ para concluir por unicidad la identidad esperada. En $\Omega_1\subseteq\Omega_2$ tenemos que $P_{\Omega_1}(\m) = 0$ y por lo tanto $\Delta(u+v) = -\mu + P_{\Omega_1}(\m) = -\mu$. En el complemento $\Omega_2\setminus \Omega_1$ usamos que $\Delta v = -P_{\Omega_1}(\m) = -(\mu + \Delta u)$ y por lo tanto $\Delta(u+v) = -\mu$. Esto concluye la demostraci贸n.
\end{proof}

Como consecuencia de la linealidad y la propiedad de semi-grupo tenemos la siguiente **interpretaci贸n dual del n煤cleo de Poisson**: Para $y\in V$ fijo, la funci贸n $u(x) = P_\Omega(x,y)$ es la soluci贸n de
$$
\begin{cases}
\Delta u = 0 \text{ en } \Omega,\\
u= 1_{y} \text{ en } V\setminus \Omega.
\end{cases}
$$
Esta formulaci贸n es m谩s sencilla de recordar y conveniente al momento de calcular $P_\Omega$ sin necesidad de calcular la funci贸n de Green.

\begin{proof}
La condici贸n de borde se sigue de la definici贸n de $P_\Omega$ sin mucho problema. Preferimos en cambio dar una justificaci贸n en t茅rminos del problema del barrendero. Cuando $x\in V\setminus \Omega$ entonces no hay que hacer nada para barrer $\mu= 1_x$ de $\Omega$, por lo tanto $P_\Omega(x,y)= 1_x(y) =  1_y(x)$ es el dato de borde esperado.

Para verificar la ecuaci贸n usamos la propiedad de semi-grupo con $\Omega_1=\{x\}\subseteq\Omega$ y $\mu= 1_x$ tal que
$$
P_\Omega( 1_x) = P_\Omega(P_{\{x\}}( 1_x)) = P_\Omega\1\sum_{y\sim x} \frac{1}{\deg(x)} 1_y\2 = \frac{1}{\deg(x)}\sum_{y\sim x} P_\Omega( 1_y).
$$
En otras palabras $\Delta_x P_\Omega(x,y) = 0$.
\end{proof}

Como consecuencia de la formulaci贸n dual de n煤cleo de Poisson y el principio de superposici贸n tenemos la **f贸rmula de representaci贸n**
$$
u(x) = \sum_{y\in V} \varphi(y) P_\Omega(x,y) \qquad\Leftrightarrow\qquad\begin{cases}
\Delta u = 0 \text{ en } \Omega,\\
u= \varphi \text{ en } V\setminus \Omega.
\end{cases}
$$
M谩s a煤n, si a esta a帽adimos la f贸rmula de representaci贸n para la funci贸n de Green, junto con su propia simetr铆a, obtenemos que
$$
u(x) = \sum_{y\in V} \varphi(y) P_\Omega(x,y)+\mu(y) G_\Omega(x,y) \qquad\Leftrightarrow\qquad \begin{cases}
\Delta u = -\mu \text{ en }\Omega,\\
u=\varphi \text{ en } V\setminus \Omega.
\end{cases}.
$$

---

:::{.example}
Veamos como calcular el n煤cleo de Poisson para $\Omega = [1,n] \subseteq V=\mathbb Z$ con $n\geq 1$ y la relaci贸n de adyacencia dada por $x\sim y$ si $|x-y|=1$. Denotamos a lo largo de este ejemplo a $p_{i,j} := P_\Omega(i,j)$ con $i,j\in \{0,1,\ldots,n,n+1\}$, los valores de inter茅s ($P_\Omega(x,y) = 0$ fuera de estos casos). En realidad solamente debemos calcular $p_{i,0}$ y $p_{i,n+1}$, los dem谩s valores tambi茅n se anulan.

Para $j=0$, tenemos la ecuaci贸n
$$
2p_{i,0} = p_{i-1,0}+p_{i+1,0},
$$
la cual junto a $p_{0,0} = 1$ y $p_{n+1,0}=0$ indica que $p_{i,0}=(n+1-i)/(n+1)$ para $i\in[0,n+1]$.\\

Para $j=n+1$, tenemos tambi茅n la ecuaci贸n
$$
2p_{i,n+1} = p_{i-1,n+1}+p_{i+1,n+1},
$$
la cual junto a $p_{0,n+1} = 0$ y $p_{n+1,n+1}=1$ indica que $p_{i,n+1}=i/(n+1)$ para $i\in[0,n+1]$.
:::

---

:::{.exercise}
Calcula el n煤cleo de Poisson para $\Omega=[1,n]\times \{0\}\cap \mathbb Z^2$.
:::

<details>
<summary>Soluci贸n</summary>
</details>

## Caminatas Aleatorias

Consideremos ahora un problema que afinar谩 nuestra intuici贸n con respecto a las herramientas que hemos presentado. Volvemos a trabajar en la ret铆cula $\mathbb Z^2$ a pesar de que el modelo es claramente generalizable a otros grafos.

Un borracho parte de una posici贸n inicial $x\in\mathbb Z^2$ y se mueve con igual probabilidad a cualquiera de sus cuatro posiciones adyacentes. Es decir que si $x_i$ es la posici贸n (aleatoria) del borracho luego de $i$ pasos, tenemos que las **probabilidades de transici贸n** est谩n dadas por
$$
\mathbb P(x_i = y \ | \ x_{i-1} = x) = \begin{cases}
1/4 \text{ si } y \sim x,\\
0 \text{ en cualquier otro caso}.
\end{cases}
$$

Dado $\Omega \subseteq\mathbb Z^2$, sea $\tau$ el n煤mero de pasos que toma el borracho para salir de $\Omega$ por primera vez, tambi茅n conocido como el **tiempo de salida** de la caminata
$$
\tau := \min\{i \geq 0 : x_i \in \mathbb Z^2\setminus \Omega\}.
$$
Para nuestro modelo, podemos interpretar $\mathbb Z^2\setminus \Omega$ como la regi贸n en la ciudad $\mathbb Z^2$ donde hay ley seca. El borracho pasea en $\Omega$ y una vez que sale de $\Omega$ se queda dormido o lo atrapa la polic铆a.

Dado $A \subseteq\mathbb Z^2$ (quiz谩s sea la casa del nuestro protagonista) queremos calcular la probabilidad de que el paseo en $\Omega$ termine (felizmente) en $A$ dado que comienza en $x$, es decir
$$
p(x) := \mathbb P(x_\tau \in A \ | \ x_0 = x).
$$

![](./drunk-1.png)

Si inicialmente $x \in \mathbb Z^2\setminus\Omega$, tenemos que $x_\tau =x_0=x$ y por lo tanto $p=  1_A$. Si en cambio $x \in \Omega$, la probabilidad $p(x)$ puede ser calculada si conocemos los valores de $p(y)$ para $y\sim x$. Para $y\sim x$ fijo, tenemos que con probabilidad $1/4$ se tiene que $x_1=y$, y a partir de $y$ tenemos que el paseo en $\Omega$ sale por $A$ con probabilidad $p(y)$. En otras palabras
$$
p(x) = \frac{1}{4}\sum_{y\sim x}p(y).
$$

En t茅rminos del Laplaciano podemos caracterizar a la probabilidad $p$ como la soluci贸n del sistema
$$
\begin{cases}
\Delta p = 0 \text{ en } \Omega,\\
p =  1_A \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}.
$$
Cuando $A=\{y\}$ conseguimos interpretar al n煤cleo de Poisson $P_\Omega(x,y) = p(x)$ como la probabilidad de que la caminata que comienza en $x$ termine en $y$. Esto es una probabilidad de transici贸n para el tiempo aleatorio $\tau$
$$
P_\Omega(x,y) = \mathbb P(x_\t=y\ | \ x_0=x).
$$
La interpretaci贸n probabilista de la f贸rmula de representaci贸n para el n煤cleo de Poisson est谩 dada en cambio por el valor esperado
$$
u(x) = \mathbb E(\varphi(x_\tau) \ | \ x_0=x) \qquad \Leftrightarrow\qquad \begin{cases}
\Delta u = 0 \text{ en }\Omega,\\
u=\varphi \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}
$$

---

:::{.exercise}
Dos borrachitos se encuentran paseando en la avenida $\Omega = [1,n]\times \{0\} \cap \mathbb Z^2$ con $n\geq 2$. Uno parte de $x=(1,0)$, el otro de $y = (n,0)$, y ambos toman pasos simult谩neamente en $\mathbb Z^2$ con igual probabilidad en las cuatro direcciones cardinales. Da una f贸rmula para la probabilidad $p(n)$ de que se encuentren en $\Omega$ (es decir que ambos coinciden en la misma casilla al mismo tiempo, no vale que se crucen) antes de que alguno de ellos salga de $\Omega$.
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

Dado $A\subseteq\mathbb Z^2$, otra variable aleatoria de inter茅s es el n煤mero de veces que encontramos $x_i \in A$ para $i < \tau$, es decir antes de salir de la regi贸n $\Omega$. Esta variable tambi茅n se conoce como el **tiempo de ocupaci贸n** de $A$ y est谩 definida de forma precisa por
$$
N := \sum_{i=0}^{\tau-1}  1_A(x_i). 
$$

El valor esperado en funci贸n de la posici贸n inicial de la caminata
$$
n(x) := \mathbb E(N \ | \ x_0=x),
$$
tambi茅n satisface un sistema de ecuaciones lineales
$$
\begin{cases}
\tfrac{1}{4}\Delta n = - 1_A \text{ en } \Omega,\\
n = 0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}.
$$

Por un lado la condici贸n de borde es autom谩tica puesto que si $x_0=x\in \mathbb Z^2\setminus\Omega$ entonces como ya est谩 fuera de $\Omega$, nunca puede visitar a $A$ en su paseo (inexistente) por $\Omega$. Por otro lado, para $x\in \Omega$, $n(x)$ se puede obtener a partir de los valores de $n(y)$ para $y\sim x$. Dado $y\sim x$, la probabilidad de que $x_1=y$ es un cuarto, y a partir de ac谩 consideramos dos casos:

- Si $x\in A$ entonces el tiempo de ocupaci贸n partiendo de $x$ es uno m谩s que el tiempo de ocupaci贸n partiendo de $y$.

- Si $x\in \Omega\setminus A$, el tiempo de ocupaci贸n partiendo de $x$ es el mismo tiempo de ocupaci贸n partiendo de $y$.

Tomando los valores esperados
$$
n(x) =  1_A(x) + \frac{1}{4}\sum_{y\sim x} n(y).
$$
Lo cual es equivalente a $\tfrac{1}{4}\Delta n = - 1_A$ en $\Omega$. Es decir que $n=4G_\Omega( 1_A)$ est谩 dado en t茅rminos de la funci贸n de Green.

En t茅rminos probabilistas interpretamos la f贸rmula de representaci贸n para la funci贸n de Green como,
$$
u(x) = \mathbb E\left(\sum_{i=0}^{\tau-1}\mu(x_i) \ | \ x_0=x\right) \qquad\Leftrightarrow\qquad \begin{cases}
\frac{1}{4}\Delta u = -\mu \text{ en } \Omega,\\
u=0 \text{ en } \mathbb Z^2\setminus \Omega.
\end{cases}.
$$

Finalmente observamos que la simetr铆a de la funci贸n de Green se interpreta como una propiedad de reversibilidad para las caminatas aleatorias. Es decir que el n煤mero promedio de veces que una caminata que comienza en $x$ visita a $y$ antes de salir de $\Omega$ ($G_\Omega(x,y)$) es igual al n煤mero promedio de veces que una caminata que comienza en $y$ visita a $x$ antes de salir de $\Omega$ ($G_\Omega(y,x)$). Esto se debe a que las caminatas de $x$ a $y$ que permanecen en $\Omega$ est谩n en biyecci贸n con las caminatas de $y$ a $x$ que permanecen en $\Omega$, simplemente cambiando la orientaci贸n.

<!--chapter:end:06-prob_dirchlet.Rmd-->

# Optimizaci贸n

Consideremos una vez m谩s el grafo $G=(V,E)$. Otra perspectiva para el Laplaciano aparece cuando consideramos la **energ铆a de Dirichlet** para una funci贸n $u:V\to \mathbb R$
$$
\mathcal E[u] := \frac{1}{2}\sum_{e\in E} (Du(e))^2.
$$
Recordemos que podemos pensar igualmente a $\mathcal E$ como una funci贸n de $\mathbb R^{|V|}$ a $\mathbb R$, y como tal podemos calcular su gradiente en una dada $u$ como un vector de $\mathbb R^{|V|}$ o equivalentemente una funci贸n real sobre $V$. Dado $x\in V$
$$
D\mathcal E[u](x) = \left.\frac{d}{d\epsilon}\right|_{\epsilon=0}\mathcal E[u+\epsilon 1_{x}] = \sum_{e\in E} Du(e) D 1_{x}(e).
$$

Dado que
$$
D 1_{x}(e) = \begin{cases}
1 \text{ si } e_+=x,\\
-1 \text{ si } e_-=x,\\
0 \text{ en cualquier otro caso},\\
\end{cases}
$$
llegamos a que
$$
D\mathcal E[u](x) = \sum_{e_+=x} Du(e) - \sum_{e_-=x} Du(e) = -\operatorname{div}(Du)(x) = -\Delta u(x).
$$

---

:::{.exercise}
Sea $f:V\to \mathbb R$ y $\mathcal F:\mathbb R^V\to \mathbb R$ tal que
$$
\mathcal F[u] = \mathcal E[u] + \sum_{x\in V} f(x)u(x).
$$
Demuestra que $\mathcal F$ es acotada por debajo si y solo si $\sum_{x\in V} f(x)=0$
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.exercise}
Demuestra que si $\partial_t^2u=\Delta u$ entonces la energ铆a total del sistema definida a continuaci贸n permanece constante
$$
E = \underbrace{\frac{1}{2}\sum_{x\in V} (\partial_t u(x))^2}_{\text{Cin茅tica}} + \underbrace{\mathcal E[u]}_{\text{Potencial}}.
$$
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.example}
Modelamos una imagen en blanco y negro est谩 dada por una funci贸n $u:V\to [0,1]$ definida sobre la ret铆cula $V = \mathbb Z^2\cap [1,N]^2$. El problema de restauraci贸n de im谩genes consiste en proponer una imagen $u$ que aproxime una dada imagen $f$ que quiz谩s est茅 contaminada con alg煤n tipo de ruido.

Por ejemplo, podemos proponer $u$ como aquella que minimiza el funcional
$$
\mathcal F[u] = \frac{1}{2}\sum_{x\in V} (u(x)-f(x))^2+\alpha(Du(x))^2.
$$
El primer t茅rmino penaliza el funcional cuando $u$ se aleja de la se帽al dada $f$ y se conoce como el t茅rmino de fidelidad. El segundo t茅rmino penaliza las oscilaciones de $u$ y se conoce como el t茅rmino de regularizaci贸n. El par谩metro $\alpha>0$ debe ser ajustado emp铆ricamente para obtener un balance entre la fidelidad de la imagen y la regularizaci贸n.

Tenemos entonces la ecuaci贸n de punto cr铆tico la cual debe satisfacerse para todo $x\in V$
$$
0 = D\mathcal F[u](x) = u(x)-f(x) - \alpha\Delta u(x).
$$
Observemos que $\Delta$ posee autovalores negativos, esto indica que el operador $I-\alpha\Delta$ tiene autovalores estrictamente positivos, en particular la ecuaci贸n $u-\alpha\Delta u=f$ tiene una 煤nica soluci贸n para $f:V\to \mathbb R$ arbitraria.
:::

---

:::{.exercise}
El t茅rmino de penalizaci贸n dado por la energ铆a de Dirichlet es conveniente al momento de calcular el gradiente, sin embargo en la pr谩ctica este difumina los contornos. Una mejor alternativa es usar en t茅rmino de **variaci贸n total**
$$
\mathcal F[u] = \sum_{x\in V} \frac{1}{2}(u(x)-f(x))^2+\alpha|Du(x)|.
$$
Calcula las ecuaciones de punto cr铆tico de $\mathcal F$.
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.exercise}
El t茅rmino de variaci贸n total tiene la desventaja de no ser diferenciable en todos lados. Una alternativa consiste en tomar para $\epsilon>0$ peque帽o
$$
\mathcal F[u] = \sum_{x\in V} \frac{1}{2}(u(x)-f(x))^2+\alpha\sqrt{(Du(x))^2+\epsilon^2}.
$$
Calcula las ecuaciones de punto cr铆tico de $\mathcal F$.
:::


<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.example}
Un dado conjunto de datos puede estar dado en t茅rminos de un grafo $G=(V,E)$ para el cual pensamos que dos v茅rtices adyacentes son de alguna forma semejantes. El prop贸sito es clasificar los v茅rtices de acuerdo a $k$ etiquetas que modelamos usando los vectores can贸nicos $\{e_1,\ldots,e_k\}\in \mathbb R^k$. De hecho el problema est谩 planteado en un subconjunto de v茅rtices $\Omega\subseteq V$, dado que en el complemento las etiquetas vienen predeterminadas por una funci贸n $g:V\setminus\Omega\to\{e_1,\ldots,e_k\}$.

Una forma de llevar a cabo esta tarea consiste en minimizar el funcional de Dirichlet bajo el dato de borde en $V\setminus \Omega$
$$
\min\{\mathcal E[u]\ | \ u=g\text{ en } V\setminus \Omega\}.
$$
Bajo esta condici贸n $u:V\to \mathbb R^k$ debe ser calculado seg煤n
$$
\begin{cases}
\Delta u = 0 \text{ en } \Omega,\\
u=g\text{ en } V\setminus \Omega.
\end{cases}
$$
Dado que la soluci贸n $u(x)$ no necesariamente toma valores en $\{e_1,\ldots,e_k\}$, tomamos la etiqueta para $x$ como el $e_j$ m谩s cercano a $u(x)$.
:::

---

:::{.exercise}
Dado que $u=(u_1,\ldots,u_k)$ satisface
$$
\begin{cases}
\Delta u = 0 \text{ en } \Omega,\\
u=g\text{ en } V\setminus \Omega.
\end{cases}
$$
con $g$ tomando valores en $\{e_1,\ldots,e_k\}$, demuestra que para todo $x\in V$
$$
u(x) \in \{y\in [0,1]^k \ | \ y_1+\ldots+y_k=1\}.
$$
:::

<details>
<summary>Soluci贸n</summary>
</details>

## M茅trica de Sobolev

Consideremos para $G = (V,E)$ conexo
$$
\dot H^1 := \left\{u:V\to\mathbb R\ | \ \sum_V u = 0\right\}.
$$
Este espacio vectorial admite el producto interno,
$$
\langle u,v\rangle_{\dot H^1} := \sum_{e\in E} Du(e)Dv(e).
$$
Recordemos r谩pidamente las propiedades que verifica para poder ser efectivamente un producto:

- Sim茅trico: $\langle u,v\rangle_{\dot H^1}=\langle v,u\rangle_{\dot H^1}$,

- Lineal: $\langle \alpha u+\beta v,w\rangle_{\dot H^1} = \alpha\langle u,w\rangle_{\dot H^1}
    +\beta\langle v,w\rangle_{\dot H^1}$.

- Positivo: $\|u\|_{\dot H^1}^2 := \langle u,u\rangle_{\dot H^1}\geq 0$

- No degenerado: $\|u\|_{\dot H^1} = 0$ si y solo si $u=0$.

De todas estas propiedades, la no degeneraci贸n es la m谩s delicada. De $\|u\|_{\dot H^1} = 0$ se deduce que $u$ es constante ($G$ es conexo). Dado que $\sum u=0$ se llega a que necesariamente dicha constante es cero.

## Capacitancia

Dado $\Omega\subseteq V$ con $V\setminus \Omega\neq \emptyset$, definimos la capacitancia de $\Omega'\subseteq\Omega$ con respecto de $\Omega$ como
$$
\operatorname{Cap}(\Omega'|\Omega) := \min\{2\mathcal E[u] \ | \ \text{$u=1$  en $\Omega'$, y $u=0$ en $V\setminus\Omega$}\}.
$$

Un minimizante $u$ de dicho problema es la funci贸n arm贸nica en $\Omega\setminus \Omega'$ que satisface los datos de borde prescritos
$$
\begin{cases}
\Delta u = 0 \text{ in } \Omega\setminus \Omega',\\
u=0 \text{ on } V\setminus \Omega,\\
u=1 \text{ on } \Omega'.
\end{cases}
$$
Gracias al teorema de la divergencia^[Recordemos que
$$
n_{\Omega'}(e) = \begin{cases}
1 \text{ si $e_-\in \Omega'$ y $e_+\in V\setminus \Omega$},\\
-1 \text{ si $e_+\in \Omega'$ y $e_-\in V\setminus \Omega$},\\
0 \text{ en cualquier otro caso}. 
\end{cases}
$$]
$$
\operatorname{Cap}(\Omega'|\Omega) = -\sum_{x\in V} u\Delta u(x) = -\sum_{x\in \Omega'} \Delta u(x) = -\sum_{e\in E} Du(e)n_{\Omega'}(e).
$$
En t茅rminos de redes el茅ctricas obtenemos la corriente total que atraviesa la red cuando se mantiene una diferencia potencial de un voltio entre $\Omega'$ y $V\setminus \Omega$. La resistencia efectiva entre dos nodos distintos $x_0$ y $x_1$ puede ser definida as铆 seg煤n
$$
R(x_0,x_1) = \frac{1}{\operatorname{Cap}(\{x_1\}|V\setminus\{x_0\})}.
$$

Equivalentemente se puede definir la capacitancia en t茅rminos de dos desigualdades sobre $\Omega'$ y $V\setminus \Omega$
$$
\operatorname{Cap}(\Omega'|\Omega) = \min\{\mathcal E[u] \ | \ \text{$u\geq 1$  en $\Omega'$, y $u\leq 0$ en $V\setminus\Omega$}\}.
$$
Es claro que el lado derecho es menor o igual que el lado izquierdo, dado que el conjunto que considera el m铆nimo es m谩s grande. Por el otro lado tenemos que para cualquier $u$ tal que $u\geq 1$  en $\Omega'$, y $u\leq 0$ en $V\setminus\Omega$, la truncaci贸n dada por
$$
v(x) := \max(\min(u(x),1),0) = \begin{cases}
1 \text{ si } x\in \Omega',\\
u(x) \text{ si } x\in \Omega\setminus\Omega',\\
0 \text{ si } x\in V\setminus \Omega.
\end{cases}
$$
disminuye la energ铆a de Dirichlet $\mathcal E[v]\leq \mathcal E[u]$, lo cual concluye la igualdad que hab铆amos anunciado.

---

:::{.exercise}
Calcula $\operatorname{Cap}(\{a\}|V\setminus \{b\})$

![](./capa2.png)
:::

<details>
<summary>Soluci贸n:</summary>
</details>

---

:::{.exercise}
Demuestra que para $\Omega_1\subseteq\Omega_2\subseteq\Omega_3\subseteq V$:

- $\operatorname{Cap}(\Omega_1|\Omega_2)= \operatorname{Cap}(V\setminus\Omega_2|V\setminus \Omega_1)$.

- $\operatorname{Cap}(\Omega_1|\Omega_3) \leq \operatorname{Cap}(\Omega_2|\Omega_3)$.

- $\operatorname{Cap}(\Omega_1|\Omega_2) \geq \operatorname{Cap}(\Omega_1|\Omega_3)$.
:::

<details>
<summary>Soluci贸n:</summary>
</details>

---

:::{.exercise}
Demuestra que para $\Omega_1,\Omega_2\subseteq\Omega\subseteq V$^[El minimizante $u$ correspondiente a $\Omega_1\cup\Omega_2$ es puntualmente mayor o igual a $\max(u_1,u_2)$ donde $u_1$ y $u_2$ son los minimizantes para $\Omega_1$ y $\Omega_2$ respectivamente.]:
$$
\operatorname{Cap}(\Omega_1\cup\Omega_2|\Omega) \leq \operatorname{Cap}(\Omega_1|\Omega)+\operatorname{Cap}(\Omega_2|\Omega).
$$
:::

<details>
<summary>Soluci贸n:</summary>
</details>

---

:::{.exercise}
Sea $\Omega'\subseteq\Omega\subseteq V$, $u$ la soluci贸n de
$$
\begin{cases}
\Delta u = 0 \text{ in } \Omega\setminus \Omega',\\
u=0 \text{ on } V\setminus \Omega,\\
u=1 \text{ on } \Omega'.
\end{cases}
$$
y sean $\mu=(\Delta u)_-$ y $\nu=(\Delta u)_+$. Demuestra que
$$
P_\Omega(\mu)=\nu \qquad \text{ y } \qquad P_{V\setminus \Omega'}(\nu)=\mu.
$$
:::

<details>
<summary>Soluci贸n:</summary>
</details>

## M茅trica dual

De forma dual proponemos el siguiente problema. Decimos que un flujo $i:E\to\mathbb R$ transporta a la distribuci贸n (de cargas) $\mu:V\to [0,\infty)$ en $\nu:V\to\mathbb R$ si satisface
$$
\operatorname{div} i = \mu-\nu.
$$
Recordemos que tal problema tiene soluci贸n si y solo si (y asumiendo $G$ conexo)
$$
\sum_{x\in V}\mu(x) = \sum_{x\in V}\nu(x).
$$

Dada la energ铆a del flujo $i$ como
$$
\mathcal K[i] := \frac{1}{2}\sum_{e\in E} i(e)^2,
$$
nos preguntamos entonces cu谩l es la menor energ铆a posible que se requiere para transportar a $\mu$ en $\nu$
$$
\mathcal D^2[\mu,\nu] := \min\{ 2\mathcal K[i] \ | \ \operatorname{div} i = \mu-\nu\}.
$$

Si $i$ minimiza $\mathcal K$ y $j$ es un flujo tal que $\operatorname{div} j=0$, entonces
$$
0=\left.\frac{d}{dt}\right|_{t=0}\mathcal K[i+tj] = \sum_{e\in E}i(e)j(e).
$$
Es decir que el m铆nimo $i$ debe ser perpendicular al n煤cleo de la divergencia. Por la descomposici贸n de Helmholtz debe ser necesariamente un gradiente $i=-Du$ por lo que
$$
\mathcal D^2[\mu,\nu] = 2\mathcal E[u]\text{ para cualquier soluci贸n de $\Delta u=\nu-\mu$}.
$$

---

:::{.exercise}
Calcula $\mathcal D^2(\mu,\nu)$

![](./wasser.png)
:::

<details>
<summary>Soluci贸n:</summary>
</details>

---

:::{.exercise}
La funci贸n $\mathcal D$, es decir la ra铆z cuadrada del m铆nimo de la energ铆a, se conoce como la **distancia dual**. Demuestra que efectivamente satisface los axiomas correspondientes:

- $\mathcal D(\mu,\nu) = \mathcal D(\nu,\mu)$,

- $\mathcal D(\mu,\nu) \geq 0$ y la igualdad se cumple exclusivamente si $\mu=\nu$,

- $\mathcal D(\mu,\nu) \leq \mathcal D(\mu,\omega)+\mathcal D(\omega,\nu)$.
:::

<details>
<summary>Soluci贸n:</summary>
</details>

---

:::{.exercise}
Definimos la norma dual en $\dot H^1$ como
$$
\|u\|_{\dot H^{-1}} := \sup\{ \langle u,v\rangle_{\dot H^1}\ | \ \|v\|_{\dot H^1}=1\}.
$$
Demuestra que si $\sum_V \mu = \sum_V\nu$, entonces
$$
\|\mu-\nu\|_{\dot H^{-1}} = \mathcal D(\mu,\nu).
$$
:::

<details>
<summary>Soluci贸n:</summary>
</details>

---

Dados $\Omega'\subseteq\Omega\subseteq V$ con $\Omega'$ y $V\setminus \Omega$ no triviales consideramos las distribuciones $\mu$ y $\nu$ tales que
$$
\begin{aligned}
\mathcal M(\Omega'|\Omega) = \{(\mu,\nu):V\to \mathbb R^2\ | \ &\operatorname{spt} \mu \in \Omega',\\
&\operatorname{spt}\nu \subseteq V\setminus\Omega,\\
&\left.\sum_{x\in V}\mu(x) = \sum_{x\in V}\nu(x)=1\right\}.
\end{aligned}
$$
Bajos estas condiciones buscamos minimizar la distancia entre $\mu$ y $\nu$.

:::{.theorem}
Para $G$ conexo y finito,
$$
\min_{(\mu,\nu) \in \mathcal M(\Omega'|\Omega)} \mathcal D^2[\mu,\nu] = \frac{1}{\operatorname{Cap}(\Omega'|\Omega)}.
$$
:::

Es decir que el problema de minimizaci贸n para $\mathcal D^2[\mu,\nu]$ bajo las restricciones $(\mu,\nu) \in \mathcal M(\Omega'|\Omega)$ generaliza la noci贸n de resistencia efectiva entre dos conjuntos.

:::{.proof}
Sean $\mu',\nu':V\to [0,\infty)$ tales que
$$
\operatorname{spt}\mu'\subseteq\Omega', \qquad \operatorname{spt} \nu'\subseteq V\setminus \Omega.
$$
Obtenemos de esta forma que
$$
\max_{\mu',\nu'} \sum_{x\in V} ((1-u)\mu'+u\nu')(x) = \begin{cases}
0 \text{ si $u\geq 1$ en $\Omega'$ y $u\leq 0$ en $V\setminus\Omega$,}\\
\infty \text{ en cualquier otro caso}.
\end{cases}
$$
De modo que sin necesidad de imponer restricciones para $u:V\to\mathbb R$ obtenemos que
$$
\operatorname{Cap}(\Omega'|\Omega) = \min_u \max_{\mu',\nu'} L[u,\mu',\nu'], \qquad L[u,\mu',\nu'] := 2\mathcal E[u] + \sum_{x\in V} ((1-u)\mu'+u\nu')(x).
$$

Procedemos entonces a analizar el problema dual para el cual sabemos que^[En general, $\min_x\max_\lambda L(x,\lambda) \geq \max_\lambda\min_x L(x,\lambda)$.]
$$
\operatorname{Cap}(\Omega'|\Omega)\geq \max_{\mu',\nu'} \mathcal J[\mu',\nu'], \qquad \mathcal J[\mu',\nu'] := \min_u L[u,\mu',\nu'].
$$

Por un lado vemos que si
$$
\sum_{x\in V}\mu'(x) \neq \sum_{x\in V}\nu'(x)
$$
entonces $\mathcal J[\mu',\nu'] = -\infty$, dado que para $u=c$ constante podemos hacer $L[u,\mu',\nu']$ arbitrariamente negativo
$$
L[c,\mu',\nu'] = \sum_{x\in V}\mu'(x) + c\sum_{x\in V}(\nu'-\mu')(x).
$$
Asumamos entonces que las sumas son iguales, en cuyo caso la forma cuadr谩tica convexa $u\mapsto L[u,\mu',\nu']$ alcanza su m铆nimo en las soluciones de
$$
2\Delta u = \nu'-\mu'.
$$
Estas est谩n bien definidas por la hip贸tesis para el lado derecho, adem谩s dos soluciones cualesquiera difieren por constantes, gracias a la conexidad de $G$. Por lo tanto
$$
\sum_{x\in V} (\nu'-\mu')u(x) = 2\sum_{x\in V} u\Delta u(x) = -4\mathcal E[u]
$$
y entonces
$$
\mathcal J[\mu',\nu'] = \sum_{x\in V} \mu'(x)-2\mathcal E[u].
$$

Denotemos por $M:=  \sum_{x\in V} \mu'(x)$ y consideremos las renormalizaciones dadas por $\mu'=M\mu$, $\nu'=M\nu$ y $2u=Mv$ tales que $(\mu,\nu) \in \mathcal M(\Omega'|\Omega)$, $\Delta v = \nu-\mu$, y $4\mathcal E[u] = M^2\mathcal E[v]$. Por lo tanto
$$
\mathcal J[\mu',\nu'] = M - \frac{M^2}{2} \mathcal E[v]
$$
Vemos que $M$ y $v$ son independientes bajo las restricciones dadas. Si maximizamos primero en $M$ obtenemos que $M=1/\mathcal E[v]$ y por lo tanto
$$
\operatorname{Cap}(\Omega'|\Omega) \geq \max_{\mu',\nu'} \mathcal J[\mu',\nu'] = \max_{\substack{\Delta v = \nu-\mu\\(\mu,\nu)\in \mathcal M(\Omega'|\Omega)}} \frac{1}{\mathcal E[v]} = \max_{(\mu,\nu)\in \mathcal M(\Omega'|\Omega)} \frac{1}{\mathcal D^2[\mu,\nu]}.
$$

Para concluir la demostraci贸n veremos que cuando $u$ es la soluci贸n de
$$
\begin{cases}
\Delta u = 0 \text{ in } \Omega\setminus \Omega',\\
u=0 \text{ on } V\setminus \Omega,\\
u=1 \text{ on } \Omega',
\end{cases}
$$
y adem谩s $(\Delta u)_- = M\mu$, $(\Delta u)_+ = M\nu$, $u=Mv$, tales que $(\mu,\nu)\in \mathcal M(\Omega'|\Omega)$, entonces
$$
\operatorname{Cap}(\Omega'|\Omega) = 2\mathcal E[u] \overset{?}{=} \frac{1}{2\mathcal E[v]} = \frac{1}{\mathcal D^2[\mu,\nu]}.
$$
Esto se debe a la f贸rmula de integraci贸n por partes y la homogeneidad de $\mathcal E$
$$
2\mathcal E[u] = M = 2M^2\mathcal E[v] \qquad\mathbb Rightarrow\qquad M= \frac{1}{2\mathcal E[v]} \qquad\mathbb Rightarrow\qquad 2\mathcal E[u] = \frac{1}{2\mathcal E[v]}.
$$
:::

En los siguientes ejercicios consideramos para $\Omega\subseteq V$
$$
\mathcal M(\Omega):= \left\{\mu:V\to [0,1] \ | \ \operatorname{spt}\mu\subseteq\Omega \text{ y } \sum_{x\in V}\mu(x)=1\right\}.
$$

---

:::{.exercise}
Sea $\Omega'\subseteq\Omega\subseteq V$. Demuestra que para $\mu\in \mathcal M(\Omega')$ se tiene que
$$
\mathcal D(\mu,P_\Omega(\mu)) = \min_{\nu \in \mathcal M(V\setminus \Omega)}\mathcal D(\mu,\nu)
$$
:::

<details>
<summary>Soluci贸n:</summary>
</details>

---

:::{.exercise}
Sea $\Omega'\subseteq\Omega\subseteq V$. Demuestra que $T:= P_{V\setminus \Omega'}\circ P_\Omega$ es un mapeo no expansivo $\mathcal M(\Omega')$ en si mismo con respecto de la m茅trica de Wasserstein, es decir que
$$
\mathcal D(T(\mu_1),T(\mu_2))\leq \mathcal D(\mu_1,\mu_2).
$$
:::

<details>
<summary>Soluci贸n:</summary>
</details>

## Cociente de Rayleigh

Sea $A\in \mathbb R^{N\times N}$ sim茅trica. Sabemos por el teorema espectral que existe una base ortogonal de autovectores de $L$ con autovalores reales. Tendremos en mente aplicar los resultados de esta secci贸n para $A=-L$ para la cual sabemos adicionalmente que sus autovalores son no-negativos.

La ecuaci贸n $A\xi = \lambda\xi$ que determina los autovectores puede pensarse tambi茅n como una ecuaci贸n de punto cr铆tico con restricciones, siendo $\lambda$ el multiplicador de Lagrange. En este caso el gradiente de la funci贸n objetivo es $A\xi$, mientras que el gradiente de la restricci贸n es $\xi$. Esto quiere decir que la funci贸n objetivo puede ser tomada como la forma cuadr谩tica $f(\xi)=A\xi\cdot \xi$, mientras que la restricci贸n es $g(\xi) = \|\xi\|^2 = \xi\cdot\xi$.

A lo largo de esta secci贸n asumimos que $A\in \mathbb R^{N\times N}$ es sim茅trica y denotamos por $\lambda_0\leq\ldots\leq \lambda_{N-1}$ sus autovalores y $\xi_0,\ldots,\xi_{N-1}$ una base ortogonal de autovectores.

---

:::{.exercise}
Demuestra que el m铆nimo de $f(\xi)=A\xi\cdot \xi$ sobre la esfera unitaria es el menor autovalor de $A$ y que los puntos donde se realiza el m铆nimo general el autoespacio de dicho autovalor.

驴Sucede algo similar para el problema de maximizaci贸n?
:::

<details>
<summary>Soluci贸n:</summary>
</details>

---

:::{.exercise}
Considera el grafo

![](./capa2.png)

Calcula el m铆nimo y m谩ximo de
$$
\sum_{e\in E} (Du(e))^2
$$
sobre todas las funciones $u:V\to \mathbb R$ tales que $\sum_V u^2=1$.
:::

<details>
<summary>Soluci贸n:</summary>
</details>

---

:::{.exercise}
Considera el grafo

![](./capa2.png)

Calcula el m铆nimo y m谩ximo de
$$
\sum_{e\in E} (Du(e))^2
$$
sobre todas las funciones $u:V\to \mathbb R$ tales que $\sum_V u^2=1$ y $u(A)=u(B)=0$.
:::

<details>
<summary>Soluci贸n:</summary>
</details>

---

Una forma alternativa del problema de optimizaci贸n consiste en tomar el cociente de Rayleigh
$$
R(\xi) := \frac{A\xi \cdot \xi}{\|\xi\|^2},
$$
y minimizar o maximizar esta funci贸n fuera del origen.

---

:::{.exercise}
Demuestra que
$$
\lambda_k = \min\{R(\xi)\ | \ \xi \in \operatorname{span}\{\xi_0,\ldots,\xi_{k-1}\}^\perp \setminus \{0\}\}
$$
:::


<details>
<summary>Soluci贸n:</summary>
</details>

---

:::{.theorem name="CourantFischerWeyl"}
$$
\lambda_k = \max\{\min\{R(\xi)\ | \ \xi \in S\setminus\{0\}\} \ | \ S \text{ es un sub-espacio de $\mathbb R^N$ con $\dim S=N-k$}\}
$$
:::

En otras palabras, dado un sub-espacio $S$ de dimensi贸n $N-k$, el m铆nimo de $R$ sobre $S\cap \partial B_1$ es a lo sumo $\lambda_k$. La igualdad se alcanza cuando $S=\operatorname{span}\{\xi_k,\ldots,\xi_{N-1}\}$.

:::{.proof}
Denotemos
$$
\mu_k := \max\{\min\{R(\xi)\ | \ \xi \in S\setminus\{0\}\} \ | \ S \text{ es un sub-espacio de $\mathbb R^N$ con $\dim S=N-k$}\}.
$$

Para demostrar que $\lambda_k\leq \mu_k$ basta con conseguir un sub-espacio $S$ de dimensi贸n $N-k$ tal que el m铆nimo de $R$ sobre $S\setminus\{0\}$ es por lo menos $\lambda_k$.

Sea $S_{N-k} = \operatorname{span}\{\xi_{k},\ldots,\xi_{N-1}\}$ tal que $\dim S_{N-k} = N-k$. Por un lado tenemos que para $\xi = \alpha_{k}\xi_{k}+\ldots+\alpha_{N-1}\xi_{N-1}\in S_{N-k}\setminus \{0\}$
$$
R(\xi) = \frac{\lambda_{k}\alpha_{k}^2+\ldots+\lambda_{N-1}\alpha_{N-1}^2}{\alpha_{k}^2+\ldots+\alpha_{N-1}^2} \geq \lambda_k
$$
cuyo m铆nimo es de hecho $\lambda_{k}$ y se alcanza por ejemplo cuando $\alpha_k=1$ y los dem谩s coeficientes se anulan. Es decir que hemos probado que $\lambda_k \leq \mu_k$.

La desigualdad $\lambda_k \geq \mu_k$ quiere decir que para cualquier sub-espacio $S$ de dimensi贸n $N-k$, existe $\xi \in S\setminus\{0\}$ tal que $R(\xi)\leq \lambda_k$. Tomemos $\xi = \alpha_0\xi_0+\ldots+\alpha_k\xi_k \in S\setminus\{0\}$, sabemos que tal vector existe puesto que
$$
\dim S + \dim\operatorname{span}\{\xi_0,\ldots,\xi_k\} = N+1.
$$
Luego
$$
R(\xi) = \frac{\lambda_{0}\alpha_{0}^2+\ldots+\lambda_{k}\alpha_{k}^2}{\alpha_{0}^2+\ldots+\alpha_{k}^2} \leq \lambda_k.
$$
:::

---

:::{.exercise}
Si $A\leq A'$, i.e. $(A'-A)$ es positiva semi-definida, entonces sus correspondientes autovalores tambi茅n est谩n ordenados, es decir $\lambda_k\leq \lambda_k'$.
:::

<details>
<summary>Soluci贸n:</summary>
</details>

---

:::{.exercise}
Sea $G'$ un sub-grafo de $G$^[$V'\subseteq V$ y $E'\subseteq E\cap V'\times V'$.]. Demuestra que para los correspondientes autovalores del Laplaciano se tiene que $\lambda_k'\geq \lambda_k$.
:::

<details>
<summary>Soluci贸n:</summary>
</details>

<!--chapter:end:07-optimizacion.Rmd-->

# (PART\*) Transporte y leyes de conservaci贸n {-}

# Cantidades conservadas

## Problemas homog茅neos

Sea $v:\mathbb R^n\to \mathbb R^n$ un campo vectorial suave y acotado, como tal genera un flujo $\phi:\mathbb R^n\times\mathbb R\to \mathbb R^n$ definido por medio del problema de valores iniciales
$$
\partial_t\phi(x,t) = v(\phi(x,t)), \qquad \phi(x,0)=x.
$$

Una funci贸n $u:\mathbb R^n\to \mathbb R$ se dice que es una **cantidad conservada** de $v$, si $u$ permanece constante a lo largo del flujo $\phi$. Es decir
$$
u(\phi(x,t)) = u(x) \qquad \forall \, t\in\mathbb R.
$$
Si $u$ es adem谩s diferenciable esto equivale a la ecuaci贸n parcial lineal de primer orden
$$
v \cdot Du = 0.
(\#eq:eq1)
$$

Por un lado, conocer una cantidad conservada $u$ nos ayuda a resolver las EDOs $x'=v(x)$, dado que las trayectorias permanecen en los conjuntos de nivel de $u$. Por otro lado, la EDO asociada a la EDP \@ref(eq:eq1) se conoce como la **ecuaci贸n caracter铆stica** y nos ayudan a calcular la soluci贸n de la EDP dado que $u$ debe permanecer constante a lo largo de estas trayectorias.

---

:::{.example}
Dado un vector constante $v = (v_1,\ldots,v_n)\in \mathbb R$, consideremos el problema
$$
v\cdot Du = 0.
$$
Este tiene asociada la ecuaci贸n caracter铆stica $x'=v$ (es decir el sistema $x_i'=v_i$) cuya soluci贸n es $x(t)=x_0+tv$. Dada que cualquier soluci贸n de la EDP debe permanecer constante a lo largo de esta trayectoria tenemos que
$$
u(x_0+tv) = u(x_0).
$$
Si $u$ estuviese predeterminada en una regi贸n $F\subseteq \mathbb R^n$ dada como la funci贸n $u_0$, entonces es conveniente tomar la posici贸n inicial $x_0$ en dicha regi贸n. Por ejemplo, si $F = \{x_1=0\}$ y $v=(v_1,\ldots,v_n)$ no es paralelo a $F$, es decir $v_1\neq0$, entonces podemos conectar cualquier punto $x=(x_1,\ldots,x_n)\in\mathbb R^n$ con alg煤n punto $x_0=(0,x_{0,2},\ldots,x_{0,n})\in F$ tal que $x_0+tv = x$ y por lo tanto $u(x) = u_0(x_0)$. En este caso particular podemos simplemente calcular $x_0$ y $t$ y obtener una f贸rmula expl铆cita para la soluci贸n
$$
\begin{aligned}
tv_1 = x_1 \qquad&\Rightarrow\qquad t=x_1/v_1,\\
x_{0,i} + tv_i = x_i \text{ si } i\geq 2 \qquad&\Rightarrow\qquad x_{0,i} = x_i - x_1v_i/v_1,\\ 
u(x) = u_0(x_0) \qquad&\Rightarrow\qquad u(x) = u_0(0,x_2 - x_1v_2/v_1,\ldots,x_n - x_1v_n/v_1)
\end{aligned}
$$
:::

---

:::{.exercise}
Calcula $u:\mathbb R^2\to \mathbb R$ tal que
$$
\begin{cases}
y\partial_x u = x\partial_y u \text{ en } \mathbb R^2\setminus\{y=0,x\geq 0\},\\
u = u_0 \text{ en } \{y=0,x\geq 0\}.
\end{cases}
$$
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.exercise}
Explica como se podr铆a extender la teor铆a al problema de Cauchy donde $u:\mathbb R^n\times[0,\infty)\to \mathbb R$ depende de una variable espacial $x\in\mathbb R^n$ y una temporal $t\in[0,\infty)$ y satisface en cambio el problema de valores iniciales
$$
\begin{cases}
\partial_t u + v\cdot Du = 0 \text{ en } \mathbb R^n,\\
u = u_0 \text{ en } \{t= 0\}
\end{cases}
$$
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.example}
**Ley de conservaci贸n de la energ铆a**

Un sistema mec谩nico se dice **conservativo** si la fuerza es menos el gradiente un potencial $U$
$$
mv' = -DU(x), \qquad v=x'.
$$
La energ铆a del sistema es la suma de la cin茅tica y potencial
$$
E(x,v) = \frac{1}{2}m|v|^2 + U(x).
$$
La **ley de la conservaci贸n de la energ铆a** dice que la energ铆a total es constante. Comprob茅moslo calculando la derivada temporal de $E$.
$$
\frac{d}{dt}E(x(t),v(t)) = x'\partial_x E + v'\partial_v E=v\cdot DU + \frac{(-DU)}{m}\cdot m v = 0.
$$
Dicho de otra forma, la energ铆a total satisface la ecuaci贸n $(v,-DU/m)\cdot DE=0$.
:::

---

:::{.exercise}
Considera el sistema mec谩nico de fuerzas centrales,
$$
mx'' = f(|x|)x.
$$
Demuestra que el momento angular $L_{ij} = x_ix_j'-x_jx_i'$ es una cantidad conservada del sistema.
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

:::{.example}
Consideremos el sistema de ecuaciones
$$
x' = f(x,y),\qquad
y' = g(x,y).
$$
La trayectoria del sistema consiste del lugar geom茅trico trazado por la soluci贸n. La ecuaci贸n se dice **exacta** si las trayectorias son el conjunto de nivel de una funci贸n $u$, equivalentemente el campo $(f,g)$ debe ser perpendicular a $(\partial_xu,\partial_y u)$. Esto sucede en particular si $(f,g) = (-\partial_y u,\partial_x u)$ lo cual implica $\operatorname{div}((f,g))= \partial_x f+\partial_y g=0$. Esta hip贸tesis no solamente es necesaria, si no tambi茅n suficiente para encontrar $u$ tal que
$$
g(x,y) = \partial_x u \quad \text{y} \quad -f(x,y) = \partial_y u.
$$

Veamos que efectivamente $u$ es constante a lo largo de las trayectorias
$$
\frac{d}{dt}u(x(t),y(t)) = x'\partial_xu + y'\partial_yu = f(x,y)g(x,y) - g(x,y)f(x,y) = 0.
$$
:::

---

:::{.example}
Un funci贸n $f = (u(x,y),v(x,y)):\mathbb{C}\to\mathbb{C}$ es **holomorfa** si satisface las **ecuaciones de Cauchy-Riemann**
$$
\partial_x u = \partial_y v, \qquad \partial_y u = - \partial_x v.
$$
Estas implican que $u$ y $v$ son funciones arm贸nicas
$$
(\partial_x^2+\partial_y^2)u=(\partial_x^2+\partial_y^2)v=0,
$$
y adicionalmente sus conjuntos de nivel son ortogonales entre si. Sus gradientes son exactamente rotaciones de 90 grados uno del otro.

Dada una funci贸n arm贸nica $u:\mathbb{C}\to\mathbb R$, es posible construir una funci贸n arm贸nica $v$ tal que $Dv = (-\partial_y u,\partial_x u)$. Estas se conocen como los conjugados arm贸nico de $u$. Cualesquiera dos conjugados de la misma funci贸n $u$ difieren por una constante.

Por ejemplo, tomemos la funci贸n arm贸nica $u(x,y) = x^2-y^2$. Debemos as铆 resolver $\partial_x v = 2y$ y $\partial_y v=2x$. De la primera ecuaci贸n obtenemos $v = 2xy+\varphi(y)$ y por lo tanto $2x=2x+C'(y)$ lo cual implica que $C$ es constante. Conclu铆mos as铆 que $v(x,y) = 2xy+C$ es el conjungado arm贸nico de $u$.
:::

---

:::{.exercise}
Calcula el conjugado arm贸nico de las siguientes funciones:

- $u(x,y) = x^3-3xy^2$,

- $u(x,y) = e^{x}\cos y$,

- $u(x,y) = \ln(x^2+y^2)$.
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

En general, dado un campo vectorial $v$, la derivada
$$
D_vu = \partial_tu+ v \cdot Du
$$
se conoce como la **derivada material** de $u$ y describe la tasa de cambio de $u$ a lo largo de las trayectorias generadas por $v$.

## Problemas no-homog茅neos

Puede darse tambi茅n el caso de que la funci贸n $u$ no sea necesariamente constante a lo largo de las trayectorias de la EDO $x'=v(x)$, pero que sin embargo sus variaciones sean conocidas en funci贸n de la posici贸n en la trayectoria.

---

:::{.example}
Si $u(x_0)$ denota el tiempo que tarda la trayectoria que parte de la posici贸n inicial $x_0$ en llegar a un dado conjunto $F$, entonces a lo largo de una soluci贸n $z(t) := u(x(t))$ tiene derivada igual a $-1$. Es decir que satisface la ecuaci贸n no-homog茅nea
$$
v\cdot Du = -1.
$$
:::

---

En general podemos aplicar un razonamiento similar a la ecuaci贸n no-homog茅nea
$$
v\cdot Du = f(x).
(\#eq:eq2)
$$
La ecuaci贸n caracter铆stica de \@ref(eq:eq2) sigue siendo $x'=v(x)$, sin embargo $z(t) = u(x(t))$ ahora no es constante a lo largo de una curva caracter铆stica. En cambio $z$ satisface $z'=f(x)$. Podemos decir as铆 que las ecuaciones caracter铆sticas est谩n dadas en verdad por un sistema d茅bilmente acoplado
$$
\begin{cases}
x'= v(x),\\
z' = f(x).
\end{cases}
$$

Se dice que es d茅bilmente acoplado porque por lo menos la ecuaci贸n $x'=v(x)$ es independiente de $z$. Para resolver el sistema uno puede comenzar resolviendo el problema para $x$ y luego substituir este resultado en la ecuaci贸n para $z$ la cual se puede resolver por medio de una integraci贸n
$$
z(t) = z_0 + \int_{0}^t f(x(s))ds.
$$

---

:::{.exercise}
Calcula el tiempo que se toma la curva $(x(t),y(t))$ que parte de $(x_0,y_0)$ en llegar a $F=\{y=0,x\geq0\}$ si esta se mueve seg煤n la ecuaci贸n diferencial
$$
x'=-y, \qquad y'=x.
$$
Usa esta informaci贸n para resolver
$$
y\partial_xu-x\partial_yu=1 \text{ en } \mathbb R^2\setminus F,\\
u=0 \text{ en } F
$$
驴Tiene sentido que $u$ sea discontinua en $F$?
:::

<details>
<summary>Soluci贸n</summary>
</details>

## Problemas semi-lineales

Generalizando la idea de las ecuaciones no-homog茅neas, puede darse el caso de que las variaciones de $z(t) = u(x(t))$ dependan de $x$ y tambi茅n de la misma $z=u(x)$. Por ejemplo, la ecuaci贸n $z'=-cz$ aparece cuando $z$ representa una ganancia descontada con taza $c$ que se obtiene cuando la trayectoria llega a una dada regi贸n $F$.

Consideremos la ecuaci贸n
$$
v\cdot Du = f(u,x).
$$
Se dice que es **semi-lineal** dado que el operador asociado a las derivadas de orden mayor (en este caso uno) es lineal y solamente depende de $x$, sin embargo el problema puede presentar combinaciones no-lineales en $u$ dadas por $f$.

Las ecuaciones caracter铆sticas vuelven a ser un sistema d茅bilmente acoplado dado por
$$
\begin{cases}
x'= v(x),\\
z' = f(z,x).
\end{cases}
$$
En este caso, tambi茅n se puede proceder resolviendo primero la ecuaci贸n para $x$ y sustituyendo el resultado en la ecuaci贸n para $z$. Sin embargo, el 煤ltimo paso requiere resolver una ecuaci贸n no-homog茅nea para $z$ y no simplemente calcular una integral.

---

:::{.exercise}
Dado el campo vectorial $v=(ax+by,cx+dy)$ en el plano, resuelve el problema de valores iniciales
$$
\begin{cases}
\partial_t u + \operatorname{div}(vu) =0 \text{ en }\mathbb R^2\times (0,\infty),\\
u=u_0 \text{ en } \{t=0\}
\end{cases}
$$
Demuestra que si $\int_{\mathbb R^2}u_0(x,y)dxdy<\infty$, entonces $m(t) = \int_{\mathbb R^2}u(x,y,t)dxdy$ permanece constante.
:::

<details>
<summary>Soluci贸n</summary>
</details>

## Problemas cuasi-lineales

Finalmente consideramos el caso donde el campo $v$ tambi茅n depende de $u$. Esto hace que la EDO y la EDP est茅n estrechamente acopladas.

---

:::{.example}
La ecuaci贸n de **Burgers** modela la ley de inercia de un flu铆do (incompresible y de densidad uniforme) con velocidad $u(x,t)$ en la posici贸n $x \in \mathbb R$ y en tiempo $t \in \mathbb R$. Para decir que el momento es una cantidad conservada a lo largo del flujo usamos que
$$
\partial_t u + u \partial_x u =0.
$$
:::

---

En el caso general
$$
v(u,x)\cdot Du = f(u,x)
$$
decimos que la ecuaci贸n es **cuasi-lineal**. Esto quiere decir que el operador asociado a las derivadas de orden mayor es lineal, pero puede depender en este caso de $u$. Como es de esperarse la ecuaci贸n caracter铆stica es ahora un sistema fuertemente acoplado
$$
\begin{cases}
x'= v(z,x),\\
z'=f(z,x).
\end{cases}
$$

---

:::{.exercise}
驴Qu茅 relaci贸n guarda la ecuaci贸n de Burgers (EDP: $\partial_t u + u \partial_x u =f$) con la ley de Newton (EDO: $x'' = f$)?
:::

<details>
<summary>Soluci贸n</summary>
</details>

---

En los casos de las ecuaciones semi-lineales encontramos que las curvas caracter铆sticas que se corresponden a la ecuaci贸n $x'=v(x)$ fibran el dominio, es decir lo cubren de forma disjunta bajo hip贸tesis regularidad y crecimiento para el campo vectorial.

El caso de las ecuaciones caracter铆sticas para problemas estrictamente cuasi-lineales, es decir de la forma
$$
\begin{cases}
x'= v(z,x),\\
z'=f(z,x),
\end{cases}
$$
es radicalmente distinto. El teorema de unicidad garantiza que las trayectorias son disjuntas, ***pero en el sistema de coordenadas $(x,z)$***, las proyecciones en el hiper-plano de las $x$'s ***puede tener intersecciones***. Esto implica que las soluciones de la EDP pasan a ser funciones multi-valuadas. En la pr谩ctica decimos que las soluciones est谩n definidas hasta el primer momento en que ocurre una colisi贸n en las caracter铆sticas.

---

:::{.exercise}
Encuentra el valor m谩s grande posible para $T$ tal que el siguiente problema de valores iniciales tiene soluci贸n en el intervalo $[0,T)$
$$
\begin{cases}
\partial_tu + u\partial_x u = -\sin x \text{ en } \mathbb R\times(0,T)\\
u=0 \text{ en } \{t=0\}
\end{cases}
$$
:::

<details>
<summary>Soluci贸n</summary>
</details>

<!--chapter:end:08-contidades_conservadas.Rmd-->

